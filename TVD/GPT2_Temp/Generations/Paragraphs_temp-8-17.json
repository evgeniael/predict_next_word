{"8": {"2": {"context": {"text": "The", "log_prob": -7.689905643463135}, "original": {"pred": "human", "cond_log_prob": -7.711894512176514}, "human": [{"pred": "dog", "cond_log_prob": -8.66474723815918, "count": 7}, {"pred": "first", "cond_log_prob": -4.53168249130249, "count": 4}, {"pred": "day", "cond_log_prob": -6.455907344818115, "count": 3}, {"pred": "cat", "cond_log_prob": -9.208684921264648, "count": 2}, {"pred": "end", "cond_log_prob": -7.269872188568115, "count": 2}, {"pred": "next", "cond_log_prob": -6.237706661224365, "count": 2}, {"pred": "pig", "cond_log_prob": -11.021047592163086, "count": 2}, {"pred": "apple", "cond_log_prob": -10.673063278198242, "count": 1}, {"pred": "barber", "cond_log_prob": -12.028100967407227, "count": 1}, {"pred": "bear", "cond_log_prob": -10.242208480834961, "count": 1}, {"pred": "best", "cond_log_prob": -5.81421422958374, "count": 1}, {"pred": "big", "cond_log_prob": -7.29749059677124, "count": 1}, {"pred": "boy", "cond_log_prob": -8.478437423706055, "count": 1}, {"pred": "elephant", "cond_log_prob": -9.535009384155273, "count": 1}, {"pred": "experiment", "cond_log_prob": -10.249006271362305, "count": 1}, {"pred": "house", "cond_log_prob": -7.798146724700928, "count": 1}, {"pred": "idea", "cond_log_prob": -6.792508602142334, "count": 1}, {"pred": "man", "cond_log_prob": -6.1509833335876465, "count": 1}, {"pred": "old", "cond_log_prob": -7.51422643661499, "count": 1}, {"pred": "only", "cond_log_prob": -6.0167670249938965, "count": 1}, {"pred": "pelican", "cond_log_prob": -12.629392623901367, "count": 1}, {"pred": "people", "cond_log_prob": -6.9892401695251465, "count": 2}, {"pred": "person", "cond_log_prob": -7.67969274520874, "count": 1}, {"pred": "point", "cond_log_prob": -8.503606796264648, "count": 1}, {"pred": "quick", "cond_log_prob": -9.478429794311523, "count": 1}, {"pred": "study", "cond_log_prob": -7.6412482261657715, "count": 1}, {"pred": "turtle", "cond_log_prob": -10.92902946472168, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -6.9898505210876465}, {"pred": "F", "count": 1, "cond_log_prob": -6.597074031829834}, {"pred": "Failed to generate word", "count": 4, "cond_log_prob": -36.48844909667969}, {"pred": "I", "count": 2, "cond_log_prob": -7.5438055992126465}, {"pred": "IRS", "count": 1, "cond_log_prob": -8.284002304077148}, {"pred": "Larkspur", "count": 1, "cond_log_prob": -13.747900009155273}, {"pred": "Nordic", "count": 1, "cond_log_prob": -9.953557968139648}, {"pred": "Ploughshares", "count": 1, "cond_log_prob": -14.429342269897461}, {"pred": "TMobile", "count": 1, "cond_log_prob": -15.690446853637695}, {"pred": "We", "count": 1, "cond_log_prob": -8.953908920288086}, {"pred": "a", "count": 1, "cond_log_prob": -7.9853034019470215}, {"pred": "a1v2", "count": 1, "cond_log_prob": -20.82883644104004}, {"pred": "aethers", "count": 1, "cond_log_prob": -14.315286636352539}, {"pred": "apertures", "count": 1, "cond_log_prob": -13.123003005981445}, {"pred": "apron", "count": 1, "cond_log_prob": -11.776723861694336}, {"pred": "community", "count": 1, "cond_log_prob": -8.186544418334961}, {"pred": "company", "count": 1, "cond_log_prob": -6.4325690269470215}, {"pred": "day", "count": 1, "cond_log_prob": -6.455907344818115}, {"pred": "first", "count": 2, "cond_log_prob": -4.53168249130249}, {"pred": "great", "count": 1, "cond_log_prob": -7.38867712020874}, {"pred": "ingame", "count": 1, "cond_log_prob": -13.638788223266602}, {"pred": "is", "count": 1, "cond_log_prob": -9.861265182495117}, {"pred": "last", "count": 1, "cond_log_prob": -5.925389766693115}, {"pred": "most", "count": 1, "cond_log_prob": -5.333486080169678}, {"pred": "new", "count": 1, "cond_log_prob": -5.301427364349365}, {"pred": "one", "count": 1, "cond_log_prob": -7.130589962005615}, {"pred": "only", "count": 1, "cond_log_prob": -6.0167670249938965}, {"pred": "other", "count": 1, "cond_log_prob": -6.929601192474365}, {"pred": "people", "count": 1, "cond_log_prob": -6.9892401695251465}, {"pred": "proKremlin", "count": 1, "cond_log_prob": -25.596208572387695}, {"pred": "route", "count": 1, "cond_log_prob": -9.335737228393555}, {"pred": "them", "count": 1, "cond_log_prob": -11.993680953979492}, {"pred": "themes", "count": 1, "cond_log_prob": -11.727224349975586}, {"pred": "theorems", "count": 1, "cond_log_prob": -13.367719650268555}, {"pred": "wellbeing", "count": 1, "cond_log_prob": -12.700643539428711}]}, "3": {"context": {"text": "The human", "log_prob": -15.401800155639648}, "original": {"pred": "body", "cond_log_prob": -1.5726947784423828}, "human": [{"pred": "body", "cond_log_prob": -1.5727062225341797, "count": 8}, {"pred": "being", "cond_log_prob": -5.81519889831543, "count": 6}, {"pred": "mind", "cond_log_prob": -4.514127731323242, "count": 6}, {"pred": "beings", "cond_log_prob": -5.49806022644043, "count": 3}, {"pred": "brain", "cond_log_prob": -2.4502086639404297, "count": 2}, {"pred": "is", "cond_log_prob": -6.816732406616211, "count": 2}, {"pred": "that", "cond_log_prob": -8.651609420776367, "count": 2}, {"pred": "will", "cond_log_prob": -7.128782272338867, "count": 2}, {"pred": "and", "cond_log_prob": -5.161954879760742, "count": 1}, {"pred": "eats", "cond_log_prob": -11.391447067260742, "count": 1}, {"pred": "experiment", "cond_log_prob": -7.290952682495117, "count": 1}, {"pred": "gene", "cond_log_prob": -6.00056266784668, "count": 1}, {"pred": "genome", "cond_log_prob": -3.126066207885742, "count": 1}, {"pred": "nature", "cond_log_prob": -7.018499374389648, "count": 1}, {"pred": "predicament", "cond_log_prob": -9.96504020690918, "count": 1}, {"pred": "reaction", "cond_log_prob": -7.476369857788086, "count": 1}, {"pred": "species", "cond_log_prob": -4.98335075378418, "count": 1}, {"pred": "tampered", "cond_log_prob": -15.210771560668945, "count": 1}, {"pred": "walked", "cond_log_prob": -11.495450973510742, "count": 1}, {"pred": "was", "cond_log_prob": -7.956235885620117, "count": 1}], "ancestral_samples": [{"pred": "body", "count": 28, "cond_log_prob": -1.5727062225341797}, {"pred": "bodyroute", "count": 1, "cond_log_prob": -25.609350204467773}, {"pred": "brain", "count": 5, "cond_log_prob": -2.4502086639404297}, {"pred": "condition", "count": 1, "cond_log_prob": -4.813955307006836}, {"pred": "eye", "count": 1, "cond_log_prob": -4.04206657409668}, {"pred": "race", "count": 4, "cond_log_prob": -3.009916305541992}]}, "4": {"context": {"text": "The human body", "log_prob": -16.97449493408203}, "original": {"pred": "can", "cond_log_prob": -3.7048072814941406}, "human": [{"pred": "is", "cond_log_prob": -0.9780158996582031, "count": 36}, {"pred": "has", "cond_log_prob": -2.5084495544433594, "count": 3}, {"pred": "parts", "cond_log_prob": -8.657306671142578, "count": 2}, {"pred": "makes", "cond_log_prob": -5.805362701416016, "count": 1}, {"pred": "works", "cond_log_prob": -5.688716888427734, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -11.236270904541016}, {"pred": "is", "count": 37, "cond_log_prob": -0.9780158996582031}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.83847427368164}, {"pred": "was", "count": 1, "cond_log_prob": -4.441761016845703}]}, "5": {"context": {"text": "The human body can", "log_prob": -20.679302215576172}, "original": {"pred": "tolerate", "cond_log_prob": -5.481683731079102}, "human": [{"pred": "do", "cond_log_prob": -4.6847381591796875, "count": 18}, {"pred": "be", "cond_log_prob": -1.5766220092773438, "count": 3}, {"pred": "heal", "cond_log_prob": -5.917747497558594, "count": 3}, {"pred": "withstand", "cond_log_prob": -4.4776763916015625, "count": 3}, {"pred": "take", "cond_log_prob": -4.0782470703125, "count": 2}, {"pred": "contain", "cond_log_prob": -4.619895935058594, "count": 1}, {"pred": "detect", "cond_log_prob": -5.532257080078125, "count": 1}, {"pred": "eat", "cond_log_prob": -7.5515899658203125, "count": 1}, {"pred": "fight", "cond_log_prob": -6.242095947265625, "count": 1}, {"pred": "function", "cond_log_prob": -4.8703765869140625, "count": 1}, {"pred": "jump", "cond_log_prob": -9.035064697265625, "count": 1}, {"pred": "make", "cond_log_prob": -4.494781494140625, "count": 1}, {"pred": "perform", "cond_log_prob": -5.61492919921875, "count": 1}, {"pred": "produce", "cond_log_prob": -3.86529541015625, "count": 1}, {"pred": "pump", "cond_log_prob": -8.698165893554688, "count": 1}, {"pred": "repair", "cond_log_prob": -6.536369323730469, "count": 1}, {"pred": "run", "cond_log_prob": -7.0042724609375, "count": 1}, {"pred": "use", "cond_log_prob": -4.341316223144531, "count": 1}, {"pred": "walk", "cond_log_prob": -7.7475128173828125, "count": 1}], "ancestral_samples": [{"pred": "also", "count": 1, "cond_log_prob": -4.29974365234375}, {"pred": "be", "count": 32, "cond_log_prob": -1.5766220092773438}, {"pred": "generate", "count": 1, "cond_log_prob": -5.480743408203125}, {"pred": "only", "count": 1, "cond_log_prob": -3.316802978515625}, {"pred": "t", "count": 4, "cond_log_prob": -8.697013854980469}, {"pred": "troute", "count": 1, "cond_log_prob": -24.037399291992188}]}, "6": {"context": {"text": "The human body can tolerate", "log_prob": -26.160985946655273}, "original": {"pred": "only", "cond_log_prob": -4.059465408325195}, "human": [{"pred": "many", "cond_log_prob": -3.5127925872802734, "count": 11}, {"pred": "a", "cond_log_prob": -2.146810531616211, "count": 5}, {"pred": "extreme", "cond_log_prob": -4.637197494506836, "count": 4}, {"pred": "pain", "cond_log_prob": -4.188924789428711, "count": 4}, {"pred": "up", "cond_log_prob": -3.6966609954833984, "count": 4}, {"pred": "high", "cond_log_prob": -4.42359733581543, "count": 2}, {"pred": "large", "cond_log_prob": -5.913717269897461, "count": 2}, {"pred": "almost", "cond_log_prob": -4.804357528686523, "count": 1}, {"pred": "an", "cond_log_prob": -4.283224105834961, "count": 1}, {"pred": "huge", "cond_log_prob": -7.929464340209961, "count": 1}, {"pred": "immense", "cond_log_prob": -8.479787826538086, "count": 1}, {"pred": "incredible", "cond_log_prob": -8.444555282592773, "count": 1}, {"pred": "lots", "cond_log_prob": -6.872518539428711, "count": 1}, {"pred": "minimal", "cond_log_prob": -7.558416366577148, "count": 1}, {"pred": "more", "cond_log_prob": -3.8372859954833984, "count": 1}, {"pred": "most", "cond_log_prob": -5.229917526245117, "count": 1}, {"pred": "much", "cond_log_prob": -5.119649887084961, "count": 1}, {"pred": "quite", "cond_log_prob": -6.312688827514648, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -10.639837265014648}, {"pred": "a", "count": 25, "cond_log_prob": -2.146810531616211}, {"pred": "and", "count": 6, "cond_log_prob": -3.4319286346435547}, {"pred": "extreme", "count": 1, "cond_log_prob": -4.637197494506836}, {"pred": "many", "count": 1, "cond_log_prob": -3.5127925872802734}, {"pred": "manyroute", "count": 1, "cond_log_prob": -27.36330223083496}, {"pred": "pain", "count": 1, "cond_log_prob": -4.188924789428711}, {"pred": "some", "count": 1, "cond_log_prob": -4.328130722045898}, {"pred": "temperatures", "count": 1, "cond_log_prob": -3.9165706634521484}, {"pred": "the", "count": 2, "cond_log_prob": -3.3694210052490234}]}, "7": {"context": {"text": "The human body can tolerate only", "log_prob": -30.22045135498047}, "original": {"pred": "a", "cond_log_prob": -1.7925567626953125}, "human": [{"pred": "so", "cond_log_prob": -3.7043113708496094, "count": 15}, {"pred": "a", "cond_log_prob": -1.7926597595214844, "count": 8}, {"pred": "certain", "cond_log_prob": -4.858890533447266, "count": 5}, {"pred": "some", "cond_log_prob": -5.354351043701172, "count": 3}, {"pred": "what", "cond_log_prob": -5.237476348876953, "count": 2}, {"pred": "four", "cond_log_prob": -4.154033660888672, "count": 1}, {"pred": "high", "cond_log_prob": -5.434719085693359, "count": 1}, {"pred": "one", "cond_log_prob": -1.7807121276855469, "count": 1}, {"pred": "pain", "cond_log_prob": -7.443874359130859, "count": 1}, {"pred": "small", "cond_log_prob": -4.617397308349609, "count": 1}, {"pred": "sone", "cond_log_prob": -18.003963470458984, "count": 1}, {"pred": "that", "cond_log_prob": -6.227016448974609, "count": 1}, {"pred": "the", "cond_log_prob": -3.5671348571777344, "count": 1}, {"pred": "three", "cond_log_prob": -3.4973106384277344, "count": 1}, {"pred": "to", "cond_log_prob": -7.635196685791016, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 21, "cond_log_prob": -1.7926597595214844}, {"pred": "one", "count": 16, "cond_log_prob": -1.7807121276855469}, {"pred": "oneroute", "count": 1, "cond_log_prob": -24.906490325927734}, {"pred": "three", "count": 1, "cond_log_prob": -3.4973106384277344}, {"pred": "two", "count": 1, "cond_log_prob": -2.949268341064453}]}, "8": {"context": {"text": "The human body can tolerate only a", "log_prob": -32.01300811767578}, "original": {"pred": "small", "cond_log_prob": -1.8195838928222656}, "human": [{"pred": "small", "cond_log_prob": -1.8196754455566406, "count": 16}, {"pred": "certain", "cond_log_prob": -3.135822296142578, "count": 10}, {"pred": "little", "cond_log_prob": -3.847675323486328, "count": 6}, {"pred": "fraction", "cond_log_prob": -3.689617156982422, "count": 2}, {"pred": "limited", "cond_log_prob": -2.616619110107422, "count": 2}, {"pred": "a", "cond_log_prob": -8.90908432006836, "count": 1}, {"pred": "day", "cond_log_prob": -8.893192291259766, "count": 1}, {"pred": "few", "cond_log_prob": -1.9354972839355469, "count": 1}, {"pred": "new", "cond_log_prob": -9.258922576904297, "count": 1}, {"pred": "specific", "cond_log_prob": -6.477443695068359, "count": 1}, {"pred": "substantial", "cond_log_prob": -8.25960922241211, "count": 1}, {"pred": "tiny", "cond_log_prob": -2.761425018310547, "count": 1}], "ancestral_samples": [{"pred": "few", "count": 17, "cond_log_prob": -1.9354972839355469}, {"pred": "partial", "count": 1, "cond_log_prob": -5.429241180419922}, {"pred": "single", "count": 1, "cond_log_prob": -3.2024497985839844}, {"pred": "small", "count": 13, "cond_log_prob": -1.8196754455566406}, {"pred": "smallroute", "count": 1, "cond_log_prob": -26.762142181396484}, {"pred": "tiny", "count": 2, "cond_log_prob": -2.761425018310547}, {"pred": "very", "count": 5, "cond_log_prob": -2.7698097229003906}]}, "9": {"context": {"text": "The human body can tolerate only a small", "log_prob": -33.83259201049805}, "original": {"pred": "range", "cond_log_prob": -4.867992401123047}, "human": [{"pred": "amount", "cond_log_prob": -0.6426010131835938, "count": 38}, {"pred": "degree", "cond_log_prob": -3.4516830444335938, "count": 2}, {"pred": "number", "cond_log_prob": -2.6743087768554688, "count": 1}, {"pred": "portion", "cond_log_prob": -3.20086669921875, "count": 1}, {"pred": "threshold", "cond_log_prob": -7.979164123535156, "count": 1}], "ancestral_samples": [{"pred": "amount", "count": 37, "cond_log_prob": -0.6426010131835938}, {"pred": "amountroute", "count": 1, "cond_log_prob": -27.7193603515625}, {"pred": "percentage", "count": 1, "cond_log_prob": -3.0261917114257812}, {"pred": "proportion", "count": 1, "cond_log_prob": -3.8854751586914062}]}, "10": {"context": {"text": "The human body can tolerate only a small range", "log_prob": -38.700584411621094}, "original": {"pred": "of", "cond_log_prob": -0.0333709716796875}, "human": [{"pred": "of", "cond_log_prob": -0.0334320068359375, "count": 43}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -13.079174041748047}, {"pred": "of", "count": 38, "cond_log_prob": -0.033538818359375}, {"pred": "ofroute", "count": 1, "cond_log_prob": -24.5032958984375}]}, "11": {"context": {"text": "The human body can tolerate only a small range of", "log_prob": -38.73395538330078}, "original": {"pred": "temperature,", "cond_log_prob": -5.021068572998047}, "human": [{"pred": "pain", "cond_log_prob": -4.82891845703125, "count": 13}, {"pred": "stress", "cond_log_prob": -3.94586181640625, "count": 3}, {"pred": "temperature", "cond_log_prob": -2.179290771484375, "count": 3}, {"pred": "temperatures", "cond_log_prob": -1.4980010986328125, "count": 3}, {"pred": "motion", "cond_log_prob": -5.7124176025390625, "count": 2}, {"pred": "a", "cond_log_prob": -7.702934265136719, "count": 1}, {"pred": "activity", "cond_log_prob": -6.681480407714844, "count": 1}, {"pred": "adverse", "cond_log_prob": -8.234909057617188, "count": 1}, {"pred": "emotion", "cond_log_prob": -9.589645385742188, "count": 1}, {"pred": "emotions", "cond_log_prob": -6.086326599121094, "count": 1}, {"pred": "exposure", "cond_log_prob": -6.350273132324219, "count": 1}, {"pred": "heat", "cond_log_prob": -4.27099609375, "count": 1}, {"pred": "levels", "cond_log_prob": -4.1262664794921875, "count": 1}, {"pred": "pains", "cond_log_prob": -9.934356689453125, "count": 1}, {"pred": "smells", "cond_log_prob": -7.884498596191406, "count": 1}, {"pred": "sound", "cond_log_prob": -9.387557983398438, "count": 1}, {"pred": "sounds", "cond_log_prob": -8.467597961425781, "count": 1}, {"pred": "stimuli", "cond_log_prob": -4.089447021484375, "count": 1}, {"pred": "things", "cond_log_prob": -6.767547607421875, "count": 1}, {"pred": "toxins", "cond_log_prob": -6.183860778808594, "count": 1}, {"pred": "tramas", "cond_log_prob": -22.194793701171875, "count": 1}, {"pred": "vicodin", "cond_log_prob": -13.945457458496094, "count": 1}, {"pred": "weight", "cond_log_prob": -6.6338348388671875, "count": 1}, {"pred": "what", "cond_log_prob": -8.698883056640625, "count": 1}], "ancestral_samples": [{"pred": "excitatory", "count": 1, "cond_log_prob": -8.195732116699219}, {"pred": "frequencies", "count": 1, "cond_log_prob": -5.455345153808594}, {"pred": "temperature", "count": 11, "cond_log_prob": -2.179290771484375}, {"pred": "temperatures", "count": 26, "cond_log_prob": -1.4980010986328125}, {"pred": "temperaturesroute", "count": 1, "cond_log_prob": -27.456329345703125}]}, "12": {"context": {"text": "The human body can tolerate only a small range of temperature,", "log_prob": -43.75502395629883}, "original": {"pred": "especially", "cond_log_prob": -5.527397155761719}, "human": [{"pred": "and", "cond_log_prob": -2.1446800231933594, "count": 7}, {"pred": "before", "cond_log_prob": -8.04452133178711, "count": 3}, {"pred": "from", "cond_log_prob": -4.241191864013672, "count": 3}, {"pred": "because", "cond_log_prob": -6.853893280029297, "count": 2}, {"pred": "pain", "cond_log_prob": -8.689334869384766, "count": 2}, {"pred": "a", "cond_log_prob": -4.594928741455078, "count": 1}, {"pred": "although", "cond_log_prob": -5.364971160888672, "count": 1}, {"pred": "any", "cond_log_prob": -8.223278045654297, "count": 1}, {"pred": "but", "cond_log_prob": -2.8583335876464844, "count": 1}, {"pred": "causing", "cond_log_prob": -7.544361114501953, "count": 1}, {"pred": "changes", "cond_log_prob": -8.753902435302734, "count": 1}, {"pred": "even", "cond_log_prob": -4.443294525146484, "count": 1}, {"pred": "if", "cond_log_prob": -7.345996856689453, "count": 1}, {"pred": "including", "cond_log_prob": -4.432262420654297, "count": 1}, {"pred": "it", "cond_log_prob": -6.139675140380859, "count": 1}, {"pred": "not", "cond_log_prob": -6.050769805908203, "count": 1}, {"pred": "only", "cond_log_prob": -6.772289276123047, "count": 1}, {"pred": "or", "cond_log_prob": -5.340267181396484, "count": 1}, {"pred": "pressure", "cond_log_prob": -4.101879119873047, "count": 1}, {"pred": "ranging", "cond_log_prob": -4.832256317138672, "count": 1}, {"pred": "sound", "cond_log_prob": -6.244136810302734, "count": 1}, {"pred": "starting", "cond_log_prob": -8.820720672607422, "count": 1}, {"pred": "that", "cond_log_prob": -6.218799591064453, "count": 1}, {"pred": "this", "cond_log_prob": -7.389873504638672, "count": 2}, {"pred": "thus", "cond_log_prob": -5.907649993896484, "count": 1}, {"pred": "too", "cond_log_prob": -7.851108551025391, "count": 1}, {"pred": "until", "cond_log_prob": -8.868785858154297, "count": 1}, {"pred": "varying", "cond_log_prob": -7.283008575439453, "count": 1}, {"pred": "weather", "cond_log_prob": -7.602855682373047, "count": 1}, {"pred": "which", "cond_log_prob": -3.511699676513672, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.594928741455078}, {"pred": "and", "count": 29, "cond_log_prob": -2.1446800231933594}, {"pred": "androute", "count": 1, "cond_log_prob": -25.720760345458984}, {"pred": "but", "count": 3, "cond_log_prob": -2.8583335876464844}, {"pred": "so", "count": 4, "cond_log_prob": -2.9585838317871094}, {"pred": "which", "count": 1, "cond_log_prob": -3.511699676513672}, {"pred": "with", "count": 1, "cond_log_prob": -3.073406219482422}]}, "13": {"context": {"text": "The human body can tolerate only a small range of temperature, especially", "log_prob": -49.28242111206055}, "original": {"pred": "when", "cond_log_prob": -1.4873809814453125}, "human": [{"pred": "when", "cond_log_prob": -1.4875602722167969, "count": 15}, {"pred": "in", "cond_log_prob": -1.9506950378417969, "count": 7}, {"pred": "cold", "cond_log_prob": -5.219730377197266, "count": 5}, {"pred": "during", "cond_log_prob": -2.9503135681152344, "count": 4}, {"pred": "if", "cond_log_prob": -3.293048858642578, "count": 4}, {"pred": "heat", "cond_log_prob": -6.650379180908203, "count": 3}, {"pred": "a", "cond_log_prob": -4.814250946044922, "count": 1}, {"pred": "below", "cond_log_prob": -5.358516693115234, "count": 1}, {"pred": "high", "cond_log_prob": -4.122409820556641, "count": 1}, {"pred": "within", "cond_log_prob": -4.592578887939453, "count": 1}, {"pred": "young", "cond_log_prob": -9.634281158447266, "count": 1}], "ancestral_samples": [{"pred": "at", "count": 1, "cond_log_prob": -2.95819091796875}, {"pred": "during", "count": 1, "cond_log_prob": -2.9503173828125}, {"pred": "for", "count": 1, "cond_log_prob": -3.1458663940429688}, {"pred": "in", "count": 13, "cond_log_prob": -1.950714111328125}, {"pred": "the", "count": 1, "cond_log_prob": -3.872161865234375}, {"pred": "when", "count": 21, "cond_log_prob": -1.4875946044921875}, {"pred": "whenroute", "count": 1, "cond_log_prob": -27.624897003173828}, {"pred": "with", "count": 1, "cond_log_prob": -4.075469970703125}]}, "14": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when", "log_prob": -50.76980209350586}, "original": {"pred": "the", "cond_log_prob": -2.629566192626953}, "human": [{"pred": "it", "cond_log_prob": -1.7738723754882812, "count": 14}, {"pred": "the", "cond_log_prob": -2.6296463012695312, "count": 13}, {"pred": "exposed", "cond_log_prob": -3.2694473266601562, "count": 2}, {"pred": "an", "cond_log_prob": -6.327766418457031, "count": 1}, {"pred": "dehydrated", "cond_log_prob": -7.015754699707031, "count": 1}, {"pred": "extreme", "cond_log_prob": -7.159950256347656, "count": 1}, {"pred": "faced", "cond_log_prob": -5.6597442626953125, "count": 1}, {"pred": "facing", "cond_log_prob": -6.364219665527344, "count": 1}, {"pred": "humans", "cond_log_prob": -7.190315246582031, "count": 1}, {"pred": "i", "cond_log_prob": -10.865898132324219, "count": 1}, {"pred": "ill", "cond_log_prob": -9.928749084472656, "count": 1}, {"pred": "in", "cond_log_prob": -4.668830871582031, "count": 1}, {"pred": "put", "cond_log_prob": -7.598060607910156, "count": 1}, {"pred": "regarding", "cond_log_prob": -12.654380798339844, "count": 1}, {"pred": "temperature", "cond_log_prob": -4.792015075683594, "count": 1}, {"pred": "they", "cond_log_prob": -5.143402099609375, "count": 1}, {"pred": "you", "cond_log_prob": -5.200111389160156, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.876075744628906}, {"pred": "compared", "count": 2, "cond_log_prob": -2.8333740234375}, {"pred": "it", "count": 25, "cond_log_prob": -1.7738723754882812}, {"pred": "itroute", "count": 1, "cond_log_prob": -29.704273223876953}, {"pred": "its", "count": 1, "cond_log_prob": -4.615226745605469}, {"pred": "temperatures", "count": 1, "cond_log_prob": -3.7984237670898438}, {"pred": "the", "count": 8, "cond_log_prob": -2.6296463012695312}, {"pred": "there", "count": 1, "cond_log_prob": -3.5438613891601562}]}, "15": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the", "log_prob": -53.39936828613281}, "original": {"pred": "person", "cond_log_prob": -5.127861022949219}, "human": [{"pred": "body", "cond_log_prob": -1.0484886169433594, "count": 17}, {"pred": "temperature", "cond_log_prob": -1.8330650329589844, "count": 9}, {"pred": "outside", "cond_log_prob": -7.300807952880859, "count": 2}, {"pred": "person", "cond_log_prob": -5.127948760986328, "count": 2}, {"pred": "weather", "cond_log_prob": -6.703823089599609, "count": 2}, {"pred": "blood", "cond_log_prob": -5.624797821044922, "count": 1}, {"pred": "climate", "cond_log_prob": -5.649623870849609, "count": 1}, {"pred": "environment", "cond_log_prob": -4.115047454833984, "count": 1}, {"pred": "first", "cond_log_prob": -7.816768646240234, "count": 1}, {"pred": "heat", "cond_log_prob": -4.526348114013672, "count": 1}, {"pred": "human", "cond_log_prob": -4.470226287841797, "count": 1}, {"pred": "legs", "cond_log_prob": -9.64468002319336, "count": 1}, {"pred": "range", "cond_log_prob": -6.047801971435547, "count": 1}, {"pred": "temperatures", "cond_log_prob": -4.689250946044922, "count": 2}, {"pred": "the", "cond_log_prob": -8.988292694091797, "count": 1}], "ancestral_samples": [{"pred": "body", "count": 23, "cond_log_prob": -1.0484886169433594}, {"pred": "skin", "count": 2, "cond_log_prob": -4.113002777099609}, {"pred": "temperature", "count": 14, "cond_log_prob": -1.8330650329589844}, {"pred": "temperatureroute", "count": 1, "cond_log_prob": -25.448211669921875}]}, "16": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person", "log_prob": -58.52722930908203}, "original": {"pred": "is", "cond_log_prob": -0.37749481201171875}, "human": [{"pred": "is", "cond_log_prob": -0.3775901794433594, "count": 38}, {"pred": "a", "cond_log_prob": -9.609489440917969, "count": 1}, {"pred": "does", "cond_log_prob": -5.331478118896484, "count": 1}, {"pred": "experiencing", "cond_log_prob": -7.095161437988281, "count": 1}, {"pred": "has", "cond_log_prob": -2.903118133544922, "count": 1}, {"pred": "starts", "cond_log_prob": -7.571479797363281, "count": 1}], "ancestral_samples": [{"pred": "is", "count": 39, "cond_log_prob": -0.3775901794433594}, {"pred": "isroute", "count": 1, "cond_log_prob": -26.825119018554688}]}, "17": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is", "log_prob": -58.90472412109375}, "original": {"pred": "engaged", "cond_log_prob": -5.8563385009765625}, "human": [{"pred": "sick", "cond_log_prob": -6.175537109375, "count": 7}, {"pred": "in", "cond_log_prob": -2.284923553466797, "count": 4}, {"pred": "young", "cond_log_prob": -3.6285743713378906, "count": 4}, {"pred": "a", "cond_log_prob": -4.358654022216797, "count": 3}, {"pred": "exposed", "cond_log_prob": -3.5313682556152344, "count": 4}, {"pred": "ill", "cond_log_prob": -6.23748779296875, "count": 3}, {"pred": "dehydrated", "cond_log_prob": -5.6134796142578125, "count": 2}, {"pred": "from", "cond_log_prob": -7.36297607421875, "count": 2}, {"pred": "not", "cond_log_prob": -4.168148040771484, "count": 2}, {"pred": "old", "cond_log_prob": -7.139068603515625, "count": 2}, {"pred": "small", "cond_log_prob": -5.93798828125, "count": 2}, {"pred": "fat", "cond_log_prob": -6.9651336669921875, "count": 1}, {"pred": "hot", "cond_log_prob": -4.900966644287109, "count": 1}, {"pred": "involved", "cond_log_prob": -7.742889404296875, "count": 1}, {"pred": "older", "cond_log_prob": -5.930084228515625, "count": 1}, {"pred": "sleeping", "cond_log_prob": -4.603511810302734, "count": 1}, {"pred": "underweight", "cond_log_prob": -8.68304443359375, "count": 1}, {"pred": "very", "cond_log_prob": -3.9470481872558594, "count": 1}, {"pred": "weak", "cond_log_prob": -6.938262939453125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -4.358654022216797}, {"pred": "already", "count": 1, "cond_log_prob": -5.2569732666015625}, {"pred": "at", "count": 1, "cond_log_prob": -3.792034149169922}, {"pred": "cold", "count": 1, "cond_log_prob": -3.4364051818847656}, {"pred": "coldThe", "count": 1, "cond_log_prob": -18.141151428222656}, {"pred": "confined", "count": 1, "cond_log_prob": -5.6274871826171875}, {"pred": "exposedroute", "count": 1, "cond_log_prob": -26.067100524902344}, {"pred": "in", "count": 20, "cond_log_prob": -2.284923553466797}, {"pred": "not", "count": 1, "cond_log_prob": -4.168148040771484}, {"pred": "on", "count": 3, "cond_log_prob": -3.846515655517578}, {"pred": "under", "count": 3, "cond_log_prob": -3.491535186767578}, {"pred": "very", "count": 2, "cond_log_prob": -3.9470481872558594}, {"pred": "warm", "count": 1, "cond_log_prob": -4.511440277099609}, {"pred": "wearing", "count": 1, "cond_log_prob": -4.042064666748047}, {"pred": "young", "count": 1, "cond_log_prob": -3.6285743713378906}]}, "18": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged", "log_prob": -64.76106262207031}, "original": {"pred": "in", "cond_log_prob": -0.02367401123046875}, "human": [{"pred": "in", "cond_log_prob": -0.02378082275390625, "count": 38}, {"pred": "to", "cond_log_prob": -7.021453857421875, "count": 3}, {"pred": "a", "cond_log_prob": -9.817100524902344, "count": 1}, {"pred": "physically", "cond_log_prob": -9.421241760253906, "count": 1}], "ancestral_samples": [{"pred": "in", "count": 39, "cond_log_prob": -0.02378082275390625}, {"pred": "inroute", "count": 1, "cond_log_prob": -23.312210083007812}]}, "19": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in", "log_prob": -64.78473663330078}, "original": {"pred": "vigorous", "cond_log_prob": -3.424224853515625}, "human": [{"pred": "physical", "cond_log_prob": -2.7658538818359375, "count": 18}, {"pred": "a", "cond_log_prob": -1.868377685546875, "count": 5}, {"pred": "activities", "cond_log_prob": -4.501678466796875, "count": 3}, {"pred": "extreme", "cond_log_prob": -4.564338684082031, "count": 3}, {"pred": "certain", "cond_log_prob": -5.6289215087890625, "count": 3}, {"pred": "strenuous", "cond_log_prob": -2.8027420043945312, "count": 2}, {"pred": "behavior", "cond_log_prob": -8.13818359375, "count": 1}, {"pred": "being", "cond_log_prob": -8.159011840820312, "count": 1}, {"pred": "especially", "cond_log_prob": -12.054702758789062, "count": 1}, {"pred": "exercise", "cond_log_prob": -3.47613525390625, "count": 1}, {"pred": "hot", "cond_log_prob": -6.960029602050781, "count": 1}, {"pred": "marriage", "cond_log_prob": -10.156692504882812, "count": 1}, {"pred": "rigorous", "cond_log_prob": -7.833343505859375, "count": 1}, {"pred": "the", "cond_log_prob": -4.175697326660156, "count": 1}, {"pred": "vigorous", "cond_log_prob": -3.4243392944335938, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 28, "cond_log_prob": -1.868377685546875}, {"pred": "an", "count": 1, "cond_log_prob": -3.1292953491210938}, {"pred": "exercise", "count": 3, "cond_log_prob": -3.47613525390625}, {"pred": "exerciseroute", "count": 1, "cond_log_prob": -29.1719970703125}, {"pred": "intense", "count": 1, "cond_log_prob": -4.299468994140625}, {"pred": "movementIn", "count": 1, "cond_log_prob": -21.850936889648438}, {"pred": "physical", "count": 1, "cond_log_prob": -2.7658538818359375}, {"pred": "some", "count": 1, "cond_log_prob": -4.466255187988281}, {"pred": "strenuous", "count": 2, "cond_log_prob": -2.8027420043945312}, {"pred": "vigorous", "count": 1, "cond_log_prob": -3.4243392944335938}]}, "20": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous", "log_prob": -68.2089614868164}, "original": {"pred": "activity.", "cond_log_prob": -2.6381149291992188}, "human": [{"pred": "physical", "cond_log_prob": -1.3122711181640625, "count": 12}, {"pred": "activity", "cond_log_prob": -1.9307861328125, "count": 12}, {"pred": "exercise", "cond_log_prob": -1.2441482543945312, "count": 8}, {"pred": "activities", "cond_log_prob": -3.4459228515625, "count": 7}, {"pred": "a", "cond_log_prob": -9.503890991210938, "count": 1}, {"pred": "experiences", "cond_log_prob": -12.212493896484375, "count": 1}, {"pred": "sex", "cond_log_prob": -6.24786376953125, "count": 1}, {"pred": "temperatures", "cond_log_prob": -11.1800537109375, "count": 1}], "ancestral_samples": [{"pred": "activity", "count": 2, "cond_log_prob": -1.9307861328125}, {"pred": "exercise", "count": 22, "cond_log_prob": -1.2441482543945312}, {"pred": "exerciseIn", "count": 1, "cond_log_prob": -16.757400512695312}, {"pred": "exerciseThe", "count": 4, "cond_log_prob": -14.559646606445312}, {"pred": "exerciseroute", "count": 1, "cond_log_prob": -29.020797729492188}, {"pred": "physical", "count": 10, "cond_log_prob": -1.3122711181640625}]}, "21": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity.", "log_prob": -70.84707641601562}, "original": {"pred": "Heat", "cond_log_prob": -5.412841796875}, "human": [{"pred": "the", "cond_log_prob": -9.307937622070312, "count": 9}, {"pred": "when", "cond_log_prob": -11.725296020507812, "count": 5}, {"pred": "this", "cond_log_prob": -11.917434692382812, "count": 7}, {"pred": "however", "cond_log_prob": -12.594314575195312, "count": 3}, {"pred": "it", "cond_log_prob": -11.538131713867188, "count": 4}, {"pred": "a", "cond_log_prob": -10.568984985351562, "count": 1}, {"pred": "additionally", "cond_log_prob": -19.432693481445312, "count": 1}, {"pred": "also", "cond_log_prob": -12.981979370117188, "count": 2}, {"pred": "average", "cond_log_prob": -17.718887329101562, "count": 1}, {"pred": "because", "cond_log_prob": -11.998291015625, "count": 1}, {"pred": "dehydration", "cond_log_prob": -19.539077758789062, "count": 1}, {"pred": "do", "cond_log_prob": -15.423980712890625, "count": 1}, {"pred": "fat", "cond_log_prob": -17.532730102539062, "count": 1}, {"pred": "heat", "cond_log_prob": -14.06085205078125, "count": 1}, {"pred": "if", "cond_log_prob": -11.635513305664062, "count": 1}, {"pred": "making", "cond_log_prob": -16.64312744140625, "count": 1}, {"pred": "our", "cond_log_prob": -14.450454711914062, "count": 1}, {"pred": "surprisingly", "cond_log_prob": -19.875900268554688, "count": 1}, {"pred": "that", "cond_log_prob": -11.7705078125, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 3, "cond_log_prob": -3.4637603759765625}, {"pred": "However", "count": 1, "cond_log_prob": -3.4789276123046875}, {"pred": "In", "count": 5, "cond_log_prob": -3.0177154541015625}, {"pred": "People", "count": 1, "cond_log_prob": -5.9020233154296875}, {"pred": "The", "count": 24, "cond_log_prob": -2.0698089599609375}, {"pred": "Therefore", "count": 3, "cond_log_prob": -3.9119720458984375}, {"pred": "Thus", "count": 1, "cond_log_prob": -4.5475311279296875}, {"pred": "When", "count": 1, "cond_log_prob": -3.9409637451171875}, {"pred": "route", "count": 1, "cond_log_prob": -22.024444580078125}]}, "22": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat", "log_prob": -76.25991821289062}, "original": {"pred": "reactions", "cond_log_prob": -8.690803527832031}, "human": [{"pred": "can", "cond_log_prob": -2.4095230102539062, "count": 14}, {"pred": "is", "cond_log_prob": -1.7538375854492188, "count": 12}, {"pred": "and", "cond_log_prob": -2.9061431884765625, "count": 4}, {"pred": "builds", "cond_log_prob": -6.1580352783203125, "count": 2}, {"pred": "has", "cond_log_prob": -4.9785919189453125, "count": 2}, {"pred": "a", "cond_log_prob": -7.0999755859375, "count": 1}, {"pred": "elevates", "cond_log_prob": -9.295700073242188, "count": 1}, {"pred": "exhaustion", "cond_log_prob": -4.571342468261719, "count": 1}, {"pred": "fluctuations", "cond_log_prob": -7.138893127441406, "count": 1}, {"pred": "reactions", "cond_log_prob": -8.690948486328125, "count": 1}, {"pred": "stroke", "cond_log_prob": -5.804130554199219, "count": 1}, {"pred": "strokes", "cond_log_prob": -9.550941467285156, "count": 1}, {"pred": "up", "cond_log_prob": -6.342620849609375, "count": 1}, {"pred": "will", "cond_log_prob": -4.72442626953125, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -10.478446960449219}, {"pred": "and", "count": 6, "cond_log_prob": -2.9061431884765625}, {"pred": "can", "count": 6, "cond_log_prob": -2.4095230102539062}, {"pred": "is", "count": 24, "cond_log_prob": -1.7538375854492188}, {"pred": "isroute", "count": 1, "cond_log_prob": -26.93669891357422}, {"pred": "sensitive", "count": 1, "cond_log_prob": -6.807342529296875}, {"pred": "transfer", "count": 1, "cond_log_prob": -5.565650939941406}]}, "23": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions", "log_prob": -84.95072174072266}, "original": {"pred": "usually", "cond_log_prob": -5.637168884277344}, "human": [{"pred": "are", "cond_log_prob": -2.0700454711914062, "count": 19}, {"pred": "can", "cond_log_prob": -2.1924514770507812, "count": 8}, {"pred": "in", "cond_log_prob": -2.7643051147460938, "count": 4}, {"pred": "cause", "cond_log_prob": -4.814353942871094, "count": 2}, {"pred": "occur", "cond_log_prob": -2.7480087280273438, "count": 2}, {"pred": "a", "cond_log_prob": -8.187248229980469, "count": 1}, {"pred": "by", "cond_log_prob": -5.398628234863281, "count": 1}, {"pred": "disrupt", "cond_log_prob": -7.667778015136719, "count": 1}, {"pred": "happen", "cond_log_prob": -6.811836242675781, "count": 1}, {"pred": "is", "cond_log_prob": -6.360496520996094, "count": 1}, {"pred": "such", "cond_log_prob": -4.279884338378906, "count": 1}, {"pred": "to", "cond_log_prob": -2.9448471069335938, "count": 1}, {"pred": "when", "cond_log_prob": -6.448646545410156, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -8.615974426269531}, {"pred": "are", "count": 17, "cond_log_prob": -2.0700454711914062}, {"pred": "can", "count": 11, "cond_log_prob": -2.1924514770507812}, {"pred": "in", "count": 6, "cond_log_prob": -2.7643051147460938}, {"pred": "occur", "count": 2, "cond_log_prob": -2.7480087280273438}, {"pred": "occurroute", "count": 1, "cond_log_prob": -28.111549377441406}, {"pred": "such", "count": 1, "cond_log_prob": -4.279884338378906}, {"pred": "that", "count": 1, "cond_log_prob": -3.4027175903320312}]}, "24": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually", "log_prob": -90.587890625}, "original": {"pred": "occur", "cond_log_prob": -0.753692626953125}, "human": [{"pred": "occur", "cond_log_prob": -0.75384521484375, "count": 9}, {"pred": "are", "cond_log_prob": -4.0030975341796875, "count": 7}, {"pred": "take", "cond_log_prob": -3.3515625, "count": 6}, {"pred": "cause", "cond_log_prob": -3.3911895751953125, "count": 3}, {"pred": "result", "cond_log_prob": -3.08868408203125, "count": 3}, {"pred": "happen", "cond_log_prob": -5.2604522705078125, "count": 2}, {"pred": "a", "cond_log_prob": -10.045730590820312, "count": 1}, {"pred": "activities", "cond_log_prob": -16.505325317382812, "count": 1}, {"pred": "affect", "cond_log_prob": -5.6922607421875, "count": 1}, {"pred": "causes", "cond_log_prob": -8.60577392578125, "count": 1}, {"pred": "conduct", "cond_log_prob": -10.004165649414062, "count": 1}, {"pred": "hurt", "cond_log_prob": -9.360565185546875, "count": 1}, {"pred": "increase", "cond_log_prob": -5.8481903076171875, "count": 1}, {"pred": "indicate", "cond_log_prob": -6.7906646728515625, "count": 1}, {"pred": "influence", "cond_log_prob": -9.12506103515625, "count": 1}, {"pred": "involve", "cond_log_prob": -3.6854400634765625, "count": 1}, {"pred": "leads", "cond_log_prob": -8.456466674804688, "count": 1}, {"pred": "range", "cond_log_prob": -6.5384674072265625, "count": 1}, {"pred": "show", "cond_log_prob": -6.3500823974609375, "count": 1}], "ancestral_samples": [{"pred": "are", "count": 1, "cond_log_prob": -4.0030975341796875}, {"pred": "begin", "count": 1, "cond_log_prob": -3.2537841796875}, {"pred": "involve", "count": 1, "cond_log_prob": -3.6854400634765625}, {"pred": "occur", "count": 35, "cond_log_prob": -0.75384521484375}, {"pred": "occurroute", "count": 1, "cond_log_prob": -25.511306762695312}, {"pred": "take", "count": 1, "cond_log_prob": -3.3515625}]}, "25": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur", "log_prob": -91.34158325195312}, "original": {"pred": "when", "cond_log_prob": -1.213958740234375}, "human": [{"pred": "when", "cond_log_prob": -1.2141265869140625, "count": 24}, {"pred": "during", "cond_log_prob": -3.0008392333984375, "count": 7}, {"pred": "in", "cond_log_prob": -1.9013214111328125, "count": 7}, {"pred": "a", "cond_log_prob": -7.1784515380859375, "count": 1}, {"pred": "faster", "cond_log_prob": -7.76031494140625, "count": 1}, {"pred": "immediately", "cond_log_prob": -5.4824066162109375, "count": 1}, {"pred": "most", "cond_log_prob": -6.7233734130859375, "count": 1}, {"pred": "within", "cond_log_prob": -3.462646484375, "count": 1}], "ancestral_samples": [{"pred": "after", "count": 1, "cond_log_prob": -3.6965789794921875}, {"pred": "afterroute", "count": 1, "cond_log_prob": -26.055084228515625}, {"pred": "as", "count": 1, "cond_log_prob": -3.3630218505859375}, {"pred": "at", "count": 1, "cond_log_prob": -2.8196258544921875}, {"pred": "because", "count": 1, "cond_log_prob": -4.1450958251953125}, {"pred": "in", "count": 11, "cond_log_prob": -1.9013214111328125}, {"pred": "only", "count": 1, "cond_log_prob": -3.4083251953125}, {"pred": "when", "count": 22, "cond_log_prob": -1.2141265869140625}, {"pred": "with", "count": 1, "cond_log_prob": -3.577880859375}]}, "26": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when", "log_prob": -92.5555419921875}, "original": {"pred": "large", "cond_log_prob": -6.0912322998046875}, "human": [{"pred": "the", "cond_log_prob": -0.991607666015625, "count": 22}, {"pred": "a", "cond_log_prob": -2.2355270385742188, "count": 4}, {"pred": "someone", "cond_log_prob": -5.588081359863281, "count": 2}, {"pred": "there", "cond_log_prob": -3.6878890991210938, "count": 2}, {"pred": "activity", "cond_log_prob": -7.203697204589844, "count": 1}, {"pred": "exertions", "cond_log_prob": -11.5908203125, "count": 1}, {"pred": "extreme", "cond_log_prob": -6.212486267089844, "count": 1}, {"pred": "friction", "cond_log_prob": -7.559700012207031, "count": 1}, {"pred": "hot", "cond_log_prob": -5.492401123046875, "count": 1}, {"pred": "individuals", "cond_log_prob": -6.024139404296875, "count": 1}, {"pred": "involved", "cond_log_prob": -10.248367309570312, "count": 1}, {"pred": "it", "cond_log_prob": -5.496803283691406, "count": 1}, {"pred": "people", "cond_log_prob": -4.3899688720703125, "count": 1}, {"pred": "temperature", "cond_log_prob": -4.580802917480469, "count": 1}, {"pred": "temperatures", "cond_log_prob": -4.869117736816406, "count": 1}, {"pred": "they", "cond_log_prob": -6.83856201171875, "count": 1}, {"pred": "we", "cond_log_prob": -6.363861083984375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 5, "cond_log_prob": -2.2355270385742188}, {"pred": "the", "count": 34, "cond_log_prob": -0.991607666015625}, {"pred": "theroute", "count": 1, "cond_log_prob": -30.353057861328125}]}, "27": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large", "log_prob": -98.64677429199219}, "original": {"pred": "amounts", "cond_log_prob": -0.9728622436523438}, "human": [{"pred": "amounts", "cond_log_prob": -0.973052978515625, "count": 33}, {"pred": "bodies", "cond_log_prob": -5.05853271484375, "count": 2}, {"pred": "a", "cond_log_prob": -8.674858093261719, "count": 1}, {"pred": "amount", "cond_log_prob": -5.791656494140625, "count": 1}, {"pred": "heat", "cond_log_prob": -4.659782409667969, "count": 1}, {"pred": "molecules", "cond_log_prob": -3.7082595825195312, "count": 1}, {"pred": "number", "cond_log_prob": -6.2467803955078125, "count": 1}, {"pred": "people", "cond_log_prob": -8.659339904785156, "count": 1}, {"pred": "quantities", "cond_log_prob": -2.3797607421875, "count": 1}, {"pred": "something", "cond_log_prob": -12.475143432617188, "count": 1}], "ancestral_samples": [{"pred": "amounts", "count": 35, "cond_log_prob": -0.973052978515625}, {"pred": "amountsroute", "count": 1, "cond_log_prob": -29.763107299804688}, {"pred": "numbers", "count": 1, "cond_log_prob": -2.779083251953125}, {"pred": "quantities", "count": 3, "cond_log_prob": -2.3797607421875}]}, "28": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts", "log_prob": -99.61963653564453}, "original": {"pred": "of", "cond_log_prob": -0.00470733642578125}, "human": [{"pred": "of", "cond_log_prob": -0.00490570068359375, "count": 41}, {"pred": "a", "cond_log_prob": -12.779022216796875, "count": 1}, {"pred": "heat", "cond_log_prob": -9.940567016601562, "count": 1}], "ancestral_samples": [{"pred": "of", "count": 39, "cond_log_prob": -0.00490570068359375}, {"pred": "ofroute", "count": 1, "cond_log_prob": -27.00298309326172}]}, "29": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of", "log_prob": -99.62434387207031}, "original": {"pred": "water", "cond_log_prob": -2.5720367431640625}, "human": [{"pred": "heat", "cond_log_prob": -1.2881622314453125, "count": 11}, {"pred": "energy", "cond_log_prob": -3.25592041015625, "count": 8}, {"pred": "activity", "cond_log_prob": -6.720069885253906, "count": 4}, {"pred": "sweat", "cond_log_prob": -4.4847564697265625, "count": 3}, {"pred": "water", "cond_log_prob": -2.572235107421875, "count": 3}, {"pred": "fat", "cond_log_prob": -4.3757476806640625, "count": 2}, {"pred": "time", "cond_log_prob": -7.59661865234375, "count": 2}, {"pred": "bacteria", "cond_log_prob": -7.469085693359375, "count": 1}, {"pred": "blood", "cond_log_prob": -4.619499206542969, "count": 1}, {"pred": "change", "cond_log_prob": -9.418960571289062, "count": 1}, {"pred": "friction", "cond_log_prob": -7.2504730224609375, "count": 1}, {"pred": "hot", "cond_log_prob": -4.3764495849609375, "count": 1}, {"pred": "motion", "cond_log_prob": -9.12139892578125, "count": 1}, {"pred": "oxygen", "cond_log_prob": -3.9096298217773438, "count": 1}, {"pred": "plutonium", "cond_log_prob": -10.312042236328125, "count": 1}, {"pred": "sunlight", "cond_log_prob": -6.2689971923828125, "count": 1}, {"pred": "the", "cond_log_prob": -4.44781494140625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.996124267578125}, {"pred": "energy", "count": 1, "cond_log_prob": -3.25592041015625}, {"pred": "heat", "count": 35, "cond_log_prob": -1.2881622314453125}, {"pred": "heatroute", "count": 1, "cond_log_prob": -23.10332489013672}, {"pred": "liquid", "count": 1, "cond_log_prob": -3.04852294921875}, {"pred": "water", "count": 1, "cond_log_prob": -2.572235107421875}]}, "30": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water", "log_prob": -102.19638061523438}, "original": {"pred": "and/or", "cond_log_prob": -6.437339782714844}, "human": [{"pred": "are", "cond_log_prob": -1.2721328735351562, "count": 25}, {"pred": "is", "cond_log_prob": -4.873878479003906, "count": 11}, {"pred": "and", "cond_log_prob": -2.8883514404296875, "count": 1}, {"pred": "boil", "cond_log_prob": -5.927543640136719, "count": 1}, {"pred": "collide", "cond_log_prob": -7.3556976318359375, "count": 1}, {"pred": "evaporate", "cond_log_prob": -3.913818359375, "count": 1}, {"pred": "get", "cond_log_prob": -5.976715087890625, "count": 1}, {"pred": "have", "cond_log_prob": -4.465705871582031, "count": 1}, {"pred": "in", "cond_log_prob": -4.8373870849609375, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 1, "cond_log_prob": -2.8883514404296875}, {"pred": "are", "count": 31, "cond_log_prob": -1.2721328735351562}, {"pred": "or", "count": 1, "cond_log_prob": -2.0822601318359375}, {"pred": "vapor", "count": 6, "cond_log_prob": -1.812896728515625}, {"pred": "vaporroute", "count": 1, "cond_log_prob": -23.068023681640625}]}, "31": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or", "log_prob": -108.63372039794922}, "original": {"pred": "salt", "cond_log_prob": -3.4364776611328125}, "human": [{"pred": "sweat", "cond_log_prob": -4.305412292480469, "count": 8}, {"pred": "air", "cond_log_prob": -3.0227203369140625, "count": 3}, {"pred": "food", "cond_log_prob": -2.6426544189453125, "count": 3}, {"pred": "liquids", "cond_log_prob": -5.822654724121094, "count": 3}, {"pred": "oxygen", "cond_log_prob": -3.4838790893554688, "count": 3}, {"pred": "salt", "cond_log_prob": -3.43670654296875, "count": 3}, {"pred": "fluids", "cond_log_prob": -5.1613006591796875, "count": 2}, {"pred": "a", "cond_log_prob": -4.1103057861328125, "count": 1}, {"pred": "activity", "cond_log_prob": -10.439361572265625, "count": 1}, {"pred": "blood", "cond_log_prob": -5.9779052734375, "count": 1}, {"pred": "calories", "cond_log_prob": -9.25823974609375, "count": 1}, {"pred": "dirt", "cond_log_prob": -6.823112487792969, "count": 1}, {"pred": "drank", "cond_log_prob": -16.995018005371094, "count": 1}, {"pred": "electricity", "cond_log_prob": -4.236473083496094, "count": 1}, {"pred": "energy", "cond_log_prob": -5.092872619628906, "count": 1}, {"pred": "fluid", "cond_log_prob": -4.566375732421875, "count": 1}, {"pred": "gas", "cond_log_prob": -3.6854934692382812, "count": 1}, {"pred": "heat", "cond_log_prob": -3.6799163818359375, "count": 1}, {"pred": "ice", "cond_log_prob": -3.5115966796875, "count": 1}, {"pred": "light", "cond_log_prob": -6.0743560791015625, "count": 1}, {"pred": "magic", "cond_log_prob": -11.353538513183594, "count": 1}, {"pred": "melt", "cond_log_prob": -10.600723266601562, "count": 1}, {"pred": "oceans", "cond_log_prob": -14.1021728515625, "count": 1}, {"pred": "oil", "cond_log_prob": -3.4714508056640625, "count": 1}, {"pred": "vapor", "cond_log_prob": -5.7223968505859375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -4.1103057861328125}, {"pred": "air", "count": 2, "cond_log_prob": -3.0227203369140625}, {"pred": "amino", "count": 1, "cond_log_prob": -6.3439483642578125}, {"pred": "chemicals", "count": 3, "cond_log_prob": -3.9182281494140625}, {"pred": "dust", "count": 1, "cond_log_prob": -4.9282684326171875}, {"pred": "energy", "count": 1, "cond_log_prob": -5.092872619628906}, {"pred": "food", "count": 9, "cond_log_prob": -2.6426544189453125}, {"pred": "gases", "count": 3, "cond_log_prob": -3.449798583984375}, {"pred": "ice", "count": 1, "cond_log_prob": -3.5115966796875}, {"pred": "liquid", "count": 2, "cond_log_prob": -3.905242919921875}, {"pred": "mucus", "count": 1, "cond_log_prob": -5.416938781738281}, {"pred": "nutrients", "count": 2, "cond_log_prob": -3.7514190673828125}, {"pred": "oilroute", "count": 1, "cond_log_prob": -24.92688751220703}, {"pred": "other", "count": 4, "cond_log_prob": -3.2442474365234375}, {"pred": "oxygen", "count": 1, "cond_log_prob": -3.4838790893554688}, {"pred": "protein", "count": 1, "cond_log_prob": -4.956817626953125}, {"pred": "salt", "count": 3, "cond_log_prob": -3.43670654296875}, {"pred": "water", "count": 1, "cond_log_prob": -3.5137176513671875}]}, "32": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt", "log_prob": -112.07019805908203}, "original": {"pred": "are", "cond_log_prob": -0.6737213134765625}, "human": [{"pred": "are", "cond_log_prob": -0.6739578247070312, "count": 23}, {"pred": "is", "cond_log_prob": -5.371711730957031, "count": 10}, {"pred": "a", "cond_log_prob": -8.493370056152344, "count": 1}, {"pred": "evaporates", "cond_log_prob": -10.957984924316406, "count": 1}, {"pred": "explodes", "cond_log_prob": -13.245826721191406, "count": 1}, {"pred": "get", "cond_log_prob": -5.324714660644531, "count": 1}, {"pred": "have", "cond_log_prob": -3.7358474731445312, "count": 1}, {"pred": "leave", "cond_log_prob": -9.171493530273438, "count": 1}, {"pred": "merge", "cond_log_prob": -10.199005126953125, "count": 1}, {"pred": "mix", "cond_log_prob": -4.656455993652344, "count": 1}, {"pred": "persperate", "cond_log_prob": -28.78026580810547, "count": 1}, {"pred": "react", "cond_log_prob": -6.25323486328125, "count": 1}], "ancestral_samples": [{"pred": "accumulate", "count": 1, "cond_log_prob": -4.125038146972656}, {"pred": "are", "count": 38, "cond_log_prob": -0.6739578247070312}, {"pred": "areroute", "count": 1, "cond_log_prob": -26.846229553222656}]}, "33": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are", "log_prob": -112.7439193725586}, "original": {"pred": "lost", "cond_log_prob": -6.644187927246094}, "human": [{"pred": "lost", "cond_log_prob": -6.644432067871094, "count": 11}, {"pred": "present", "cond_log_prob": -1.7590560913085938, "count": 5}, {"pred": "combined", "cond_log_prob": -4.046028137207031, "count": 3}, {"pred": "consumed", "cond_log_prob": -4.148002624511719, "count": 3}, {"pred": "not", "cond_log_prob": -6.272682189941406, "count": 3}, {"pred": "excreted", "cond_log_prob": -7.705009460449219, "count": 2}, {"pred": "mixed", "cond_log_prob": -3.0799407958984375, "count": 2}, {"pred": "put", "cond_log_prob": -6.166252136230469, "count": 2}, {"pred": "removed", "cond_log_prob": -6.085441589355469, "count": 2}, {"pred": "used", "cond_log_prob": -2.6356735229492188, "count": 2}, {"pred": "a", "cond_log_prob": -8.236900329589844, "count": 1}, {"pred": "applied", "cond_log_prob": -2.9027175903320312, "count": 1}, {"pred": "depleted", "cond_log_prob": -8.728187561035156, "count": 1}, {"pred": "evaporating", "cond_log_prob": -10.663032531738281, "count": 1}, {"pred": "expended", "cond_log_prob": -8.994316101074219, "count": 1}, {"pred": "in", "cond_log_prob": -4.554100036621094, "count": 1}, {"pred": "near", "cond_log_prob": -9.557624816894531, "count": 1}, {"pred": "twisted", "cond_log_prob": -12.797019958496094, "count": 1}], "ancestral_samples": [{"pred": "absorbed", "count": 1, "cond_log_prob": -3.4533615112304688}, {"pred": "added", "count": 13, "cond_log_prob": -2.2859420776367188}, {"pred": "addedroute", "count": 1, "cond_log_prob": -25.140464782714844}, {"pred": "mixed", "count": 1, "cond_log_prob": -3.0799407958984375}, {"pred": "present", "count": 18, "cond_log_prob": -1.7590560913085938}, {"pred": "presentIn", "count": 1, "cond_log_prob": -16.59386444091797}, {"pred": "presentThe", "count": 1, "cond_log_prob": -17.691078186035156}, {"pred": "used", "count": 4, "cond_log_prob": -2.6356735229492188}]}, "34": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost", "log_prob": -119.38810729980469}, "original": {"pred": "through", "cond_log_prob": -2.5972747802734375}, "human": [{"pred": "in", "cond_log_prob": -1.6446075439453125, "count": 13}, {"pred": "from", "cond_log_prob": -1.7674713134765625, "count": 8}, {"pred": "through", "cond_log_prob": -2.5975265502929688, "count": 7}, {"pred": "during", "cond_log_prob": -2.839996337890625, "count": 5}, {"pred": "and", "cond_log_prob": -3.0851516723632812, "count": 3}, {"pred": "due", "cond_log_prob": -3.9988937377929688, "count": 2}, {"pred": "a", "cond_log_prob": -9.765670776367188, "count": 1}, {"pred": "by", "cond_log_prob": -4.8460540771484375, "count": 1}, {"pred": "especially", "cond_log_prob": -11.526168823242188, "count": 1}, {"pred": "to", "cond_log_prob": -2.7255401611328125, "count": 1}, {"pred": "together", "cond_log_prob": -8.772872924804688, "count": 1}], "ancestral_samples": [{"pred": "Heat", "count": 1, "cond_log_prob": -17.037948608398438}, {"pred": "The", "count": 1, "cond_log_prob": -12.861282348632812}, {"pred": "While", "count": 1, "cond_log_prob": -14.893356323242188}, {"pred": "and", "count": 2, "cond_log_prob": -3.0851516723632812}, {"pred": "but", "count": 1, "cond_log_prob": -7.369056701660156}, {"pred": "during", "count": 3, "cond_log_prob": -2.839996337890625}, {"pred": "from", "count": 8, "cond_log_prob": -1.7674713134765625}, {"pred": "fromroute", "count": 1, "cond_log_prob": -24.866531372070312}, {"pred": "in", "count": 14, "cond_log_prob": -1.6446075439453125}, {"pred": "or", "count": 2, "cond_log_prob": -2.4563369750976562}, {"pred": "through", "count": 2, "cond_log_prob": -2.5975265502929688}, {"pred": "to", "count": 4, "cond_log_prob": -2.7255401611328125}]}, "35": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through", "log_prob": -121.98538208007812}, "original": {"pred": "excessive", "cond_log_prob": -5.0443267822265625}, "human": [{"pred": "sweat", "cond_log_prob": -3.9080734252929688, "count": 9}, {"pred": "sweating", "cond_log_prob": -3.510711669921875, "count": 6}, {"pred": "the", "cond_log_prob": -1.1827392578125, "count": 6}, {"pred": "perspiration", "cond_log_prob": -6.7873687744140625, "count": 5}, {"pred": "a", "cond_log_prob": -3.351776123046875, "count": 2}, {"pred": "activity", "cond_log_prob": -7.2513580322265625, "count": 2}, {"pred": "chemical", "cond_log_prob": -5.239387512207031, "count": 2}, {"pred": "osmosis", "cond_log_prob": -8.566329956054688, "count": 2}, {"pred": "activities", "cond_log_prob": -7.354339599609375, "count": 1}, {"pred": "dehydration", "cond_log_prob": -5.399688720703125, "count": 1}, {"pred": "excretion", "cond_log_prob": -6.572723388671875, "count": 1}, {"pred": "exercise", "cond_log_prob": -6.8575897216796875, "count": 1}, {"pred": "gas", "cond_log_prob": -7.767913818359375, "count": 1}, {"pred": "out", "cond_log_prob": -8.424957275390625, "count": 1}, {"pred": "said", "cond_log_prob": -10.20758056640625, "count": 1}, {"pred": "skin", "cond_log_prob": -5.010978698730469, "count": 1}, {"pred": "vigorous", "cond_log_prob": -6.9837188720703125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.351776123046875}, {"pred": "the", "count": 37, "cond_log_prob": -1.1827392578125}, {"pred": "theroute", "count": 1, "cond_log_prob": -29.149169921875}]}, "36": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive", "log_prob": -127.02970886230469}, "original": {"pred": "sweating", "cond_log_prob": -1.772796630859375}, "human": [{"pred": "sweating", "cond_log_prob": -1.7730560302734375, "count": 11}, {"pred": "activity", "cond_log_prob": -5.43634033203125, "count": 6}, {"pred": "exercise", "cond_log_prob": -5.278717041015625, "count": 6}, {"pred": "perspiration", "cond_log_prob": -5.0680084228515625, "count": 5}, {"pred": "amounts", "cond_log_prob": -5.603912353515625, "count": 5}, {"pred": "sweat", "cond_log_prob": -4.4614715576171875, "count": 3}, {"pred": "a", "cond_log_prob": -9.84185791015625, "count": 1}, {"pred": "eating", "cond_log_prob": -8.076065063476562, "count": 1}, {"pred": "heating", "cond_log_prob": -3.3346710205078125, "count": 1}, {"pred": "mixing", "cond_log_prob": -4.9481353759765625, "count": 1}, {"pred": "physical", "cond_log_prob": -6.0929412841796875, "count": 1}, {"pred": "use", "cond_log_prob": -3.1102294921875, "count": 1}, {"pred": "ways", "cond_log_prob": -11.651992797851562, "count": 1}], "ancestral_samples": [{"pred": "cooking", "count": 1, "cond_log_prob": -4.9217681884765625}, {"pred": "cooling", "count": 2, "cond_log_prob": -4.5717926025390625}, {"pred": "evaporation", "count": 1, "cond_log_prob": -4.4163970947265625}, {"pred": "excretion", "count": 1, "cond_log_prob": -6.3818511962890625}, {"pred": "heat", "count": 11, "cond_log_prob": -2.0453338623046875}, {"pred": "heatHeat", "count": 1, "cond_log_prob": -19.358810424804688}, {"pred": "heatThe", "count": 1, "cond_log_prob": -16.092453002929688}, {"pred": "heating", "count": 2, "cond_log_prob": -3.3346710205078125}, {"pred": "movement", "count": 1, "cond_log_prob": -3.92431640625}, {"pred": "or", "count": 1, "cond_log_prob": -4.10577392578125}, {"pred": "sweating", "count": 12, "cond_log_prob": -1.7730560302734375}, {"pred": "sweatingFor", "count": 1, "cond_log_prob": -20.111740112304688}, {"pred": "sweatingHeat", "count": 1, "cond_log_prob": -21.793380737304688}, {"pred": "sweatingIn", "count": 1, "cond_log_prob": -17.368392944335938}, {"pred": "sweatingThe", "count": 1, "cond_log_prob": -15.826705932617188}, {"pred": "sweatingroute", "count": 1, "cond_log_prob": -24.531448364257812}, {"pred": "use", "count": 1, "cond_log_prob": -3.1102294921875}]}, "37": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating", "log_prob": -128.80250549316406}, "original": {"pred": "following", "cond_log_prob": -8.682449340820312}, "human": [{"pred": "and", "cond_log_prob": -2.2717437744140625, "count": 19}, {"pred": "during", "cond_log_prob": -4.8714447021484375, "count": 5}, {"pred": "or", "cond_log_prob": -1.541717529296875, "count": 5}, {"pred": "and/or", "cond_log_prob": -3.5384063720703125, "count": 2}, {"pred": "while", "cond_log_prob": -6.6045684814453125, "count": 2}, {"pred": "a", "cond_log_prob": -9.818374633789062, "count": 1}, {"pred": "although", "cond_log_prob": -10.142105102539062, "count": 1}, {"pred": "because", "cond_log_prob": -7.5706024169921875, "count": 1}, {"pred": "following", "cond_log_prob": -8.6827392578125, "count": 1}, {"pred": "from", "cond_log_prob": -5.9433135986328125, "count": 1}, {"pred": "in", "cond_log_prob": -4.53765869140625, "count": 1}, {"pred": "occurs", "cond_log_prob": -10.607513427734375, "count": 1}, {"pred": "of", "cond_log_prob": -5.5914306640625, "count": 1}, {"pred": "the", "cond_log_prob": -8.515853881835938, "count": 1}, {"pred": "this", "cond_log_prob": -11.229736328125, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 4, "cond_log_prob": -11.726364135742188}, {"pred": "Heat", "count": 4, "cond_log_prob": -14.672897338867188}, {"pred": "In", "count": 1, "cond_log_prob": -12.5191650390625}, {"pred": "The", "count": 13, "cond_log_prob": -10.8582763671875}, {"pred": "There", "count": 1, "cond_log_prob": -14.233383178710938}, {"pred": "This", "count": 1, "cond_log_prob": -13.011154174804688}, {"pred": "When", "count": 1, "cond_log_prob": -12.511444091796875}, {"pred": "While", "count": 1, "cond_log_prob": -13.763916015625}, {"pred": "and", "count": 1, "cond_log_prob": -2.2717437744140625}, {"pred": "andor", "count": 2, "cond_log_prob": -18.183090209960938}, {"pred": "but", "count": 1, "cond_log_prob": -7.2560577392578125}, {"pred": "diarrhea", "count": 1, "cond_log_prob": -15.078353881835938}, {"pred": "or", "count": 7, "cond_log_prob": -1.541717529296875}, {"pred": "route", "count": 1, "cond_log_prob": -16.195968627929688}, {"pred": "so", "count": 1, "cond_log_prob": -9.098541259765625}]}, "38": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following", "log_prob": -137.48495483398438}, "original": {"pred": "strenuous", "cond_log_prob": -2.86090087890625}, "human": [{"pred": "exercise", "cond_log_prob": -2.3258819580078125, "count": 13}, {"pred": "vigorous", "cond_log_prob": -2.89410400390625, "count": 9}, {"pred": "a", "cond_log_prob": -1.6448211669921875, "count": 8}, {"pred": "activity", "cond_log_prob": -5.8684234619140625, "count": 2}, {"pred": "physical", "cond_log_prob": -4.756195068359375, "count": 2}, {"pred": "strenuous", "cond_log_prob": -2.8612060546875, "count": 2}, {"pred": "an", "cond_log_prob": -2.702789306640625, "count": 1}, {"pred": "excessive", "cond_log_prob": -5.6417999267578125, "count": 1}, {"pred": "intense", "cond_log_prob": -3.2202911376953125, "count": 1}, {"pred": "rest", "cond_log_prob": -8.137939453125, "count": 1}, {"pred": "sex", "cond_log_prob": -8.240020751953125, "count": 1}, {"pred": "thanksgiving", "cond_log_prob": -15.54156494140625, "count": 1}, {"pred": "working", "cond_log_prob": -8.966537475585938, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 23, "cond_log_prob": -1.6448211669921875}, {"pred": "an", "count": 2, "cond_log_prob": -2.702789306640625}, {"pred": "exercise", "count": 2, "cond_log_prob": -2.3258819580078125}, {"pred": "exerciseIn", "count": 2, "cond_log_prob": -17.036651611328125}, {"pred": "exerciseThe", "count": 1, "cond_log_prob": -16.435882568359375}, {"pred": "exerciseThere", "count": 1, "cond_log_prob": -18.749298095703125}, {"pred": "exerciseroute", "count": 1, "cond_log_prob": -29.737945556640625}, {"pred": "intense", "count": 1, "cond_log_prob": -3.2202911376953125}, {"pred": "prolonged", "count": 5, "cond_log_prob": -2.7747650146484375}, {"pred": "strenuous", "count": 1, "cond_log_prob": -2.8612060546875}, {"pred": "vigorous", "count": 1, "cond_log_prob": -2.89410400390625}]}, "39": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous", "log_prob": -140.34585571289062}, "original": {"pred": "exercise.", "cond_log_prob": -1.17724609375}, "human": [{"pred": "exercise", "cond_log_prob": -0.860137939453125, "count": 18}, {"pred": "activity", "cond_log_prob": -1.428558349609375, "count": 14}, {"pred": "activities", "cond_log_prob": -2.2381134033203125, "count": 3}, {"pred": "physical", "cond_log_prob": -3.186492919921875, "count": 3}, {"pred": "a", "cond_log_prob": -10.269927978515625, "count": 1}, {"pred": "levels", "cond_log_prob": -9.156097412109375, "count": 1}, {"pred": "movement", "cond_log_prob": -5.0655517578125, "count": 1}, {"pred": "work", "cond_log_prob": -4.52154541015625, "count": 1}, {"pred": "workout", "cond_log_prob": -6.7635498046875, "count": 1}], "ancestral_samples": [{"pred": "activities", "count": 1, "cond_log_prob": -2.2381134033203125}, {"pred": "activity", "count": 1, "cond_log_prob": -1.428558349609375}, {"pred": "activityThe", "count": 1, "cond_log_prob": -15.311859130859375}, {"pred": "exercise", "count": 23, "cond_log_prob": -0.860137939453125}, {"pred": "exerciseA", "count": 1, "cond_log_prob": -15.848236083984375}, {"pred": "exerciseHeat", "count": 1, "cond_log_prob": -21.976165771484375}, {"pred": "exerciseIn", "count": 3, "cond_log_prob": -15.99212646484375}, {"pred": "exerciseIt", "count": 1, "cond_log_prob": -16.845306396484375}, {"pred": "exerciseThe", "count": 6, "cond_log_prob": -14.997650146484375}, {"pred": "exerciseThere", "count": 1, "cond_log_prob": -17.3427734375}, {"pred": "exerciseroute", "count": 1, "cond_log_prob": -28.50506591796875}]}, "40": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise.", "log_prob": -141.52310180664062}, "original": {"pred": "When", "cond_log_prob": -3.8095855712890625}, "human": [{"pred": "the", "cond_log_prob": -9.612060546875, "count": 10}, {"pred": "this", "cond_log_prob": -12.624176025390625, "count": 9}, {"pred": "cold", "cond_log_prob": -13.391204833984375, "count": 6}, {"pred": "when", "cond_log_prob": -11.927520751953125, "count": 3}, {"pred": "a", "cond_log_prob": -10.978729248046875, "count": 1}, {"pred": "after", "cond_log_prob": -13.533172607421875, "count": 1}, {"pred": "also", "cond_log_prob": -12.35479736328125, "count": 1}, {"pred": "because", "cond_log_prob": -12.150054931640625, "count": 1}, {"pred": "but", "cond_log_prob": -12.31854248046875, "count": 1}, {"pred": "even", "cond_log_prob": -14.883575439453125, "count": 1}, {"pred": "high", "cond_log_prob": -15.612701416015625, "count": 1}, {"pred": "however", "cond_log_prob": -13.02392578125, "count": 1}, {"pred": "most", "cond_log_prob": -14.10015869140625, "count": 1}, {"pred": "only", "cond_log_prob": -14.456878662109375, "count": 1}, {"pred": "sweat", "cond_log_prob": -14.394989013671875, "count": 1}, {"pred": "temperature", "cond_log_prob": -14.0233154296875, "count": 1}, {"pred": "that", "cond_log_prob": -12.72314453125, "count": 1}, {"pred": "therefore", "cond_log_prob": -13.86199951171875, "count": 1}, {"pred": "we", "cond_log_prob": -14.1622314453125, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 3, "cond_log_prob": -3.61199951171875}, {"pred": "Heat", "count": 1, "cond_log_prob": -3.5520782470703125}, {"pred": "If", "count": 1, "cond_log_prob": -4.1561126708984375}, {"pred": "In", "count": 5, "cond_log_prob": -3.000823974609375}, {"pred": "It", "count": 1, "cond_log_prob": -3.881103515625}, {"pred": "Some", "count": 1, "cond_log_prob": -4.4311676025390625}, {"pred": "The", "count": 26, "cond_log_prob": -2.1894378662109375}, {"pred": "When", "count": 1, "cond_log_prob": -3.809906005859375}, {"pred": "route", "count": 1, "cond_log_prob": -20.917755126953125}]}, "41": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When", "log_prob": -145.3326873779297}, "original": {"pred": "the", "cond_log_prob": -1.6209869384765625}, "human": [{"pred": "the", "cond_log_prob": -1.6212921142578125, "count": 14}, {"pred": "a", "cond_log_prob": -2.6619720458984375, "count": 6}, {"pred": "we", "cond_log_prob": -6.1630401611328125, "count": 4}, {"pred": "this", "cond_log_prob": -2.8399200439453125, "count": 4}, {"pred": "cold", "cond_log_prob": -4.7334136962890625, "count": 2}, {"pred": "you", "cond_log_prob": -5.5106048583984375, "count": 2}, {"pred": "america", "cond_log_prob": -20.242568969726562, "count": 1}, {"pred": "engaged", "cond_log_prob": -8.931747436523438, "count": 1}, {"pred": "exercise", "cond_log_prob": -5.3115386962890625, "count": 1}, {"pred": "exercising", "cond_log_prob": -6.0606231689453125, "count": 1}, {"pred": "humans", "cond_log_prob": -5.3549652099609375, "count": 1}, {"pred": "large", "cond_log_prob": -5.4928436279296875, "count": 1}, {"pred": "some", "cond_log_prob": -5.8456878662109375, "count": 1}, {"pred": "temperatures", "cond_log_prob": -4.2804412841796875, "count": 1}, {"pred": "there", "cond_log_prob": -4.0290069580078125, "count": 1}, {"pred": "water", "cond_log_prob": -3.8177947998046875, "count": 1}, {"pred": "will", "cond_log_prob": -9.881149291992188, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 5, "cond_log_prob": -2.6619720458984375}, {"pred": "salt", "count": 1, "cond_log_prob": -4.8163909912109375}, {"pred": "temperaturesroute", "count": 1, "cond_log_prob": -28.278060913085938}, {"pred": "the", "count": 30, "cond_log_prob": -1.6212921142578125}, {"pred": "these", "count": 1, "cond_log_prob": -3.0748138427734375}, {"pred": "this", "count": 2, "cond_log_prob": -2.8399200439453125}]}, "42": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the", "log_prob": -146.95367431640625}, "original": {"pred": "body", "cond_log_prob": -0.9769134521484375}, "human": [{"pred": "body", "cond_log_prob": -0.97723388671875, "count": 28}, {"pred": "person", "cond_log_prob": -1.670379638671875, "count": 4}, {"pred": "cold", "cond_log_prob": -6.9732666015625, "count": 2}, {"pred": "a", "cond_log_prob": -9.132904052734375, "count": 1}, {"pred": "amount", "cond_log_prob": -4.973419189453125, "count": 1}, {"pred": "first", "cond_log_prob": -7.889007568359375, "count": 1}, {"pred": "occurs", "cond_log_prob": -13.384735107421875, "count": 1}, {"pred": "situation", "cond_log_prob": -7.44775390625, "count": 1}, {"pred": "temperature", "cond_log_prob": -2.972320556640625, "count": 1}, {"pred": "this", "cond_log_prob": -11.237747192382812, "count": 1}, {"pred": "water", "cond_log_prob": -4.02264404296875, "count": 1}, {"pred": "weight", "cond_log_prob": -6.627777099609375, "count": 1}], "ancestral_samples": [{"pred": "body", "count": 21, "cond_log_prob": -0.97723388671875}, {"pred": "bodys", "count": 1, "cond_log_prob": -13.45263671875}, {"pred": "heat", "count": 1, "cond_log_prob": -3.6141357421875}, {"pred": "human", "count": 1, "cond_log_prob": -2.831787109375}, {"pred": "person", "count": 15, "cond_log_prob": -1.670379638671875}, {"pred": "personroute", "count": 1, "cond_log_prob": -28.116790771484375}]}, "43": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body", "log_prob": -147.9305877685547}, "original": {"pred": "becomes", "cond_log_prob": -3.4856414794921875}, "human": [{"pred": "is", "cond_log_prob": -0.9836883544921875, "count": 12}, {"pred": "loses", "cond_log_prob": -3.8649444580078125, "count": 7}, {"pred": "becomes", "cond_log_prob": -3.4859771728515625, "count": 3}, {"pred": "goes", "cond_log_prob": -6.1700592041015625, "count": 3}, {"pred": "experiences", "cond_log_prob": -3.6941986083984375, "count": 2}, {"pred": "sweats", "cond_log_prob": -8.120559692382812, "count": 2}, {"pred": "a", "cond_log_prob": -10.251968383789062, "count": 1}, {"pred": "can", "cond_log_prob": -4.0335845947265625, "count": 1}, {"pred": "cools", "cond_log_prob": -6.3545684814453125, "count": 1}, {"pred": "does", "cond_log_prob": -4.0362701416015625, "count": 1}, {"pred": "expends", "cond_log_prob": -10.957626342773438, "count": 1}, {"pred": "has", "cond_log_prob": -3.4239959716796875, "count": 1}, {"pred": "losses", "cond_log_prob": -12.208999633789062, "count": 1}, {"pred": "meets", "cond_log_prob": -8.033554077148438, "count": 1}, {"pred": "reaches", "cond_log_prob": -5.5803375244140625, "count": 1}, {"pred": "reacts", "cond_log_prob": -4.2450103759765625, "count": 1}, {"pred": "realizes", "cond_log_prob": -7.6173858642578125, "count": 1}, {"pred": "starts", "cond_log_prob": -4.9193878173828125, "count": 1}, {"pred": "type", "cond_log_prob": -10.943954467773438, "count": 1}, {"pred": "undergoes", "cond_log_prob": -5.3305511474609375, "count": 1}], "ancestral_samples": [{"pred": "becomes", "count": 1, "cond_log_prob": -3.4859771728515625}, {"pred": "is", "count": 37, "cond_log_prob": -0.9836883544921875}, {"pred": "isroute", "count": 1, "cond_log_prob": -26.211013793945312}, {"pred": "s", "count": 1, "cond_log_prob": -8.993392944335938}]}, "44": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes", "log_prob": -151.41622924804688}, "original": {"pred": "overheated", "cond_log_prob": -3.134521484375}, "human": [{"pred": "dehydrated", "cond_log_prob": -2.024322509765625, "count": 8}, {"pred": "overheated", "cond_log_prob": -3.134857177734375, "count": 7}, {"pred": "too", "cond_log_prob": -2.278472900390625, "count": 7}, {"pred": "hot", "cond_log_prob": -3.987091064453125, "count": 4}, {"pred": "over", "cond_log_prob": -5.524200439453125, "count": 3}, {"pred": "tired", "cond_log_prob": -5.142822265625, "count": 3}, {"pred": "cold", "cond_log_prob": -3.39898681640625, "count": 2}, {"pred": "deflated", "cond_log_prob": -7.8367919921875, "count": 1}, {"pred": "depleted", "cond_log_prob": -7.333160400390625, "count": 1}, {"pred": "deprived", "cond_log_prob": -7.207611083984375, "count": 1}, {"pred": "heated", "cond_log_prob": -4.175933837890625, "count": 1}, {"pred": "like", "cond_log_prob": -9.820404052734375, "count": 1}, {"pred": "subject", "cond_log_prob": -7.925567626953125, "count": 1}, {"pred": "susceptible", "cond_log_prob": -6.4945068359375, "count": 1}, {"pred": "to", "cond_log_prob": -8.6427001953125, "count": 1}, {"pred": "weak", "cond_log_prob": -5.670257568359375, "count": 1}], "ancestral_samples": [{"pred": "accustomed", "count": 1, "cond_log_prob": -3.96759033203125}, {"pred": "dehydrated", "count": 20, "cond_log_prob": -2.024322509765625}, {"pred": "fatigued", "count": 1, "cond_log_prob": -3.5872802734375}, {"pred": "hyperventilating", "count": 1, "cond_log_prob": -6.048370361328125}, {"pred": "ill", "count": 1, "cond_log_prob": -4.135833740234375}, {"pred": "overheroute", "count": 1, "cond_log_prob": -35.9835205078125}, {"pred": "tired", "count": 1, "cond_log_prob": -5.142822265625}, {"pred": "too", "count": 13, "cond_log_prob": -2.278472900390625}, {"pred": "unable", "count": 1, "cond_log_prob": -4.569915771484375}]}, "45": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated", "log_prob": -154.55075073242188}, "original": {"pred": "and", "cond_log_prob": -2.6591796875}, "human": [{"pred": "it", "cond_log_prob": -3.761444091796875, "count": 30}, {"pred": "and", "cond_log_prob": -2.6595458984375, "count": 4}, {"pred": "the", "cond_log_prob": -3.54400634765625, "count": 4}, {"pred": "during", "cond_log_prob": -3.4093017578125, "count": 1}, {"pred": "or", "cond_log_prob": -2.70831298828125, "count": 1}, {"pred": "sweat", "cond_log_prob": -11.65716552734375, "count": 1}, {"pred": "through", "cond_log_prob": -5.758148193359375, "count": 1}, {"pred": "water", "cond_log_prob": -9.755340576171875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -5.903839111328125}, {"pred": "it", "count": 11, "cond_log_prob": -3.761444091796875}, {"pred": "or", "count": 1, "cond_log_prob": -2.70831298828125}, {"pred": "route", "count": 1, "cond_log_prob": -17.580963134765625}, {"pred": "sweating", "count": 1, "cond_log_prob": -11.0684814453125}, {"pred": "the", "count": 25, "cond_log_prob": -3.54400634765625}]}, "46": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and", "log_prob": -157.20993041992188}, "original": {"pred": "cannot", "cond_log_prob": -4.6321868896484375}, "human": [{"pred": "dehydrated", "cond_log_prob": -2.507720947265625, "count": 14}, {"pred": "exhausted", "cond_log_prob": -5.6226806640625, "count": 4}, {"pred": "not", "cond_log_prob": -5.584014892578125, "count": 3}, {"pred": "sweats", "cond_log_prob": -7.37640380859375, "count": 2}, {"pred": "sweaty", "cond_log_prob": -5.6983642578125, "count": 2}, {"pred": "begins", "cond_log_prob": -4.64337158203125, "count": 1}, {"pred": "cant", "cond_log_prob": -11.1722412109375, "count": 1}, {"pred": "cold", "cond_log_prob": -4.22283935546875, "count": 1}, {"pred": "dry", "cond_log_prob": -5.812835693359375, "count": 1}, {"pred": "explodes", "cond_log_prob": -10.982025146484375, "count": 1}, {"pred": "fatigued", "cond_log_prob": -5.1141357421875, "count": 1}, {"pred": "hot", "cond_log_prob": -4.745697021484375, "count": 1}, {"pred": "it", "cond_log_prob": -5.080413818359375, "count": 1}, {"pred": "loses", "cond_log_prob": -4.21356201171875, "count": 1}, {"pred": "overexhausted", "cond_log_prob": -18.89166259765625, "count": 1}, {"pred": "starts", "cond_log_prob": -4.9107666015625, "count": 1}, {"pred": "strained", "cond_log_prob": -9.0093994140625, "count": 1}, {"pred": "stressed", "cond_log_prob": -6.329681396484375, "count": 1}, {"pred": "temperature", "cond_log_prob": -6.58233642578125, "count": 1}, {"pred": "the", "cond_log_prob": -2.42742919921875, "count": 1}, {"pred": "tired", "cond_log_prob": -5.576263427734375, "count": 1}, {"pred": "water", "cond_log_prob": -5.04608154296875, "count": 1}, {"pred": "you", "cond_log_prob": -6.887176513671875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -5.046295166015625}, {"pred": "becomes", "count": 1, "cond_log_prob": -3.96746826171875}, {"pred": "dehydrated", "count": 16, "cond_log_prob": -2.507720947265625}, {"pred": "is", "count": 1, "cond_log_prob": -3.85284423828125}, {"pred": "lacks", "count": 1, "cond_log_prob": -5.428558349609375}, {"pred": "overheated", "count": 1, "cond_log_prob": -3.589813232421875}, {"pred": "overheroute", "count": 1, "cond_log_prob": -31.884674072265625}, {"pred": "the", "count": 16, "cond_log_prob": -2.42742919921875}, {"pred": "tired", "count": 1, "cond_log_prob": -5.576263427734375}, {"pred": "unable", "count": 1, "cond_log_prob": -3.692413330078125}]}, "47": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot", "log_prob": -161.8421173095703}, "original": {"pred": "eliminate", "cond_log_prob": -8.592529296875}, "human": [{"pred": "cool", "cond_log_prob": -6.0506744384765625, "count": 13}, {"pred": "function", "cond_log_prob": -4.7983245849609375, "count": 7}, {"pred": "produce", "cond_log_prob": -4.3741302490234375, "count": 3}, {"pred": "release", "cond_log_prob": -7.3136444091796875, "count": 3}, {"pred": "get", "cond_log_prob": -5.3117828369140625, "count": 2}, {"pred": "regulate", "cond_log_prob": -4.5755462646484375, "count": 2}, {"pred": "sweat", "cond_log_prob": -6.5446624755859375, "count": 2}, {"pred": "continue", "cond_log_prob": -5.4458770751953125, "count": 2}, {"pred": "cope", "cond_log_prob": -2.2190093994140625, "count": 1}, {"pred": "eliminate", "cond_log_prob": -8.592910766601562, "count": 1}, {"pred": "handle", "cond_log_prob": -3.3396453857421875, "count": 1}, {"pred": "keep", "cond_log_prob": -4.0587921142578125, "count": 1}, {"pred": "maintain", "cond_log_prob": -2.9987640380859375, "count": 1}, {"pred": "overcome", "cond_log_prob": -8.017562866210938, "count": 1}, {"pred": "prevent", "cond_log_prob": -6.7183990478515625, "count": 1}, {"pred": "retain", "cond_log_prob": -4.6925506591796875, "count": 1}, {"pred": "rid", "cond_log_prob": -10.686386108398438, "count": 1}], "ancestral_samples": [{"pred": "cope", "count": 3, "cond_log_prob": -2.2190093994140625}, {"pred": "tolerate", "count": 36, "cond_log_prob": -0.8769378662109375}, {"pred": "tolerateroute", "count": 1, "cond_log_prob": -42.75569152832031}]}, "48": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate", "log_prob": -170.4346466064453}, "original": {"pred": "this", "cond_log_prob": -3.8985137939453125}, "human": [{"pred": "the", "cond_log_prob": -0.9901580810546875, "count": 15}, {"pred": "heat", "cond_log_prob": -1.8398590087890625, "count": 11}, {"pred": "excess", "cond_log_prob": -3.1932220458984375, "count": 5}, {"pred": "any", "cond_log_prob": -3.4059906005859375, "count": 3}, {"pred": "evil", "cond_log_prob": -13.698562622070312, "count": 1}, {"pred": "excesse", "cond_log_prob": -26.989791870117188, "count": 1}, {"pred": "extra", "cond_log_prob": -7.4597930908203125, "count": 1}, {"pred": "leftover", "cond_log_prob": -10.641616821289062, "count": 1}, {"pred": "oxygen", "cond_log_prob": -7.1884002685546875, "count": 1}, {"pred": "salt", "cond_log_prob": -4.1420135498046875, "count": 1}, {"pred": "that", "cond_log_prob": -5.3985748291015625, "count": 1}, {"pred": "wastes", "cond_log_prob": -9.254776000976562, "count": 1}, {"pred": "water", "cond_log_prob": -3.4959869384765625, "count": 1}], "ancestral_samples": [{"pred": "heat", "count": 2, "cond_log_prob": -1.8398590087890625}, {"pred": "its", "count": 1, "cond_log_prob": -3.3521881103515625}, {"pred": "the", "count": 36, "cond_log_prob": -0.9901580810546875}, {"pred": "theroute", "count": 1, "cond_log_prob": -29.946197509765625}]}, "49": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this", "log_prob": -174.33316040039062}, "original": {"pred": "excess", "cond_log_prob": -3.3491363525390625}, "human": [{"pred": "heat", "cond_log_prob": -1.467559814453125, "count": 17}, {"pred": "excess", "cond_log_prob": -3.349517822265625, "count": 5}, {"pred": "water", "cond_log_prob": -2.5155029296875, "count": 3}, {"pred": "it", "cond_log_prob": -9.09429931640625, "count": 2}, {"pred": "problem", "cond_log_prob": -3.680755615234375, "count": 2}, {"pred": "sweat", "cond_log_prob": -5.768890380859375, "count": 3}, {"pred": "amount", "cond_log_prob": -3.853118896484375, "count": 1}, {"pred": "extra", "cond_log_prob": -5.7884521484375, "count": 1}, {"pred": "issue", "cond_log_prob": -5.930816650390625, "count": 1}, {"pred": "large", "cond_log_prob": -5.230072021484375, "count": 1}, {"pred": "leftover", "cond_log_prob": -9.378280639648438, "count": 1}, {"pred": "overheating", "cond_log_prob": -7.31109619140625, "count": 1}, {"pred": "phenomenon", "cond_log_prob": -6.9461822509765625, "count": 1}, {"pred": "product", "cond_log_prob": -8.649444580078125, "count": 1}, {"pred": "s", "cond_log_prob": -8.48980712890625, "count": 1}, {"pred": "the", "cond_log_prob": -7.314605712890625, "count": 1}, {"pred": "thing", "cond_log_prob": -10.51861572265625, "count": 1}], "ancestral_samples": [{"pred": "amount", "count": 1, "cond_log_prob": -3.853118896484375}, {"pred": "excess", "count": 1, "cond_log_prob": -3.349517822265625}, {"pred": "heat", "count": 35, "cond_log_prob": -1.467559814453125}, {"pred": "heatroute", "count": 1, "cond_log_prob": -19.94927978515625}, {"pred": "water", "count": 2, "cond_log_prob": -2.5155029296875}]}, "50": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this excess", "log_prob": -177.6822967529297}, "original": {"pred": "heat,", "cond_log_prob": -1.5104827880859375}, "human": [{"pred": "heat", "cond_log_prob": -1.1240081787109375, "count": 27}, {"pred": "of", "cond_log_prob": -4.4043426513671875, "count": 4}, {"pred": "water", "cond_log_prob": -0.7322540283203125, "count": 4}, {"pred": "amount", "cond_log_prob": -6.0594329833984375, "count": 2}, {"pred": "sweat", "cond_log_prob": -6.1223297119140625, "count": 3}, {"pred": "energy", "cond_log_prob": -4.6562042236328125, "count": 1}, {"pred": "stress", "cond_log_prob": -7.8795013427734375, "count": 1}, {"pred": "waste", "cond_log_prob": -8.761886596679688, "count": 1}], "ancestral_samples": [{"pred": "heat", "count": 13, "cond_log_prob": -1.1240081787109375}, {"pred": "water", "count": 26, "cond_log_prob": -0.7322540283203125}, {"pred": "waterroute", "count": 1, "cond_log_prob": -20.160873413085938}]}, "51": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this excess heat,", "log_prob": -179.19277954101562}, "original": {"pred": "heat", "cond_log_prob": -3.79071044921875}, "human": [{"pred": "it", "cond_log_prob": -1.428436279296875, "count": 31}, {"pred": "the", "cond_log_prob": -1.35357666015625, "count": 4}, {"pred": "heat", "cond_log_prob": -3.791107177734375, "count": 2}, {"pred": "and", "cond_log_prob": -5.64013671875, "count": 1}, {"pred": "but", "cond_log_prob": -7.37548828125, "count": 1}, {"pred": "death", "cond_log_prob": -7.2054443359375, "count": 1}, {"pred": "hey", "cond_log_prob": -15.3411865234375, "count": 1}, {"pred": "i", "cond_log_prob": -9.80694580078125, "count": 1}, {"pred": "then", "cond_log_prob": -3.97796630859375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.24371337890625}, {"pred": "it", "count": 16, "cond_log_prob": -1.428436279296875}, {"pred": "itroute", "count": 1, "cond_log_prob": -29.482574462890625}, {"pred": "the", "count": 20, "cond_log_prob": -1.35357666015625}, {"pred": "then", "count": 1, "cond_log_prob": -3.97796630859375}]}, "52": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this excess heat, heat", "log_prob": -182.98348999023438}, "original": {"pred": "exhaustion", "cond_log_prob": -3.7639923095703125}, "human": [{"pred": "is", "cond_log_prob": -2.6522216796875, "count": 7}, {"pred": "begins", "cond_log_prob": -6.964874267578125, "count": 4}, {"pred": "builds", "cond_log_prob": -7.118682861328125, "count": 4}, {"pred": "stroke", "cond_log_prob": -5.856964111328125, "count": 4}, {"pred": "will", "cond_log_prob": -4.62677001953125, "count": 4}, {"pred": "becomes", "cond_log_prob": -5.694976806640625, "count": 2}, {"pred": "can", "cond_log_prob": -3.282318115234375, "count": 2}, {"pred": "overtakes", "cond_log_prob": -14.533538818359375, "count": 2}, {"pred": "rises", "cond_log_prob": -6.89617919921875, "count": 2}, {"pred": "starts", "cond_log_prob": -7.019989013671875, "count": 2}, {"pred": "exhaustion", "cond_log_prob": -3.764404296875, "count": 1}, {"pred": "explodes", "cond_log_prob": -11.400390625, "count": 1}, {"pred": "finds", "cond_log_prob": -11.449859619140625, "count": 1}, {"pred": "got", "cond_log_prob": -11.95703125, "count": 1}, {"pred": "overcomes", "cond_log_prob": -12.451416015625, "count": 1}, {"pred": "overpowers", "cond_log_prob": -14.839569091796875, "count": 1}, {"pred": "remains", "cond_log_prob": -6.768890380859375, "count": 1}, {"pred": "takes", "cond_log_prob": -8.400238037109375, "count": 1}, {"pred": "tends", "cond_log_prob": -6.556793212890625, "count": 1}, {"pred": "then", "cond_log_prob": -9.012542724609375, "count": 1}], "ancestral_samples": [{"pred": "buildup", "count": 1, "cond_log_prob": -5.562744140625}, {"pred": "can", "count": 1, "cond_log_prob": -3.282318115234375}, {"pred": "damage", "count": 1, "cond_log_prob": -4.6212158203125}, {"pred": "damages", "count": 1, "cond_log_prob": -4.90179443359375}, {"pred": "dissipation", "count": 2, "cond_log_prob": -3.73284912109375}, {"pred": "escapes", "count": 1, "cond_log_prob": -5.836090087890625}, {"pred": "exchangers", "count": 1, "cond_log_prob": -5.470245361328125}, {"pred": "is", "count": 14, "cond_log_prob": -2.6522216796875}, {"pred": "isroute", "count": 1, "cond_log_prob": -26.963714599609375}, {"pred": "loss", "count": 4, "cond_log_prob": -3.127838134765625}, {"pred": "production", "count": 1, "cond_log_prob": -4.633544921875}, {"pred": "reactions", "count": 2, "cond_log_prob": -3.183441162109375}, {"pred": "related", "count": 3, "cond_log_prob": -6.509368896484375}, {"pred": "releasing", "count": 1, "cond_log_prob": -8.117767333984375}, {"pred": "sensitive", "count": 2, "cond_log_prob": -6.870269775390625}, {"pred": "transfer", "count": 1, "cond_log_prob": -4.895294189453125}, {"pred": "transport", "count": 1, "cond_log_prob": -5.259613037109375}, {"pred": "waves", "count": 1, "cond_log_prob": -5.264617919921875}, {"pred": "will", "count": 1, "cond_log_prob": -4.62677001953125}]}, "53": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this excess heat, heat exhaustion", "log_prob": -186.7474822998047}, "original": {"pred": "and", "cond_log_prob": -3.522857666015625}, "human": [{"pred": "occurs", "cond_log_prob": -2.4839630126953125, "count": 13}, {"pred": "can", "cond_log_prob": -1.4618988037109375, "count": 9}, {"pred": "and", "cond_log_prob": -3.5232696533203125, "count": 2}, {"pred": "becomes", "cond_log_prob": -3.9396209716796875, "count": 2}, {"pred": "begins", "cond_log_prob": -4.1230926513671875, "count": 2}, {"pred": "ensues", "cond_log_prob": -5.2920989990234375, "count": 2}, {"pred": "may", "cond_log_prob": -2.1150054931640625, "count": 2}, {"pred": "often", "cond_log_prob": -3.8534088134765625, "count": 2}, {"pred": "sets", "cond_log_prob": -6.7284393310546875, "count": 2}, {"pred": "comes", "cond_log_prob": -6.9718170166015625, "count": 1}, {"pred": "happens", "cond_log_prob": -6.4872283935546875, "count": 1}, {"pred": "is", "cond_log_prob": -1.9524383544921875, "count": 1}, {"pred": "kicks", "cond_log_prob": -8.127487182617188, "count": 1}, {"pred": "or", "cond_log_prob": -3.8865509033203125, "count": 1}, {"pred": "results", "cond_log_prob": -3.7032012939453125, "count": 1}, {"pred": "will", "cond_log_prob": -4.0200042724609375, "count": 1}], "ancestral_samples": [{"pred": "becomes", "count": 1, "cond_log_prob": -3.9396209716796875}, {"pred": "can", "count": 18, "cond_log_prob": -1.4618988037109375}, {"pred": "canroute", "count": 1, "cond_log_prob": -25.362014770507812}, {"pred": "develops", "count": 1, "cond_log_prob": -3.9477386474609375}, {"pred": "is", "count": 9, "cond_log_prob": -1.9524383544921875}, {"pred": "leads", "count": 1, "cond_log_prob": -4.1024017333984375}, {"pred": "may", "count": 6, "cond_log_prob": -2.1150054931640625}, {"pred": "occurs", "count": 1, "cond_log_prob": -2.4839630126953125}, {"pred": "occursHeat", "count": 1, "cond_log_prob": -26.522842407226562}, {"pred": "or", "count": 1, "cond_log_prob": -3.8865509033203125}]}, "54": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this excess heat, heat exhaustion and", "log_prob": -190.2703399658203}, "original": {"pred": "heat", "cond_log_prob": -2.2773895263671875}, "human": [{"pred": "heat", "cond_log_prob": -2.2778167724609375, "count": 11}, {"pred": "dehydration", "cond_log_prob": -2.0632781982421875, "count": 8}, {"pred": "death", "cond_log_prob": -3.7520904541015625, "count": 4}, {"pred": "fatigue", "cond_log_prob": -4.8962249755859375, "count": 4}, {"pred": "dehyrdation", "cond_log_prob": -33.73484802246094, "count": 3}, {"pred": "stroke", "cond_log_prob": -8.418563842773438, "count": 2}, {"pred": "the", "cond_log_prob": -3.7057647705078125, "count": 2}, {"pred": "damage", "cond_log_prob": -7.1091461181640625, "count": 1}, {"pred": "drowsiness", "cond_log_prob": -6.9417877197265625, "count": 1}, {"pred": "hyperthermia", "cond_log_prob": -5.0453338623046875, "count": 1}, {"pred": "may", "cond_log_prob": -8.862136840820312, "count": 1}, {"pred": "stress", "cond_log_prob": -5.9074554443359375, "count": 1}, {"pred": "sweat", "cond_log_prob": -6.1134796142578125, "count": 1}, {"pred": "sweating", "cond_log_prob": -3.7010345458984375, "count": 1}, {"pred": "then", "cond_log_prob": -7.3519744873046875, "count": 1}, {"pred": "tiredness", "cond_log_prob": -7.9227752685546875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.9281158447265625}, {"pred": "body", "count": 1, "cond_log_prob": -3.7116851806640625}, {"pred": "dehydration", "count": 24, "cond_log_prob": -2.0632781982421875}, {"pred": "dehydrationroute", "count": 1, "cond_log_prob": -24.898513793945312}, {"pred": "heat", "count": 7, "cond_log_prob": -2.2778167724609375}, {"pred": "hyperthermia", "count": 1, "cond_log_prob": -5.0453338623046875}, {"pred": "or", "count": 3, "cond_log_prob": -7.0799407958984375}, {"pred": "other", "count": 2, "cond_log_prob": -3.1392364501953125}]}, "55": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this excess heat, heat exhaustion and heat", "log_prob": -192.5477294921875}, "original": {"pred": "stroke", "cond_log_prob": -2.27325439453125}, "human": [{"pred": "stroke", "cond_log_prob": -2.273712158203125, "count": 25}, {"pred": "dehydration", "cond_log_prob": -7.942474365234375, "count": 2}, {"pred": "will", "cond_log_prob": -9.56072998046875, "count": 2}, {"pred": "absorption", "cond_log_prob": -7.3165283203125, "count": 1}, {"pred": "are", "cond_log_prob": -9.13818359375, "count": 1}, {"pred": "death", "cond_log_prob": -4.87567138671875, "count": 1}, {"pred": "exceptionalism", "cond_log_prob": -18.601882934570312, "count": 1}, {"pred": "fatigue", "cond_log_prob": -6.15283203125, "count": 1}, {"pred": "fever", "cond_log_prob": -8.550262451171875, "count": 1}, {"pred": "fluctuations", "cond_log_prob": -10.090301513671875, "count": 1}, {"pred": "is", "cond_log_prob": -7.543365478515625, "count": 1}, {"pred": "remains", "cond_log_prob": -12.27862548828125, "count": 1}, {"pred": "s", "cond_log_prob": -9.57037353515625, "count": 1}, {"pred": "something", "cond_log_prob": -14.9051513671875, "count": 1}, {"pred": "stoke", "cond_log_prob": -14.090362548828125, "count": 1}, {"pred": "strokes", "cond_log_prob": -8.06109619140625, "count": 1}, {"pred": "up", "cond_log_prob": -9.19354248046875, "count": 1}], "ancestral_samples": [{"pred": "exhaustion", "count": 19, "cond_log_prob": -1.814971923828125}, {"pred": "exhaustionroute", "count": 1, "cond_log_prob": -25.177886962890625}, {"pred": "related", "count": 4, "cond_log_prob": -4.704620361328125}, {"pred": "shock", "count": 11, "cond_log_prob": -2.067413330078125}, {"pred": "stroke", "count": 5, "cond_log_prob": -2.273712158203125}]}, "56": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this excess heat, heat exhaustion and heat stroke", "log_prob": -194.82098388671875}, "original": {"pred": "are", "cond_log_prob": -1.28326416015625}, "human": [{"pred": "can", "cond_log_prob": -1.440887451171875, "count": 10}, {"pred": "occur", "cond_log_prob": -2.72845458984375, "count": 8}, {"pred": "are", "cond_log_prob": -1.28375244140625, "count": 5}, {"pred": "may", "cond_log_prob": -2.1927642822265625, "count": 5}, {"pred": "will", "cond_log_prob": -4.445709228515625, "count": 4}, {"pred": "become", "cond_log_prob": -4.518829345703125, "count": 3}, {"pred": "begin", "cond_log_prob": -6.4298095703125, "count": 1}, {"pred": "come", "cond_log_prob": -7.42657470703125, "count": 1}, {"pred": "happens", "cond_log_prob": -8.546844482421875, "count": 1}, {"pred": "have", "cond_log_prob": -4.3187255859375, "count": 1}, {"pred": "occurs", "cond_log_prob": -4.697265625, "count": 1}, {"pred": "often", "cond_log_prob": -3.39349365234375, "count": 1}, {"pred": "reigns", "cond_log_prob": -13.677337646484375, "count": 1}, {"pred": "usually", "cond_log_prob": -4.1968536376953125, "count": 1}], "ancestral_samples": [{"pred": "are", "count": 23, "cond_log_prob": -1.28375244140625}, {"pred": "can", "count": 14, "cond_log_prob": -1.440887451171875}, {"pred": "canroute", "count": 1, "cond_log_prob": -25.377777099609375}, {"pred": "may", "count": 1, "cond_log_prob": -2.1927642822265625}, {"pred": "occurThe", "count": 1, "cond_log_prob": -16.424468994140625}]}, "57": {"context": {"text": "The human body can tolerate only a small range of temperature, especially when the person is engaged in vigorous activity. Heat reactions usually occur when large amounts of water and/or salt are lost through excessive sweating following strenuous exercise. When the body becomes overheated and cannot eliminate this excess heat, heat exhaustion and heat stroke are", "log_prob": -196.104248046875}, "original": {"pred": "possible.", "cond_log_prob": -4.1492462158203125}, "human": [{"pred": "likely", "cond_log_prob": -4.080596923828125, "count": 9}, {"pred": "possible", "cond_log_prob": -3.949493408203125, "count": 7}, {"pred": "common", "cond_log_prob": -2.507537841796875, "count": 4}, {"pred": "imminent", "cond_log_prob": -8.119110107421875, "count": 2}, {"pred": "inevitable", "cond_log_prob": -4.93975830078125, "count": 2}, {"pred": "able", "cond_log_prob": -7.827392578125, "count": 1}, {"pred": "at", "cond_log_prob": -5.683441162109375, "count": 1}, {"pred": "bad", "cond_log_prob": -8.753265380859375, "count": 1}, {"pred": "evident", "cond_log_prob": -9.610382080078125, "count": 1}, {"pred": "forced", "cond_log_prob": -9.77642822265625, "count": 1}, {"pred": "given", "cond_log_prob": -8.95233154296875, "count": 1}, {"pred": "happening", "cond_log_prob": -10.250030517578125, "count": 1}, {"pred": "highly", "cond_log_prob": -5.54931640625, "count": 1}, {"pred": "more", "cond_log_prob": -3.5789794921875, "count": 1}, {"pred": "not", "cond_log_prob": -4.30413818359375, "count": 1}, {"pred": "often", "cond_log_prob": -2.141754150390625, "count": 1}, {"pred": "probable", "cond_log_prob": -9.802215576171875, "count": 1}, {"pred": "problems", "cond_log_prob": -7.723388671875, "count": 1}, {"pred": "reasonable", "cond_log_prob": -10.76422119140625, "count": 1}, {"pred": "risks", "cond_log_prob": -9.229522705078125, "count": 1}, {"pred": "soon", "cond_log_prob": -8.46673583984375, "count": 1}, {"pred": "taken", "cond_log_prob": -8.784088134765625, "count": 1}, {"pred": "two", "cond_log_prob": -5.5059814453125, "count": 1}, {"pred": "very", "cond_log_prob": -4.46881103515625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.88348388671875}, {"pred": "common", "count": 3, "cond_log_prob": -2.507537841796875}, {"pred": "commonHeat", "count": 2, "cond_log_prob": -24.714080810546875}, {"pred": "commonThe", "count": 2, "cond_log_prob": -17.712646484375}, {"pred": "experiencedA", "count": 1, "cond_log_prob": -20.2557373046875}, {"pred": "most", "count": 1, "cond_log_prob": -3.766082763671875}, {"pred": "often", "count": 10, "cond_log_prob": -2.141754150390625}, {"pred": "the", "count": 17, "cond_log_prob": -2.150970458984375}, {"pred": "theroute", "count": 1, "cond_log_prob": -36.49810791015625}, {"pred": "usually", "count": 2, "cond_log_prob": -2.97271728515625}]}}, "9": {"2": {"context": {"text": "It", "log_prob": -8.75300407409668}, "original": {"pred": "was", "cond_log_prob": -2.2296066284179688}, "human": [{"pred": "is", "cond_log_prob": -2.277963638305664, "count": 16}, {"pred": "will", "cond_log_prob": -4.672029495239258, "count": 7}, {"pred": "was", "cond_log_prob": -2.2296085357666016, "count": 5}, {"pred": "has", "cond_log_prob": -3.5312747955322266, "count": 2}, {"pred": "may", "cond_log_prob": -4.624795913696289, "count": 2}, {"pred": "would", "cond_log_prob": -4.025056838989258, "count": 2}, {"pred": "behooves", "cond_log_prob": -10.517526626586914, "count": 1}, {"pred": "comes", "cond_log_prob": -6.480134963989258, "count": 1}, {"pred": "does", "cond_log_prob": -5.716936111450195, "count": 1}, {"pred": "happened", "cond_log_prob": -6.050058364868164, "count": 1}, {"pred": "happens", "cond_log_prob": -6.513368606567383, "count": 1}, {"pred": "likes", "cond_log_prob": -10.20292854309082, "count": 1}, {"pred": "seems", "cond_log_prob": -3.7516956329345703, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 3, "cond_log_prob": -9.622636795043945}, {"pred": "In", "count": 1, "cond_log_prob": -11.859643936157227}, {"pred": "The", "count": 1, "cond_log_prob": -11.504610061645508}, {"pred": "We", "count": 1, "cond_log_prob": -12.37071418762207}, {"pred": "a", "count": 1, "cond_log_prob": -9.398721694946289}, {"pred": "are", "count": 2, "cond_log_prob": -9.520875930786133}, {"pred": "however", "count": 1, "cond_log_prob": -12.675020217895508}, {"pred": "is", "count": 13, "cond_log_prob": -2.277963638305664}, {"pred": "isroutemotor", "count": 1, "cond_log_prob": -39.109222412109375}, {"pred": "s", "count": 7, "cond_log_prob": -9.794939041137695}, {"pred": "the", "count": 1, "cond_log_prob": -9.167886734008789}, {"pred": "to", "count": 1, "cond_log_prob": -9.608621597290039}, {"pred": "too", "count": 3, "cond_log_prob": -9.512002944946289}, {"pred": "was", "count": 4, "cond_log_prob": -2.2296085357666016}]}, "3": {"context": {"text": "It was", "log_prob": -10.982610702514648}, "original": {"pred": "a", "cond_log_prob": -1.8301067352294922}, "human": [{"pred": "a", "cond_log_prob": -1.8301639556884766, "count": 11}, {"pred": "the", "cond_log_prob": -2.820840835571289, "count": 7}, {"pred": "dark", "cond_log_prob": -7.43174934387207, "count": 3}, {"pred": "very", "cond_log_prob": -5.631937026977539, "count": 2}, {"pred": "alright", "cond_log_prob": -9.496110916137695, "count": 1}, {"pred": "big", "cond_log_prob": -7.939943313598633, "count": 1}, {"pred": "cold", "cond_log_prob": -7.62986946105957, "count": 1}, {"pred": "cool", "cond_log_prob": -7.889596939086914, "count": 1}, {"pred": "discovered", "cond_log_prob": -7.225847244262695, "count": 1}, {"pred": "funny", "cond_log_prob": -7.671098709106445, "count": 1}, {"pred": "good", "cond_log_prob": -6.527734756469727, "count": 1}, {"pred": "have", "cond_log_prob": -11.149660110473633, "count": 1}, {"pred": "long", "cond_log_prob": -6.29533576965332, "count": 1}, {"pred": "my", "cond_log_prob": -4.97191047668457, "count": 1}, {"pred": "not", "cond_log_prob": -3.757333755493164, "count": 1}, {"pred": "on", "cond_log_prob": -4.860811233520508, "count": 1}, {"pred": "only", "cond_log_prob": -3.6350879669189453, "count": 1}, {"pred": "recently", "cond_log_prob": -6.164911270141602, "count": 1}, {"pred": "said", "cond_log_prob": -5.214662551879883, "count": 1}, {"pred": "so", "cond_log_prob": -5.37553596496582, "count": 1}, {"pred": "then", "cond_log_prob": -5.543184280395508, "count": 1}, {"pred": "wonderful", "cond_log_prob": -8.392335891723633, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -7.69365119934082}, {"pred": "a", "count": 32, "cond_log_prob": -1.8301639556884766}, {"pred": "also", "count": 2, "cond_log_prob": -4.171358108520508}, {"pred": "aroute", "count": 1, "cond_log_prob": -24.606904983520508}, {"pred": "my", "count": 1, "cond_log_prob": -4.97191047668457}, {"pred": "not", "count": 1, "cond_log_prob": -3.757333755493164}, {"pred": "the", "count": 1, "cond_log_prob": -2.820840835571289}, {"pred": "then", "count": 1, "cond_log_prob": -5.543184280395508}]}, "4": {"context": {"text": "It was a", "log_prob": -12.81271743774414}, "original": {"pred": "forbidding", "cond_log_prob": -11.379402160644531}, "human": [{"pred": "dark", "cond_log_prob": -5.104854583740234, "count": 9}, {"pred": "cold", "cond_log_prob": -4.863079071044922, "count": 5}, {"pred": "beautiful", "cond_log_prob": -4.761806488037109, "count": 4}, {"pred": "great", "cond_log_prob": -4.356929779052734, "count": 3}, {"pred": "hard", "cond_log_prob": -5.487590789794922, "count": 3}, {"pred": "long", "cond_log_prob": -3.787944793701172, "count": 2}, {"pred": "surprise", "cond_log_prob": -5.661579132080078, "count": 2}, {"pred": "very", "cond_log_prob": -3.938182830810547, "count": 2}, {"pred": "big", "cond_log_prob": -4.200283050537109, "count": 1}, {"pred": "day", "cond_log_prob": -4.385585784912109, "count": 1}, {"pred": "freak", "cond_log_prob": -8.002788543701172, "count": 1}, {"pred": "mistake", "cond_log_prob": -6.417049407958984, "count": 1}, {"pred": "nice", "cond_log_prob": -5.059497833251953, "count": 1}, {"pred": "pleasure", "cond_log_prob": -6.712795257568359, "count": 1}, {"pred": "red", "cond_log_prob": -7.156948089599609, "count": 1}, {"pred": "small", "cond_log_prob": -5.117954254150391, "count": 1}, {"pred": "starry", "cond_log_prob": -11.21194839477539, "count": 1}, {"pred": "strange", "cond_log_prob": -4.562938690185547, "count": 1}, {"pred": "tall", "cond_log_prob": -6.863658905029297, "count": 1}], "ancestral_samples": [{"pred": "beautiful", "count": 1, "cond_log_prob": -4.761806488037109}, {"pred": "big", "count": 2, "cond_log_prob": -4.200283050537109}, {"pred": "bit", "count": 2, "cond_log_prob": -5.035594940185547}, {"pred": "day", "count": 1, "cond_log_prob": -4.385585784912109}, {"pred": "good", "count": 3, "cond_log_prob": -3.780803680419922}, {"pred": "goodroute", "count": 1, "cond_log_prob": -22.802188873291016}, {"pred": "great", "count": 7, "cond_log_prob": -4.356929779052734}, {"pred": "happy", "count": 1, "cond_log_prob": -6.337825775146484}, {"pred": "little", "count": 1, "cond_log_prob": -4.893260955810547}, {"pred": "long", "count": 1, "cond_log_prob": -3.787944793701172}, {"pred": "lot", "count": 2, "cond_log_prob": -5.194446563720703}, {"pred": "real", "count": 1, "cond_log_prob": -6.002140045166016}, {"pred": "strange", "count": 1, "cond_log_prob": -4.562938690185547}, {"pred": "terrible", "count": 3, "cond_log_prob": -5.729564666748047}, {"pred": "very", "count": 13, "cond_log_prob": -3.938182830810547}]}, "5": {"context": {"text": "It was a forbidding", "log_prob": -24.192119598388672}, "original": {"pred": "challenge,", "cond_log_prob": -10.728618621826172}, "human": [{"pred": "night", "cond_log_prob": -2.3654327392578125, "count": 6}, {"pred": "and", "cond_log_prob": -3.764129638671875, "count": 4}, {"pred": "day", "cond_log_prob": -2.36798095703125, "count": 3}, {"pred": "place", "cond_log_prob": -4.477989196777344, "count": 3}, {"pred": "time", "cond_log_prob": -4.1475372314453125, "count": 3}, {"pred": "sign", "cond_log_prob": -6.986328125, "count": 2}, {"pred": "example", "cond_log_prob": -8.372406005859375, "count": 1}, {"pred": "feeling", "cond_log_prob": -5.57635498046875, "count": 1}, {"pred": "forest", "cond_log_prob": -7.4544525146484375, "count": 1}, {"pred": "grade", "cond_log_prob": -9.86627197265625, "count": 1}, {"pred": "love", "cond_log_prob": -7.9777374267578125, "count": 1}, {"pred": "message", "cond_log_prob": -7.9384765625, "count": 1}, {"pred": "moment", "cond_log_prob": -4.068084716796875, "count": 1}, {"pred": "omen", "cond_log_prob": -9.328811645507812, "count": 1}, {"pred": "path", "cond_log_prob": -8.531524658203125, "count": 1}, {"pred": "scene", "cond_log_prob": -3.950164794921875, "count": 1}, {"pred": "school", "cond_log_prob": -7.525726318359375, "count": 1}, {"pred": "spider", "cond_log_prob": -11.962646484375, "count": 1}, {"pred": "task", "cond_log_prob": -7.8050994873046875, "count": 1}, {"pred": "thought", "cond_log_prob": -5.595878601074219, "count": 1}, {"pred": "to", "cond_log_prob": -8.057769775390625, "count": 1}, {"pred": "tone", "cond_log_prob": -7.620574951171875, "count": 1}, {"pred": "voice", "cond_log_prob": -8.494010925292969, "count": 1}, {"pred": "when", "cond_log_prob": -10.361091613769531, "count": 1}, {"pred": "wind", "cond_log_prob": -5.8866424560546875, "count": 1}, {"pred": "word", "cond_log_prob": -7.9735107421875, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.941299438476562}, {"pred": "afternoon", "count": 1, "cond_log_prob": -3.9929351806640625}, {"pred": "and", "count": 6, "cond_log_prob": -3.764129638671875}, {"pred": "atmosphere", "count": 2, "cond_log_prob": -4.786750793457031}, {"pred": "chilly", "count": 1, "cond_log_prob": -8.513298034667969}, {"pred": "day", "count": 10, "cond_log_prob": -2.36798095703125}, {"pred": "dayroute", "count": 1, "cond_log_prob": -24.11516571044922}, {"pred": "experience", "count": 2, "cond_log_prob": -4.955596923828125}, {"pred": "moment", "count": 2, "cond_log_prob": -4.068084716796875}, {"pred": "night", "count": 3, "cond_log_prob": -2.3654327392578125}, {"pred": "place", "count": 3, "cond_log_prob": -4.477989196777344}, {"pred": "quiet", "count": 1, "cond_log_prob": -6.9465789794921875}, {"pred": "scene", "count": 2, "cond_log_prob": -3.950164794921875}, {"pred": "situation", "count": 2, "cond_log_prob": -5.410026550292969}, {"pred": "unBiblical", "count": 1, "cond_log_prob": -22.955883026123047}, {"pred": "unending", "count": 1, "cond_log_prob": -14.067211151123047}, {"pred": "unruly", "count": 1, "cond_log_prob": -13.720638275146484}]}, "6": {"context": {"text": "It was a forbidding challenge,", "log_prob": -34.920738220214844}, "original": {"pred": "and", "cond_log_prob": -2.172515869140625}, "human": [{"pred": "but", "cond_log_prob": -1.4987754821777344, "count": 16}, {"pred": "to", "cond_log_prob": -4.539798736572266, "count": 7}, {"pred": "the", "cond_log_prob": -3.7972984313964844, "count": 4}, {"pred": "eating", "cond_log_prob": -10.838138580322266, "count": 2}, {"pred": "which", "cond_log_prob": -4.482448577880859, "count": 2}, {"pred": "even", "cond_log_prob": -5.131313323974609, "count": 1}, {"pred": "i", "cond_log_prob": -9.10416030883789, "count": 2}, {"pred": "it", "cond_log_prob": -5.446689605712891, "count": 1}, {"pred": "looking", "cond_log_prob": -7.658046722412109, "count": 1}, {"pred": "that", "cond_log_prob": -5.537654876708984, "count": 1}, {"pred": "unfortunately", "cond_log_prob": -9.39346694946289, "count": 1}, {"pred": "walking", "cond_log_prob": -10.214969635009766, "count": 1}, {"pred": "we", "cond_log_prob": -7.394489288330078, "count": 1}, {"pred": "when", "cond_log_prob": -6.083240509033203, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -2.8257789611816406}, {"pred": "and", "count": 15, "cond_log_prob": -2.1726417541503906}, {"pred": "but", "count": 20, "cond_log_prob": -1.4987754821777344}, {"pred": "butroutecom", "count": 1, "cond_log_prob": -36.25859832763672}, {"pred": "not", "count": 1, "cond_log_prob": -3.954364776611328}]}, "7": {"context": {"text": "It was a forbidding challenge, and", "log_prob": -37.09325408935547}, "original": {"pred": "it", "cond_log_prob": -2.5777664184570312}, "human": [{"pred": "i", "cond_log_prob": -10.002338409423828, "count": 5}, {"pred": "it", "cond_log_prob": -2.5778541564941406, "count": 4}, {"pred": "the", "cond_log_prob": -1.9537544250488281, "count": 4}, {"pred": "they", "cond_log_prob": -4.724674224853516, "count": 4}, {"pred": "a", "cond_log_prob": -3.4383277893066406, "count": 3}, {"pred": "we", "cond_log_prob": -4.740390777587891, "count": 3}, {"pred": "he", "cond_log_prob": -3.2349281311035156, "count": 2}, {"pred": "many", "cond_log_prob": -5.946109771728516, "count": 2}, {"pred": "as", "cond_log_prob": -4.646694183349609, "count": 1}, {"pred": "came", "cond_log_prob": -7.565769195556641, "count": 1}, {"pred": "chester", "cond_log_prob": -20.08890151977539, "count": 1}, {"pred": "fernando", "cond_log_prob": -18.794998168945312, "count": 1}, {"pred": "few", "cond_log_prob": -7.750980377197266, "count": 1}, {"pred": "no", "cond_log_prob": -4.678058624267578, "count": 1}, {"pred": "none", "cond_log_prob": -6.303623199462891, "count": 1}, {"pred": "testing", "cond_log_prob": -11.984119415283203, "count": 1}, {"pred": "that", "cond_log_prob": -4.572727203369141, "count": 1}, {"pred": "those", "cond_log_prob": -6.284137725830078, "count": 1}, {"pred": "to", "cond_log_prob": -5.432697296142578, "count": 1}, {"pred": "was", "cond_log_prob": -5.637302398681641, "count": 1}, {"pred": "what", "cond_log_prob": -6.179004669189453, "count": 1}, {"pred": "when", "cond_log_prob": -4.568386077880859, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 8, "cond_log_prob": -3.1996498107910156}, {"pred": "Im", "count": 1, "cond_log_prob": -9.947834014892578}, {"pred": "Ive", "count": 1, "cond_log_prob": -15.066761016845703}, {"pred": "a", "count": 3, "cond_log_prob": -3.4383277893066406}, {"pred": "he", "count": 3, "cond_log_prob": -3.2349281311035156}, {"pred": "it", "count": 3, "cond_log_prob": -2.5778541564941406}, {"pred": "itrouteed", "count": 1, "cond_log_prob": -32.82159423828125}, {"pred": "my", "count": 1, "cond_log_prob": -5.275501251220703}, {"pred": "she", "count": 1, "cond_log_prob": -3.9302101135253906}, {"pred": "the", "count": 17, "cond_log_prob": -1.9537544250488281}, {"pred": "then", "count": 1, "cond_log_prob": -4.796863555908203}]}, "8": {"context": {"text": "It was a forbidding challenge, and it", "log_prob": -39.6710205078125}, "original": {"pred": "says", "cond_log_prob": -9.001670837402344}, "human": [{"pred": "was", "cond_log_prob": -1.2810554504394531, "count": 17}, {"pred": "looked", "cond_log_prob": -4.717960357666016, "count": 2}, {"pred": "seemed", "cond_log_prob": -3.7106971740722656, "count": 2}, {"pred": "would", "cond_log_prob": -3.6488075256347656, "count": 2}, {"pred": "a", "cond_log_prob": -9.213214874267578, "count": 1}, {"pred": "also", "cond_log_prob": -5.369556427001953, "count": 1}, {"pred": "came", "cond_log_prob": -4.066715240478516, "count": 1}, {"pred": "causes", "cond_log_prob": -11.93729019165039, "count": 1}, {"pred": "confused", "cond_log_prob": -10.04251480102539, "count": 1}, {"pred": "could", "cond_log_prob": -4.745563507080078, "count": 1}, {"pred": "did", "cond_log_prob": -3.8408546447753906, "count": 1}, {"pred": "essay", "cond_log_prob": -15.599300384521484, "count": 1}, {"pred": "happened", "cond_log_prob": -6.166728973388672, "count": 1}, {"pred": "is", "cond_log_prob": -4.792728424072266, "count": 1}, {"pred": "killed", "cond_log_prob": -7.654132843017578, "count": 1}, {"pred": "made", "cond_log_prob": -4.548877716064453, "count": 1}, {"pred": "often", "cond_log_prob": -6.967288970947266, "count": 1}, {"pred": "only", "cond_log_prob": -5.188449859619141, "count": 1}, {"pred": "posed", "cond_log_prob": -7.459873199462891, "count": 1}, {"pred": "tested", "cond_log_prob": -7.926288604736328, "count": 1}, {"pred": "that", "cond_log_prob": -9.29989242553711, "count": 1}, {"pred": "took", "cond_log_prob": -3.841625213623047, "count": 1}], "ancestral_samples": [{"pred": "did", "count": 1, "cond_log_prob": -3.8408546447753906}, {"pred": "is", "count": 1, "cond_log_prob": -4.792728424072266}, {"pred": "s", "count": 1, "cond_log_prob": -8.904346466064453}, {"pred": "was", "count": 35, "cond_log_prob": -1.2810554504394531}, {"pred": "wasnt", "count": 1, "cond_log_prob": -12.244220733642578}, {"pred": "wasroute", "count": 1, "cond_log_prob": -23.973766326904297}]}, "9": {"context": {"text": "It was a forbidding challenge, and it says", "log_prob": -48.672691345214844}, "original": {"pred": "much", "cond_log_prob": -3.6256866455078125}, "human": [{"pred": "that", "cond_log_prob": -2.8224220275878906, "count": 26}, {"pred": "a", "cond_log_prob": -2.400104522705078, "count": 3}, {"pred": "it", "cond_log_prob": -2.6828880310058594, "count": 2}, {"pred": "the", "cond_log_prob": -3.3198890686035156, "count": 2}, {"pred": "all", "cond_log_prob": -5.551212310791016, "count": 1}, {"pred": "do", "cond_log_prob": -10.15311050415039, "count": 1}, {"pred": "many", "cond_log_prob": -5.992252349853516, "count": 1}, {"pred": "much", "cond_log_prob": -3.6257972717285156, "count": 1}, {"pred": "not", "cond_log_prob": -6.664958953857422, "count": 1}, {"pred": "only", "cond_log_prob": -5.889713287353516, "count": 1}, {"pred": "to", "cond_log_prob": -5.952747344970703, "count": 1}, {"pred": "when", "cond_log_prob": -7.142017364501953, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -8.947986602783203}, {"pred": "a", "count": 13, "cond_log_prob": -2.400104522705078}, {"pred": "it", "count": 1, "cond_log_prob": -2.6828880310058594}, {"pred": "little", "count": 3, "cond_log_prob": -3.087200164794922}, {"pred": "more", "count": 2, "cond_log_prob": -2.802898406982422}, {"pred": "much", "count": 1, "cond_log_prob": -3.6257972717285156}, {"pred": "nothing", "count": 6, "cond_log_prob": -2.2157325744628906}, {"pred": "nothingroute", "count": 1, "cond_log_prob": -31.933448791503906}, {"pred": "so", "count": 2, "cond_log_prob": -2.6478233337402344}, {"pred": "something", "count": 7, "cond_log_prob": -2.609668731689453}, {"pred": "that", "count": 2, "cond_log_prob": -2.8224220275878906}, {"pred": "the", "count": 1, "cond_log_prob": -3.3198890686035156}]}, "10": {"context": {"text": "It was a forbidding challenge, and it says much", "log_prob": -52.298377990722656}, "original": {"pred": "for", "cond_log_prob": -4.065399169921875}, "human": [{"pred": "about", "cond_log_prob": -0.2621116638183594, "count": 36}, {"pred": "of", "cond_log_prob": -2.9230308532714844, "count": 2}, {"pred": "for", "cond_log_prob": -4.065540313720703, "count": 1}, {"pred": "money", "cond_log_prob": -10.959918975830078, "count": 1}, {"pred": "to", "cond_log_prob": -5.103816986083984, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -11.62228775024414}, {"pred": "about", "count": 38, "cond_log_prob": -0.2621421813964844}, {"pred": "aboutroutes", "count": 1, "cond_log_prob": -22.976791381835938}]}, "11": {"context": {"text": "It was a forbidding challenge, and it says much for", "log_prob": -56.36377716064453}, "original": {"pred": "Winstanley's", "cond_log_prob": -14.753044128417969}, "human": [{"pred": "the", "cond_log_prob": -1.0112342834472656, "count": 24}, {"pred": "those", "cond_log_prob": -4.744106292724609, "count": 4}, {"pred": "a", "cond_log_prob": -3.6521873474121094, "count": 1}, {"pred": "all", "cond_log_prob": -5.775470733642578, "count": 1}, {"pred": "allowing", "cond_log_prob": -9.996192932128906, "count": 1}, {"pred": "him", "cond_log_prob": -5.965473175048828, "count": 1}, {"pred": "his", "cond_log_prob": -3.741718292236328, "count": 1}, {"pred": "me", "cond_log_prob": -6.440509796142578, "count": 1}, {"pred": "participants", "cond_log_prob": -11.556190490722656, "count": 1}, {"pred": "people", "cond_log_prob": -7.618907928466797, "count": 1}, {"pred": "success", "cond_log_prob": -8.746498107910156, "count": 1}, {"pred": "them", "cond_log_prob": -7.264080047607422, "count": 1}, {"pred": "what", "cond_log_prob": -3.5388221740722656, "count": 1}, {"pred": "who", "cond_log_prob": -6.478527069091797, "count": 1}, {"pred": "you", "cond_log_prob": -7.866035461425781, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.652210235595703}, {"pred": "the", "count": 38, "cond_log_prob": -1.0112571716308594}, {"pred": "theroutes", "count": 1, "cond_log_prob": -28.07353973388672}]}, "12": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's", "log_prob": -71.1168212890625}, "original": {"pred": "persuasive", "cond_log_prob": -8.832237243652344}, "human": [{"pred": "character", "cond_log_prob": -3.7761993408203125, "count": 5}, {"pred": "courage", "cond_log_prob": -6.4882965087890625, "count": 4}, {"pred": "ability", "cond_log_prob": -4.313934326171875, "count": 2}, {"pred": "theory", "cond_log_prob": -6.1920166015625, "count": 2}, {"pred": "approach", "cond_log_prob": -5.582183837890625, "count": 1}, {"pred": "argument", "cond_log_prob": -5.961029052734375, "count": 1}, {"pred": "confidence", "cond_log_prob": -5.100738525390625, "count": 1}, {"pred": "crew", "cond_log_prob": -10.767410278320312, "count": 1}, {"pred": "cup", "cond_log_prob": -11.401992797851562, "count": 1}, {"pred": "drug", "cond_log_prob": -8.963272094726562, "count": 1}, {"pred": "family", "cond_log_prob": -7.4890899658203125, "count": 1}, {"pred": "hopes", "cond_log_prob": -5.9167022705078125, "count": 1}, {"pred": "intelligence", "cond_log_prob": -7.717254638671875, "count": 1}, {"pred": "life", "cond_log_prob": -5.99029541015625, "count": 1}, {"pred": "magic", "cond_log_prob": -8.6844482421875, "count": 1}, {"pred": "mom", "cond_log_prob": -10.612564086914062, "count": 1}, {"pred": "money", "cond_log_prob": -10.180343627929688, "count": 1}, {"pred": "oral", "cond_log_prob": -9.198760986328125, "count": 1}, {"pred": "passion", "cond_log_prob": -7.4264373779296875, "count": 1}, {"pred": "people", "cond_log_prob": -9.703765869140625, "count": 1}, {"pred": "perseverance", "cond_log_prob": -6.4871063232421875, "count": 1}, {"pred": "purple", "cond_log_prob": -11.846588134765625, "count": 1}, {"pred": "resilience", "cond_log_prob": -6.7609405517578125, "count": 1}, {"pred": "skill", "cond_log_prob": -6.847442626953125, "count": 1}, {"pred": "soldiers", "cond_log_prob": -10.673675537109375, "count": 1}, {"pred": "speech", "cond_log_prob": -7.6338043212890625, "count": 1}, {"pred": "statement", "cond_log_prob": -6.98553466796875, "count": 1}, {"pred": "strength", "cond_log_prob": -6.76776123046875, "count": 1}, {"pred": "talent", "cond_log_prob": -7.22491455078125, "count": 1}, {"pred": "thoery", "cond_log_prob": -22.182830810546875, "count": 1}, {"pred": "win", "cond_log_prob": -7.4785614013671875, "count": 1}, {"pred": "wish", "cond_log_prob": -8.635116577148438, "count": 1}], "ancestral_samples": [{"pred": "ability", "count": 5, "cond_log_prob": -4.313934326171875}, {"pred": "career", "count": 1, "cond_log_prob": -4.814178466796875}, {"pred": "character", "count": 9, "cond_log_prob": -3.7761993408203125}, {"pred": "commitment", "count": 1, "cond_log_prob": -5.49017333984375}, {"pred": "decision", "count": 2, "cond_log_prob": -4.5448760986328125}, {"pred": "early", "count": 1, "cond_log_prob": -5.358978271484375}, {"pred": "faith", "count": 1, "cond_log_prob": -5.1598358154296875}, {"pred": "faithroute", "count": 1, "cond_log_prob": -25.352706909179688}, {"pred": "hopes", "count": 1, "cond_log_prob": -5.9167022705078125}, {"pred": "legacy", "count": 1, "cond_log_prob": -5.5007171630859375}, {"pred": "past", "count": 1, "cond_log_prob": -6.38983154296875}, {"pred": "political", "count": 1, "cond_log_prob": -5.9304046630859375}, {"pred": "proclivity", "count": 1, "cond_log_prob": -8.683685302734375}, {"pred": "professional", "count": 1, "cond_log_prob": -7.272064208984375}, {"pred": "reputation", "count": 6, "cond_log_prob": -4.0697479248046875}, {"pred": "reputationBut", "count": 1, "cond_log_prob": -21.087387084960938}, {"pred": "standing", "count": 1, "cond_log_prob": -5.9889984130859375}, {"pred": "status", "count": 1, "cond_log_prob": -5.9083099365234375}, {"pred": "story", "count": 1, "cond_log_prob": -4.592559814453125}, {"pred": "willingness", "count": 2, "cond_log_prob": -5.9520263671875}, {"pred": "workAs", "count": 1, "cond_log_prob": -18.2603759765625}]}, "13": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive", "log_prob": -79.94905853271484}, "original": {"pred": "abilities,", "cond_log_prob": -7.9342498779296875}, "human": [{"pred": "argument", "cond_log_prob": -3.8708419799804688, "count": 4}, {"pred": "attitude", "cond_log_prob": -7.571586608886719, "count": 3}, {"pred": "writing", "cond_log_prob": -4.665046691894531, "count": 3}, {"pred": "ability", "cond_log_prob": -3.8192062377929688, "count": 2}, {"pred": "nature", "cond_log_prob": -6.077384948730469, "count": 2}, {"pred": "personality", "cond_log_prob": -5.286872863769531, "count": 2}, {"pred": "powers", "cond_log_prob": -5.662330627441406, "count": 2}, {"pred": "prowess", "cond_log_prob": -5.882225036621094, "count": 2}, {"pred": "stance", "cond_log_prob": -7.437355041503906, "count": 2}, {"pred": "abilities", "cond_log_prob": -4.617195129394531, "count": 1}, {"pred": "and", "cond_log_prob": -3.2411422729492188, "count": 1}, {"pred": "arguments", "cond_log_prob": -4.156059265136719, "count": 1}, {"pred": "art", "cond_log_prob": -5.758369445800781, "count": 1}, {"pred": "as", "cond_log_prob": -6.680824279785156, "count": 1}, {"pred": "aura", "cond_log_prob": -7.840995788574219, "count": 1}, {"pred": "character", "cond_log_prob": -3.1592483520507812, "count": 1}, {"pred": "charm", "cond_log_prob": -5.455604553222656, "count": 1}, {"pred": "essay", "cond_log_prob": -7.411476135253906, "count": 1}, {"pred": "language", "cond_log_prob": -6.902046203613281, "count": 1}, {"pred": "methods", "cond_log_prob": -6.651557922363281, "count": 1}, {"pred": "oratory", "cond_log_prob": -8.031929016113281, "count": 1}, {"pred": "reasoning", "cond_log_prob": -6.347190856933594, "count": 1}, {"pred": "skills", "cond_log_prob": -3.8812332153320312, "count": 1}, {"pred": "speaking", "cond_log_prob": -8.299079895019531, "count": 1}, {"pred": "speech", "cond_log_prob": -5.392280578613281, "count": 1}, {"pred": "speeches", "cond_log_prob": -6.401786804199219, "count": 1}, {"pred": "ways", "cond_log_prob": -7.941490173339844, "count": 1}, {"pred": "words", "cond_log_prob": -5.856239318847656, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -11.299507141113281}, {"pred": "ability", "count": 4, "cond_log_prob": -3.8192062377929688}, {"pred": "and", "count": 8, "cond_log_prob": -3.2411422729492188}, {"pred": "appealBut", "count": 1, "cond_log_prob": -20.14305877685547}, {"pred": "argument", "count": 2, "cond_log_prob": -3.8708419799804688}, {"pred": "arguments", "count": 2, "cond_log_prob": -4.156059265136719}, {"pred": "case", "count": 1, "cond_log_prob": -4.139091491699219}, {"pred": "character", "count": 9, "cond_log_prob": -3.1592483520507812}, {"pred": "characterThe", "count": 1, "cond_log_prob": -15.950355529785156}, {"pred": "characterroute", "count": 1, "cond_log_prob": -24.75585174560547}, {"pred": "persuasive", "count": 1, "cond_log_prob": -5.538185119628906}, {"pred": "power", "count": 1, "cond_log_prob": -3.9769668579101562}, {"pred": "proclamations", "count": 1, "cond_log_prob": -8.160743713378906}, {"pred": "skills", "count": 3, "cond_log_prob": -3.8812332153320312}, {"pred": "style", "count": 3, "cond_log_prob": -3.9262619018554688}, {"pred": "writing", "count": 1, "cond_log_prob": -4.665046691894531}]}, "14": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities,", "log_prob": -87.88330841064453}, "original": {"pred": "not", "cond_log_prob": -4.506843566894531}, "human": [{"pred": "that", "cond_log_prob": -4.436058044433594, "count": 16}, {"pred": "but", "cond_log_prob": -2.3379135131835938, "count": 5}, {"pred": "and", "cond_log_prob": -3.0116806030273438, "count": 3}, {"pred": "he", "cond_log_prob": -6.006401062011719, "count": 2}, {"pred": "to", "cond_log_prob": -4.962104797363281, "count": 2}, {"pred": "which", "cond_log_prob": -1.8461380004882812, "count": 2}, {"pred": "also", "cond_log_prob": -7.563438415527344, "count": 1}, {"pred": "be", "cond_log_prob": -8.445732116699219, "count": 1}, {"pred": "because", "cond_log_prob": -5.321388244628906, "count": 1}, {"pred": "considering", "cond_log_prob": -6.632759094238281, "count": 1}, {"pred": "for", "cond_log_prob": -5.757530212402344, "count": 1}, {"pred": "giving", "cond_log_prob": -7.628273010253906, "count": 1}, {"pred": "granted", "cond_log_prob": -10.191322326660156, "count": 1}, {"pred": "however", "cond_log_prob": -6.036567687988281, "count": 1}, {"pred": "seeing", "cond_log_prob": -7.693168640136719, "count": 1}, {"pred": "showing", "cond_log_prob": -6.734931945800781, "count": 1}, {"pred": "when", "cond_log_prob": -5.583061218261719, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.361091613769531}, {"pred": "and", "count": 2, "cond_log_prob": -3.0116806030273438}, {"pred": "as", "count": 7, "cond_log_prob": -2.5770187377929688}, {"pred": "but", "count": 3, "cond_log_prob": -2.3379135131835938}, {"pred": "especially", "count": 1, "cond_log_prob": -3.1071395874023438}, {"pred": "her", "count": 2, "cond_log_prob": -4.567070007324219}, {"pred": "which", "count": 22, "cond_log_prob": -1.8461380004882812}, {"pred": "whichroute", "count": 1, "cond_log_prob": -22.82416534423828}, {"pred": "who", "count": 1, "cond_log_prob": -4.797966003417969}]}, "15": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not", "log_prob": -92.39015197753906}, "original": {"pred": "to", "cond_log_prob": -1.6622238159179688}, "human": [{"pred": "to", "cond_log_prob": -1.6623687744140625, "count": 13}, {"pred": "his", "cond_log_prob": -2.54510498046875, "count": 4}, {"pred": "that", "cond_log_prob": -3.798736572265625, "count": 4}, {"pred": "only", "cond_log_prob": -2.3051605224609375, "count": 3}, {"pred": "the", "cond_log_prob": -3.1544952392578125, "count": 3}, {"pred": "because", "cond_log_prob": -4.4715728759765625, "count": 2}, {"pred": "for", "cond_log_prob": -4.4244842529296875, "count": 2}, {"pred": "about", "cond_log_prob": -7.6788482666015625, "count": 1}, {"pred": "allowing", "cond_log_prob": -10.593948364257812, "count": 1}, {"pred": "as", "cond_log_prob": -6.1702728271484375, "count": 1}, {"pred": "by", "cond_log_prob": -6.7049407958984375, "count": 1}, {"pred": "forgetting", "cond_log_prob": -9.482772827148438, "count": 1}, {"pred": "including", "cond_log_prob": -9.020965576171875, "count": 1}, {"pred": "many", "cond_log_prob": -6.7671356201171875, "count": 1}, {"pred": "meaning", "cond_log_prob": -12.233688354492188, "count": 1}, {"pred": "much", "cond_log_prob": -7.341400146484375, "count": 1}, {"pred": "once", "cond_log_prob": -7.5320587158203125, "count": 1}], "ancestral_samples": [{"pred": "her", "count": 1, "cond_log_prob": -3.7723846435546875}, {"pred": "his", "count": 6, "cond_log_prob": -2.54510498046875}, {"pred": "least", "count": 9, "cond_log_prob": -1.4079742431640625}, {"pred": "leastroute", "count": 1, "cond_log_prob": -26.79736328125}, {"pred": "only", "count": 3, "cond_log_prob": -2.3051605224609375}, {"pred": "the", "count": 2, "cond_log_prob": -3.1544952392578125}, {"pred": "to", "count": 18, "cond_log_prob": -1.6623687744140625}]}, "16": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to", "log_prob": -94.05237579345703}, "original": {"pred": "mention", "cond_log_prob": -0.08939361572265625}, "human": [{"pred": "mention", "cond_log_prob": -0.08956146240234375, "count": 13}, {"pred": "be", "cond_log_prob": -5.381156921386719, "count": 6}, {"pred": "say", "cond_log_prob": -3.9473953247070312, "count": 4}, {"pred": "give", "cond_log_prob": -7.595329284667969, "count": 2}, {"pred": "take", "cond_log_prob": -7.680824279785156, "count": 2}, {"pred": "undermine", "cond_log_prob": -10.691307067871094, "count": 2}, {"pred": "allow", "cond_log_prob": -9.315483093261719, "count": 1}, {"pred": "avoid", "cond_log_prob": -10.322822570800781, "count": 1}, {"pred": "boast", "cond_log_prob": -9.065376281738281, "count": 1}, {"pred": "discourage", "cond_log_prob": -11.689888000488281, "count": 1}, {"pred": "go", "cond_log_prob": -8.062705993652344, "count": 1}, {"pred": "help", "cond_log_prob": -9.739021301269531, "count": 1}, {"pred": "make", "cond_log_prob": -7.503105163574219, "count": 1}, {"pred": "murder", "cond_log_prob": -12.726890563964844, "count": 1}, {"pred": "participate", "cond_log_prob": -12.423164367675781, "count": 1}, {"pred": "put", "cond_log_prob": -6.579887390136719, "count": 1}, {"pred": "suggest", "cond_log_prob": -7.158348083496094, "count": 1}], "ancestral_samples": [{"pred": "mention", "count": 39, "cond_log_prob": -0.08956146240234375}, {"pred": "mentionroute", "count": 1, "cond_log_prob": -21.66443634033203}]}, "17": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention", "log_prob": -94.14176940917969}, "original": {"pred": "his", "cond_log_prob": -0.9209976196289062}, "human": [{"pred": "his", "cond_log_prob": -0.921173095703125, "count": 14}, {"pred": "the", "cond_log_prob": -1.940582275390625, "count": 14}, {"pred": "he", "cond_log_prob": -6.5479736328125, "count": 5}, {"pred": "that", "cond_log_prob": -2.93060302734375, "count": 3}, {"pred": "it", "cond_log_prob": -6.4095611572265625, "count": 1}, {"pred": "lean", "cond_log_prob": -12.668289184570312, "count": 1}, {"pred": "talent", "cond_log_prob": -9.338653564453125, "count": 1}, {"pred": "those", "cond_log_prob": -5.346466064453125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.3724822998046875}, {"pred": "her", "count": 5, "cond_log_prob": -1.6663665771484375}, {"pred": "his", "count": 31, "cond_log_prob": -0.921173095703125}, {"pred": "hisroute", "count": 1, "cond_log_prob": -22.092987060546875}, {"pred": "the", "count": 2, "cond_log_prob": -1.940582275390625}]}, "18": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his", "log_prob": -95.0627670288086}, "original": {"pred": "self-confidence,", "cond_log_prob": -10.17474365234375}, "human": [{"pred": "ability", "cond_log_prob": -2.9887313842773438, "count": 7}, {"pred": "courage", "cond_log_prob": -6.345527648925781, "count": 3}, {"pred": "cunning", "cond_log_prob": -6.830421447753906, "count": 2}, {"pred": "very", "cond_log_prob": -7.197334289550781, "count": 2}, {"pred": "accident", "cond_log_prob": -11.712654113769531, "count": 1}, {"pred": "accomplishments", "cond_log_prob": -7.268043518066406, "count": 1}, {"pred": "aptitude", "cond_log_prob": -6.656379699707031, "count": 1}, {"pred": "as", "cond_log_prob": -8.560951232910156, "count": 1}, {"pred": "beautiful", "cond_log_prob": -8.557929992675781, "count": 1}, {"pred": "character", "cond_log_prob": -5.738670349121094, "count": 1}, {"pred": "confidence", "cond_log_prob": -6.271507263183594, "count": 1}, {"pred": "egocentric", "cond_log_prob": -11.443305969238281, "count": 1}, {"pred": "fat", "cond_log_prob": -10.560401916503906, "count": 1}, {"pred": "father", "cond_log_prob": -7.770210266113281, "count": 1}, {"pred": "friend", "cond_log_prob": -8.453056335449219, "count": 1}, {"pred": "grandiose", "cond_log_prob": -8.998603820800781, "count": 1}, {"pred": "great", "cond_log_prob": -5.853752136230469, "count": 1}, {"pred": "hot", "cond_log_prob": -9.480567932128906, "count": 1}, {"pred": "incident", "cond_log_prob": -12.037513732910156, "count": 1}, {"pred": "intelligent", "cond_log_prob": -8.056129455566406, "count": 1}, {"pred": "lack", "cond_log_prob": -5.978126525878906, "count": 1}, {"pred": "other", "cond_log_prob": -6.978797912597656, "count": 1}, {"pred": "outrageous", "cond_log_prob": -8.951744079589844, "count": 1}, {"pred": "persuasive", "cond_log_prob": -6.284019470214844, "count": 1}, {"pred": "powerful", "cond_log_prob": -6.877540588378906, "count": 1}, {"pred": "ridiculous", "cond_log_prob": -9.220893859863281, "count": 1}, {"pred": "secret", "cond_log_prob": -9.918891906738281, "count": 1}, {"pred": "struggle", "cond_log_prob": -8.813987731933594, "count": 1}, {"pred": "talent", "cond_log_prob": -5.702613830566406, "count": 1}, {"pred": "wicked", "cond_log_prob": -8.224327087402344, "count": 1}], "ancestral_samples": [{"pred": "ability", "count": 27, "cond_log_prob": -2.9887313842773438}, {"pred": "creative", "count": 1, "cond_log_prob": -6.592689514160156}, {"pred": "great", "count": 1, "cond_log_prob": -5.853752136230469}, {"pred": "knowledge", "count": 1, "cond_log_prob": -5.423667907714844}, {"pred": "persistence", "count": 1, "cond_log_prob": -6.478904724121094}, {"pred": "persuasive", "count": 1, "cond_log_prob": -6.284019470214844}, {"pred": "proclivity", "count": 1, "cond_log_prob": -8.197319030761719}, {"pred": "professional", "count": 1, "cond_log_prob": -7.154228210449219}, {"pred": "understandingroute", "count": 1, "cond_log_prob": -30.84333038330078}, {"pred": "wellcrafted", "count": 1, "cond_log_prob": -16.21569061279297}, {"pred": "wellregarded", "count": 1, "cond_log_prob": -19.431007385253906}, {"pred": "willingness", "count": 3, "cond_log_prob": -4.512779235839844}]}, "19": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence,", "log_prob": -105.23751068115234}, "original": {"pred": "that", "cond_log_prob": -1.6519012451171875}, "human": [{"pred": "that", "cond_log_prob": -1.6521072387695312, "count": 11}, {"pred": "and", "cond_log_prob": -3.1853713989257812, "count": 7}, {"pred": "he", "cond_log_prob": -5.859062194824219, "count": 6}, {"pred": "but", "cond_log_prob": -3.5641250610351562, "count": 3}, {"pred": "which", "cond_log_prob": -2.1728897094726562, "count": 2}, {"pred": "aka", "cond_log_prob": -13.430107116699219, "count": 1}, {"pred": "although", "cond_log_prob": -6.964164733886719, "count": 1}, {"pred": "arrogance", "cond_log_prob": -8.629692077636719, "count": 1}, {"pred": "be", "cond_log_prob": -8.507637023925781, "count": 1}, {"pred": "charm", "cond_log_prob": -5.418525695800781, "count": 1}, {"pred": "good", "cond_log_prob": -6.351142883300781, "count": 1}, {"pred": "however", "cond_log_prob": -7.123664855957031, "count": 1}, {"pred": "intelligence", "cond_log_prob": -5.661003112792969, "count": 1}, {"pred": "stubbornness", "cond_log_prob": -8.911323547363281, "count": 1}, {"pred": "the", "cond_log_prob": -4.357093811035156, "count": 1}, {"pred": "these", "cond_log_prob": -9.526084899902344, "count": 1}], "ancestral_samples": [{"pred": "in", "count": 1, "cond_log_prob": -3.1793136596679688}, {"pred": "that", "count": 19, "cond_log_prob": -1.6521072387695312}, {"pred": "thatroute", "count": 1, "cond_log_prob": -22.30107879638672}, {"pred": "to", "count": 14, "cond_log_prob": -2.2545242309570312}, {"pred": "which", "count": 5, "cond_log_prob": -2.1728897094726562}]}, "20": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that", "log_prob": -106.88941192626953}, "original": {"pred": "the", "cond_log_prob": -4.623924255371094}, "human": [{"pred": "he", "cond_log_prob": -3.4527511596679688, "count": 21}, {"pred": "is", "cond_log_prob": -5.411338806152344, "count": 3}, {"pred": "helped", "cond_log_prob": -3.1917648315429688, "count": 2}, {"pred": "the", "cond_log_prob": -4.624137878417969, "count": 2}, {"pred": "was", "cond_log_prob": -5.088676452636719, "count": 2}, {"pred": "as", "cond_log_prob": -7.523841857910156, "count": 1}, {"pred": "caused", "cond_log_prob": -6.739768981933594, "count": 1}, {"pred": "exuded", "cond_log_prob": -10.628807067871094, "count": 1}, {"pred": "had", "cond_log_prob": -5.079124450683594, "count": 1}, {"pred": "has", "cond_log_prob": -4.207466125488281, "count": 1}, {"pred": "his", "cond_log_prob": -5.744300842285156, "count": 1}, {"pred": "inevitably", "cond_log_prob": -10.140327453613281, "count": 1}, {"pred": "persuaded", "cond_log_prob": -4.757789611816406, "count": 1}, {"pred": "showed", "cond_log_prob": -7.043464660644531, "count": 1}, {"pred": "sucks", "cond_log_prob": -14.929328918457031, "count": 1}], "ancestral_samples": [{"pred": "earned", "count": 1, "cond_log_prob": -3.9187698364257812}, {"pred": "gave", "count": 1, "cond_log_prob": -4.172981262207031}, {"pred": "he", "count": 6, "cond_log_prob": -3.4527511596679688}, {"pred": "helped", "count": 2, "cond_log_prob": -3.1917648315429688}, {"pred": "heroute", "count": 1, "cond_log_prob": -24.22020721435547}, {"pred": "inspired", "count": 1, "cond_log_prob": -4.790687561035156}, {"pred": "led", "count": 4, "cond_log_prob": -3.2047042846679688}, {"pred": "made", "count": 17, "cond_log_prob": -2.2939834594726562}, {"pred": "she", "count": 2, "cond_log_prob": -4.054847717285156}, {"pred": "ultimately", "count": 2, "cond_log_prob": -5.122688293457031}, {"pred": "was", "count": 1, "cond_log_prob": -5.088676452636719}, {"pred": "won", "count": 2, "cond_log_prob": -3.6067123413085938}]}, "21": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the", "log_prob": -111.51333618164062}, "original": {"pred": "admiralty", "cond_log_prob": -12.898887634277344}, "human": [{"pred": "challenge", "cond_log_prob": -5.9456939697265625, "count": 15}, {"pred": "people", "cond_log_prob": -6.510406494140625, "count": 3}, {"pred": "as", "cond_log_prob": -10.539443969726562, "count": 1}, {"pred": "best", "cond_log_prob": -5.6208343505859375, "count": 1}, {"pred": "brothers", "cond_log_prob": -8.867355346679688, "count": 1}, {"pred": "can", "cond_log_prob": -10.113784790039062, "count": 1}, {"pred": "cannibals", "cond_log_prob": -12.144546508789062, "count": 1}, {"pred": "clock", "cond_log_prob": -8.914230346679688, "count": 1}, {"pred": "difficulty", "cond_log_prob": -8.332504272460938, "count": 1}, {"pred": "doctor", "cond_log_prob": -7.481048583984375, "count": 1}, {"pred": "girls", "cond_log_prob": -7.1932220458984375, "count": 1}, {"pred": "kids", "cond_log_prob": -7.978668212890625, "count": 1}, {"pred": "king", "cond_log_prob": -7.756439208984375, "count": 1}, {"pred": "men", "cond_log_prob": -6.1667327880859375, "count": 1}, {"pred": "opponent", "cond_log_prob": -7.648956298828125, "count": 1}, {"pred": "other", "cond_log_prob": -5.7523040771484375, "count": 1}, {"pred": "perfect", "cond_log_prob": -9.042083740234375, "count": 1}, {"pred": "person", "cond_log_prob": -7.410430908203125, "count": 1}, {"pred": "players", "cond_log_prob": -7.0863037109375, "count": 1}, {"pred": "press", "cond_log_prob": -7.7655029296875, "count": 1}, {"pred": "professor", "cond_log_prob": -7.0053253173828125, "count": 1}, {"pred": "rest", "cond_log_prob": -6.2212066650390625, "count": 1}, {"pred": "treat", "cond_log_prob": -11.204254150390625, "count": 1}, {"pred": "world", "cond_log_prob": -5.6909027099609375, "count": 1}], "ancestral_samples": [{"pred": "Chicago", "count": 1, "cond_log_prob": -8.183029174804688}, {"pred": "Tories", "count": 1, "cond_log_prob": -7.970916748046875}, {"pred": "audience", "count": 1, "cond_log_prob": -5.8131561279296875}, {"pred": "book", "count": 9, "cond_log_prob": -4.24322509765625}, {"pred": "books", "count": 1, "cond_log_prob": -7.5755615234375}, {"pred": "challenge", "count": 1, "cond_log_prob": -5.9456939697265625}, {"pred": "company", "count": 1, "cond_log_prob": -6.8468170166015625}, {"pred": "court", "count": 1, "cond_log_prob": -4.7659759521484375}, {"pred": "courts", "count": 1, "cond_log_prob": -6.8351593017578125}, {"pred": "day", "count": 1, "cond_log_prob": -6.613433837890625}, {"pred": "film", "count": 1, "cond_log_prob": -4.8209228515625}, {"pred": "films", "count": 2, "cond_log_prob": -8.95989990234375}, {"pred": "governmentroute", "count": 1, "cond_log_prob": -26.79302978515625}, {"pred": "investigators", "count": 1, "cond_log_prob": -8.505661010742188}, {"pred": "judges", "count": 3, "cond_log_prob": -5.195709228515625}, {"pred": "jury", "count": 2, "cond_log_prob": -4.693359375}, {"pred": "man", "count": 1, "cond_log_prob": -4.6865234375}, {"pred": "most", "count": 1, "cond_log_prob": -5.449859619140625}, {"pred": "other", "count": 1, "cond_log_prob": -5.7523040771484375}, {"pred": "police", "count": 1, "cond_log_prob": -6.26422119140625}, {"pred": "prodigy", "count": 1, "cond_log_prob": -9.784164428710938}, {"pred": "public", "count": 1, "cond_log_prob": -6.1703033447265625}, {"pred": "shows", "count": 1, "cond_log_prob": -10.623931884765625}, {"pred": "state", "count": 1, "cond_log_prob": -5.6955108642578125}, {"pred": "team", "count": 1, "cond_log_prob": -5.622314453125}, {"pred": "trial", "count": 1, "cond_log_prob": -5.90753173828125}, {"pred": "whole", "count": 1, "cond_log_prob": -6.0140380859375}, {"pred": "young", "count": 1, "cond_log_prob": -4.8915863037109375}]}, "22": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty", "log_prob": -124.41222381591797}, "original": {"pred": "agreed", "cond_log_prob": -7.729255676269531}, "human": [{"pred": "of", "cond_log_prob": -5.931648254394531, "count": 21}, {"pred": "and", "cond_log_prob": -5.394081115722656, "count": 2}, {"pred": "did", "cond_log_prob": -4.775871276855469, "count": 2}, {"pred": "gave", "cond_log_prob": -5.680976867675781, "count": 2}, {"pred": "was", "cond_log_prob": -2.5995559692382812, "count": 2}, {"pred": "accepted", "cond_log_prob": -6.413887023925781, "count": 1}, {"pred": "attempted", "cond_log_prob": -7.609596252441406, "count": 1}, {"pred": "be", "cond_log_prob": -8.627479553222656, "count": 1}, {"pred": "difficult", "cond_log_prob": -12.944938659667969, "count": 1}, {"pred": "had", "cond_log_prob": -2.9513626098632812, "count": 1}, {"pred": "he", "cond_log_prob": -7.492225646972656, "count": 1}, {"pred": "listened", "cond_log_prob": -9.480186462402344, "count": 1}, {"pred": "predominantly", "cond_log_prob": -15.486686706542969, "count": 1}, {"pred": "thought", "cond_log_prob": -7.583015441894531, "count": 1}, {"pred": "trusted", "cond_log_prob": -9.630058288574219, "count": 1}, {"pred": "wow", "cond_log_prob": -15.549186706542969, "count": 1}], "ancestral_samples": [{"pred": "did", "count": 1, "cond_log_prob": -4.775871276855469}, {"pred": "had", "count": 5, "cond_log_prob": -2.9513626098632812}, {"pred": "is", "count": 1, "cond_log_prob": -4.443504333496094}, {"pred": "refusedroute", "count": 1, "cond_log_prob": -23.29572296142578}, {"pred": "s", "count": 13, "cond_log_prob": -8.649772644042969}, {"pred": "secretary", "count": 1, "cond_log_prob": -3.5817337036132812}, {"pred": "secretarys", "count": 1, "cond_log_prob": -14.011085510253906}, {"pred": "was", "count": 17, "cond_log_prob": -2.5995559692382812}]}, "23": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed", "log_prob": -132.1414794921875}, "original": {"pred": "to", "cond_log_prob": -0.5322113037109375}, "human": [{"pred": "to", "cond_log_prob": -0.532470703125, "count": 19}, {"pred": "that", "cond_log_prob": -3.2430572509765625, "count": 4}, {"pred": "with", "cond_log_prob": -1.8973541259765625, "count": 4}, {"pred": "he", "cond_log_prob": -4.9714202880859375, "count": 2}, {"pred": "upon", "cond_log_prob": -6.54034423828125, "count": 2}, {"pred": "challenge", "cond_log_prob": -15.06585693359375, "count": 1}, {"pred": "completely", "cond_log_prob": -10.355621337890625, "count": 1}, {"pred": "could", "cond_log_prob": -9.344146728515625, "count": 1}, {"pred": "his", "cond_log_prob": -6.50811767578125, "count": 1}, {"pred": "not", "cond_log_prob": -3.8073577880859375, "count": 1}, {"pred": "on", "cond_log_prob": -5.0427093505859375, "count": 1}, {"pred": "people", "cond_log_prob": -12.09234619140625, "count": 1}, {"pred": "really", "cond_log_prob": -12.016204833984375, "count": 1}, {"pred": "the", "cond_log_prob": -5.1490478515625, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -10.84979248046875}, {"pred": "not", "count": 1, "cond_log_prob": -3.8073577880859375}, {"pred": "to", "count": 35, "cond_log_prob": -0.532470703125}, {"pred": "toroute", "count": 1, "cond_log_prob": -27.2681884765625}, {"pred": "with", "count": 2, "cond_log_prob": -1.8973541259765625}]}, "24": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to", "log_prob": -132.67369079589844}, "original": {"pred": "fund", "cond_log_prob": -6.5177764892578125}, "human": [{"pred": "give", "cond_log_prob": -4.1006622314453125, "count": 4}, {"pred": "allow", "cond_log_prob": -3.391937255859375, "count": 3}, {"pred": "do", "cond_log_prob": -5.312286376953125, "count": 3}, {"pred": "accept", "cond_log_prob": -3.5760345458984375, "count": 2}, {"pred": "change", "cond_log_prob": -7.0176544189453125, "count": 2}, {"pred": "his", "cond_log_prob": -4.035491943359375, "count": 2}, {"pred": "say", "cond_log_prob": -8.717636108398438, "count": 2}, {"pred": "as", "cond_log_prob": -9.400833129882812, "count": 1}, {"pred": "assassinate", "cond_log_prob": -10.254043579101562, "count": 1}, {"pred": "attempt", "cond_log_prob": -8.88336181640625, "count": 1}, {"pred": "attend", "cond_log_prob": -6.815765380859375, "count": 1}, {"pred": "become", "cond_log_prob": -7.08721923828125, "count": 1}, {"pred": "bestow", "cond_log_prob": -9.603744506835938, "count": 1}, {"pred": "deem", "cond_log_prob": -11.303237915039062, "count": 1}, {"pred": "fund", "cond_log_prob": -6.5180511474609375, "count": 1}, {"pred": "go", "cond_log_prob": -5.39263916015625, "count": 1}, {"pred": "grant", "cond_log_prob": -4.29290771484375, "count": 1}, {"pred": "help", "cond_log_prob": -4.649078369140625, "count": 1}, {"pred": "invest", "cond_log_prob": -7.0217742919921875, "count": 1}, {"pred": "look", "cond_log_prob": -7.150634765625, "count": 1}, {"pred": "make", "cond_log_prob": -4.7392578125, "count": 1}, {"pred": "not", "cond_log_prob": -6.5782470703125, "count": 1}, {"pred": "order", "cond_log_prob": -7.2776336669921875, "count": 1}, {"pred": "promote", "cond_log_prob": -8.293563842773438, "count": 1}, {"pred": "reward", "cond_log_prob": -7.371185302734375, "count": 1}, {"pred": "see", "cond_log_prob": -6.5511474609375, "count": 1}, {"pred": "spare", "cond_log_prob": -6.6221923828125, "count": 1}, {"pred": "the", "cond_log_prob": -2.89215087890625, "count": 1}, {"pred": "this", "cond_log_prob": -5.9192657470703125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -10.660751342773438}, {"pred": "a", "count": 5, "cond_log_prob": -3.6414947509765625}, {"pred": "accept", "count": 2, "cond_log_prob": -3.5760345458984375}, {"pred": "allow", "count": 3, "cond_log_prob": -3.391937255859375}, {"pred": "block", "count": 1, "cond_log_prob": -6.3697509765625}, {"pred": "continue", "count": 1, "cond_log_prob": -5.927337646484375}, {"pred": "deal", "count": 1, "cond_log_prob": -6.4868316650390625}, {"pred": "give", "count": 1, "cond_log_prob": -4.1006622314453125}, {"pred": "her", "count": 2, "cond_log_prob": -4.6604461669921875}, {"pred": "its", "count": 1, "cond_log_prob": -4.9095916748046875}, {"pred": "keep", "count": 1, "cond_log_prob": -4.1848907470703125}, {"pred": "let", "count": 1, "cond_log_prob": -3.5071258544921875}, {"pred": "pay", "count": 2, "cond_log_prob": -3.3832550048828125}, {"pred": "protect", "count": 1, "cond_log_prob": -4.917449951171875}, {"pred": "put", "count": 1, "cond_log_prob": -4.773193359375}, {"pred": "send", "count": 3, "cond_log_prob": -3.5940093994140625}, {"pred": "sendroute", "count": 1, "cond_log_prob": -23.856369018554688}, {"pred": "take", "count": 4, "cond_log_prob": -3.8904571533203125}, {"pred": "the", "count": 8, "cond_log_prob": -2.89215087890625}]}, "25": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund", "log_prob": -139.19146728515625}, "original": {"pred": "him.", "cond_log_prob": -3.6954345703125}, "human": [{"pred": "the", "cond_log_prob": -1.106170654296875, "count": 17}, {"pred": "his", "cond_log_prob": -1.905181884765625, "count": 16}, {"pred": "him", "cond_log_prob": -2.6192169189453125, "count": 3}, {"pred": "a", "cond_log_prob": -2.6357269287109375, "count": 2}, {"pred": "for", "cond_log_prob": -7.1142578125, "count": 1}, {"pred": "is", "cond_log_prob": -9.9881591796875, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.2916259765625}, {"pred": "a", "count": 3, "cond_log_prob": -2.6357269287109375}, {"pred": "herThe", "count": 1, "cond_log_prob": -15.822906494140625}, {"pred": "himThe", "count": 1, "cond_log_prob": -16.92132568359375}, {"pred": "his", "count": 4, "cond_log_prob": -1.905181884765625}, {"pred": "the", "count": 29, "cond_log_prob": -1.106170654296875}, {"pred": "theroute", "count": 1, "cond_log_prob": -29.768707275390625}]}, "26": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him.", "log_prob": -142.88690185546875}, "original": {"pred": "No", "cond_log_prob": -5.88580322265625}, "human": [{"pred": "he", "cond_log_prob": -10.64190673828125, "count": 12}, {"pred": "however", "cond_log_prob": -15.06207275390625, "count": 4}, {"pred": "the", "cond_log_prob": -9.394439697265625, "count": 3}, {"pred": "for", "cond_log_prob": -11.17022705078125, "count": 2}, {"pred": "it", "cond_log_prob": -12.1624755859375, "count": 2}, {"pred": "winstanley", "cond_log_prob": -13.854446411132812, "count": 2}, {"pred": "?", "cond_log_prob": -11.442901611328125, "count": 1}, {"pred": "because", "cond_log_prob": -12.9571533203125, "count": 1}, {"pred": "fernando", "cond_log_prob": -22.141586303710938, "count": 1}, {"pred": "if", "cond_log_prob": -12.44171142578125, "count": 1}, {"pred": "in", "cond_log_prob": -10.406097412109375, "count": 1}, {"pred": "luckily", "cond_log_prob": -21.3758544921875, "count": 1}, {"pred": "no", "cond_log_prob": -13.548492431640625, "count": 1}, {"pred": "now", "cond_log_prob": -13.828826904296875, "count": 1}, {"pred": "so", "cond_log_prob": -12.592498779296875, "count": 1}, {"pred": "taking", "cond_log_prob": -19.26165771484375, "count": 1}, {"pred": "that", "cond_log_prob": -12.0494384765625, "count": 1}, {"pred": "they", "cond_log_prob": -14.238922119140625, "count": 2}, {"pred": "what", "cond_log_prob": -13.869140625, "count": 1}, {"pred": "wow", "cond_log_prob": -17.990203857421875, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -4.420135498046875}, {"pred": "He", "count": 4, "cond_log_prob": -2.96514892578125}, {"pred": "I", "count": 11, "cond_log_prob": -5.68157958984375}, {"pred": "Im", "count": 1, "cond_log_prob": -10.083740234375}, {"pred": "In", "count": 2, "cond_log_prob": -3.4873046875}, {"pred": "It", "count": 2, "cond_log_prob": -3.54339599609375}, {"pred": "The", "count": 14, "cond_log_prob": -2.705352783203125}, {"pred": "There", "count": 1, "cond_log_prob": -5.530242919921875}, {"pred": "They", "count": 1, "cond_log_prob": -5.74078369140625}, {"pred": "We", "count": 1, "cond_log_prob": -6.536163330078125}, {"pred": "Winstanley", "count": 1, "cond_log_prob": -4.117340087890625}, {"pred": "route", "count": 1, "cond_log_prob": -21.52899169921875}]}, "27": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No", "log_prob": -148.772705078125}, "original": {"pred": "lighthouse", "cond_log_prob": -11.229690551757812}, "human": [{"pred": "one", "cond_log_prob": -1.73394775390625, "count": 15}, {"pred": "matter", "cond_log_prob": -3.2731781005859375, "count": 8}, {"pred": "other", "cond_log_prob": -3.31951904296875, "count": 3}, {"pred": "person", "cond_log_prob": -7.087249755859375, "count": 3}, {"pred": "he", "cond_log_prob": -8.72216796875, "count": 2}, {"pred": "aliens", "cond_log_prob": -11.640914916992188, "count": 1}, {"pred": "amount", "cond_log_prob": -5.586334228515625, "count": 1}, {"pred": "body", "cond_log_prob": -7.856842041015625, "count": 1}, {"pred": "doubt", "cond_log_prob": -2.480712890625, "count": 1}, {"pred": "forever", "cond_log_prob": -14.519058227539062, "count": 1}, {"pred": "longer", "cond_log_prob": -4.607452392578125, "count": 1}, {"pred": "more", "cond_log_prob": -3.8810577392578125, "count": 1}, {"pred": "previous", "cond_log_prob": -7.935577392578125, "count": 1}, {"pred": "way", "cond_log_prob": -6.267791748046875, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 1, "cond_log_prob": -8.508712768554688}, {"pred": "doubt", "count": 7, "cond_log_prob": -2.480712890625}, {"pred": "money", "count": 1, "cond_log_prob": -5.644744873046875}, {"pred": "one", "count": 25, "cond_log_prob": -1.73394775390625}, {"pred": "oneroute", "count": 1, "cond_log_prob": -23.48626708984375}, {"pred": "other", "count": 3, "cond_log_prob": -3.31951904296875}, {"pred": "such", "count": 1, "cond_log_prob": -4.044189453125}, {"pred": "wonder", "count": 1, "cond_log_prob": -3.4066619873046875}]}, "28": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse", "log_prob": -160.0023956298828}, "original": {"pred": "had", "cond_log_prob": -2.7542877197265625}, "human": [{"pred": "was", "cond_log_prob": -2.20941162109375, "count": 7}, {"pred": "could", "cond_log_prob": -3.9029693603515625, "count": 6}, {"pred": "in", "cond_log_prob": -3.249664306640625, "count": 5}, {"pred": "would", "cond_log_prob": -3.3714141845703125, "count": 5}, {"pred": "had", "cond_log_prob": -2.75457763671875, "count": 4}, {"pred": "can", "cond_log_prob": -4.55938720703125, "count": 2}, {"pred": "ever", "cond_log_prob": -5.3122100830078125, "count": 2}, {"pred": "existed", "cond_log_prob": -7.6522674560546875, "count": 2}, {"pred": "is", "cond_log_prob": -3.40631103515625, "count": 2}, {"pred": "guiding", "cond_log_prob": -11.0665283203125, "count": 1}, {"pred": "has", "cond_log_prob": -3.809906005859375, "count": 1}, {"pred": "i", "cond_log_prob": -10.97174072265625, "count": 1}, {"pred": "or", "cond_log_prob": -3.20947265625, "count": 1}, {"pred": "will", "cond_log_prob": -5.06048583984375, "count": 1}], "ancestral_samples": [{"pred": "No", "count": 1, "cond_log_prob": -10.349227905273438}, {"pred": "company", "count": 1, "cond_log_prob": -5.1209564208984375}, {"pred": "could", "count": 1, "cond_log_prob": -3.9029693603515625}, {"pred": "had", "count": 6, "cond_log_prob": -2.75457763671875}, {"pred": "in", "count": 4, "cond_log_prob": -3.249664306640625}, {"pred": "is", "count": 2, "cond_log_prob": -3.40631103515625}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.587921142578125}, {"pred": "no", "count": 2, "cond_log_prob": -9.19842529296875}, {"pred": "not", "count": 1, "cond_log_prob": -8.724105834960938}, {"pred": "or", "count": 2, "cond_log_prob": -3.20947265625}, {"pred": "was", "count": 18, "cond_log_prob": -2.20941162109375}, {"pred": "would", "count": 1, "cond_log_prob": -3.3714141845703125}]}, "29": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had", "log_prob": -162.75668334960938}, "original": {"pred": "ever", "cond_log_prob": -0.67864990234375}, "human": [{"pred": "ever", "cond_log_prob": -0.6789398193359375, "count": 17}, {"pred": "been", "cond_log_prob": -1.6185760498046875, "count": 9}, {"pred": "a", "cond_log_prob": -4.4346771240234375, "count": 3}, {"pred": "quite", "cond_log_prob": -7.3515167236328125, "count": 2}, {"pred": "the", "cond_log_prob": -4.7192230224609375, "count": 2}, {"pred": "any", "cond_log_prob": -5.4893035888671875, "count": 1}, {"pred": "as", "cond_log_prob": -6.7285003662109375, "count": 1}, {"pred": "bright", "cond_log_prob": -9.814315795898438, "count": 1}, {"pred": "given", "cond_log_prob": -6.5894012451171875, "count": 1}, {"pred": "have", "cond_log_prob": -10.267562866210938, "count": 1}, {"pred": "power", "cond_log_prob": -8.944992065429688, "count": 1}, {"pred": "seen", "cond_log_prob": -4.8707427978515625, "count": 1}], "ancestral_samples": [{"pred": "been", "count": 8, "cond_log_prob": -1.6185760498046875}, {"pred": "ever", "count": 31, "cond_log_prob": -0.6789398193359375}, {"pred": "everroute", "count": 1, "cond_log_prob": -22.759140014648438}]}, "30": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever", "log_prob": -163.43533325195312}, "original": {"pred": "been", "cond_log_prob": -0.5841522216796875}, "human": [{"pred": "been", "cond_log_prob": -0.5844573974609375, "count": 23}, {"pred": "before", "cond_log_prob": -5.4362335205078125, "count": 4}, {"pred": "seen", "cond_log_prob": -4.3117218017578125, "count": 2}, {"pred": "shone", "cond_log_prob": -7.3124847412109375, "count": 2}, {"pred": "beamed", "cond_log_prob": -11.585769653320312, "count": 1}, {"pred": "come", "cond_log_prob": -4.8946685791015625, "count": 1}, {"pred": "done", "cond_log_prob": -5.5884552001953125, "count": 1}, {"pred": "had", "cond_log_prob": -3.7967071533203125, "count": 1}, {"pred": "i", "cond_log_prob": -13.403488159179688, "count": 1}, {"pred": "reached", "cond_log_prob": -5.1728973388671875, "count": 1}, {"pred": "required", "cond_log_prob": -6.2190399169921875, "count": 1}, {"pred": "safely", "cond_log_prob": -9.764114379882812, "count": 1}, {"pred": "used", "cond_log_prob": -5.9097747802734375, "count": 1}], "ancestral_samples": [{"pred": "been", "count": 38, "cond_log_prob": -0.5844573974609375}, {"pred": "beenrouteed", "count": 1, "cond_log_prob": -29.280624389648438}, {"pred": "participated", "count": 1, "cond_log_prob": -8.591659545898438}]}, "31": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been", "log_prob": -164.0194854736328}, "original": {"pred": "built", "cond_log_prob": -0.790679931640625}, "human": [{"pred": "so", "cond_log_prob": -3.517364501953125, "count": 9}, {"pred": "built", "cond_log_prob": -0.790985107421875, "count": 7}, {"pred": "able", "cond_log_prob": -6.295654296875, "count": 2}, {"pred": "in", "cond_log_prob": -5.38238525390625, "count": 2}, {"pred": "lit", "cond_log_prob": -6.22967529296875, "count": 2}, {"pred": "allowed", "cond_log_prob": -7.0518798828125, "count": 1}, {"pred": "around", "cond_log_prob": -9.3116455078125, "count": 1}, {"pred": "as", "cond_log_prob": -5.926910400390625, "count": 1}, {"pred": "close", "cond_log_prob": -8.90655517578125, "count": 1}, {"pred": "constructed", "cond_log_prob": -2.916595458984375, "count": 1}, {"pred": "drawn", "cond_log_prob": -8.38861083984375, "count": 1}, {"pred": "erected", "cond_log_prob": -3.978912353515625, "count": 1}, {"pred": "funded", "cond_log_prob": -6.701416015625, "count": 1}, {"pred": "have", "cond_log_prob": -11.789947509765625, "count": 1}, {"pred": "present", "cond_log_prob": -10.194122314453125, "count": 1}, {"pred": "restored", "cond_log_prob": -6.88433837890625, "count": 1}, {"pred": "seen", "cond_log_prob": -5.235504150390625, "count": 1}, {"pred": "such", "cond_log_prob": -7.262786865234375, "count": 1}, {"pred": "that", "cond_log_prob": -7.368194580078125, "count": 1}, {"pred": "this", "cond_log_prob": -7.4034423828125, "count": 1}, {"pred": "to", "cond_log_prob": -7.0091552734375, "count": 1}, {"pred": "treated", "cond_log_prob": -9.22747802734375, "count": 1}, {"pred": "used", "cond_log_prob": -4.837860107421875, "count": 1}], "ancestral_samples": [{"pred": "built", "count": 36, "cond_log_prob": -0.790985107421875}, {"pred": "builtBut", "count": 1, "cond_log_prob": -18.49139404296875}, {"pred": "builtWin", "count": 1, "cond_log_prob": -25.596099853515625}, {"pred": "builtroute", "count": 1, "cond_log_prob": -43.378875732421875}, {"pred": "constructed", "count": 1, "cond_log_prob": -2.916595458984375}]}, "32": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built", "log_prob": -164.81016540527344}, "original": {"pred": "out", "cond_log_prob": -6.185333251953125}, "human": [{"pred": "in", "cond_log_prob": -1.9456787109375, "count": 10}, {"pred": "on", "cond_log_prob": -2.4329833984375, "count": 9}, {"pred": "like", "cond_log_prob": -4.5262451171875, "count": 4}, {"pred": "so", "cond_log_prob": -3.911834716796875, "count": 4}, {"pred": "that", "cond_log_prob": -4.168792724609375, "count": 3}, {"pred": "to", "cond_log_prob": -3.97015380859375, "count": 2}, {"pred": "with", "cond_log_prob": -3.86517333984375, "count": 2}, {"pred": "a", "cond_log_prob": -7.069366455078125, "count": 1}, {"pred": "after", "cond_log_prob": -5.85308837890625, "count": 1}, {"pred": "again", "cond_log_prob": -9.209136962890625, "count": 1}, {"pred": "at", "cond_log_prob": -4.280731201171875, "count": 1}, {"pred": "by", "cond_log_prob": -3.140625, "count": 1}, {"pred": "until", "cond_log_prob": -5.036346435546875, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.680572509765625}, {"pred": "and", "count": 8, "cond_log_prob": -3.789459228515625}, {"pred": "before", "count": 3, "cond_log_prob": -2.63226318359375}, {"pred": "beforeIn", "count": 1, "cond_log_prob": -17.188720703125}, {"pred": "beforeroute", "count": 1, "cond_log_prob": -23.563079833984375}, {"pred": "but", "count": 1, "cond_log_prob": -5.177978515625}, {"pred": "by", "count": 3, "cond_log_prob": -3.140625}, {"pred": "for", "count": 1, "cond_log_prob": -3.145751953125}, {"pred": "in", "count": 15, "cond_log_prob": -1.9456787109375}, {"pred": "on", "count": 4, "cond_log_prob": -2.4329833984375}, {"pred": "to", "count": 1, "cond_log_prob": -3.97015380859375}, {"pred": "without", "count": 1, "cond_log_prob": -3.702392578125}]}, "33": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out", "log_prob": -170.99549865722656}, "original": {"pred": "to", "cond_log_prob": -3.4451751708984375}, "human": [{"pred": "of", "cond_log_prob": -0.3055419921875, "count": 23}, {"pred": "in", "cond_log_prob": -3.288543701171875, "count": 4}, {"pred": "so", "cond_log_prob": -5.67266845703125, "count": 3}, {"pred": "to", "cond_log_prob": -3.445526123046875, "count": 2}, {"pred": "at", "cond_log_prob": -5.31060791015625, "count": 1}, {"pred": "by", "cond_log_prob": -5.8424072265625, "count": 1}, {"pred": "here", "cond_log_prob": -5.30242919921875, "count": 1}, {"pred": "life", "cond_log_prob": -13.77093505859375, "count": 1}, {"pred": "on", "cond_log_prob": -3.796661376953125, "count": 1}, {"pred": "that", "cond_log_prob": -6.32965087890625, "count": 1}, {"pred": "there", "cond_log_prob": -3.4342041015625, "count": 1}, {"pred": "west", "cond_log_prob": -4.778228759765625, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -10.5950927734375}, {"pred": "of", "count": 38, "cond_log_prob": -0.3055419921875}, {"pred": "ofroute", "count": 1, "cond_log_prob": -21.008880615234375}]}, "34": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to", "log_prob": -174.440673828125}, "original": {"pred": "sea", "cond_log_prob": -2.5489501953125}, "human": [{"pred": "the", "cond_log_prob": -2.0896453857421875, "count": 12}, {"pred": "sea", "cond_log_prob": -2.5493011474609375, "count": 8}, {"pred": "be", "cond_log_prob": -3.4461822509765625, "count": 3}, {"pred": "do", "cond_log_prob": -6.5064544677734375, "count": 1}, {"pred": "far", "cond_log_prob": -8.151016235351562, "count": 1}, {"pred": "grab", "cond_log_prob": -11.601058959960938, "count": 1}, {"pred": "help", "cond_log_prob": -6.2284393310546875, "count": 1}, {"pred": "illuminate", "cond_log_prob": -9.429733276367188, "count": 1}, {"pred": "increase", "cond_log_prob": -8.904342651367188, "count": 1}, {"pred": "man", "cond_log_prob": -7.1431121826171875, "count": 1}, {"pred": "protect", "cond_log_prob": -4.8935699462890625, "count": 1}, {"pred": "see", "cond_log_prob": -6.6263885498046875, "count": 1}, {"pred": "shore", "cond_log_prob": -5.4259490966796875, "count": 1}, {"pred": "state", "cond_log_prob": -10.092880249023438, "count": 1}, {"pred": "such", "cond_log_prob": -3.6561737060546875, "count": 1}, {"pred": "that", "cond_log_prob": -4.4955291748046875, "count": 1}, {"pred": "those", "cond_log_prob": -7.5109710693359375, "count": 1}, {"pred": "undergo", "cond_log_prob": -9.397384643554688, "count": 1}, {"pred": "warn", "cond_log_prob": -7.4717559814453125, "count": 1}, {"pred": "withstand", "cond_log_prob": -3.8137969970703125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 4, "cond_log_prob": -3.5807037353515625}, {"pred": "accommodate", "count": 4, "cond_log_prob": -3.7452392578125}, {"pred": "be", "count": 3, "cond_log_prob": -3.446197509765625}, {"pred": "sea", "count": 11, "cond_log_prob": -2.5493011474609375}, {"pred": "such", "count": 1, "cond_log_prob": -3.6561737060546875}, {"pred": "the", "count": 14, "cond_log_prob": -2.0896453857421875}, {"pred": "this", "count": 1, "cond_log_prob": -3.5392303466796875}, {"pred": "withstand", "count": 1, "cond_log_prob": -3.813812255859375}, {"pred": "withstandroute", "count": 1, "cond_log_prob": -25.679901123046875}]}, "35": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea", "log_prob": -176.9896240234375}, "original": {"pred": "on", "cond_log_prob": -4.0496826171875}, "human": [{"pred": "before", "cond_log_prob": -2.814300537109375, "count": 6}, {"pred": "that", "cond_log_prob": -5.419219970703125, "count": 6}, {"pred": "so", "cond_log_prob": -4.461761474609375, "count": 5}, {"pred": "and", "cond_log_prob": -3.3177490234375, "count": 3}, {"pred": "with", "cond_log_prob": -4.177947998046875, "count": 3}, {"pred": "like", "cond_log_prob": -5.2020263671875, "count": 2}, {"pred": "this", "cond_log_prob": -6.9150390625, "count": 2}, {"pred": "to", "cond_log_prob": -4.9127044677734375, "count": 2}, {"pred": "as", "cond_log_prob": -4.7643585205078125, "count": 1}, {"pred": "ever", "cond_log_prob": -8.210525512695312, "count": 1}, {"pred": "for", "cond_log_prob": -4.1232452392578125, "count": 1}, {"pred": "more", "cond_log_prob": -6.8192138671875, "count": 1}, {"pred": "overpowering", "cond_log_prob": -16.768142700195312, "count": 1}, {"pred": "prior", "cond_log_prob": -7.5705108642578125, "count": 1}, {"pred": "quite", "cond_log_prob": -8.69415283203125, "count": 1}, {"pred": "until", "cond_log_prob": -5.219940185546875, "count": 1}, {"pred": "when", "cond_log_prob": -6.5811004638671875, "count": 1}, {"pred": "where", "cond_log_prob": -6.770782470703125, "count": 1}, {"pred": "without", "cond_log_prob": -3.927398681640625, "count": 1}], "ancestral_samples": [{"pred": "But", "count": 1, "cond_log_prob": -12.698410034179688}, {"pred": "The", "count": 1, "cond_log_prob": -11.742950439453125}, {"pred": "and", "count": 28, "cond_log_prob": -3.3177490234375}, {"pred": "beforeIn", "count": 1, "cond_log_prob": -16.972702026367188}, {"pred": "beforeWin", "count": 1, "cond_log_prob": -15.167633056640625}, {"pred": "but", "count": 4, "cond_log_prob": -4.6598663330078125}, {"pred": "it", "count": 1, "cond_log_prob": -8.631729125976562}, {"pred": "route", "count": 1, "cond_log_prob": -13.185195922851562}, {"pred": "so", "count": 2, "cond_log_prob": -4.461761474609375}]}, "36": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on", "log_prob": -181.039306640625}, "original": {"pred": "an", "cond_log_prob": -3.9342498779296875}, "human": [{"pred": "the", "cond_log_prob": -1.7174835205078125, "count": 11}, {"pred": "a", "cond_log_prob": -1.839691162109375, "count": 10}, {"pred": "such", "cond_log_prob": -2.1826934814453125, "count": 7}, {"pred": "water", "cond_log_prob": -6.989105224609375, "count": 3}, {"pred": "an", "cond_log_prob": -3.9346160888671875, "count": 2}, {"pred": "concrete", "cond_log_prob": -8.532501220703125, "count": 1}, {"pred": "conditions", "cond_log_prob": -9.708053588867188, "count": 1}, {"pred": "nothing", "cond_log_prob": -9.403518676757812, "count": 1}, {"pred": "rocks", "cond_log_prob": -8.168930053710938, "count": 1}, {"pred": "should", "cond_log_prob": -13.681396484375, "count": 1}, {"pred": "solid", "cond_log_prob": -8.027420043945312, "count": 1}, {"pred": "top", "cond_log_prob": -5.705078125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 17, "cond_log_prob": -1.839691162109375}, {"pred": "its", "count": 3, "cond_log_prob": -2.6802520751953125}, {"pred": "land", "count": 2, "cond_log_prob": -2.939453125}, {"pred": "such", "count": 2, "cond_log_prob": -2.1826934814453125}, {"pred": "the", "count": 15, "cond_log_prob": -1.7174835205078125}, {"pred": "theroute", "count": 1, "cond_log_prob": -28.493743896484375}]}, "37": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an", "log_prob": -184.9735565185547}, "original": {"pred": "isolated", "cond_log_prob": -6.1436920166015625}, "human": [{"pred": "island", "cond_log_prob": -1.213531494140625, "count": 19}, {"pred": "airplane", "cond_log_prob": -7.6836090087890625, "count": 2}, {"pred": "ocean", "cond_log_prob": -3.2691650390625, "count": 2}, {"pred": "?", "cond_log_prob": -15.264328002929688, "count": 1}, {"pred": "admirable", "cond_log_prob": -10.466567993164062, "count": 1}, {"pred": "airship", "cond_log_prob": -8.570602416992188, "count": 1}, {"pred": "almost", "cond_log_prob": -6.042205810546875, "count": 1}, {"pred": "apparatus", "cond_log_prob": -12.445480346679688, "count": 1}, {"pred": "coastside", "cond_log_prob": -18.779953002929688, "count": 1}, {"pred": "elevated", "cond_log_prob": -7.534942626953125, "count": 1}, {"pred": "empty", "cond_log_prob": -4.5452423095703125, "count": 1}, {"pred": "ice", "cond_log_prob": -5.12310791015625, "count": 1}, {"pred": "ice-shelf", "cond_log_prob": -11.218475341796875, "count": 1}, {"pred": "incredible", "cond_log_prob": -9.116943359375, "count": 1}, {"pred": "interesting", "cond_log_prob": -10.231201171875, "count": 1}, {"pred": "oil", "cond_log_prob": -7.4590911865234375, "count": 1}, {"pred": "outcropping", "cond_log_prob": -8.872528076171875, "count": 1}, {"pred": "outlet", "cond_log_prob": -8.9326171875, "count": 1}, {"pred": "rock", "cond_log_prob": -14.081695556640625, "count": 1}, {"pred": "take", "cond_log_prob": -11.663421630859375, "count": 1}], "ancestral_samples": [{"pred": "American", "count": 2, "cond_log_prob": -3.3055572509765625}, {"pred": "Americanroute", "count": 1, "cond_log_prob": -18.190048217773438}, {"pred": "actual", "count": 1, "cond_log_prob": -3.680999755859375}, {"pred": "inhabited", "count": 1, "cond_log_prob": -5.7906951904296875}, {"pred": "island", "count": 31, "cond_log_prob": -1.213531494140625}, {"pred": "ocean", "count": 1, "cond_log_prob": -3.2691650390625}, {"pred": "oceangoing", "count": 1, "cond_log_prob": -9.014755249023438}, {"pred": "original", "count": 1, "cond_log_prob": -5.0769195556640625}, {"pred": "unguarded", "count": 1, "cond_log_prob": -5.8262176513671875}]}, "38": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated", "log_prob": -191.11724853515625}, "original": {"pred": "rock", "cond_log_prob": -6.378204345703125}, "human": [{"pred": "island", "cond_log_prob": -0.689697265625, "count": 22}, {"pred": "rock", "cond_log_prob": -6.3785858154296875, "count": 4}, {"pred": "piece", "cond_log_prob": -3.517547607421875, "count": 2}, {"pred": "platform", "cond_log_prob": -5.1735076904296875, "count": 2}, {"pred": "area", "cond_log_prob": -7.613250732421875, "count": 1}, {"pred": "boat", "cond_log_prob": -6.9178466796875, "count": 1}, {"pred": "horrifying", "cond_log_prob": -17.850799560546875, "count": 1}, {"pred": "reef", "cond_log_prob": -3.462921142578125, "count": 1}, {"pred": "shelf", "cond_log_prob": -5.360504150390625, "count": 1}, {"pred": "small", "cond_log_prob": -7.2826690673828125, "count": 1}, {"pred": "so", "cond_log_prob": -9.40887451171875, "count": 1}, {"pred": "spit", "cond_log_prob": -8.715972900390625, "count": 1}, {"pred": "stretch", "cond_log_prob": -5.3360137939453125, "count": 1}], "ancestral_samples": [{"pred": "island", "count": 37, "cond_log_prob": -0.689697265625}, {"pred": "islandIn", "count": 1, "cond_log_prob": -16.434906005859375}, {"pred": "islandWin", "count": 1, "cond_log_prob": -23.078338623046875}, {"pred": "islandroute", "count": 1, "cond_log_prob": -15.895645141601562}]}, "39": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock", "log_prob": -197.49545288085938}, "original": {"pred": "before.", "cond_log_prob": -6.48529052734375}, "human": [{"pred": "before", "cond_log_prob": -5.2953033447265625, "count": 8}, {"pred": "that", "cond_log_prob": -4.7858428955078125, "count": 5}, {"pred": "formation", "cond_log_prob": -6.2192535400390625, "count": 4}, {"pred": "in", "cond_log_prob": -2.9171905517578125, "count": 4}, {"pred": "so", "cond_log_prob": -4.6531982421875, "count": 3}, {"pred": "like", "cond_log_prob": -5.8936767578125, "count": 2}, {"pred": "of", "cond_log_prob": -5.0716094970703125, "count": 2}, {"pred": "shelf", "cond_log_prob": -5.297149658203125, "count": 2}, {"pred": "such", "cond_log_prob": -6.9252166748046875, "count": 2}, {"pred": "and", "cond_log_prob": -4.178253173828125, "count": 1}, {"pred": "as", "cond_log_prob": -5.5660552978515625, "count": 1}, {"pred": "far", "cond_log_prob": -7.0773773193359375, "count": 1}, {"pred": "island", "cond_log_prob": -5.5138397216796875, "count": 1}, {"pred": "long", "cond_log_prob": -8.7041015625, "count": 1}, {"pred": "on", "cond_log_prob": -4.5015411376953125, "count": 1}, {"pred": "separated", "cond_log_prob": -9.807632446289062, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -11.616455078125}, {"pred": "But", "count": 2, "cond_log_prob": -10.811676025390625}, {"pred": "I", "count": 2, "cond_log_prob": -8.4852294921875}, {"pred": "It", "count": 2, "cond_log_prob": -12.410202026367188}, {"pred": "The", "count": 7, "cond_log_prob": -11.632537841796875}, {"pred": "There", "count": 1, "cond_log_prob": -12.881088256835938}, {"pred": "and", "count": 15, "cond_log_prob": -4.178253173828125}, {"pred": "but", "count": 4, "cond_log_prob": -6.1268463134765625}, {"pred": "he", "count": 1, "cond_log_prob": -8.74261474609375}, {"pred": "not", "count": 1, "cond_log_prob": -8.474227905273438}, {"pred": "route", "count": 1, "cond_log_prob": -9.461639404296875}, {"pred": "so", "count": 3, "cond_log_prob": -4.6531982421875}]}, "40": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before.", "log_prob": -203.98074340820312}, "original": {"pred": "The", "cond_log_prob": -2.210357666015625}, "human": [{"pred": "this", "cond_log_prob": -13.160568237304688, "count": 8}, {"pred": "he", "cond_log_prob": -11.149642944335938, "count": 4}, {"pred": "the", "cond_log_prob": -8.689254760742188, "count": 4}, {"pred": "winstanley", "cond_log_prob": -15.116378784179688, "count": 4}, {"pred": "but", "cond_log_prob": -11.521316528320312, "count": 2}, {"pred": "!", "cond_log_prob": -12.086166381835938, "count": 1}, {"pred": "?", "cond_log_prob": -11.323471069335938, "count": 1}, {"pred": "and", "cond_log_prob": -8.290908813476562, "count": 1}, {"pred": "everyone", "cond_log_prob": -16.614059448242188, "count": 1}, {"pred": "for", "cond_log_prob": -10.997817993164062, "count": 1}, {"pred": "however", "cond_log_prob": -15.5430908203125, "count": 1}, {"pred": "if", "cond_log_prob": -12.28167724609375, "count": 1}, {"pred": "it", "cond_log_prob": -11.262527465820312, "count": 2}, {"pred": "lighthouses", "cond_log_prob": -16.528121948242188, "count": 1}, {"pred": "so", "cond_log_prob": -11.778121948242188, "count": 1}, {"pred": "that", "cond_log_prob": -11.974472045898438, "count": 1}, {"pred": "then", "cond_log_prob": -14.562911987304688, "count": 1}, {"pred": "there", "cond_log_prob": -12.592666625976562, "count": 1}, {"pred": "when", "cond_log_prob": -12.52545166015625, "count": 1}, {"pred": "wow", "cond_log_prob": -18.093795776367188, "count": 1}, {"pred": "yes", "cond_log_prob": -16.720993041992188, "count": 1}], "ancestral_samples": [{"pred": "And", "count": 3, "cond_log_prob": -3.047088623046875}, {"pred": "I", "count": 5, "cond_log_prob": -6.6127471923828125}, {"pred": "In", "count": 2, "cond_log_prob": -3.35687255859375}, {"pred": "It", "count": 2, "cond_log_prob": -2.6903533935546875}, {"pred": "Its", "count": 1, "cond_log_prob": -5.2061309814453125}, {"pred": "The", "count": 21, "cond_log_prob": -2.21075439453125}, {"pred": "There", "count": 1, "cond_log_prob": -4.1616363525390625}, {"pred": "They", "count": 1, "cond_log_prob": -5.20721435546875}, {"pred": "We", "count": 1, "cond_log_prob": -6.5664825439453125}, {"pred": "When", "count": 1, "cond_log_prob": -4.9314727783203125}, {"pred": "You", "count": 1, "cond_log_prob": -6.8864593505859375}, {"pred": "route", "count": 1, "cond_log_prob": -21.473983764648438}]}, "41": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The", "log_prob": -206.19110107421875}, "original": {"pred": "Eddystone", "cond_log_prob": -15.321258544921875}, "human": [{"pred": "lighthouse", "cond_log_prob": -3.5839385986328125, "count": 12}, {"pred": "only", "cond_log_prob": -3.7112579345703125, "count": 3}, {"pred": "admiral", "cond_log_prob": -6.099456787109375, "count": 2}, {"pred": "admiralty", "cond_log_prob": -6.53289794921875, "count": 2}, {"pred": "day", "cond_log_prob": -7.173187255859375, "count": 2}, {"pred": "aliens", "cond_log_prob": -10.663848876953125, "count": 1}, {"pred": "building", "cond_log_prob": -5.357147216796875, "count": 1}, {"pred": "challenge", "cond_log_prob": -6.249481201171875, "count": 1}, {"pred": "creativity", "cond_log_prob": -13.156707763671875, "count": 1}, {"pred": "crew", "cond_log_prob": -6.4550018310546875, "count": 1}, {"pred": "dangers", "cond_log_prob": -9.800201416015625, "count": 1}, {"pred": "idea", "cond_log_prob": -5.7886199951171875, "count": 1}, {"pred": "most", "cond_log_prob": -5.6388397216796875, "count": 1}, {"pred": "next", "cond_log_prob": -5.7506866455078125, "count": 1}, {"pred": "odds", "cond_log_prob": -7.5044097900390625, "count": 1}, {"pred": "plan", "cond_log_prob": -5.6716156005859375, "count": 1}, {"pred": "plans", "cond_log_prob": -7.663482666015625, "count": 1}, {"pred": "project", "cond_log_prob": -6.944000244140625, "count": 1}, {"pred": "rock", "cond_log_prob": -6.714935302734375, "count": 1}, {"pred": "task", "cond_log_prob": -7.5712127685546875, "count": 1}, {"pred": "waves", "cond_log_prob": -6.962066650390625, "count": 1}, {"pred": "way", "cond_log_prob": -7.307373046875, "count": 1}, {"pred": "worst", "cond_log_prob": -8.204299926757812, "count": 1}], "ancestral_samples": [{"pred": "company", "count": 1, "cond_log_prob": -6.3435516357421875}, {"pred": "first", "count": 3, "cond_log_prob": -4.2595062255859375}, {"pred": "last", "count": 1, "cond_log_prob": -5.6977691650390625}, {"pred": "lighthouse", "count": 12, "cond_log_prob": -3.5839385986328125}, {"pred": "most", "count": 1, "cond_log_prob": -5.6388397216796875}, {"pred": "only", "count": 13, "cond_log_prob": -3.7112579345703125}, {"pred": "onlyroute", "count": 1, "cond_log_prob": -22.081024169921875}, {"pred": "original", "count": 1, "cond_log_prob": -5.593719482421875}, {"pred": "rocks", "count": 1, "cond_log_prob": -5.858673095703125}, {"pred": "sea", "count": 1, "cond_log_prob": -5.194183349609375}, {"pred": "ship", "count": 4, "cond_log_prob": -3.9502716064453125}, {"pred": "whole", "count": 1, "cond_log_prob": -5.6279144287109375}]}, "42": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone", "log_prob": -221.51235961914062}, "original": {"pred": "is", "cond_log_prob": -4.069061279296875}, "human": [{"pred": "was", "cond_log_prob": -2.0877838134765625, "count": 10}, {"pred": "lighthouse", "cond_log_prob": -2.2943572998046875, "count": 9}, {"pred": "rock", "cond_log_prob": -7.5621490478515625, "count": 2}, {"pred": "bridge", "cond_log_prob": -5.7935028076171875, "count": 1}, {"pred": "could", "cond_log_prob": -4.9893035888671875, "count": 1}, {"pred": "created", "cond_log_prob": -9.973342895507812, "count": 1}, {"pred": "essay", "cond_log_prob": -13.441421508789062, "count": 1}, {"pred": "foundation", "cond_log_prob": -8.682662963867188, "count": 1}, {"pred": "is", "cond_log_prob": -4.0694732666015625, "count": 1}, {"pred": "island", "cond_log_prob": -6.1577911376953125, "count": 1}, {"pred": "mermaids", "cond_log_prob": -14.189743041992188, "count": 1}, {"pred": "monument", "cond_log_prob": -6.2510833740234375, "count": 1}, {"pred": "of", "cond_log_prob": -5.8999176025390625, "count": 1}, {"pred": "project", "cond_log_prob": -7.7877349853515625, "count": 1}, {"pred": "proved", "cond_log_prob": -6.9726409912109375, "count": 1}, {"pred": "ship", "cond_log_prob": -6.1875762939453125, "count": 1}, {"pred": "stone", "cond_log_prob": -7.1622772216796875, "count": 1}, {"pred": "story", "cond_log_prob": -8.625869750976562, "count": 1}, {"pred": "structure", "cond_log_prob": -7.2662200927734375, "count": 1}, {"pred": "thought", "cond_log_prob": -9.689834594726562, "count": 1}, {"pred": "three", "cond_log_prob": -8.658462524414062, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -8.663253784179688}, {"pred": "built", "count": 1, "cond_log_prob": -7.1764984130859375}, {"pred": "had", "count": 4, "cond_log_prob": -2.5224456787109375}, {"pred": "is", "count": 1, "cond_log_prob": -4.0694732666015625}, {"pred": "lighthouse", "count": 12, "cond_log_prob": -2.2943572998046875}, {"pred": "lighthouseroute", "count": 1, "cond_log_prob": -47.419830322265625}, {"pred": "s", "count": 1, "cond_log_prob": -8.430374145507812}, {"pred": "the", "count": 1, "cond_log_prob": -7.7949371337890625}, {"pred": "was", "count": 18, "cond_log_prob": -2.0877838134765625}]}, "43": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is", "log_prob": -225.5814208984375}, "original": {"pred": "hard", "cond_log_prob": -6.926544189453125}, "human": [{"pred": "a", "cond_log_prob": -1.7515411376953125, "count": 11}, {"pred": "the", "cond_log_prob": -2.4800262451171875, "count": 11}, {"pred": "one", "cond_log_prob": -3.2571868896484375, "count": 4}, {"pred": "credits", "cond_log_prob": -15.086624145507812, "count": 1}, {"pred": "dead", "cond_log_prob": -8.199478149414062, "count": 1}, {"pred": "difficult", "cond_log_prob": -7.9544525146484375, "count": 1}, {"pred": "enchanting", "cond_log_prob": -11.757003784179688, "count": 1}, {"pred": "enormous", "cond_log_prob": -8.623855590820312, "count": 1}, {"pred": "famous", "cond_log_prob": -6.3271026611328125, "count": 1}, {"pred": "known", "cond_log_prob": -6.0069122314453125, "count": 1}, {"pred": "really", "cond_log_prob": -7.3708038330078125, "count": 1}, {"pred": "right", "cond_log_prob": -6.8377838134765625, "count": 1}, {"pred": "slippery", "cond_log_prob": -11.384506225585938, "count": 1}, {"pred": "such", "cond_log_prob": -7.1416778564453125, "count": 1}, {"pred": "too", "cond_log_prob": -6.2211151123046875, "count": 1}, {"pred": "very", "cond_log_prob": -6.1227264404296875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 30, "cond_log_prob": -1.7515411376953125}, {"pred": "aroute", "count": 1, "cond_log_prob": -26.293289184570312}, {"pred": "not", "count": 1, "cond_log_prob": -3.6989898681640625}, {"pred": "now", "count": 1, "cond_log_prob": -3.6322174072265625}, {"pred": "one", "count": 3, "cond_log_prob": -3.2571868896484375}, {"pred": "the", "count": 4, "cond_log_prob": -2.4800262451171875}]}, "44": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard", "log_prob": -232.50796508789062}, "original": {"pred": "enough", "cond_log_prob": -4.8569488525390625}, "human": [{"pred": "to", "cond_log_prob": -0.2491912841796875, "count": 24}, {"pred": "as", "cond_log_prob": -4.9510955810546875, "count": 5}, {"pred": "enough", "cond_log_prob": -4.8574066162109375, "count": 4}, {"pred": "rock", "cond_log_prob": -5.1625823974609375, "count": 2}, {"pred": ",", "cond_log_prob": -9.667465209960938, "count": 1}, {"pred": "and", "cond_log_prob": -3.8543853759765625, "count": 1}, {"pred": "evidence", "cond_log_prob": -6.4586944580078125, "count": 1}, {"pred": "impenetrable", "cond_log_prob": -15.182785034179688, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -10.725662231445312}, {"pred": "to", "count": 38, "cond_log_prob": -0.2491912841796875}, {"pred": "toroute", "count": 1, "cond_log_prob": -29.2703857421875}]}, "45": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough", "log_prob": -237.3649139404297}, "original": {"pred": "to", "cond_log_prob": -0.3154449462890625}, "human": [{"pred": "to", "cond_log_prob": -0.31591796875, "count": 28}, {"pred": "that", "cond_log_prob": -4.037017822265625, "count": 3}, {"pred": "as", "cond_log_prob": -5.33770751953125, "count": 2}, {"pred": "without", "cond_log_prob": -5.6375732421875, "count": 2}, {"pred": "alright", "cond_log_prob": -14.671356201171875, "count": 1}, {"pred": "get", "cond_log_prob": -12.171966552734375, "count": 1}, {"pred": "passage", "cond_log_prob": -16.387542724609375, "count": 1}, {"pred": "proof", "cond_log_prob": -10.736114501953125, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -13.519287109375}, {"pred": "to", "count": 38, "cond_log_prob": -0.31591796875}, {"pred": "toroute", "count": 1, "cond_log_prob": -28.271743774414062}]}, "46": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to", "log_prob": -237.68035888671875}, "original": {"pred": "avoid,", "cond_log_prob": -7.4865570068359375}, "human": [{"pred": "build", "cond_log_prob": -4.3571624755859375, "count": 9}, {"pred": "see", "cond_log_prob": -2.7553253173828125, "count": 5}, {"pred": "withstand", "cond_log_prob": -6.1228485107421875, "count": 5}, {"pred": "break", "cond_log_prob": -4.5850982666015625, "count": 4}, {"pred": "find", "cond_log_prob": -2.2225799560546875, "count": 2}, {"pred": "hold", "cond_log_prob": -5.3231658935546875, "count": 2}, {"pred": "reach", "cond_log_prob": -3.7341766357421875, "count": 2}, {"pred": "be", "cond_log_prob": -3.9235687255859375, "count": 1}, {"pred": "bypass", "cond_log_prob": -9.422378540039062, "count": 1}, {"pred": "come", "cond_log_prob": -5.3346405029296875, "count": 1}, {"pred": "get", "cond_log_prob": -3.3670196533203125, "count": 1}, {"pred": "imagine", "cond_log_prob": -4.6093597412109375, "count": 1}, {"pred": "move", "cond_log_prob": -6.6085052490234375, "count": 1}, {"pred": "navigate", "cond_log_prob": -3.4694366455078125, "count": 1}, {"pred": "real", "cond_log_prob": -12.517196655273438, "count": 1}, {"pred": "support", "cond_log_prob": -7.5045928955078125, "count": 1}, {"pred": "sustain", "cond_log_prob": -7.9394378662109375, "count": 1}], "ancestral_samples": [{"pred": "climb", "count": 1, "cond_log_prob": -3.7517852783203125}, {"pred": "cross", "count": 1, "cond_log_prob": -3.8710174560546875}, {"pred": "crossroute", "count": 1, "cond_log_prob": -21.1534423828125}, {"pred": "deal", "count": 1, "cond_log_prob": -6.4091949462890625}, {"pred": "find", "count": 23, "cond_log_prob": -2.2225799560546875}, {"pred": "get", "count": 2, "cond_log_prob": -3.3670196533203125}, {"pred": "reach", "count": 1, "cond_log_prob": -3.7341766357421875}, {"pred": "rideBut", "count": 1, "cond_log_prob": -21.68798828125}, {"pred": "see", "count": 8, "cond_log_prob": -2.7553253173828125}, {"pred": "walk", "count": 1, "cond_log_prob": -4.1665496826171875}]}, "47": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid,", "log_prob": -245.1669158935547}, "original": {"pred": "but", "cond_log_prob": -1.08203125}, "human": [{"pred": "but", "cond_log_prob": -1.082489013671875, "count": 17}, {"pred": "let", "cond_log_prob": -5.576263427734375, "count": 5}, {"pred": "without", "cond_log_prob": -6.0131072998046875, "count": 4}, {"pred": "and", "cond_log_prob": -1.574859619140625, "count": 3}, {"pred": "any", "cond_log_prob": -7.776824951171875, "count": 2}, {"pred": "collisions", "cond_log_prob": -16.166793823242188, "count": 1}, {"pred": "crumble", "cond_log_prob": -14.421401977539062, "count": 1}, {"pred": "especially", "cond_log_prob": -4.748626708984375, "count": 1}, {"pred": "now", "cond_log_prob": -7.18438720703125, "count": 1}, {"pred": "so", "cond_log_prob": -3.6240386962890625, "count": 1}, {"pred": "that", "cond_log_prob": -6.485382080078125, "count": 1}, {"pred": "the", "cond_log_prob": -4.454986572265625, "count": 1}, {"pred": "withstand", "cond_log_prob": -13.603866577148438, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 13, "cond_log_prob": -1.574859619140625}, {"pred": "but", "count": 26, "cond_log_prob": -1.082489013671875}, {"pred": "butroute", "count": 1, "cond_log_prob": -21.174179077148438}]}, "48": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid, but", "log_prob": -246.2489471435547}, "original": {"pred": "landing", "cond_log_prob": -8.495376586914062}, "human": [{"pred": "the", "cond_log_prob": -2.04449462890625, "count": 8}, {"pred": "now", "cond_log_prob": -5.2744140625, "count": 5}, {"pred": "it", "cond_log_prob": -1.769317626953125, "count": 4}, {"pred": "not", "cond_log_prob": -3.39300537109375, "count": 3}, {"pred": "with", "cond_log_prob": -4.9394989013671875, "count": 3}, {"pred": "there", "cond_log_prob": -2.868865966796875, "count": 2}, {"pred": "building", "cond_log_prob": -8.03778076171875, "count": 1}, {"pred": "came", "cond_log_prob": -10.043136596679688, "count": 1}, {"pred": "captain", "cond_log_prob": -11.720657348632812, "count": 1}, {"pred": "despite", "cond_log_prob": -7.291015625, "count": 1}, {"pred": "even", "cond_log_prob": -4.7310791015625, "count": 1}, {"pred": "finding", "cond_log_prob": -9.100479125976562, "count": 1}, {"pred": "for", "cond_log_prob": -4.358367919921875, "count": 1}, {"pred": "impossible", "cond_log_prob": -8.4984130859375, "count": 1}, {"pred": "landing", "cond_log_prob": -8.495834350585938, "count": 1}, {"pred": "somehow", "cond_log_prob": -7.3364105224609375, "count": 1}, {"pred": "that", "cond_log_prob": -3.9510345458984375, "count": 1}, {"pred": "to", "cond_log_prob": -4.71295166015625, "count": 1}, {"pred": "we", "cond_log_prob": -5.7596282958984375, "count": 1}, {"pred": "without", "cond_log_prob": -6.475311279296875, "count": 1}], "ancestral_samples": [{"pred": "Winstanleys", "count": 1, "cond_log_prob": -14.498001098632812}, {"pred": "a", "count": 1, "cond_log_prob": -3.9113006591796875}, {"pred": "it", "count": 6, "cond_log_prob": -1.769317626953125}, {"pred": "itroute", "count": 1, "cond_log_prob": -27.706832885742188}, {"pred": "its", "count": 18, "cond_log_prob": -3.6991119384765625}, {"pred": "not", "count": 1, "cond_log_prob": -3.39300537109375}, {"pred": "the", "count": 9, "cond_log_prob": -2.04449462890625}, {"pred": "there", "count": 2, "cond_log_prob": -2.868865966796875}, {"pred": "theres", "count": 1, "cond_log_prob": -12.439285278320312}]}, "49": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid, but landing", "log_prob": -254.74432373046875}, "original": {"pred": "on", "cond_log_prob": -1.099456787109375}, "human": [{"pred": "on", "cond_log_prob": -1.099945068359375, "count": 20}, {"pred": "is", "cond_log_prob": -4.40447998046875, "count": 4}, {"pred": "was", "cond_log_prob": -4.093292236328125, "count": 3}, {"pred": "a", "cond_log_prob": -3.334930419921875, "count": 2}, {"pred": "at", "cond_log_prob": -2.762176513671875, "count": 2}, {"pred": "the", "cond_log_prob": -4.0706787109375, "count": 2}, {"pred": "an", "cond_log_prob": -5.23370361328125, "count": 1}, {"pred": "are", "cond_log_prob": -9.21881103515625, "count": 1}, {"pred": "down", "cond_log_prob": -6.435791015625, "count": 1}, {"pred": "planes", "cond_log_prob": -8.9119873046875, "count": 1}, {"pred": "there", "cond_log_prob": -2.681915283203125, "count": 1}, {"pred": "would", "cond_log_prob": -4.985565185546875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.334930419921875}, {"pred": "at", "count": 1, "cond_log_prob": -2.762176513671875}, {"pred": "in", "count": 2, "cond_log_prob": -2.507904052734375}, {"pred": "is", "count": 1, "cond_log_prob": -4.40447998046875}, {"pred": "it", "count": 3, "cond_log_prob": -2.612335205078125}, {"pred": "on", "count": 30, "cond_log_prob": -1.099945068359375}, {"pred": "onroute", "count": 1, "cond_log_prob": -18.981353759765625}, {"pred": "there", "count": 1, "cond_log_prob": -2.681915283203125}]}, "50": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid, but landing on", "log_prob": -255.84378051757812}, "original": {"pred": "it", "cond_log_prob": -1.440887451171875}, "human": [{"pred": "the", "cond_log_prob": -1.478851318359375, "count": 20}, {"pred": "it", "cond_log_prob": -1.441375732421875, "count": 14}, {"pred": "a", "cond_log_prob": -1.818267822265625, "count": 3}, {"pred": "pads", "cond_log_prob": -13.80767822265625, "count": 1}, {"pred": "pillows", "cond_log_prob": -14.600128173828125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 12, "cond_log_prob": -1.818267822265625}, {"pred": "it", "count": 15, "cond_log_prob": -1.441375732421875}, {"pred": "itroute", "count": 1, "cond_log_prob": -26.936248779296875}, {"pred": "one", "count": 1, "cond_log_prob": -2.798492431640625}, {"pred": "the", "count": 11, "cond_log_prob": -1.478851318359375}]}, "51": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid, but landing on it", "log_prob": -257.28466796875}, "original": {"pred": "is", "cond_log_prob": -2.593597412109375}, "human": [{"pred": "is", "cond_log_prob": -2.594085693359375, "count": 15}, {"pred": "was", "cond_log_prob": -1.755615234375, "count": 9}, {"pred": "would", "cond_log_prob": -1.877349853515625, "count": 8}, {"pred": "can", "cond_log_prob": -4.928466796875, "count": 2}, {"pred": "could", "cond_log_prob": -3.77093505859375, "count": 1}, {"pred": "gave", "cond_log_prob": -5.38482666015625, "count": 1}, {"pred": "now", "cond_log_prob": -5.85540771484375, "count": 1}, {"pred": "seems", "cond_log_prob": -5.936981201171875, "count": 1}, {"pred": "will", "cond_log_prob": -5.19805908203125, "count": 1}], "ancestral_samples": [{"pred": "is", "count": 4, "cond_log_prob": -2.594085693359375}, {"pred": "isroute", "count": 1, "cond_log_prob": -24.9019775390625}, {"pred": "was", "count": 21, "cond_log_prob": -1.755615234375}, {"pred": "wasnt", "count": 1, "cond_log_prob": -13.61175537109375}, {"pred": "would", "count": 13, "cond_log_prob": -1.877349853515625}]}, "52": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid, but landing on it is", "log_prob": -259.8782653808594}, "original": {"pred": "a", "cond_log_prob": -1.90594482421875}, "human": [{"pred": "even", "cond_log_prob": -4.901153564453125, "count": 6}, {"pred": "nearly", "cond_log_prob": -5.0546875, "count": 6}, {"pred": "a", "cond_log_prob": -1.90643310546875, "count": 4}, {"pred": "harder", "cond_log_prob": -4.820220947265625, "count": 2}, {"pred": "impossible", "cond_log_prob": -4.1611328125, "count": 3}, {"pred": "not", "cond_log_prob": -2.81146240234375, "count": 2}, {"pred": "quite", "cond_log_prob": -4.738128662109375, "count": 2}, {"pred": "able", "cond_log_prob": -11.402923583984375, "count": 1}, {"pred": "all", "cond_log_prob": -5.39501953125, "count": 1}, {"pred": "almost", "cond_log_prob": -4.023590087890625, "count": 1}, {"pred": "always", "cond_log_prob": -5.1507568359375, "count": 1}, {"pred": "another", "cond_log_prob": -5.35247802734375, "count": 1}, {"pred": "dangerous", "cond_log_prob": -5.23193359375, "count": 1}, {"pred": "devastating", "cond_log_prob": -8.5479736328125, "count": 1}, {"pred": "difficult", "cond_log_prob": -3.8255615234375, "count": 1}, {"pred": "more", "cond_log_prob": -3.892120361328125, "count": 1}, {"pred": "now", "cond_log_prob": -5.9205322265625, "count": 1}, {"pred": "possible", "cond_log_prob": -7.519989013671875, "count": 1}, {"pred": "soft", "cond_log_prob": -10.103179931640625, "count": 1}, {"pred": "still", "cond_log_prob": -4.4801025390625, "count": 1}, {"pred": "very", "cond_log_prob": -5.470245361328125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 31, "cond_log_prob": -1.90643310546875}, {"pred": "aroute", "count": 1, "cond_log_prob": -24.965911865234375}, {"pred": "challengingThe", "count": 1, "cond_log_prob": -21.033447265625}, {"pred": "harder", "count": 1, "cond_log_prob": -4.820220947265625}, {"pred": "not", "count": 6, "cond_log_prob": -2.81146240234375}]}, "53": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid, but landing on it is a", "log_prob": -261.7842102050781}, "original": {"pred": "separate", "cond_log_prob": -7.513885498046875}, "human": [{"pred": "difficult", "cond_log_prob": -4.523223876953125, "count": 4}, {"pred": "challenge", "cond_log_prob": -3.2607421875, "count": 3}, {"pred": "bad", "cond_log_prob": -6.336883544921875, "count": 2}, {"pred": "different", "cond_log_prob": -4.60546875, "count": 2}, {"pred": "insurmountable", "cond_log_prob": -11.288238525390625, "count": 2}, {"pred": "pain", "cond_log_prob": -5.08935546875, "count": 2}, {"pred": "task", "cond_log_prob": -4.622802734375, "count": 2}, {"pred": "very", "cond_log_prob": -5.127532958984375, "count": 2}, {"pred": "admirable", "cond_log_prob": -13.91748046875, "count": 1}, {"pred": "big", "cond_log_prob": -5.03564453125, "count": 1}, {"pred": "bigger", "cond_log_prob": -7.167694091796875, "count": 1}, {"pred": "even", "cond_log_prob": -9.416473388671875, "count": 1}, {"pred": "ever", "cond_log_prob": -9.829132080078125, "count": 1}, {"pred": "feat", "cond_log_prob": -4.702056884765625, "count": 1}, {"pred": "greater", "cond_log_prob": -7.60943603515625, "count": 1}, {"pred": "hazard", "cond_log_prob": -6.420501708984375, "count": 1}, {"pred": "huge", "cond_log_prob": -5.128204345703125, "count": 1}, {"pred": "likely", "cond_log_prob": -8.601104736328125, "count": 1}, {"pred": "lot", "cond_log_prob": -4.644989013671875, "count": 1}, {"pred": "more", "cond_log_prob": -4.999908447265625, "count": 1}, {"pred": "near", "cond_log_prob": -6.160369873046875, "count": 1}, {"pred": "nearly", "cond_log_prob": -6.856658935546875, "count": 1}, {"pred": "now", "cond_log_prob": -10.1986083984375, "count": 1}, {"pred": "okay", "cond_log_prob": -14.600341796875, "count": 1}, {"pred": "real", "cond_log_prob": -4.68035888671875, "count": 1}, {"pred": "really", "cond_log_prob": -7.578277587890625, "count": 1}, {"pred": "risky", "cond_log_prob": -4.712249755859375, "count": 1}, {"pred": "terrible", "cond_log_prob": -6.300872802734375, "count": 1}], "ancestral_samples": [{"pred": "bit", "count": 5, "cond_log_prob": -3.763671875}, {"pred": "challenge", "count": 6, "cond_log_prob": -3.2607421875}, {"pred": "challengeThe", "count": 3, "cond_log_prob": -18.445648193359375}, {"pred": "dangerous", "count": 1, "cond_log_prob": -4.611053466796875}, {"pred": "daunting", "count": 3, "cond_log_prob": -3.964111328125}, {"pred": "days", "count": 1, "cond_log_prob": -12.03662109375}, {"pred": "difficult", "count": 2, "cond_log_prob": -4.523223876953125}, {"pred": "far", "count": 2, "cond_log_prob": -4.4906005859375}, {"pred": "great", "count": 2, "cond_log_prob": -5.31121826171875}, {"pred": "hardshipBut", "count": 1, "cond_log_prob": -23.536895751953125}, {"pred": "little", "count": 3, "cond_log_prob": -4.195892333984375}, {"pred": "long", "count": 2, "cond_log_prob": -4.079498291015625}, {"pred": "matterroute", "count": 1, "cond_log_prob": -25.45684814453125}, {"pred": "monumental", "count": 1, "cond_log_prob": -5.616546630859375}, {"pred": "nightmareAt", "count": 1, "cond_log_prob": -22.733978271484375}, {"pred": "nightmareThe", "count": 1, "cond_log_prob": -19.316925048828125}, {"pred": "perilous", "count": 1, "cond_log_prob": -4.95648193359375}, {"pred": "strange", "count": 1, "cond_log_prob": -6.13165283203125}, {"pred": "task", "count": 1, "cond_log_prob": -4.622802734375}, {"pred": "terrible", "count": 1, "cond_log_prob": -6.300872802734375}, {"pred": "whole", "count": 1, "cond_log_prob": -5.775665283203125}]}, "54": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid, but landing on it is a separate", "log_prob": -269.298095703125}, "original": {"pred": "challenge", "cond_log_prob": -3.458770751953125}, "human": [{"pred": "matter", "cond_log_prob": -1.1175537109375, "count": 9}, {"pred": "challenge", "cond_log_prob": -3.45928955078125, "count": 8}, {"pred": "issue", "cond_log_prob": -2.772857666015625, "count": 6}, {"pred": "problem", "cond_log_prob": -4.01312255859375, "count": 3}, {"pred": "task", "cond_log_prob": -3.1126708984375, "count": 3}, {"pred": "and", "cond_log_prob": -3.05419921875, "count": 2}, {"pred": "adventure", "cond_log_prob": -4.863037109375, "count": 1}, {"pred": "feat", "cond_log_prob": -4.69683837890625, "count": 1}, {"pred": "ideal", "cond_log_prob": -13.562530517578125, "count": 1}, {"pred": "obstacle", "cond_log_prob": -6.87811279296875, "count": 1}, {"pred": "ordeal", "cond_log_prob": -4.939483642578125, "count": 1}, {"pred": "rock", "cond_log_prob": -10.7564697265625, "count": 1}, {"pred": "thing", "cond_log_prob": -4.386932373046875, "count": 1}, {"pred": "topic", "cond_log_prob": -5.816497802734375, "count": 1}], "ancestral_samples": [{"pred": "challengeThe", "count": 1, "cond_log_prob": -19.004730224609375}, {"pred": "issue", "count": 2, "cond_log_prob": -2.772857666015625}, {"pred": "issueOne", "count": 1, "cond_log_prob": -21.89666748046875}, {"pred": "matter", "count": 17, "cond_log_prob": -1.1175537109375}, {"pred": "matterAs", "count": 2, "cond_log_prob": -19.809722900390625}, {"pred": "matterAt", "count": 1, "cond_log_prob": -20.32073974609375}, {"pred": "matterBut", "count": 1, "cond_log_prob": -18.219482421875}, {"pred": "matterIn", "count": 1, "cond_log_prob": -19.747314453125}, {"pred": "matterIt", "count": 2, "cond_log_prob": -18.674896240234375}, {"pred": "matterThe", "count": 8, "cond_log_prob": -17.1290283203125}, {"pred": "matterWin", "count": 2, "cond_log_prob": -23.089111328125}, {"pred": "matterroute", "count": 1, "cond_log_prob": -24.963409423828125}, {"pred": "task", "count": 1, "cond_log_prob": -3.1126708984375}]}, "55": {"context": {"text": "It was a forbidding challenge, and it says much for Winstanley's persuasive abilities, not to mention his self-confidence, that the admiralty agreed to fund him. No lighthouse had ever been built out to sea on an isolated rock before. The Eddystone is hard enough to avoid, but landing on it is a separate challenge", "log_prob": -272.7568664550781}, "original": {"pred": "entirely.", "cond_log_prob": -6.132232666015625}, "human": [{"pred": "in", "cond_log_prob": -5.125946044921875, "count": 7}, {"pred": "to", "cond_log_prob": -3.05047607421875, "count": 7}, {"pred": "altogether", "cond_log_prob": -5.80194091796875, "count": 6}, {"pred": "that", "cond_log_prob": -4.52996826171875, "count": 5}, {"pred": "completely", "cond_log_prob": -9.133056640625, "count": 3}, {"pred": "for", "cond_log_prob": -3.299835205078125, "count": 3}, {"pred": "of", "cond_log_prob": -6.013031005859375, "count": 3}, {"pred": "because", "cond_log_prob": -6.28704833984375, "count": 1}, {"pred": "even", "cond_log_prob": -6.52386474609375, "count": 1}, {"pred": "he", "cond_log_prob": -9.41314697265625, "count": 1}, {"pred": "itself", "cond_log_prob": -9.4549560546875, "count": 1}, {"pred": "own", "cond_log_prob": -15.150390625, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 2, "cond_log_prob": -12.466217041015625}, {"pred": "I", "count": 5, "cond_log_prob": -9.744659423828125}, {"pred": "In", "count": 1, "cond_log_prob": -14.160125732421875}, {"pred": "It", "count": 5, "cond_log_prob": -13.81329345703125}, {"pred": "Its", "count": 1, "cond_log_prob": -18.22601318359375}, {"pred": "The", "count": 21, "cond_log_prob": -11.688262939453125}, {"pred": "There", "count": 1, "cond_log_prob": -14.234649658203125}, {"pred": "Winstan", "count": 2, "cond_log_prob": -16.18927001953125}, {"pred": "and", "count": 1, "cond_log_prob": -3.669677734375}, {"pred": "route", "count": 1, "cond_log_prob": -15.626983642578125}]}}, "10": {"2": {"context": {"text": "A", "log_prob": -8.911191940307617}, "original": {"pred": "clergyman", "cond_log_prob": -11.832019805908203}, "human": [{"pred": "man", "cond_log_prob": -3.267282485961914, "count": 4}, {"pred": "car", "cond_log_prob": -6.583284378051758, "count": 2}, {"pred": "cat", "cond_log_prob": -8.212221145629883, "count": 2}, {"pred": "dog", "cond_log_prob": -7.339227676391602, "count": 2}, {"pred": "large", "cond_log_prob": -5.463220596313477, "count": 2}, {"pred": "monkey", "cond_log_prob": -8.444108963012695, "count": 2}, {"pred": "apple", "cond_log_prob": -14.830698013305664, "count": 1}, {"pred": "b", "cond_log_prob": -8.33757209777832, "count": 1}, {"pred": "banana", "cond_log_prob": -10.591150283813477, "count": 1}, {"pred": "bee", "cond_log_prob": -10.006990432739258, "count": 1}, {"pred": "bird", "cond_log_prob": -7.993318557739258, "count": 1}, {"pred": "blundering", "cond_log_prob": -16.51029396057129, "count": 1}, {"pred": "boat", "cond_log_prob": -7.92192268371582, "count": 1}, {"pred": "butterfly", "cond_log_prob": -11.191629409790039, "count": 1}, {"pred": "calculus", "cond_log_prob": -13.22966194152832, "count": 1}, {"pred": "certain", "cond_log_prob": -7.646333694458008, "count": 1}, {"pred": "cow", "cond_log_prob": -9.359224319458008, "count": 1}, {"pred": "deer", "cond_log_prob": -9.574785232543945, "count": 1}, {"pred": "gardener", "cond_log_prob": -11.35380744934082, "count": 1}, {"pred": "girl", "cond_log_prob": -6.602853775024414, "count": 1}, {"pred": "lesson", "cond_log_prob": -9.450761795043945, "count": 1}, {"pred": "lion", "cond_log_prob": -8.659624099731445, "count": 1}, {"pred": "long", "cond_log_prob": -6.358026504516602, "count": 1}, {"pred": "lot", "cond_log_prob": -5.07737922668457, "count": 1}, {"pred": "new", "cond_log_prob": -3.710298538208008, "count": 1}, {"pred": "paragraph", "cond_log_prob": -11.149309158325195, "count": 1}, {"pred": "person", "cond_log_prob": -5.42564582824707, "count": 1}, {"pred": "rabbit", "cond_log_prob": -9.469644546508789, "count": 1}, {"pred": "recent", "cond_log_prob": -5.274835586547852, "count": 1}, {"pred": "sure", "cond_log_prob": -11.420610427856445, "count": 1}, {"pred": "train", "cond_log_prob": -7.755228042602539, "count": 1}, {"pred": "was", "cond_log_prob": -8.947786331176758, "count": 1}, {"pred": "woman", "cond_log_prob": -3.8164920806884766, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 2, "cond_log_prob": -7.777276992797852}, {"pred": "1910", "count": 1, "cond_log_prob": -13.107820510864258}, {"pred": "1D3", "count": 1, "cond_log_prob": -19.75419807434082}, {"pred": "2", "count": 1, "cond_log_prob": -7.322969436645508}, {"pred": "B", "count": 2, "cond_log_prob": -6.509546279907227}, {"pred": "D", "count": 1, "cond_log_prob": -6.899721145629883}, {"pred": "Failed to generate word", "count": 3, "cond_log_prob": -37.15637969970703}, {"pred": "GB", "count": 1, "cond_log_prob": -11.587556838989258}, {"pred": "HF", "count": 1, "cond_log_prob": -13.381715774536133}, {"pred": "HR", "count": 1, "cond_log_prob": -12.195901870727539}, {"pred": "I", "count": 2, "cond_log_prob": -9.360048294067383}, {"pred": "It", "count": 1, "cond_log_prob": -10.849878311157227}, {"pred": "LK", "count": 1, "cond_log_prob": -15.932794570922852}, {"pred": "S", "count": 1, "cond_log_prob": -7.525781631469727}, {"pred": "T", "count": 1, "cond_log_prob": -7.199319839477539}, {"pred": "The", "count": 3, "cond_log_prob": -8.988718032836914}, {"pred": "There", "count": 1, "cond_log_prob": -11.504281997680664}, {"pred": "This", "count": 1, "cond_log_prob": -10.492265701293945}, {"pred": "We", "count": 3, "cond_log_prob": -9.778200149536133}, {"pred": "a", "count": 3, "cond_log_prob": -8.50334358215332}, {"pred": "ak", "count": 1, "cond_log_prob": -15.927095413208008}, {"pred": "and", "count": 1, "cond_log_prob": -8.069276809692383}, {"pred": "ccording", "count": 1, "cond_log_prob": -18.941633224487305}, {"pred": "d", "count": 1, "cond_log_prob": -8.74974250793457}, {"pred": "is", "count": 1, "cond_log_prob": -8.948175430297852}, {"pred": "route", "count": 1, "cond_log_prob": -10.332483291625977}, {"pred": "the", "count": 1, "cond_log_prob": -7.732393264770508}, {"pred": "to", "count": 1, "cond_log_prob": -8.638628005981445}, {"pred": "was", "count": 1, "cond_log_prob": -8.947786331176758}]}, "3": {"context": {"text": "A clergyman", "log_prob": -20.74321174621582}, "original": {"pred": "remarked", "cond_log_prob": -12.091398239135742}, "human": [{"pred": "once", "cond_log_prob": -7.466009140014648, "count": 5}, {"pred": "was", "cond_log_prob": -2.300657272338867, "count": 5}, {"pred": "and", "cond_log_prob": -3.4901561737060547, "count": 3}, {"pred": "will", "cond_log_prob": -6.13618278503418, "count": 3}, {"pred": "came", "cond_log_prob": -6.991010665893555, "count": 2}, {"pred": "has", "cond_log_prob": -2.4480953216552734, "count": 2}, {"pred": "preaches", "cond_log_prob": -11.227373123168945, "count": 2}, {"pred": "said", "cond_log_prob": -4.806989669799805, "count": 2}, {"pred": "walked", "cond_log_prob": -7.335210800170898, "count": 2}, {"pred": "blessed", "cond_log_prob": -11.224607467651367, "count": 1}, {"pred": "bowed", "cond_log_prob": -10.868040084838867, "count": 1}, {"pred": "eats", "cond_log_prob": -11.340696334838867, "count": 1}, {"pred": "had", "cond_log_prob": -5.163671493530273, "count": 1}, {"pred": "is", "cond_log_prob": -2.932462692260742, "count": 1}, {"pred": "of", "cond_log_prob": -4.903203964233398, "count": 1}, {"pred": "prayed", "cond_log_prob": -7.907102584838867, "count": 1}, {"pred": "preached", "cond_log_prob": -9.24775505065918, "count": 1}, {"pred": "preaching", "cond_log_prob": -9.21748161315918, "count": 1}, {"pred": "priest", "cond_log_prob": -10.366178512573242, "count": 1}, {"pred": "ran", "cond_log_prob": -7.96491813659668, "count": 1}, {"pred": "speaks", "cond_log_prob": -7.045064926147461, "count": 1}, {"pred": "spoke", "cond_log_prob": -8.038785934448242, "count": 1}, {"pred": "stood", "cond_log_prob": -7.10462760925293, "count": 1}, {"pred": "who", "cond_log_prob": -1.8749752044677734, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -12.85951042175293}, {"pred": "a", "count": 1, "cond_log_prob": -8.472013473510742}, {"pred": "and", "count": 2, "cond_log_prob": -3.4901561737060547}, {"pred": "he", "count": 1, "cond_log_prob": -8.979337692260742}, {"pred": "in", "count": 4, "cond_log_prob": -2.9536571502685547}, {"pred": "is", "count": 1, "cond_log_prob": -2.932462692260742}, {"pred": "routemotor", "count": 1, "cond_log_prob": -39.49694061279297}, {"pred": "s", "count": 2, "cond_log_prob": -11.019834518432617}, {"pred": "said", "count": 5, "cond_log_prob": -4.806989669799805}, {"pred": "was", "count": 6, "cond_log_prob": -2.300657272338867}, {"pred": "who", "count": 16, "cond_log_prob": -1.8749752044677734}]}, "4": {"context": {"text": "A clergyman remarked", "log_prob": -32.83460998535156}, "original": {"pred": "to", "cond_log_prob": -2.077484130859375}, "human": [{"pred": "that", "cond_log_prob": -0.9317092895507812, "count": 21}, {"pred": "about", "cond_log_prob": -3.5118865966796875, "count": 4}, {"pred": "on", "cond_log_prob": -2.2778472900390625, "count": 2}, {"pred": "at", "cond_log_prob": -4.0439910888671875, "count": 1}, {"pred": "by", "cond_log_prob": -5.9944000244140625, "count": 1}, {"pred": "concerning", "cond_log_prob": -7.724205017089844, "count": 1}, {"pred": "hello", "cond_log_prob": -13.022346496582031, "count": 1}, {"pred": "how", "cond_log_prob": -4.8426513671875, "count": 1}, {"pred": "in", "cond_log_prob": -3.7318038940429688, "count": 1}, {"pred": "obligations", "cond_log_prob": -18.604171752929688, "count": 1}, {"pred": "of", "cond_log_prob": -5.26605224609375, "count": 1}, {"pred": "once", "cond_log_prob": -7.6694793701171875, "count": 1}, {"pred": "religiously", "cond_log_prob": -13.25537109375, "count": 1}, {"pred": "said", "cond_log_prob": -10.06646728515625, "count": 1}, {"pred": "to", "cond_log_prob": -2.07745361328125, "count": 1}, {"pred": "towards", "cond_log_prob": -9.569328308105469, "count": 1}, {"pred": "upon", "cond_log_prob": -5.1432342529296875, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -11.434288024902344}, {"pred": "I", "count": 10, "cond_log_prob": -8.22052001953125}, {"pred": "It", "count": 1, "cond_log_prob": -13.257247924804688}, {"pred": "Its", "count": 2, "cond_log_prob": -18.766342163085938}, {"pred": "Ive", "count": 1, "cond_log_prob": -16.150413513183594}, {"pred": "The", "count": 6, "cond_log_prob": -10.592483520507812}, {"pred": "We", "count": 1, "cond_log_prob": -13.844108581542969}, {"pred": "What", "count": 1, "cond_log_prob": -14.114845275878906}, {"pred": "that", "count": 12, "cond_log_prob": -0.9317092895507812}, {"pred": "thatroute", "count": 1, "cond_log_prob": -21.751693725585938}, {"pred": "to", "count": 4, "cond_log_prob": -2.07745361328125}]}, "5": {"context": {"text": "A clergyman remarked to", "log_prob": -34.91209411621094}, "original": {"pred": "him,", "cond_log_prob": -5.7843780517578125}, "human": [{"pred": "his", "cond_log_prob": -2.2996292114257812, "count": 14}, {"pred": "the", "cond_log_prob": -2.1046905517578125, "count": 14}, {"pred": "a", "cond_log_prob": -1.4598846435546875, "count": 4}, {"pred": "me", "cond_log_prob": -2.1496505737304688, "count": 3}, {"pred": "close", "cond_log_prob": -9.936752319335938, "count": 1}, {"pred": "get", "cond_log_prob": -10.078956604003906, "count": 1}, {"pred": "have", "cond_log_prob": -9.350776672363281, "count": 1}, {"pred": "once", "cond_log_prob": -11.721778869628906, "count": 1}, {"pred": "paying", "cond_log_prob": -13.107131958007812, "count": 1}, {"pred": "teach", "cond_log_prob": -12.288528442382812, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 4, "cond_log_prob": -1.4598846435546875}, {"pred": "her", "count": 1, "cond_log_prob": -5.299934387207031}, {"pred": "him", "count": 1, "cond_log_prob": -4.1558990478515625}, {"pred": "me", "count": 27, "cond_log_prob": -2.1496505737304688}, {"pred": "meroute", "count": 1, "cond_log_prob": -32.11656188964844}, {"pred": "the", "count": 6, "cond_log_prob": -2.1046905517578125}]}, "6": {"context": {"text": "A clergyman remarked to him,", "log_prob": -40.69647216796875}, "original": {"pred": "\"The", "cond_log_prob": -3.70599365234375}, "human": [{"pred": "that", "cond_log_prob": -3.3837738037109375, "count": 8}, {"pred": "what", "cond_log_prob": -7.0460205078125, "count": 4}, {"pred": "you", "cond_log_prob": -8.481613159179688, "count": 6}, {"pred": "and", "cond_log_prob": -5.1047821044921875, "count": 3}, {"pred": "i", "cond_log_prob": -9.67755126953125, "count": 3}, {"pred": "the", "cond_log_prob": -5.565467834472656, "count": 2}, {"pred": "why", "cond_log_prob": -8.605979919433594, "count": 2}, {"pred": "00 puq", "cond_log_prob": -32.9017333984375, "count": 1}, {"pred": "as", "cond_log_prob": -3.9387054443359375, "count": 1}, {"pred": "behold", "cond_log_prob": -11.058624267578125, "count": 1}, {"pred": "do", "cond_log_prob": -9.863906860351562, "count": 1}, {"pred": "god", "cond_log_prob": -11.499618530273438, "count": 1}, {"pred": "guys", "cond_log_prob": -14.144500732421875, "count": 1}, {"pred": "hey", "cond_log_prob": -12.037689208984375, "count": 1}, {"pred": "how", "cond_log_prob": -6.87799072265625, "count": 1}, {"pred": "if", "cond_log_prob": -6.4237060546875, "count": 1}, {"pred": "my", "cond_log_prob": -8.471649169921875, "count": 1}, {"pred": "saying", "cond_log_prob": -5.4625396728515625, "count": 1}, {"pred": "sir", "cond_log_prob": -9.241653442382812, "count": 1}, {"pred": "there", "cond_log_prob": -7.6350250244140625, "count": 1}], "ancestral_samples": [{"pred": "And", "count": 1, "cond_log_prob": -9.363815307617188}, {"pred": "But", "count": 1, "cond_log_prob": -10.064888000488281}, {"pred": "Do", "count": 1, "cond_log_prob": -10.178817749023438}, {"pred": "Gentlemen", "count": 1, "cond_log_prob": -11.955902099609375}, {"pred": "I", "count": 13, "cond_log_prob": -6.366386413574219}, {"pred": "If", "count": 1, "cond_log_prob": -8.651359558105469}, {"pred": "Im", "count": 2, "cond_log_prob": -12.738250732421875}, {"pred": "In", "count": 1, "cond_log_prob": -7.992530822753906}, {"pred": "Its", "count": 1, "cond_log_prob": -12.902191162109375}, {"pred": "Ive", "count": 1, "cond_log_prob": -15.565299987792969}, {"pred": "The", "count": 2, "cond_log_prob": -6.6489410400390625}, {"pred": "There", "count": 2, "cond_log_prob": -8.839317321777344}, {"pred": "Though", "count": 1, "cond_log_prob": -9.961837768554688}, {"pred": "To", "count": 1, "cond_log_prob": -10.137435913085938}, {"pred": "We", "count": 2, "cond_log_prob": -9.091529846191406}, {"pred": "You", "count": 4, "cond_log_prob": -9.188880920410156}, {"pred": "Your", "count": 1, "cond_log_prob": -10.099807739257812}, {"pred": "Youre", "count": 3, "cond_log_prob": -17.42646026611328}, {"pred": "route", "count": 1, "cond_log_prob": -16.26702117919922}]}, "7": {"context": {"text": "A clergyman remarked to him, \"The", "log_prob": -44.4024658203125}, "original": {"pred": "Lord", "cond_log_prob": -3.1182022094726562}, "human": [{"pred": "lord", "cond_log_prob": -6.35894775390625, "count": 4}, {"pred": "bible", "cond_log_prob": -7.7153472900390625, "count": 3}, {"pred": "good", "cond_log_prob": -6.069236755371094, "count": 2}, {"pred": "man", "cond_log_prob": -4.489234924316406, "count": 2}, {"pred": "meaning", "cond_log_prob": -7.6832427978515625, "count": 2}, {"pred": "sermon", "cond_log_prob": -6.873374938964844, "count": 2}, {"pred": "best", "cond_log_prob": -4.800773620605469, "count": 1}, {"pred": "congregation", "cond_log_prob": -7.012184143066406, "count": 1}, {"pred": "dog", "cond_log_prob": -7.395576477050781, "count": 1}, {"pred": "end", "cond_log_prob": -7.719779968261719, "count": 1}, {"pred": "fairy", "cond_log_prob": -10.434776306152344, "count": 1}, {"pred": "fox", "cond_log_prob": -8.767066955566406, "count": 1}, {"pred": "god", "cond_log_prob": -6.911811828613281, "count": 1}, {"pred": "important", "cond_log_prob": -8.432670593261719, "count": 1}, {"pred": "is", "cond_log_prob": -9.825569152832031, "count": 1}, {"pred": "judge", "cond_log_prob": -7.9869537353515625, "count": 1}, {"pred": "largest", "cond_log_prob": -8.692039489746094, "count": 1}, {"pred": "money", "cond_log_prob": -6.983543395996094, "count": 1}, {"pred": "moon", "cond_log_prob": -7.577384948730469, "count": 1}, {"pred": "one", "cond_log_prob": -5.5170135498046875, "count": 1}, {"pred": "only", "cond_log_prob": -4.071403503417969, "count": 1}, {"pred": "place", "cond_log_prob": -6.410377502441406, "count": 1}, {"pred": "price", "cond_log_prob": -7.9881134033203125, "count": 1}, {"pred": "rain", "cond_log_prob": -8.3636474609375, "count": 1}, {"pred": "saint", "cond_log_prob": -7.297203063964844, "count": 1}, {"pred": "sand", "cond_log_prob": -9.57867431640625, "count": 1}, {"pred": "savior", "cond_log_prob": -10.587799072265625, "count": 1}, {"pred": "supplies", "cond_log_prob": -12.761329650878906, "count": 1}, {"pred": "swallow", "cond_log_prob": -12.139945983886719, "count": 1}, {"pred": "teller", "cond_log_prob": -11.806625366210938, "count": 1}, {"pred": "thing", "cond_log_prob": -6.074851989746094, "count": 1}, {"pred": "world", "cond_log_prob": -5.13421630859375, "count": 1}], "ancestral_samples": [{"pred": "Bible", "count": 2, "cond_log_prob": -4.62017822265625}, {"pred": "Church", "count": 3, "cond_log_prob": -4.073646545410156}, {"pred": "King", "count": 1, "cond_log_prob": -5.391731262207031}, {"pred": "Lord", "count": 9, "cond_log_prob": -3.1182479858398438}, {"pred": "best", "count": 2, "cond_log_prob": -4.800773620605469}, {"pred": "day", "count": 1, "cond_log_prob": -5.888603210449219}, {"pred": "great", "count": 2, "cond_log_prob": -5.6567535400390625}, {"pred": "man", "count": 1, "cond_log_prob": -4.489234924316406}, {"pred": "most", "count": 2, "cond_log_prob": -4.898017883300781}, {"pred": "one", "count": 1, "cond_log_prob": -5.5170135498046875}, {"pred": "only", "count": 6, "cond_log_prob": -4.071403503417969}, {"pred": "onlyroute", "count": 1, "cond_log_prob": -25.160919189453125}, {"pred": "people", "count": 2, "cond_log_prob": -4.527412414550781}, {"pred": "pope", "count": 1, "cond_log_prob": -5.2484588623046875}, {"pred": "priest", "count": 2, "cond_log_prob": -4.340202331542969}, {"pred": "priests", "count": 1, "cond_log_prob": -4.7704925537109375}, {"pred": "way", "count": 1, "cond_log_prob": -5.4000244140625}, {"pred": "whole", "count": 2, "cond_log_prob": -4.9258270263671875}]}, "8": {"context": {"text": "A clergyman remarked to him, \"The Lord", "log_prob": -47.520668029785156}, "original": {"pred": "is", "cond_log_prob": -2.046131134033203}, "human": [{"pred": "has", "cond_log_prob": -1.7703781127929688, "count": 6}, {"pred": "is", "cond_log_prob": -2.0461654663085938, "count": 6}, {"pred": "will", "cond_log_prob": -2.6827011108398438, "count": 6}, {"pred": "shall", "cond_log_prob": -5.936531066894531, "count": 4}, {"pred": "said", "cond_log_prob": -4.415992736816406, "count": 3}, {"pred": "loves", "cond_log_prob": -4.2896575927734375, "count": 2}, {"pred": "of", "cond_log_prob": -5.020942687988281, "count": 2}, {"pred": "says", "cond_log_prob": -4.202812194824219, "count": 2}, {"pred": "always", "cond_log_prob": -5.886146545410156, "count": 1}, {"pred": "and", "cond_log_prob": -5.788749694824219, "count": 1}, {"pred": "asks", "cond_log_prob": -6.680137634277344, "count": 1}, {"pred": "bless", "cond_log_prob": -4.811195373535156, "count": 1}, {"pred": "does", "cond_log_prob": -4.112251281738281, "count": 1}, {"pred": "forgives", "cond_log_prob": -6.444629669189453, "count": 1}, {"pred": "knows", "cond_log_prob": -3.5713348388671875, "count": 1}, {"pred": "preaches", "cond_log_prob": -9.887264251708984, "count": 1}, {"pred": "saith", "cond_log_prob": -9.069465637207031, "count": 1}, {"pred": "wants", "cond_log_prob": -4.423362731933594, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -6.926200866699219}, {"pred": "did", "count": 1, "cond_log_prob": -4.790397644042969}, {"pred": "has", "count": 21, "cond_log_prob": -1.7703781127929688}, {"pred": "is", "count": 12, "cond_log_prob": -2.0461654663085938}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.491455078125}, {"pred": "knows", "count": 1, "cond_log_prob": -3.5713348388671875}, {"pred": "s", "count": 1, "cond_log_prob": -8.182167053222656}, {"pred": "will", "count": 2, "cond_log_prob": -2.6827011108398438}]}, "9": {"context": {"text": "A clergyman remarked to him, \"The Lord is", "log_prob": -49.56679916381836}, "original": {"pred": "on", "cond_log_prob": -4.866336822509766}, "human": [{"pred": "good", "cond_log_prob": -4.834239959716797, "count": 7}, {"pred": "our", "cond_log_prob": -4.533611297607422, "count": 5}, {"pred": "always", "cond_log_prob": -4.181316375732422, "count": 4}, {"pred": "my", "cond_log_prob": -3.689533233642578, "count": 4}, {"pred": "the", "cond_log_prob": -3.195934295654297, "count": 4}, {"pred": "great", "cond_log_prob": -4.361858367919922, "count": 2}, {"pred": "on", "cond_log_prob": -4.866436004638672, "count": 2}, {"pred": "all", "cond_log_prob": -4.956783294677734, "count": 1}, {"pred": "coming", "cond_log_prob": -4.050746917724609, "count": 1}, {"pred": "evil", "cond_log_prob": -8.372150421142578, "count": 1}, {"pred": "gone", "cond_log_prob": -7.420772552490234, "count": 1}, {"pred": "listening", "cond_log_prob": -6.116954803466797, "count": 1}, {"pred": "merciful", "cond_log_prob": -5.131725311279297, "count": 1}, {"pred": "mighty", "cond_log_prob": -5.696796417236328, "count": 1}, {"pred": "omnipotent", "cond_log_prob": -6.903682708740234, "count": 1}, {"pred": "real", "cond_log_prob": -7.273578643798828, "count": 1}, {"pred": "risen", "cond_log_prob": -8.201412200927734, "count": 1}, {"pred": "talking", "cond_log_prob": -6.322872161865234, "count": 1}, {"pred": "thy", "cond_log_prob": -7.417469024658203, "count": 1}, {"pred": "willing", "cond_log_prob": -5.130878448486328, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 9, "cond_log_prob": -3.3339271545410156}, {"pred": "alwaysroute", "count": 1, "cond_log_prob": -28.230777740478516}, {"pred": "great", "count": 2, "cond_log_prob": -4.361858367919922}, {"pred": "happy", "count": 1, "cond_log_prob": -6.404544830322266}, {"pred": "here", "count": 1, "cond_log_prob": -4.889919281005859}, {"pred": "mighty", "count": 1, "cond_log_prob": -5.696796417236328}, {"pred": "my", "count": 1, "cond_log_prob": -3.689533233642578}, {"pred": "not", "count": 14, "cond_log_prob": -2.5023841857910156}, {"pred": "our", "count": 1, "cond_log_prob": -4.533611297607422}, {"pred": "pleased", "count": 1, "cond_log_prob": -4.249706268310547}, {"pred": "the", "count": 3, "cond_log_prob": -3.195934295654297}, {"pred": "very", "count": 2, "cond_log_prob": -4.193248748779297}, {"pred": "well", "count": 1, "cond_log_prob": -5.883922576904297}, {"pred": "your", "count": 2, "cond_log_prob": -4.153064727783203}]}, "10": {"context": {"text": "A clergyman remarked to him, \"The Lord is on", "log_prob": -54.433135986328125}, "original": {"pred": "our", "cond_log_prob": -3.0268821716308594}, "human": [{"pred": "your", "cond_log_prob": -1.5147933959960938, "count": 15}, {"pred": "our", "cond_log_prob": -3.0269851684570312, "count": 9}, {"pred": "the", "cond_log_prob": -2.1185989379882812, "count": 6}, {"pred": "high", "cond_log_prob": -5.1023101806640625, "count": 3}, {"pred": "his", "cond_log_prob": -2.6128158569335938, "count": 3}, {"pred": "a", "cond_log_prob": -4.000236511230469, "count": 1}, {"pred": "from", "cond_log_prob": -10.400192260742188, "count": 1}, {"pred": "my", "cond_log_prob": -1.6002044677734375, "count": 1}, {"pred": "thy", "cond_log_prob": -4.376914978027344, "count": 1}, {"pred": "top", "cond_log_prob": -4.757972717285156, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -4.000236511230469}, {"pred": "his", "count": 4, "cond_log_prob": -2.6128158569335938}, {"pred": "my", "count": 10, "cond_log_prob": -1.6002044677734375}, {"pred": "myroute", "count": 1, "cond_log_prob": -21.516441345214844}, {"pred": "our", "count": 2, "cond_log_prob": -3.0269851684570312}, {"pred": "the", "count": 7, "cond_log_prob": -2.1185989379882812}, {"pred": "your", "count": 14, "cond_log_prob": -1.5147933959960938}]}, "11": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our", "log_prob": -57.460018157958984}, "original": {"pred": "side.\"", "cond_log_prob": -1.8360328674316406}, "human": [{"pred": "side", "cond_log_prob": -0.2886161804199219, "count": 35}, {"pred": "earth", "cond_log_prob": -7.538066864013672, "count": 2}, {"pred": "front", "cond_log_prob": -7.406749725341797, "count": 1}, {"pred": "minds", "cond_log_prob": -5.949825286865234, "count": 1}, {"pred": "shepherd", "cond_log_prob": -9.260723114013672, "count": 1}, {"pred": "this", "cond_log_prob": -10.65743637084961, "count": 1}], "ancestral_samples": [{"pred": "side", "count": 36, "cond_log_prob": -0.2886085510253906}, {"pred": "sideHe", "count": 1, "cond_log_prob": -15.084056854248047}, {"pred": "sideThe", "count": 2, "cond_log_prob": -14.057842254638672}, {"pred": "sideroute", "count": 1, "cond_log_prob": -26.842632293701172}]}, "12": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\"", "log_prob": -59.296051025390625}, "original": {"pred": "I", "cond_log_prob": -4.477684020996094}, "human": [{"pred": "he", "cond_log_prob": -9.015792846679688, "count": 17}, {"pred": "i", "cond_log_prob": -9.130874633789062, "count": 3}, {"pred": "so", "cond_log_prob": -10.623886108398438, "count": 2}, {"pred": "the", "cond_log_prob": -8.621673583984375, "count": 2}, {"pred": "then", "cond_log_prob": -10.903091430664062, "count": 3}, {"pred": "amen", "cond_log_prob": -17.165298461914062, "count": 1}, {"pred": "and", "cond_log_prob": -7.4668731689453125, "count": 1}, {"pred": "bingo", "cond_log_prob": -19.87749481201172, "count": 1}, {"pred": "but", "cond_log_prob": -10.430694580078125, "count": 1}, {"pred": "do", "cond_log_prob": -13.755279541015625, "count": 1}, {"pred": "in", "cond_log_prob": -9.695846557617188, "count": 1}, {"pred": "no", "cond_log_prob": -13.172195434570312, "count": 1}, {"pred": "now", "cond_log_prob": -12.334396362304688, "count": 1}, {"pred": "this", "cond_log_prob": -10.804977416992188, "count": 1}, {"pred": "to", "cond_log_prob": -9.732528686523438, "count": 1}, {"pred": "we", "cond_log_prob": -12.12628173828125, "count": 2}, {"pred": "which", "cond_log_prob": -10.914779663085938, "count": 1}, {"pred": "yes", "cond_log_prob": -16.626434326171875, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 1, "cond_log_prob": -5.18115234375}, {"pred": "A", "count": 1, "cond_log_prob": -4.446563720703125}, {"pred": "And", "count": 5, "cond_log_prob": -3.429656982421875}, {"pred": "Are", "count": 1, "cond_log_prob": -9.28631591796875}, {"pred": "He", "count": 4, "cond_log_prob": -3.1614227294921875}, {"pred": "How", "count": 2, "cond_log_prob": -6.5802459716796875}, {"pred": "I", "count": 5, "cond_log_prob": -4.4777984619140625}, {"pred": "In", "count": 1, "cond_log_prob": -4.4608001708984375}, {"pred": "The", "count": 13, "cond_log_prob": -2.656494140625}, {"pred": "Then", "count": 1, "cond_log_prob": -3.815338134765625}, {"pred": "We", "count": 1, "cond_log_prob": -5.9666748046875}, {"pred": "When", "count": 1, "cond_log_prob": -4.357025146484375}, {"pred": "Yes", "count": 2, "cond_log_prob": -8.137786865234375}, {"pred": "You", "count": 1, "cond_log_prob": -7.2145843505859375}, {"pred": "route", "count": 1, "cond_log_prob": -19.396713256835938}]}, "13": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I", "log_prob": -63.77373504638672}, "original": {"pred": "am", "cond_log_prob": -3.9642868041992188}, "human": [{"pred": "believe", "cond_log_prob": -4.843681335449219, "count": 5}, {"pred": "do", "cond_log_prob": -5.266212463378906, "count": 3}, {"pred": "know", "cond_log_prob": -5.262458801269531, "count": 3}, {"pred": "want", "cond_log_prob": -7.501197814941406, "count": 3}, {"pred": "will", "cond_log_prob": -5.586219787597656, "count": 3}, {"pred": "am", "cond_log_prob": -3.9644088745117188, "count": 2}, {"pred": "heard", "cond_log_prob": -3.9151992797851562, "count": 2}, {"pred": "replied", "cond_log_prob": -2.0567550659179688, "count": 2}, {"pred": "responded", "cond_log_prob": -4.863258361816406, "count": 2}, {"pred": "said", "cond_log_prob": -2.4134063720703125, "count": 2}, {"pred": "think", "cond_log_prob": -4.255775451660156, "count": 2}, {"pred": "was", "cond_log_prob": -3.3781204223632812, "count": 2}, {"pred": "declare", "cond_log_prob": -8.595573425292969, "count": 1}, {"pred": "did", "cond_log_prob": -4.731300354003906, "count": 1}, {"pred": "hope", "cond_log_prob": -7.259681701660156, "count": 1}, {"pred": "need", "cond_log_prob": -8.201622009277344, "count": 1}, {"pred": "noticed", "cond_log_prob": -6.173713684082031, "count": 1}, {"pred": "shall", "cond_log_prob": -6.224922180175781, "count": 1}, {"pred": "then", "cond_log_prob": -4.883857727050781, "count": 1}, {"pred": "thought", "cond_log_prob": -3.6007461547851562, "count": 1}, {"pred": "told", "cond_log_prob": -3.7961959838867188, "count": 1}, {"pred": "turned", "cond_log_prob": -5.834297180175781, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.216087341308594}, {"pred": "am", "count": 1, "cond_log_prob": -3.9644088745117188}, {"pred": "answered", "count": 2, "cond_log_prob": -3.5005416870117188}, {"pred": "asked", "count": 4, "cond_log_prob": -2.5491561889648438}, {"pred": "did", "count": 1, "cond_log_prob": -4.731300354003906}, {"pred": "felt", "count": 1, "cond_log_prob": -4.989906311035156}, {"pred": "had", "count": 1, "cond_log_prob": -4.360466003417969}, {"pred": "have", "count": 1, "cond_log_prob": -4.107734680175781}, {"pred": "heardroute", "count": 1, "cond_log_prob": -30.823928833007812}, {"pred": "participated", "count": 1, "cond_log_prob": -10.629005432128906}, {"pred": "replied", "count": 6, "cond_log_prob": -2.0567550659179688}, {"pred": "said", "count": 11, "cond_log_prob": -2.4134063720703125}, {"pred": "then", "count": 1, "cond_log_prob": -4.883857727050781}, {"pred": "think", "count": 1, "cond_log_prob": -4.255775451660156}, {"pred": "thought", "count": 1, "cond_log_prob": -3.6007461547851562}, {"pred": "told", "count": 1, "cond_log_prob": -3.7961959838867188}, {"pred": "was", "count": 5, "cond_log_prob": -3.3781204223632812}]}, "14": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am", "log_prob": -67.73802185058594}, "original": {"pred": "not", "cond_log_prob": -2.22723388671875}, "human": [{"pred": "not", "cond_log_prob": -2.22735595703125, "count": 7}, {"pred": "sure", "cond_log_prob": -2.4329299926757812, "count": 7}, {"pred": "a", "cond_log_prob": -3.1662368774414062, "count": 4}, {"pred": "certain", "cond_log_prob": -3.9987258911132812, "count": 2}, {"pred": "glad", "cond_log_prob": -3.0471572875976562, "count": 2}, {"pred": "here", "cond_log_prob": -5.805335998535156, "count": 2}, {"pred": "proud", "cond_log_prob": -5.9861602783203125, "count": 2}, {"pred": "the", "cond_log_prob": -3.8920669555664062, "count": 2}, {"pred": "always", "cond_log_prob": -6.039817810058594, "count": 1}, {"pred": "an", "cond_log_prob": -4.693824768066406, "count": 1}, {"pred": "called", "cond_log_prob": -6.781219482421875, "count": 1}, {"pred": "happy", "cond_log_prob": -5.871788024902344, "count": 1}, {"pred": "his", "cond_log_prob": -5.737693786621094, "count": 1}, {"pred": "nice", "cond_log_prob": -11.133842468261719, "count": 1}, {"pred": "on", "cond_log_prob": -5.609443664550781, "count": 1}, {"pred": "positive", "cond_log_prob": -9.267341613769531, "count": 1}, {"pred": "saved", "cond_log_prob": -9.661300659179688, "count": 1}, {"pred": "so", "cond_log_prob": -5.032463073730469, "count": 1}, {"pred": "thankful", "cond_log_prob": -6.043182373046875, "count": 1}, {"pred": "totally", "cond_log_prob": -8.432838439941406, "count": 1}, {"pred": "used", "cond_log_prob": -7.7862091064453125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.758064270019531}, {"pred": "a", "count": 4, "cond_log_prob": -3.1662368774414062}, {"pred": "afraid", "count": 1, "cond_log_prob": -3.9462661743164062}, {"pred": "convinced", "count": 2, "cond_log_prob": -4.797981262207031}, {"pred": "happy", "count": 1, "cond_log_prob": -5.871788024902344}, {"pred": "informed", "count": 1, "cond_log_prob": -5.5272064208984375}, {"pred": "not", "count": 12, "cond_log_prob": -2.22735595703125}, {"pred": "sorry", "count": 3, "cond_log_prob": -3.4078292846679688}, {"pred": "sure", "count": 14, "cond_log_prob": -2.4329299926757812}, {"pred": "sureroute", "count": 1, "cond_log_prob": -25.818206787109375}]}, "15": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not", "log_prob": -69.96525573730469}, "original": {"pred": "at", "cond_log_prob": -5.1124420166015625}, "human": [{"pred": "sure", "cond_log_prob": -1.5196151733398438, "count": 7}, {"pred": "a", "cond_log_prob": -2.9216079711914062, "count": 5}, {"pred": "afraid", "cond_log_prob": -4.692359924316406, "count": 4}, {"pred": "going", "cond_log_prob": -4.320594787597656, "count": 4}, {"pred": "so", "cond_log_prob": -3.6738052368164062, "count": 3}, {"pred": "the", "cond_log_prob": -4.063224792480469, "count": 3}, {"pred": "always", "cond_log_prob": -7.045783996582031, "count": 1}, {"pred": "arguing", "cond_log_prob": -7.574775695800781, "count": 1}, {"pred": "ashamed", "cond_log_prob": -4.296501159667969, "count": 1}, {"pred": "at", "cond_log_prob": -5.112571716308594, "count": 1}, {"pred": "concerned", "cond_log_prob": -5.615577697753906, "count": 1}, {"pred": "confident", "cond_log_prob": -6.812263488769531, "count": 1}, {"pred": "good", "cond_log_prob": -8.181266784667969, "count": 1}, {"pred": "in", "cond_log_prob": -4.411201477050781, "count": 1}, {"pred": "is", "cond_log_prob": -10.650779724121094, "count": 1}, {"pred": "lying", "cond_log_prob": -8.204048156738281, "count": 1}, {"pred": "saying", "cond_log_prob": -3.3571090698242188, "count": 1}, {"pred": "surprised", "cond_log_prob": -4.325279235839844, "count": 1}, {"pred": "telling", "cond_log_prob": -5.683998107910156, "count": 1}, {"pred": "there", "cond_log_prob": -6.478065490722656, "count": 1}, {"pred": "trying", "cond_log_prob": -5.503501892089844, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.657310485839844}, {"pred": "a", "count": 4, "cond_log_prob": -2.9216079711914062}, {"pred": "quite", "count": 1, "cond_log_prob": -4.392036437988281}, {"pred": "sure", "count": 32, "cond_log_prob": -1.5196151733398438}, {"pred": "sureBut", "count": 1, "cond_log_prob": -17.36431884765625}, {"pred": "sureroute", "count": 1, "cond_log_prob": -27.416641235351562}]}, "16": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at", "log_prob": -75.07769775390625}, "original": {"pred": "all", "cond_log_prob": -0.4606781005859375}, "human": [{"pred": "all", "cond_log_prob": -0.4608154296875, "count": 17}, {"pred": "the", "cond_log_prob": -4.485542297363281, "count": 10}, {"pred": "a", "cond_log_prob": -4.2839508056640625, "count": 3}, {"pred": "peace", "cond_log_prob": -4.425636291503906, "count": 2}, {"pred": "that", "cond_log_prob": -4.601707458496094, "count": 2}, {"pred": "your", "cond_log_prob": -6.862327575683594, "count": 2}, {"pred": "church", "cond_log_prob": -8.38775634765625, "count": 1}, {"pred": "his", "cond_log_prob": -7.01458740234375, "count": 1}, {"pred": "home", "cond_log_prob": -4.9296112060546875, "count": 1}, {"pred": "liberty", "cond_log_prob": -1.510711669921875, "count": 1}, {"pred": "my", "cond_log_prob": -6.416831970214844, "count": 1}], "ancestral_samples": [{"pred": "all", "count": 33, "cond_log_prob": -0.4608154296875}, {"pred": "allroute", "count": 1, "cond_log_prob": -26.484275817871094}, {"pred": "liberty", "count": 6, "cond_log_prob": -1.510711669921875}]}, "17": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all", "log_prob": -75.53837585449219}, "original": {"pred": "concerned", "cond_log_prob": -4.619468688964844}, "human": [{"pred": "surprised", "cond_log_prob": -1.3489532470703125, "count": 5}, {"pred": "convinced", "cond_log_prob": -3.1006698608398438, "count": 4}, {"pred": "afraid", "cond_log_prob": -4.589057922363281, "count": 3}, {"pred": "impressed", "cond_log_prob": -3.3438644409179688, "count": 3}, {"pred": "a", "cond_log_prob": -4.464874267578125, "count": 2}, {"pred": "concerned", "cond_log_prob": -4.619621276855469, "count": 2}, {"pred": "sure", "cond_log_prob": -2.1981964111328125, "count": 2}, {"pred": "the", "cond_log_prob": -5.131324768066406, "count": 2}, {"pred": "alone", "cond_log_prob": -8.031852722167969, "count": 1}, {"pred": "attempting", "cond_log_prob": -9.823982238769531, "count": 1}, {"pred": "aware", "cond_log_prob": -3.9947433471679688, "count": 1}, {"pred": "by", "cond_log_prob": -9.101158142089844, "count": 1}, {"pred": "crazy", "cond_log_prob": -8.580673217773438, "count": 1}, {"pred": "going", "cond_log_prob": -6.703041076660156, "count": 1}, {"pred": "implying", "cond_log_prob": -8.253349304199219, "count": 1}, {"pred": "in", "cond_log_prob": -4.590080261230469, "count": 1}, {"pred": "interested", "cond_log_prob": -4.486778259277344, "count": 1}, {"pred": "of", "cond_log_prob": -6.8157806396484375, "count": 1}, {"pred": "offended", "cond_log_prob": -5.671722412109375, "count": 1}, {"pred": "perturbed", "cond_log_prob": -7.854209899902344, "count": 1}, {"pred": "proud", "cond_log_prob": -5.955085754394531, "count": 1}, {"pred": "religious", "cond_log_prob": -7.429237365722656, "count": 1}, {"pred": "sad", "cond_log_prob": -8.168502807617188, "count": 1}, {"pred": "saying", "cond_log_prob": -5.971717834472656, "count": 1}, {"pred": "that", "cond_log_prob": -6.068702697753906, "count": 1}, {"pred": "your", "cond_log_prob": -7.507469177246094, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.464874267578125}, {"pred": "convinced", "count": 3, "cond_log_prob": -3.1006698608398438}, {"pred": "happy", "count": 1, "cond_log_prob": -5.446311950683594}, {"pred": "sure", "count": 9, "cond_log_prob": -2.1981964111328125}, {"pred": "surprised", "count": 25, "cond_log_prob": -1.3489532470703125}, {"pred": "surprisedroute", "count": 1, "cond_log_prob": -25.180099487304688}]}, "18": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned", "log_prob": -80.15784454345703}, "original": {"pred": "about", "cond_log_prob": -2.0268478393554688}, "human": [{"pred": "with", "cond_log_prob": -0.5832290649414062, "count": 21}, {"pred": "about", "cond_log_prob": -2.027008056640625, "count": 14}, {"pred": "for", "cond_log_prob": -4.2345123291015625, "count": 3}, {"pred": "at", "cond_log_prob": -3.96209716796875, "count": 1}, {"pred": "by", "cond_log_prob": -4.6945953369140625, "count": 1}, {"pred": "that", "cond_log_prob": -3.3145217895507812, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.484024047851562}, {"pred": "with", "count": 38, "cond_log_prob": -0.5832290649414062}, {"pred": "withroute", "count": 1, "cond_log_prob": -24.498153686523438}]}, "19": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about", "log_prob": -82.1846923828125}, "original": {"pred": "that,", "cond_log_prob": -4.169097900390625}, "human": [{"pred": "the", "cond_log_prob": -1.5468978881835938, "count": 12}, {"pred": "his", "cond_log_prob": -2.5824737548828125, "count": 3}, {"pred": "my", "cond_log_prob": -3.3169174194335938, "count": 3}, {"pred": "that", "cond_log_prob": -2.5056304931640625, "count": 3}, {"pred": "this", "cond_log_prob": -2.1904525756835938, "count": 3}, {"pred": "what", "cond_log_prob": -3.474395751953125, "count": 3}, {"pred": "being", "cond_log_prob": -5.125617980957031, "count": 2}, {"pred": "it", "cond_log_prob": -3.3936767578125, "count": 2}, {"pred": "your", "cond_log_prob": -3.6518783569335938, "count": 2}, {"pred": "anything", "cond_log_prob": -5.646018981933594, "count": 1}, {"pred": "darn", "cond_log_prob": -14.824493408203125, "count": 1}, {"pred": "him", "cond_log_prob": -3.04949951171875, "count": 1}, {"pred": "myself", "cond_log_prob": -6.543449401855469, "count": 1}, {"pred": "religion", "cond_log_prob": -5.677398681640625, "count": 1}, {"pred": "such", "cond_log_prob": -4.2777252197265625, "count": 1}, {"pred": "whether", "cond_log_prob": -4.055145263671875, "count": 1}, {"pred": "you", "cond_log_prob": -4.7608642578125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.566658020019531}, {"pred": "his", "count": 1, "cond_log_prob": -2.5824737548828125}, {"pred": "my", "count": 2, "cond_log_prob": -3.3169174194335938}, {"pred": "that", "count": 2, "cond_log_prob": -2.5056304931640625}, {"pred": "the", "count": 28, "cond_log_prob": -1.5468978881835938}, {"pred": "this", "count": 4, "cond_log_prob": -2.1904525756835938}, {"pred": "thisroute", "count": 1, "cond_log_prob": -23.570724487304688}, {"pred": "your", "count": 1, "cond_log_prob": -3.6518783569335938}]}, "20": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that,", "log_prob": -86.35379028320312}, "original": {"pred": "replied", "cond_log_prob": -10.135017395019531}, "human": [{"pred": "but", "cond_log_prob": -1.4903564453125, "count": 14}, {"pred": "i", "cond_log_prob": -8.451004028320312, "count": 8}, {"pred": "because", "cond_log_prob": -2.296051025390625, "count": 3}, {"pred": "he", "cond_log_prob": -4.651832580566406, "count": 3}, {"pred": "said", "cond_log_prob": -6.523895263671875, "count": 2}, {"pred": "although", "cond_log_prob": -4.847381591796875, "count": 1}, {"pred": "and", "cond_log_prob": -2.7783355712890625, "count": 1}, {"pred": "as", "cond_log_prob": -3.4588623046875, "count": 1}, {"pred": "however", "cond_log_prob": -5.0823516845703125, "count": 1}, {"pred": "it", "cond_log_prob": -4.8931732177734375, "count": 1}, {"pred": "replied", "cond_log_prob": -10.135200500488281, "count": 1}, {"pred": "so", "cond_log_prob": -4.838104248046875, "count": 1}, {"pred": "the", "cond_log_prob": -5.1323394775390625, "count": 1}, {"pred": "then", "cond_log_prob": -6.9220428466796875, "count": 1}, {"pred": "what", "cond_log_prob": -7.1464996337890625, "count": 1}, {"pred": "why", "cond_log_prob": -8.437751770019531, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 2, "cond_log_prob": -2.7783355712890625}, {"pred": "because", "count": 5, "cond_log_prob": -2.296051025390625}, {"pred": "but", "count": 17, "cond_log_prob": -1.4903564453125}, {"pred": "for", "count": 15, "cond_log_prob": -1.5702743530273438}, {"pred": "forroute", "count": 1, "cond_log_prob": -24.46611785888672}]}, "21": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied", "log_prob": -96.48880767822266}, "original": {"pred": "Mr.", "cond_log_prob": -3.5440902709960938}, "human": [{"pred": "the", "cond_log_prob": -0.7852935791015625, "count": 37}, {"pred": "gone", "cond_log_prob": -15.430023193359375, "count": 1}, {"pred": "he", "cond_log_prob": -1.9291229248046875, "count": 1}, {"pred": "i", "cond_log_prob": -10.373725891113281, "count": 1}, {"pred": "noah", "cond_log_prob": -17.319175720214844, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.109222412109375}, {"pred": "he", "count": 4, "cond_log_prob": -1.9291229248046875}, {"pred": "the", "count": 34, "cond_log_prob": -0.7852935791015625}, {"pred": "theroute", "count": 1, "cond_log_prob": -28.07183837890625}]}, "22": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr.", "log_prob": -100.03289794921875}, "original": {"pred": "Lincoln;", "cond_log_prob": -9.047897338867188}, "human": [{"pred": "smith", "cond_log_prob": -13.771751403808594, "count": 12}, {"pred": "jones", "cond_log_prob": -15.507652282714844, "count": 5}, {"pred": "brown", "cond_log_prob": -15.395294189453125, "count": 3}, {"pred": "johnson", "cond_log_prob": -15.439842224121094, "count": 2}, {"pred": "apple", "cond_log_prob": -17.370132446289062, "count": 1}, {"pred": "banks", "cond_log_prob": -16.918228149414062, "count": 1}, {"pred": "bart", "cond_log_prob": -18.217987060546875, "count": 1}, {"pred": "black", "cond_log_prob": -13.765625, "count": 1}, {"pred": "cool", "cond_log_prob": -17.383895874023438, "count": 1}, {"pred": "darcy", "cond_log_prob": -18.733299255371094, "count": 1}, {"pred": "darsey", "cond_log_prob": -21.371109008789062, "count": 1}, {"pred": "garfield", "cond_log_prob": -19.8580322265625, "count": 1}, {"pred": "green", "cond_log_prob": -15.962844848632812, "count": 1}, {"pred": "johns", "cond_log_prob": -17.61284637451172, "count": 1}, {"pred": "jordan", "cond_log_prob": -15.646018981933594, "count": 1}, {"pred": "lincoln", "cond_log_prob": -15.410293579101562, "count": 1}, {"pred": "mathew", "cond_log_prob": -18.825355529785156, "count": 1}, {"pred": "scott", "cond_log_prob": -16.830307006835938, "count": 1}, {"pred": "scrooge", "cond_log_prob": -18.167312622070312, "count": 1}, {"pred": "self-assured", "cond_log_prob": -20.581634521484375, "count": 1}, {"pred": "stone", "cond_log_prob": -14.311203002929688, "count": 1}, {"pred": "whitby", "cond_log_prob": -23.451980590820312, "count": 1}, {"pred": "wood", "cond_log_prob": -14.063140869140625, "count": 1}], "ancestral_samples": [{"pred": "B", "count": 2, "cond_log_prob": -4.69549560546875}, {"pred": "Beaumont", "count": 1, "cond_log_prob": -8.781745910644531}, {"pred": "Bishop", "count": 3, "cond_log_prob": -4.7790985107421875}, {"pred": "Bruges", "count": 1, "cond_log_prob": -12.663230895996094}, {"pred": "Butler", "count": 2, "cond_log_prob": -5.403350830078125}, {"pred": "C", "count": 2, "cond_log_prob": -5.3769683837890625}, {"pred": "DAntonio", "count": 1, "cond_log_prob": -19.366806030273438}, {"pred": "Droute", "count": 1, "cond_log_prob": -18.219017028808594}, {"pred": "G", "count": 1, "cond_log_prob": -4.6371917724609375}, {"pred": "H", "count": 1, "cond_log_prob": -4.9290771484375}, {"pred": "Hubbard", "count": 1, "cond_log_prob": -7.599945068359375}, {"pred": "Justice", "count": 1, "cond_log_prob": -5.645050048828125}, {"pred": "K", "count": 1, "cond_log_prob": -5.651519775390625}, {"pred": "King", "count": 1, "cond_log_prob": -5.442138671875}, {"pred": "Lacy", "count": 1, "cond_log_prob": -9.851455688476562}, {"pred": "Ladd", "count": 1, "cond_log_prob": -9.779090881347656}, {"pred": "Loyola", "count": 1, "cond_log_prob": -11.156082153320312}, {"pred": "M", "count": 1, "cond_log_prob": -5.2265472412109375}, {"pred": "Miller", "count": 1, "cond_log_prob": -6.9252777099609375}, {"pred": "Morgan", "count": 1, "cond_log_prob": -6.65185546875}, {"pred": "P", "count": 1, "cond_log_prob": -4.781036376953125}, {"pred": "Platt", "count": 1, "cond_log_prob": -8.549293518066406}, {"pred": "Seward", "count": 1, "cond_log_prob": -7.8003387451171875}, {"pred": "Smith", "count": 6, "cond_log_prob": -4.317771911621094}, {"pred": "Spence", "count": 1, "cond_log_prob": -7.208984375}, {"pred": "St", "count": 1, "cond_log_prob": -5.14410400390625}, {"pred": "T", "count": 2, "cond_log_prob": -5.386322021484375}, {"pred": "Thomas", "count": 1, "cond_log_prob": -5.6339569091796875}, {"pred": "Whitten", "count": 1, "cond_log_prob": -9.670738220214844}]}, "23": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln;", "log_prob": -109.08079528808594}, "original": {"pred": "\"for", "cond_log_prob": -8.5120849609375}, "human": [{"pred": "i", "cond_log_prob": -8.630264282226562, "count": 15}, {"pred": "but", "cond_log_prob": -1.30316162109375, "count": 5}, {"pred": "the", "cond_log_prob": -3.7545623779296875, "count": 3}, {"pred": "what", "cond_log_prob": -5.6134185791015625, "count": 3}, {"pred": "he", "cond_log_prob": -2.9369964599609375, "count": 3}, {"pred": "then", "cond_log_prob": -7.710784912109375, "count": 2}, {"pred": "for", "cond_log_prob": -2.0256881713867188, "count": 1}, {"pred": "however", "cond_log_prob": -5.93878173828125, "count": 1}, {"pred": "lincoln", "cond_log_prob": -17.984237670898438, "count": 1}, {"pred": "so", "cond_log_prob": -5.72589111328125, "count": 1}, {"pred": "there", "cond_log_prob": -5.063301086425781, "count": 1}, {"pred": "though", "cond_log_prob": -6.0608367919921875, "count": 1}, {"pred": "to", "cond_log_prob": -6.009071350097656, "count": 1}, {"pred": "we", "cond_log_prob": -4.802604675292969, "count": 2}, {"pred": "who", "cond_log_prob": -6.46533203125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 12, "cond_log_prob": -1.7874908447265625}, {"pred": "and", "count": 1, "cond_log_prob": -2.9567794799804688}, {"pred": "but", "count": 20, "cond_log_prob": -1.30316162109375}, {"pred": "butroute", "count": 1, "cond_log_prob": -26.431259155273438}, {"pred": "for", "count": 4, "cond_log_prob": -2.0256881713867188}, {"pred": "he", "count": 1, "cond_log_prob": -2.9369964599609375}, {"pred": "it", "count": 1, "cond_log_prob": -3.22412109375}]}, "24": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for", "log_prob": -117.59288024902344}, "original": {"pred": "I", "cond_log_prob": -1.7393417358398438}, "human": [{"pred": "i", "cond_log_prob": -9.294754028320312, "count": 21}, {"pred": "the", "cond_log_prob": -2.3030242919921875, "count": 8}, {"pred": "we", "cond_log_prob": -2.6885223388671875, "count": 4}, {"pred": "he", "cond_log_prob": -2.92645263671875, "count": 3}, {"pred": "a", "cond_log_prob": -4.808372497558594, "count": 1}, {"pred": "god", "cond_log_prob": -10.359878540039062, "count": 1}, {"pred": "our", "cond_log_prob": -4.23577880859375, "count": 1}, {"pred": "when", "cond_log_prob": -4.8446044921875, "count": 1}, {"pred": "your", "cond_log_prob": -5.3285064697265625, "count": 1}], "ancestral_samples": [{"pred": "God", "count": 1, "cond_log_prob": -3.7231597900390625}, {"pred": "I", "count": 22, "cond_log_prob": -1.7396087646484375}, {"pred": "Iroute", "count": 1, "cond_log_prob": -25.880111694335938}, {"pred": "a", "count": 1, "cond_log_prob": -4.808372497558594}, {"pred": "he", "count": 2, "cond_log_prob": -2.92645263671875}, {"pred": "if", "count": 1, "cond_log_prob": -3.2752532958984375}, {"pred": "it", "count": 1, "cond_log_prob": -2.524627685546875}, {"pred": "my", "count": 2, "cond_log_prob": -3.9064865112304688}, {"pred": "the", "count": 8, "cond_log_prob": -2.3030242919921875}, {"pred": "we", "count": 1, "cond_log_prob": -2.6885223388671875}]}, "25": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I", "log_prob": -119.33222198486328}, "original": {"pred": "know", "cond_log_prob": -2.7944869995117188}, "human": [{"pred": "am", "cond_log_prob": -1.4125289916992188, "count": 17}, {"pred": "know", "cond_log_prob": -2.7947616577148438, "count": 16}, {"pred": "already", "cond_log_prob": -7.534355163574219, "count": 1}, {"pred": "are", "cond_log_prob": -6.234748840332031, "count": 1}, {"pred": "believe", "cond_log_prob": -3.2209396362304688, "count": 1}, {"pred": "feel", "cond_log_prob": -4.745445251464844, "count": 1}, {"pred": "have", "cond_log_prob": -2.1996078491210938, "count": 1}, {"pred": "i", "cond_log_prob": -14.624504089355469, "count": 1}, {"pred": "speak", "cond_log_prob": -6.132423400878906, "count": 1}, {"pred": "the", "cond_log_prob": -9.873802185058594, "count": 1}], "ancestral_samples": [{"pred": "am", "count": 23, "cond_log_prob": -1.4125289916992188}, {"pred": "believe", "count": 1, "cond_log_prob": -3.2209396362304688}, {"pred": "do", "count": 3, "cond_log_prob": -2.5898361206054688}, {"pred": "have", "count": 9, "cond_log_prob": -2.1996078491210938}, {"pred": "haverouteed", "count": 1, "cond_log_prob": -32.66307830810547}, {"pred": "know", "count": 2, "cond_log_prob": -2.7947616577148438}, {"pred": "will", "count": 1, "cond_log_prob": -3.8041915893554688}]}, "26": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know", "log_prob": -122.126708984375}, "original": {"pred": "that", "cond_log_prob": -1.2687225341796875}, "human": [{"pred": "that", "cond_log_prob": -1.269012451171875, "count": 30}, {"pred": "the", "cond_log_prob": -2.8663482666015625, "count": 5}, {"pred": "he", "cond_log_prob": -3.2701416015625, "count": 3}, {"pred": "am", "cond_log_prob": -11.246566772460938, "count": 1}, {"pred": "i", "cond_log_prob": -11.094070434570312, "count": 1}, {"pred": "what", "cond_log_prob": -3.4965057373046875, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -4.1479339599609375}, {"pred": "a", "count": 1, "cond_log_prob": -4.7257080078125}, {"pred": "he", "count": 1, "cond_log_prob": -3.2701416015625}, {"pred": "my", "count": 1, "cond_log_prob": -4.3130340576171875}, {"pred": "not", "count": 3, "cond_log_prob": -2.7277984619140625}, {"pred": "that", "count": 29, "cond_log_prob": -1.269012451171875}, {"pred": "thatroute", "count": 1, "cond_log_prob": -24.56488037109375}, {"pred": "the", "count": 1, "cond_log_prob": -2.8663482666015625}, {"pred": "very", "count": 1, "cond_log_prob": -4.2504425048828125}, {"pred": "well", "count": 1, "cond_log_prob": -4.2700042724609375}]}, "27": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that", "log_prob": -123.39543151855469}, "original": {"pred": "the", "cond_log_prob": -1.816375732421875}, "human": [{"pred": "the", "cond_log_prob": -1.8166656494140625, "count": 24}, {"pred": "we", "cond_log_prob": -3.065643310546875, "count": 4}, {"pred": "god", "cond_log_prob": -9.465530395507812, "count": 2}, {"pred": "he", "cond_log_prob": -2.2369537353515625, "count": 4}, {"pred": "i", "cond_log_prob": -10.095291137695312, "count": 3}, {"pred": "is", "cond_log_prob": -6.21746826171875, "count": 1}, {"pred": "mentally", "cond_log_prob": -13.911056518554688, "count": 1}, {"pred": "my", "cond_log_prob": -4.415191650390625, "count": 1}, {"pred": "thou", "cond_log_prob": -6.5284881591796875, "count": 1}], "ancestral_samples": [{"pred": "God", "count": 3, "cond_log_prob": -2.4122161865234375}, {"pred": "Godroute", "count": 1, "cond_log_prob": -28.708755493164062}, {"pred": "I", "count": 3, "cond_log_prob": -3.1748809814453125}, {"pred": "a", "count": 1, "cond_log_prob": -4.910675048828125}, {"pred": "he", "count": 7, "cond_log_prob": -2.2369537353515625}, {"pred": "it", "count": 1, "cond_log_prob": -3.2899932861328125}, {"pred": "my", "count": 1, "cond_log_prob": -4.415191650390625}, {"pred": "the", "count": 20, "cond_log_prob": -1.8166656494140625}, {"pred": "you", "count": 2, "cond_log_prob": -3.037872314453125}, {"pred": "your", "count": 1, "cond_log_prob": -4.667694091796875}]}, "28": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the", "log_prob": -125.21180725097656}, "original": {"pred": "Lord", "cond_log_prob": -0.5674819946289062}, "human": [{"pred": "lord", "cond_log_prob": -6.4927825927734375, "count": 36}, {"pred": "done", "cond_log_prob": -13.493484497070312, "count": 1}, {"pred": "flesh", "cond_log_prob": -8.285125732421875, "count": 1}, {"pred": "jesus", "cond_log_prob": -13.488082885742188, "count": 1}, {"pred": "people", "cond_log_prob": -4.3078765869140625, "count": 1}, {"pred": "world", "cond_log_prob": -6.08660888671875, "count": 1}], "ancestral_samples": [{"pred": "Church", "count": 1, "cond_log_prob": -3.8629302978515625}, {"pred": "Lord", "count": 38, "cond_log_prob": -0.567779541015625}, {"pred": "Lordroute", "count": 1, "cond_log_prob": -27.040481567382812}]}, "29": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord", "log_prob": -125.77928924560547}, "original": {"pred": "is", "cond_log_prob": -0.8046646118164062}, "human": [{"pred": "is", "cond_log_prob": -0.8049697875976562, "count": 22}, {"pred": "will", "cond_log_prob": -2.2193832397460938, "count": 10}, {"pred": "has", "cond_log_prob": -2.3525009155273438, "count": 2}, {"pred": "knows", "cond_log_prob": -4.447257995605469, "count": 2}, {"pred": "loves", "cond_log_prob": -4.654396057128906, "count": 2}, {"pred": "my", "cond_log_prob": -8.715812683105469, "count": 1}, {"pred": "surely", "cond_log_prob": -9.799613952636719, "count": 1}, {"pred": "with", "cond_log_prob": -7.761314392089844, "count": 1}], "ancestral_samples": [{"pred": "has", "count": 1, "cond_log_prob": -2.3525009155273438}, {"pred": "is", "count": 33, "cond_log_prob": -0.8049697875976562}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.495399475097656}, {"pred": "will", "count": 5, "cond_log_prob": -2.2193832397460938}]}, "30": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is", "log_prob": -126.58395385742188}, "original": {"pred": "always", "cond_log_prob": -4.281341552734375}, "human": [{"pred": "on", "cond_log_prob": -0.9768524169921875, "count": 21}, {"pred": "always", "cond_log_prob": -4.281646728515625, "count": 4}, {"pred": "good", "cond_log_prob": -5.9423675537109375, "count": 4}, {"pred": "with", "cond_log_prob": -3.0456695556640625, "count": 2}, {"pred": "also", "cond_log_prob": -5.220611572265625, "count": 1}, {"pred": "evil", "cond_log_prob": -8.962448120117188, "count": 1}, {"pred": "god", "cond_log_prob": -9.049896240234375, "count": 1}, {"pred": "helping", "cond_log_prob": -7.4791107177734375, "count": 1}, {"pred": "here", "cond_log_prob": -5.0934295654296875, "count": 1}, {"pred": "in", "cond_log_prob": -3.598785400390625, "count": 1}, {"pred": "my", "cond_log_prob": -5.7594146728515625, "count": 1}, {"pred": "our", "cond_log_prob": -4.9329681396484375, "count": 1}, {"pred": "this", "cond_log_prob": -8.24993896484375, "count": 1}, {"pred": "watching", "cond_log_prob": -6.1623992919921875, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.845550537109375}, {"pred": "not", "count": 2, "cond_log_prob": -2.57025146484375}, {"pred": "on", "count": 36, "cond_log_prob": -0.9768447875976562}, {"pred": "onroute", "count": 1, "cond_log_prob": -24.80792236328125}]}, "31": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always", "log_prob": -130.86529541015625}, "original": {"pred": "on", "cond_log_prob": -0.8299102783203125}, "human": [{"pred": "on", "cond_log_prob": -0.830230712890625, "count": 19}, {"pred": "with", "cond_log_prob": -2.419464111328125, "count": 7}, {"pred": "watching", "cond_log_prob": -4.736968994140625, "count": 5}, {"pred": "there", "cond_log_prob": -3.1033935546875, "count": 3}, {"pred": "at", "cond_log_prob": -3.990020751953125, "count": 1}, {"pred": "aware", "cond_log_prob": -8.1800537109375, "count": 1}, {"pred": "going", "cond_log_prob": -5.088287353515625, "count": 1}, {"pred": "hurting", "cond_log_prob": -10.837005615234375, "count": 1}, {"pred": "looking", "cond_log_prob": -4.636871337890625, "count": 1}, {"pred": "near", "cond_log_prob": -6.0330810546875, "count": 1}, {"pred": "test", "cond_log_prob": -11.7969970703125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.01483154296875}, {"pred": "on", "count": 36, "cond_log_prob": -0.830230712890625}, {"pred": "onroute", "count": 1, "cond_log_prob": -24.411056518554688}, {"pred": "right", "count": 1, "cond_log_prob": -3.411102294921875}, {"pred": "with", "count": 1, "cond_log_prob": -2.419464111328125}]}, "32": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on", "log_prob": -131.69520568847656}, "original": {"pred": "the", "cond_log_prob": -2.8608551025390625}, "human": [{"pred": "our", "cond_log_prob": -0.2560577392578125, "count": 28}, {"pred": "my", "cond_log_prob": -2.85699462890625, "count": 8}, {"pred": "the", "cond_log_prob": -2.8611907958984375, "count": 5}], "ancestral_samples": [{"pred": "my", "count": 2, "cond_log_prob": -2.85699462890625}, {"pred": "our", "count": 37, "cond_log_prob": -0.2560577392578125}, {"pred": "ourroute", "count": 1, "cond_log_prob": -25.758499145507812}]}, "33": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the", "log_prob": -134.55606079101562}, "original": {"pred": "side", "cond_log_prob": -0.1212310791015625}, "human": [{"pred": "side", "cond_log_prob": -0.12158203125, "count": 27}, {"pred": "right", "cond_log_prob": -3.930450439453125, "count": 8}, {"pred": "good", "cond_log_prob": -7.03436279296875, "count": 1}, {"pred": "job", "cond_log_prob": -10.828887939453125, "count": 1}, {"pred": "mission", "cond_log_prob": -9.577392578125, "count": 1}, {"pred": "same", "cond_log_prob": -6.17193603515625, "count": 1}, {"pred": "shelf", "cond_log_prob": -13.1827392578125, "count": 1}, {"pred": "winning", "cond_log_prob": -10.200958251953125, "count": 1}], "ancestral_samples": [{"pred": "side", "count": 39, "cond_log_prob": -0.12158203125}, {"pred": "sideroute", "count": 1, "cond_log_prob": -26.614013671875}]}, "34": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side", "log_prob": -134.6772918701172}, "original": {"pred": "of", "cond_log_prob": -0.103271484375}, "human": [{"pred": "of", "cond_log_prob": -0.1036224365234375, "count": 33}, {"pred": "that", "cond_log_prob": -5.7977142333984375, "count": 5}, {"pred": "and", "cond_log_prob": -6.0191497802734375, "count": 1}, {"pred": "right", "cond_log_prob": -10.507766723632812, "count": 1}, {"pred": "which", "cond_log_prob": -6.0683746337890625, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.672073364257812}, {"pred": "of", "count": 38, "cond_log_prob": -0.1036224365234375}, {"pred": "ofroute", "count": 1, "cond_log_prob": -25.422012329101562}]}, "35": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of", "log_prob": -134.7805633544922}, "original": {"pred": "the", "cond_log_prob": -0.888092041015625}, "human": [{"pred": "the", "cond_log_prob": -0.8884429931640625, "count": 21}, {"pred": "those", "cond_log_prob": -3.0511322021484375, "count": 7}, {"pred": "justice", "cond_log_prob": -6.2405853271484375, "count": 3}, {"pred": "righteousness", "cond_log_prob": -6.0804901123046875, "count": 2}, {"pred": "truth", "cond_log_prob": -6.3808746337890625, "count": 2}, {"pred": "his", "cond_log_prob": -2.6880645751953125, "count": 1}, {"pred": "man", "cond_log_prob": -5.3598175048828125, "count": 1}, {"pred": "me", "cond_log_prob": -4.4350738525390625, "count": 1}, {"pred": "our", "cond_log_prob": -2.3131561279296875, "count": 1}, {"pred": "right", "cond_log_prob": -7.5270843505859375, "count": 1}, {"pred": "this", "cond_log_prob": -5.8422088623046875, "count": 1}], "ancestral_samples": [{"pred": "his", "count": 1, "cond_log_prob": -2.6880645751953125}, {"pred": "my", "count": 1, "cond_log_prob": -3.1464996337890625}, {"pred": "our", "count": 4, "cond_log_prob": -2.3131561279296875}, {"pred": "the", "count": 33, "cond_log_prob": -0.8884429931640625}, {"pred": "theroute", "count": 1, "cond_log_prob": -29.345718383789062}]}, "36": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the", "log_prob": -135.6686553955078}, "original": {"pred": "right.", "cond_log_prob": -8.566482543945312}, "human": [{"pred": "righteous", "cond_log_prob": -4.8362884521484375, "count": 16}, {"pred": "just", "cond_log_prob": -8.308242797851562, "count": 4}, {"pred": "people", "cond_log_prob": -1.4658966064453125, "count": 3}, {"pred": "right", "cond_log_prob": -6.1154632568359375, "count": 3}, {"pred": "good", "cond_log_prob": -4.7443695068359375, "count": 2}, {"pred": "ones", "cond_log_prob": -8.451339721679688, "count": 2}, {"pred": "truth", "cond_log_prob": -6.7977752685546875, "count": 2}, {"pred": "bad", "cond_log_prob": -9.415908813476562, "count": 1}, {"pred": "clergyman", "cond_log_prob": -8.653060913085938, "count": 1}, {"pred": "correct", "cond_log_prob": -11.832107543945312, "count": 1}, {"pred": "followers", "cond_log_prob": -8.357864379882812, "count": 1}, {"pred": "free", "cond_log_prob": -7.0160675048828125, "count": 1}, {"pred": "law", "cond_log_prob": -6.1601409912109375, "count": 1}, {"pred": "union", "cond_log_prob": -9.058364868164062, "count": 1}, {"pred": "victors", "cond_log_prob": -8.796646118164062, "count": 1}, {"pred": "winners", "cond_log_prob": -11.941085815429688, "count": 1}], "ancestral_samples": [{"pred": "Church", "count": 4, "cond_log_prob": -2.2593841552734375}, {"pred": "ChurchAs", "count": 1, "cond_log_prob": -17.740158081054688}, {"pred": "ChurchI", "count": 1, "cond_log_prob": -16.085098266601562}, {"pred": "ChurchMr", "count": 1, "cond_log_prob": -20.681198120117188}, {"pred": "People", "count": 1, "cond_log_prob": -5.4886627197265625}, {"pred": "faithful", "count": 2, "cond_log_prob": -3.0396270751953125}, {"pred": "nationroute", "count": 1, "cond_log_prob": -30.108352661132812}, {"pred": "people", "count": 20, "cond_log_prob": -1.4658966064453125}, {"pred": "peopleI", "count": 2, "cond_log_prob": -15.632156372070312}, {"pred": "peopleIt", "count": 1, "cond_log_prob": -18.331802368164062}, {"pred": "peopleMr", "count": 2, "cond_log_prob": -19.929122924804688}, {"pred": "peopleThe", "count": 3, "cond_log_prob": -17.107162475585938}, {"pred": "peopleWe", "count": 1, "cond_log_prob": -17.695175170898438}]}, "37": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right.", "log_prob": -144.23513793945312}, "original": {"pred": "But", "cond_log_prob": -2.7182464599609375}, "human": [{"pred": "i", "cond_log_prob": -10.52215576171875, "count": 16}, {"pred": "and", "cond_log_prob": -6.87762451171875, "count": 4}, {"pred": "he", "cond_log_prob": -9.254852294921875, "count": 4}, {"pred": "the", "cond_log_prob": -8.730987548828125, "count": 2}, {"pred": "this", "cond_log_prob": -12.4354248046875, "count": 2}, {"pred": "we", "cond_log_prob": -11.22808837890625, "count": 2}, {"pred": "for", "cond_log_prob": -8.82598876953125, "count": 1}, {"pred": "god", "cond_log_prob": -18.158355712890625, "count": 1}, {"pred": "good", "cond_log_prob": -15.59454345703125, "count": 1}, {"pred": "however", "cond_log_prob": -14.491424560546875, "count": 1}, {"pred": "if", "cond_log_prob": -9.72161865234375, "count": 1}, {"pred": "it", "cond_log_prob": -10.8199462890625, "count": 1}, {"pred": "so", "cond_log_prob": -10.589752197265625, "count": 1}, {"pred": "that", "cond_log_prob": -10.50640869140625, "count": 1}, {"pred": "then", "cond_log_prob": -13.59478759765625, "count": 1}, {"pred": "therefore", "cond_log_prob": -12.66534423828125, "count": 1}, {"pred": "yes", "cond_log_prob": -15.362579345703125, "count": 1}], "ancestral_samples": [{"pred": "And", "count": 4, "cond_log_prob": -2.5833740234375}, {"pred": "But", "count": 1, "cond_log_prob": -2.7186279296875}, {"pred": "He", "count": 15, "cond_log_prob": -2.078948974609375}, {"pred": "I", "count": 12, "cond_log_prob": -1.986083984375}, {"pred": "If", "count": 2, "cond_log_prob": -3.079833984375}, {"pred": "Iroute", "count": 1, "cond_log_prob": -22.042083740234375}, {"pred": "Let", "count": 2, "cond_log_prob": -4.25042724609375}, {"pred": "The", "count": 2, "cond_log_prob": -2.9776611328125}, {"pred": "We", "count": 1, "cond_log_prob": -3.632049560546875}]}, "38": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But", "log_prob": -146.95338439941406}, "original": {"pred": "it", "cond_log_prob": -3.04644775390625}, "human": [{"pred": "i", "cond_log_prob": -9.837142944335938, "count": 24}, {"pred": "he", "cond_log_prob": -3.1845550537109375, "count": 6}, {"pred": "we", "cond_log_prob": -3.5607147216796875, "count": 3}, {"pred": "what", "cond_log_prob": -3.0356597900390625, "count": 3}, {"pred": "it", "cond_log_prob": -3.0468292236328125, "count": 1}, {"pred": "that", "cond_log_prob": -3.9459991455078125, "count": 1}, {"pred": "the", "cond_log_prob": -2.8177032470703125, "count": 1}, {"pred": "there", "cond_log_prob": -3.8622589111328125, "count": 1}, {"pred": "those", "cond_log_prob": -6.1103973388671875, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 28, "cond_log_prob": -1.7846527099609375}, {"pred": "Iroute", "count": 1, "cond_log_prob": -26.071090698242188}, {"pred": "he", "count": 1, "cond_log_prob": -3.1845550537109375}, {"pred": "if", "count": 5, "cond_log_prob": -2.4268341064453125}, {"pred": "it", "count": 1, "cond_log_prob": -3.0468292236328125}, {"pred": "my", "count": 1, "cond_log_prob": -4.6307220458984375}, {"pred": "the", "count": 2, "cond_log_prob": -2.8177032470703125}, {"pred": "what", "count": 1, "cond_log_prob": -3.0356597900390625}]}, "39": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it", "log_prob": -149.9998321533203}, "original": {"pred": "is", "cond_log_prob": -0.5357666015625}, "human": [{"pred": "is", "cond_log_prob": -0.5361480712890625, "count": 17}, {"pred": "does", "cond_log_prob": -3.5612030029296875, "count": 10}, {"pred": "concerns", "cond_log_prob": -7.3645477294921875, "count": 2}, {"pred": "will", "cond_log_prob": -3.7711944580078125, "count": 2}, {"pred": "cant", "cond_log_prob": -12.691207885742188, "count": 1}, {"pred": "makes", "cond_log_prob": -5.5376739501953125, "count": 1}, {"pred": "only", "cond_log_prob": -7.2779388427734375, "count": 1}, {"pred": "seems", "cond_log_prob": -3.0696563720703125, "count": 1}, {"pred": "so", "cond_log_prob": -8.598495483398438, "count": 1}, {"pred": "still", "cond_log_prob": -7.4351043701171875, "count": 1}, {"pred": "sufficeth", "cond_log_prob": -13.226226806640625, "count": 1}, {"pred": "tells", "cond_log_prob": -8.883438110351562, "count": 1}, {"pred": "was", "cond_log_prob": -3.489471435546875, "count": 1}, {"pred": "worries", "cond_log_prob": -10.020431518554688, "count": 1}], "ancestral_samples": [{"pred": "is", "count": 38, "cond_log_prob": -0.5361480712890625}, {"pred": "isroute", "count": 1, "cond_log_prob": -28.58587646484375}, {"pred": "was", "count": 1, "cond_log_prob": -3.489471435546875}]}, "40": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is", "log_prob": -150.5355987548828}, "original": {"pred": "my", "cond_log_prob": -3.2947998046875}, "human": [{"pred": "not", "cond_log_prob": -1.752197265625, "count": 11}, {"pred": "concerning", "cond_log_prob": -7.8560791015625, "count": 3}, {"pred": "important", "cond_log_prob": -5.18096923828125, "count": 3}, {"pred": "the", "cond_log_prob": -2.8945465087890625, "count": 3}, {"pred": "always", "cond_log_prob": -4.82159423828125, "count": 2}, {"pred": "good", "cond_log_prob": -5.088531494140625, "count": 2}, {"pred": "my", "cond_log_prob": -3.295166015625, "count": 2}, {"pred": "only", "cond_log_prob": -3.75152587890625, "count": 2}, {"pred": "still", "cond_log_prob": -5.82501220703125, "count": 2}, {"pred": "a", "cond_log_prob": -2.7842559814453125, "count": 1}, {"pred": "as", "cond_log_prob": -5.03192138671875, "count": 1}, {"pred": "by", "cond_log_prob": -5.91656494140625, "count": 1}, {"pred": "cause", "cond_log_prob": -9.726318359375, "count": 1}, {"pred": "certain", "cond_log_prob": -4.901153564453125, "count": 1}, {"pred": "clear", "cond_log_prob": -5.033843994140625, "count": 1}, {"pred": "dependent", "cond_log_prob": -10.54913330078125, "count": 1}, {"pred": "difficult", "cond_log_prob": -5.0452880859375, "count": 1}, {"pred": "hard", "cond_log_prob": -5.362457275390625, "count": 1}, {"pred": "our", "cond_log_prob": -4.587127685546875, "count": 1}, {"pred": "that", "cond_log_prob": -5.20196533203125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 10, "cond_log_prob": -2.7842559814453125}, {"pred": "my", "count": 2, "cond_log_prob": -3.295166015625}, {"pred": "not", "count": 25, "cond_log_prob": -1.752197265625}, {"pred": "notroute", "count": 1, "cond_log_prob": -29.12939453125}, {"pred": "the", "count": 1, "cond_log_prob": -2.8945465087890625}, {"pred": "very", "count": 1, "cond_log_prob": -3.871429443359375}]}, "41": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my", "log_prob": -153.8303985595703}, "original": {"pred": "constant", "cond_log_prob": -9.142547607421875}, "human": [{"pred": "duty", "cond_log_prob": -0.833160400390625, "count": 8}, {"pred": "concern", "cond_log_prob": -6.27691650390625, "count": 6}, {"pred": "belief", "cond_log_prob": -5.117584228515625, "count": 4}, {"pred": "opinion", "cond_log_prob": -3.266448974609375, "count": 4}, {"pred": "choice", "cond_log_prob": -6.254791259765625, "count": 2}, {"pred": "best", "cond_log_prob": -7.588348388671875, "count": 1}, {"pred": "decision", "cond_log_prob": -5.803955078125, "count": 1}, {"pred": "desire", "cond_log_prob": -5.78076171875, "count": 1}, {"pred": "fear", "cond_log_prob": -7.556427001953125, "count": 1}, {"pred": "good", "cond_log_prob": -6.093017578125, "count": 1}, {"pred": "greatest", "cond_log_prob": -7.591949462890625, "count": 1}, {"pred": "hope", "cond_log_prob": -4.06036376953125, "count": 1}, {"pred": "job", "cond_log_prob": -4.96221923828125, "count": 1}, {"pred": "mom", "cond_log_prob": -13.042816162109375, "count": 1}, {"pred": "prayer", "cond_log_prob": -5.79180908203125, "count": 1}, {"pred": "responsibility", "cond_log_prob": -4.7982177734375, "count": 1}, {"pred": "right", "cond_log_prob": -3.29034423828125, "count": 1}, {"pred": "side", "cond_log_prob": -7.53448486328125, "count": 1}, {"pred": "suggestion", "cond_log_prob": -8.3372802734375, "count": 1}, {"pred": "thinking", "cond_log_prob": -8.966888427734375, "count": 1}, {"pred": "will", "cond_log_prob": -5.86431884765625, "count": 1}, {"pred": "work", "cond_log_prob": -7.20147705078125, "count": 1}], "ancestral_samples": [{"pred": "duty", "count": 39, "cond_log_prob": -0.833160400390625}, {"pred": "dutyroute", "count": 1, "cond_log_prob": -40.5006103515625}]}, "42": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant", "log_prob": -162.9729461669922}, "original": {"pred": "anxiety", "cond_log_prob": -6.551544189453125}, "human": [{"pred": "fear", "cond_log_prob": -5.623260498046875, "count": 9}, {"pred": "concern", "cond_log_prob": -3.867889404296875, "count": 5}, {"pred": "prayer", "cond_log_prob": -4.400177001953125, "count": 4}, {"pred": "belief", "cond_log_prob": -5.34814453125, "count": 3}, {"pred": "reminder", "cond_log_prob": -6.228851318359375, "count": 3}, {"pred": "duty", "cond_log_prob": -1.02032470703125, "count": 2}, {"pred": "worry", "cond_log_prob": -6.372222900390625, "count": 2}, {"pred": "battle", "cond_log_prob": -7.055450439453125, "count": 1}, {"pred": "burden", "cond_log_prob": -8.26019287109375, "count": 1}, {"pred": "companion", "cond_log_prob": -5.87139892578125, "count": 1}, {"pred": "desire", "cond_log_prob": -3.24420166015625, "count": 1}, {"pred": "faith", "cond_log_prob": -6.832733154296875, "count": 1}, {"pred": "help", "cond_log_prob": -8.73443603515625, "count": 1}, {"pred": "hope", "cond_log_prob": -4.674407958984375, "count": 1}, {"pred": "mom", "cond_log_prob": -15.573272705078125, "count": 1}, {"pred": "protector", "cond_log_prob": -11.0101318359375, "count": 1}, {"pred": "quest", "cond_log_prob": -6.6043701171875, "count": 1}, {"pred": "sinning", "cond_log_prob": -13.7447509765625, "count": 1}, {"pred": "that", "cond_log_prob": -7.132843017578125, "count": 1}, {"pred": "thought", "cond_log_prob": -6.228515625, "count": 1}], "ancestral_samples": [{"pred": "duty", "count": 38, "cond_log_prob": -1.02032470703125}, {"pred": "dutyroute", "count": 1, "cond_log_prob": -38.1923828125}, {"pred": "request", "count": 1, "cond_log_prob": -4.7340087890625}]}, "43": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety", "log_prob": -169.5244903564453}, "original": {"pred": "and", "cond_log_prob": -3.117401123046875}, "human": [{"pred": "that", "cond_log_prob": -1.337066650390625, "count": 33}, {"pred": "to", "cond_log_prob": -0.94140625, "count": 4}, {"pred": "and", "cond_log_prob": -3.1177978515625, "count": 2}, {"pred": "so", "cond_log_prob": -7.90087890625, "count": 1}, {"pred": "with", "cond_log_prob": -6.027069091796875, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -7.59112548828125}, {"pred": "that", "count": 13, "cond_log_prob": -1.337066650390625}, {"pred": "thatroute", "count": 1, "cond_log_prob": -24.574249267578125}, {"pred": "to", "count": 25, "cond_log_prob": -0.94140625}]}, "44": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and", "log_prob": -172.6418914794922}, "original": {"pred": "prayer", "cond_log_prob": -4.26953125}, "human": [{"pred": "fear", "cond_log_prob": -3.49591064453125, "count": 12}, {"pred": "worry", "cond_log_prob": -4.051513671875, "count": 9}, {"pred": "concern", "cond_log_prob": -3.37750244140625, "count": 5}, {"pred": "hope", "cond_log_prob": -3.870513916015625, "count": 2}, {"pred": "i", "cond_log_prob": -9.694915771484375, "count": 2}, {"pred": "my", "cond_log_prob": -3.259307861328125, "count": 2}, {"pred": "prayer", "cond_log_prob": -4.269927978515625, "count": 2}, {"pred": "burden", "cond_log_prob": -7.7607421875, "count": 1}, {"pred": "problem", "cond_log_prob": -8.8394775390625, "count": 1}, {"pred": "quest", "cond_log_prob": -8.396881103515625, "count": 1}, {"pred": "responsibility", "cond_log_prob": -6.506988525390625, "count": 1}, {"pred": "she", "cond_log_prob": -9.804229736328125, "count": 1}, {"pred": "stuff", "cond_log_prob": -11.1778564453125, "count": 1}, {"pred": "worrying", "cond_log_prob": -9.377899169921875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -5.600311279296875}, {"pred": "anxiety", "count": 1, "cond_log_prob": -3.9107666015625}, {"pred": "concern", "count": 3, "cond_log_prob": -3.37750244140625}, {"pred": "desire", "count": 13, "cond_log_prob": -2.969329833984375}, {"pred": "desireroute", "count": 1, "cond_log_prob": -28.065765380859375}, {"pred": "distress", "count": 3, "cond_log_prob": -3.959442138671875}, {"pred": "dread", "count": 1, "cond_log_prob": -4.485626220703125}, {"pred": "fear", "count": 1, "cond_log_prob": -3.49591064453125}, {"pred": "hope", "count": 1, "cond_log_prob": -3.870513916015625}, {"pred": "my", "count": 6, "cond_log_prob": -3.259307861328125}, {"pred": "our", "count": 1, "cond_log_prob": -5.233062744140625}, {"pred": "prayer", "count": 1, "cond_log_prob": -4.269927978515625}, {"pred": "pride", "count": 1, "cond_log_prob": -5.8310546875}, {"pred": "regret", "count": 1, "cond_log_prob": -3.981475830078125}, {"pred": "request", "count": 1, "cond_log_prob": -5.422760009765625}, {"pred": "sorrow", "count": 2, "cond_log_prob": -3.9267578125}, {"pred": "that", "count": 1, "cond_log_prob": -4.311279296875}, {"pred": "the", "count": 1, "cond_log_prob": -3.74041748046875}]}, "45": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer", "log_prob": -176.9114227294922}, "original": {"pred": "that", "cond_log_prob": -0.833099365234375}, "human": [{"pred": "that", "cond_log_prob": -0.833526611328125, "count": 40}, {"pred": "to", "cond_log_prob": -1.023712158203125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -7.814910888671875}, {"pred": "that", "count": 18, "cond_log_prob": -0.833526611328125}, {"pred": "thatroute", "count": 1, "cond_log_prob": -24.001800537109375}, {"pred": "to", "count": 20, "cond_log_prob": -1.023712158203125}]}, "46": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that", "log_prob": -177.74452209472656}, "original": {"pred": "I", "cond_log_prob": -2.3717193603515625}, "human": [{"pred": "the", "cond_log_prob": -1.740081787109375, "count": 11}, {"pred": "we", "cond_log_prob": -2.452056884765625, "count": 10}, {"pred": "i", "cond_log_prob": -10.225372314453125, "count": 9}, {"pred": "he", "cond_log_prob": -2.07220458984375, "count": 2}, {"pred": "frozen", "cond_log_prob": -17.46966552734375, "count": 1}, {"pred": "god", "cond_log_prob": -11.3258056640625, "count": 1}, {"pred": "keep", "cond_log_prob": -10.31719970703125, "count": 1}, {"pred": "keeps", "cond_log_prob": -10.451934814453125, "count": 1}, {"pred": "our", "cond_log_prob": -3.816375732421875, "count": 1}, {"pred": "there", "cond_log_prob": -4.74591064453125, "count": 1}, {"pred": "this", "cond_log_prob": -3.16802978515625, "count": 1}, {"pred": "will", "cond_log_prob": -6.8274383544921875, "count": 1}, {"pred": "you", "cond_log_prob": -2.733978271484375, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 4, "cond_log_prob": -2.3721466064453125}, {"pred": "a", "count": 1, "cond_log_prob": -4.7777099609375}, {"pred": "he", "count": 7, "cond_log_prob": -2.07220458984375}, {"pred": "heroute", "count": 1, "cond_log_prob": -23.840591430664062}, {"pred": "my", "count": 1, "cond_log_prob": -3.9791259765625}, {"pred": "the", "count": 23, "cond_log_prob": -1.740081787109375}, {"pred": "we", "count": 1, "cond_log_prob": -2.452056884765625}, {"pred": "you", "count": 2, "cond_log_prob": -2.733978271484375}]}, "47": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I", "log_prob": -180.11624145507812}, "original": {"pred": "and", "cond_log_prob": -6.8311004638671875}, "human": [{"pred": "will", "cond_log_prob": -2.7585296630859375, "count": 13}, {"pred": "am", "cond_log_prob": -4.4800262451171875, "count": 9}, {"pred": "can", "cond_log_prob": -4.3912811279296875, "count": 6}, {"pred": "do", "cond_log_prob": -4.380035400390625, "count": 2}, {"pred": "may", "cond_log_prob": -0.9373321533203125, "count": 2}, {"pred": "always", "cond_log_prob": -6.97174072265625, "count": 1}, {"pred": "be", "cond_log_prob": -3.6165313720703125, "count": 1}, {"pred": "choose", "cond_log_prob": -8.31610107421875, "count": 1}, {"pred": "is", "cond_log_prob": -8.53961181640625, "count": 1}, {"pred": "know", "cond_log_prob": -5.4747161865234375, "count": 1}, {"pred": "love", "cond_log_prob": -8.513580322265625, "count": 1}, {"pred": "protect", "cond_log_prob": -8.849517822265625, "count": 1}, {"pred": "this", "cond_log_prob": -10.104095458984375, "count": 1}, {"pred": "worry", "cond_log_prob": -11.664031982421875, "count": 1}], "ancestral_samples": [{"pred": "may", "count": 29, "cond_log_prob": -0.9373321533203125}, {"pred": "might", "count": 1, "cond_log_prob": -3.1147308349609375}, {"pred": "shall", "count": 5, "cond_log_prob": -2.0625762939453125}, {"pred": "shallroute", "count": 1, "cond_log_prob": -26.9888916015625}, {"pred": "should", "count": 3, "cond_log_prob": -1.9311676025390625}, {"pred": "will", "count": 1, "cond_log_prob": -2.7585296630859375}]}, "48": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I and", "log_prob": -186.9473419189453}, "original": {"pred": "this", "cond_log_prob": -5.16851806640625}, "human": [{"pred": "my", "cond_log_prob": -0.8536376953125, "count": 15}, {"pred": "the", "cond_log_prob": -2.1410369873046875, "count": 8}, {"pred": "this", "cond_log_prob": -5.168975830078125, "count": 4}, {"pred": "you", "cond_log_prob": -4.393310546875, "count": 3}, {"pred": "everyone", "cond_log_prob": -5.4250030517578125, "count": 2}, {"pred": "all", "cond_log_prob": -2.08502197265625, "count": 1}, {"pred": "america", "cond_log_prob": -18.892257690429688, "count": 1}, {"pred": "form", "cond_log_prob": -14.053482055664062, "count": 1}, {"pred": "god", "cond_log_prob": -11.292678833007812, "count": 2}, {"pred": "i", "cond_log_prob": -11.828475952148438, "count": 1}, {"pred": "our", "cond_log_prob": -3.653350830078125, "count": 1}, {"pred": "so", "cond_log_prob": -6.0421295166015625, "count": 1}, {"pred": "will", "cond_log_prob": -8.175506591796875, "count": 1}], "ancestral_samples": [{"pred": "every", "count": 1, "cond_log_prob": -3.876617431640625}, {"pred": "my", "count": 33, "cond_log_prob": -0.8536376953125}, {"pred": "myroute", "count": 1, "cond_log_prob": -23.724105834960938}, {"pred": "the", "count": 4, "cond_log_prob": -2.1410369873046875}, {"pred": "your", "count": 1, "cond_log_prob": -3.8422698974609375}]}, "49": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I and this", "log_prob": -192.11585998535156}, "original": {"pred": "nation", "cond_log_prob": -3.21954345703125}, "human": [{"pred": "country", "cond_log_prob": -2.6777191162109375, "count": 14}, {"pred": "nation", "cond_log_prob": -3.220001220703125, "count": 6}, {"pred": "people", "cond_log_prob": -4.34716796875, "count": 6}, {"pred": "is", "cond_log_prob": -7.7328338623046875, "count": 4}, {"pred": "cause", "cond_log_prob": -6.2811737060546875, "count": 1}, {"pred": "congregation", "cond_log_prob": -3.9272918701171875, "count": 1}, {"pred": "generation", "cond_log_prob": -5.8343963623046875, "count": 1}, {"pred": "good", "cond_log_prob": -5.4638671875, "count": 1}, {"pred": "house", "cond_log_prob": -4.0167388916015625, "count": 1}, {"pred": "life", "cond_log_prob": -5.579193115234375, "count": 1}, {"pred": "organization", "cond_log_prob": -6.9603424072265625, "count": 1}, {"pred": "paper", "cond_log_prob": -7.3217315673828125, "count": 1}, {"pred": "war", "cond_log_prob": -8.57177734375, "count": 1}, {"pred": "will", "cond_log_prob": -7.701751708984375, "count": 1}, {"pred": "world", "cond_log_prob": -5.3349761962890625, "count": 1}], "ancestral_samples": [{"pred": "Church", "count": 4, "cond_log_prob": -3.07952880859375}, {"pred": "church", "count": 3, "cond_log_prob": -3.1808319091796875}, {"pred": "country", "count": 13, "cond_log_prob": -2.6777191162109375}, {"pred": "family", "count": 2, "cond_log_prob": -3.6864166259765625}, {"pred": "gentleman", "count": 1, "cond_log_prob": -3.544677734375}, {"pred": "great", "count": 4, "cond_log_prob": -3.7669677734375}, {"pred": "house", "count": 2, "cond_log_prob": -4.0167388916015625}, {"pred": "lady", "count": 1, "cond_log_prob": -5.17779541015625}, {"pred": "man", "count": 3, "cond_log_prob": -2.8206939697265625}, {"pred": "most", "count": 1, "cond_log_prob": -6.005645751953125}, {"pred": "nation", "count": 3, "cond_log_prob": -3.220001220703125}, {"pred": "nationroute", "count": 1, "cond_log_prob": -29.648147583007812}, {"pred": "people", "count": 1, "cond_log_prob": -4.34716796875}, {"pred": "whole", "count": 1, "cond_log_prob": -4.798675537109375}]}, "50": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I and this nation", "log_prob": -195.3354034423828}, "original": {"pred": "should", "cond_log_prob": -1.7419891357421875}, "human": [{"pred": "will", "cond_log_prob": -2.0346832275390625, "count": 14}, {"pred": "are", "cond_log_prob": -4.11004638671875, "count": 11}, {"pred": "can", "cond_log_prob": -4.05792236328125, "count": 5}, {"pred": "i", "cond_log_prob": -13.191665649414062, "count": 2}, {"pred": "is", "cond_log_prob": -6.7381439208984375, "count": 2}, {"pred": "act", "cond_log_prob": -8.742965698242188, "count": 1}, {"pred": "be", "cond_log_prob": -3.39044189453125, "count": 1}, {"pred": "choose", "cond_log_prob": -8.256484985351562, "count": 1}, {"pred": "do", "cond_log_prob": -5.372283935546875, "count": 1}, {"pred": "over", "cond_log_prob": -8.727096557617188, "count": 1}, {"pred": "pray", "cond_log_prob": -8.464126586914062, "count": 1}, {"pred": "should", "cond_log_prob": -1.7424468994140625, "count": 1}], "ancestral_samples": [{"pred": "as", "count": 1, "cond_log_prob": -6.5675506591796875}, {"pred": "may", "count": 16, "cond_log_prob": -1.6064300537109375}, {"pred": "might", "count": 1, "cond_log_prob": -3.3356781005859375}, {"pred": "shall", "count": 5, "cond_log_prob": -2.5067291259765625}, {"pred": "shallroute", "count": 1, "cond_log_prob": -27.814987182617188}, {"pred": "should", "count": 11, "cond_log_prob": -1.7424468994140625}, {"pred": "will", "count": 5, "cond_log_prob": -2.0346832275390625}]}, "51": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I and this nation should", "log_prob": -197.077392578125}, "original": {"pred": "be", "cond_log_prob": -1.5096893310546875}, "human": [{"pred": "be", "cond_log_prob": -1.5101470947265625, "count": 20}, {"pred": "always", "cond_log_prob": -3.7959442138671875, "count": 5}, {"pred": "come", "cond_log_prob": -4.3890533447265625, "count": 4}, {"pred": "eat", "cond_log_prob": -9.24822998046875, "count": 1}, {"pred": "fear", "cond_log_prob": -7.95343017578125, "count": 1}, {"pred": "follow", "cond_log_prob": -5.8436279296875, "count": 1}, {"pred": "hate", "cond_log_prob": -8.936370849609375, "count": 1}, {"pred": "have", "cond_log_prob": -2.8392333984375, "count": 1}, {"pred": "never", "cond_log_prob": -3.5733642578125, "count": 1}, {"pred": "prepare", "cond_log_prob": -8.163970947265625, "count": 1}, {"pred": "rely", "cond_log_prob": -8.782257080078125, "count": 1}, {"pred": "remain", "cond_log_prob": -4.307342529296875, "count": 1}, {"pred": "remember", "cond_log_prob": -6.5296630859375, "count": 1}, {"pred": "stand", "cond_log_prob": -4.4805908203125, "count": 1}, {"pred": "triumph", "cond_log_prob": -6.856903076171875, "count": 1}], "ancestral_samples": [{"pred": "be", "count": 33, "cond_log_prob": -1.5101470947265625}, {"pred": "beroute", "count": 1, "cond_log_prob": -27.80120849609375}, {"pred": "find", "count": 1, "cond_log_prob": -3.986175537109375}, {"pred": "go", "count": 1, "cond_log_prob": -4.4680023193359375}, {"pred": "have", "count": 2, "cond_log_prob": -2.8392333984375}, {"pred": "not", "count": 1, "cond_log_prob": -3.1372222900390625}, {"pred": "remain", "count": 1, "cond_log_prob": -4.307342529296875}]}, "52": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I and this nation should be", "log_prob": -198.5870819091797}, "original": {"pred": "on", "cond_log_prob": -4.135467529296875}, "human": [{"pred": "on", "cond_log_prob": -4.1359405517578125, "count": 9}, {"pred": "right", "cond_log_prob": -5.5127716064453125, "count": 3}, {"pred": "united", "cond_log_prob": -3.4981842041015625, "count": 3}, {"pred": "able", "cond_log_prob": -2.1685028076171875, "count": 2}, {"pred": "doing", "cond_log_prob": -7.1493988037109375, "count": 2}, {"pred": "aware", "cond_log_prob": -7.3879852294921875, "count": 1}, {"pred": "brought", "cond_log_prob": -4.8724822998046875, "count": 1}, {"pred": "close", "cond_log_prob": -8.153030395507812, "count": 1}, {"pred": "concerned", "cond_log_prob": -7.9624786376953125, "count": 1}, {"pred": "constantly", "cond_log_prob": -7.1977691650390625, "count": 1}, {"pred": "correct", "cond_log_prob": -8.533248901367188, "count": 1}, {"pred": "crazy", "cond_log_prob": -14.200576782226562, "count": 1}, {"pred": "embarked", "cond_log_prob": -10.917953491210938, "count": 1}, {"pred": "ever", "cond_log_prob": -6.5486602783203125, "count": 1}, {"pred": "forever", "cond_log_prob": -6.7072296142578125, "count": 1}, {"pred": "found", "cond_log_prob": -5.8350982666015625, "count": 1}, {"pred": "kept", "cond_log_prob": -4.7088165283203125, "count": 1}, {"pred": "more", "cond_log_prob": -5.2835540771484375, "count": 1}, {"pred": NaN, "cond_log_prob": -19.583450317382812, "count": 0}, {"pred": "open", "cond_log_prob": -7.5540313720703125, "count": 1}, {"pred": "prepared", "cond_log_prob": -5.8404083251953125, "count": 1}, {"pred": "saved", "cond_log_prob": -3.5173492431640625, "count": 1}, {"pred": "scared", "cond_log_prob": -11.490371704101562, "count": 1}, {"pred": "there", "cond_log_prob": -7.0435333251953125, "count": 1}, {"pred": "this", "cond_log_prob": -7.7731170654296875, "count": 1}, {"pred": "willing", "cond_log_prob": -6.5900421142578125, "count": 1}, {"pred": "with", "cond_log_prob": -6.2742156982421875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -4.4422454833984375}, {"pred": "able", "count": 26, "cond_log_prob": -2.1685028076171875}, {"pred": "ableroute", "count": 1, "cond_log_prob": -41.37422180175781}, {"pred": "free", "count": 1, "cond_log_prob": -4.087432861328125}, {"pred": "freed", "count": 1, "cond_log_prob": -6.33221435546875}, {"pred": "in", "count": 3, "cond_log_prob": -3.5007781982421875}, {"pred": "on", "count": 1, "cond_log_prob": -4.1359405517578125}, {"pred": "prostrated", "count": 1, "cond_log_prob": -8.26751708984375}, {"pred": "saved", "count": 1, "cond_log_prob": -3.517364501953125}, {"pred": "the", "count": 2, "cond_log_prob": -3.8070220947265625}, {"pred": "well", "count": 1, "cond_log_prob": -5.049957275390625}]}, "53": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I and this nation should be on", "log_prob": -202.72254943847656}, "original": {"pred": "the", "cond_log_prob": -0.7995452880859375}, "human": [{"pred": "the", "cond_log_prob": -0.8000030517578125, "count": 33}, {"pred": "his", "cond_log_prob": -3.3103790283203125, "count": 3}, {"pred": "a", "cond_log_prob": -3.9490203857421875, "count": 1}, {"pred": "high", "cond_log_prob": -7.7936859130859375, "count": 1}, {"pred": "our", "cond_log_prob": -1.1256866455078125, "count": 1}, {"pred": "survey", "cond_log_prob": -15.355667114257812, "count": 1}, {"pred": "watch", "cond_log_prob": -11.258987426757812, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.9490203857421875}, {"pred": "our", "count": 11, "cond_log_prob": -1.125701904296875}, {"pred": "the", "count": 27, "cond_log_prob": -0.800018310546875}, {"pred": "theroute", "count": 1, "cond_log_prob": -28.310867309570312}]}, "54": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I and this nation should be on the", "log_prob": -203.5220947265625}, "original": {"pred": "Lord's", "cond_log_prob": -7.833953857421875}, "human": [{"pred": "side", "cond_log_prob": -0.244171142578125, "count": 12}, {"pred": "lord", "cond_log_prob": -12.62847900390625, "count": 10}, {"pred": "right", "cond_log_prob": -2.44647216796875, "count": 6}, {"pred": "lords", "cond_log_prob": -13.088088989257812, "count": 5}, {"pred": "correct", "cond_log_prob": -8.0771484375, "count": 1}, {"pred": "look", "cond_log_prob": -10.30548095703125, "count": 1}, {"pred": "path", "cond_log_prob": -7.8025665283203125, "count": 1}, {"pred": "road", "cond_log_prob": -6.9014892578125, "count": 1}, {"pred": "same", "cond_log_prob": -2.973358154296875, "count": 1}, {"pred": "stupid", "cond_log_prob": -14.11895751953125, "count": 1}, {"pred": "top", "cond_log_prob": -8.421981811523438, "count": 1}, {"pred": "watch", "cond_log_prob": -8.574234008789062, "count": 1}], "ancestral_samples": [{"pred": "right", "count": 1, "cond_log_prob": -2.44647216796875}, {"pred": "side", "count": 38, "cond_log_prob": -0.244171142578125}, {"pred": "sideroute", "count": 1, "cond_log_prob": -24.9873046875}]}, "55": {"context": {"text": "A clergyman remarked to him, \"The Lord is on our side.\" I am not at all concerned about that, replied Mr. Lincoln; \"for I know that the Lord is always on the side of the right. But it is my constant anxiety and prayer that I and this nation should be on the Lord's", "log_prob": -211.35604858398438}, "original": {"pred": "side.\"", "cond_log_prob": -1.13446044921875}, "human": [{"pred": "side", "cond_log_prob": -0.01055908203125, "count": 36}, {"pred": "errand", "cond_log_prob": -14.072052001953125, "count": 2}, {"pred": "right", "cond_log_prob": -5.825439453125, "count": 1}, {"pred": "sides", "cond_log_prob": -7.60400390625, "count": 1}, {"pred": "survey", "cond_log_prob": -16.911041259765625, "count": 1}], "ancestral_samples": [{"pred": "side", "count": 31, "cond_log_prob": -0.01055908203125}, {"pred": "sideI", "count": 2, "cond_log_prob": -14.424560546875}, {"pred": "sideIt", "count": 2, "cond_log_prob": -16.77752685546875}, {"pred": "sideMr", "count": 1, "cond_log_prob": -18.231201171875}, {"pred": "sideThe", "count": 3, "cond_log_prob": -14.76251220703125}, {"pred": "sideroute", "count": 1, "cond_log_prob": -26.28985595703125}]}}, "11": {"2": {"context": {"text": "Known", "log_prob": -15.060159683227539}, "original": {"pred": "as", "cond_log_prob": -1.290374755859375}, "human": [{"pred": "to", "cond_log_prob": -3.6257877349853516, "count": 6}, {"pred": "facts", "cond_log_prob": -7.743280410766602, "count": 3}, {"pred": "species", "cond_log_prob": -7.322690963745117, "count": 3}, {"pred": "about", "cond_log_prob": -7.877866744995117, "count": 2}, {"pred": "as", "cond_log_prob": -1.290365219116211, "count": 2}, {"pred": "data", "cond_log_prob": -7.108205795288086, "count": 2}, {"pred": "for", "cond_log_prob": -1.8625926971435547, "count": 2}, {"pred": "is", "cond_log_prob": -7.856901168823242, "count": 2}, {"pred": "people", "cond_log_prob": -8.119649887084961, "count": 2}, {"pred": "across", "cond_log_prob": -9.294828414916992, "count": 1}, {"pred": "artists", "cond_log_prob": -9.617132186889648, "count": 1}, {"pred": "by", "cond_log_prob": -4.480348587036133, "count": 1}, {"pred": "causes", "cond_log_prob": -8.643651962280273, "count": 1}, {"pred": "friend", "cond_log_prob": -11.235876083374023, "count": 1}, {"pred": "instances", "cond_log_prob": -6.977445602416992, "count": 1}, {"pred": "little", "cond_log_prob": -11.249872207641602, "count": 1}, {"pred": "only", "cond_log_prob": -6.165246963500977, "count": 1}, {"pred": "planets", "cond_log_prob": -9.762075424194336, "count": 1}, {"pred": "scientists", "cond_log_prob": -9.401456832885742, "count": 1}, {"pred": "strains", "cond_log_prob": -9.39375114440918, "count": 1}, {"pred": "things", "cond_log_prob": -8.272783279418945, "count": 1}, {"pred": "types", "cond_log_prob": -10.669950485229492, "count": 1}, {"pred": "unknown", "cond_log_prob": -8.85682487487793, "count": 2}, {"pred": "violators", "cond_log_prob": -12.125848770141602, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 1, "cond_log_prob": -10.836286544799805}, {"pred": "Achievements", "count": 1, "cond_log_prob": -10.138906478881836}, {"pred": "Banks", "count": 1, "cond_log_prob": -12.095968246459961}, {"pred": "GameCube", "count": 1, "cond_log_prob": -18.659093856811523}, {"pred": "I", "count": 1, "cond_log_prob": -9.476873397827148}, {"pred": "The", "count": 1, "cond_log_prob": -7.344083786010742}, {"pred": "We", "count": 1, "cond_log_prob": -10.795003890991211}, {"pred": "a", "count": 2, "cond_log_prob": -7.313196182250977}, {"pred": "and", "count": 5, "cond_log_prob": -6.358209609985352}, {"pred": "androutetxt", "count": 1, "cond_log_prob": -42.79026794433594}, {"pred": "but", "count": 2, "cond_log_prob": -8.833169937133789}, {"pred": "by", "count": 2, "cond_log_prob": -4.480348587036133}, {"pred": "comW2", "count": 1, "cond_log_prob": -30.3858585357666}, {"pred": "for", "count": 1, "cond_log_prob": -1.8625926971435547}, {"pred": "in", "count": 4, "cond_log_prob": -4.087423324584961}, {"pred": "is", "count": 1, "cond_log_prob": -7.856901168823242}, {"pred": "of", "count": 1, "cond_log_prob": -7.099302291870117}, {"pred": "on", "count": 1, "cond_log_prob": -6.430559158325195}, {"pred": "the", "count": 6, "cond_log_prob": -6.608854293823242}, {"pred": "to", "count": 6, "cond_log_prob": -3.6257877349853516}]}, "3": {"context": {"text": "Known as", "log_prob": -16.350534439086914}, "original": {"pred": "Rapa", "cond_log_prob": -13.037227630615234}, "human": [{"pred": "the", "cond_log_prob": -1.1288127899169922, "count": 26}, {"pred": "a", "cond_log_prob": -2.339689254760742, "count": 6}, {"pred": "bob", "cond_log_prob": -12.038385391235352, "count": 1}, {"pred": "harry", "cond_log_prob": -15.043069839477539, "count": 1}, {"pred": "here", "cond_log_prob": -10.844911575317383, "count": 1}, {"pred": "libertarianism", "cond_log_prob": -12.084218978881836, "count": 1}, {"pred": "little", "cond_log_prob": -8.966386795043945, "count": 1}, {"pred": "long", "cond_log_prob": -8.179437637329102, "count": 1}, {"pred": "pumpkin", "cond_log_prob": -11.528467178344727, "count": 1}, {"pred": "well", "cond_log_prob": -8.469076156616211, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 2, "cond_log_prob": -4.794588088989258}, {"pred": "a", "count": 5, "cond_log_prob": -2.339689254760742}, {"pred": "the", "count": 32, "cond_log_prob": -1.1288127899169922}, {"pred": "theroute", "count": 1, "cond_log_prob": -24.120267868041992}]}, "4": {"context": {"text": "Known as Rapa", "log_prob": -29.38776206970215}, "original": {"pred": "Nui", "cond_log_prob": -0.31991004943847656}, "human": [{"pred": "the", "cond_log_prob": -8.509782791137695, "count": 13}, {"pred": "or", "cond_log_prob": -6.611406326293945, "count": 2}, {"pred": "bapa", "cond_log_prob": -19.87799644470215, "count": 1}, {"pred": "by", "cond_log_prob": -9.520029067993164, "count": 1}, {"pred": "do", "cond_log_prob": -7.361871719360352, "count": 1}, {"pred": "dura", "cond_log_prob": -13.871683120727539, "count": 1}, {"pred": "gord", "cond_log_prob": -15.952051162719727, "count": 1}, {"pred": "hannock", "cond_log_prob": -22.529802322387695, "count": 1}, {"pred": "he", "cond_log_prob": -9.248468399047852, "count": 1}, {"pred": "i", "cond_log_prob": -13.066385269165039, "count": 1}, {"pred": "in", "cond_log_prob": -8.220010757446289, "count": 1}, {"pred": "instructor", "cond_log_prob": -17.137392044067383, "count": 1}, {"pred": "john", "cond_log_prob": -16.201425552368164, "count": 1}, {"pred": "kapa", "cond_log_prob": -18.30527687072754, "count": 1}, {"pred": "nui", "cond_log_prob": -11.283868789672852, "count": 1}, {"pred": "nuki", "cond_log_prob": -18.53880500793457, "count": 1}, {"pred": "palooza", "cond_log_prob": -22.207624435424805, "count": 1}, {"pred": "part", "cond_log_prob": -17.511423110961914, "count": 1}, {"pred": "port", "cond_log_prob": -13.330263137817383, "count": 1}, {"pred": "river", "cond_log_prob": -16.554094314575195, "count": 1}, {"pred": "rock", "cond_log_prob": -14.34453010559082, "count": 1}, {"pred": "shara", "cond_log_prob": -18.4951114654541, "count": 1}, {"pred": "she", "cond_log_prob": -12.088312149047852, "count": 1}, {"pred": "snappa", "cond_log_prob": -20.371652603149414, "count": 1}, {"pred": "something", "cond_log_prob": -15.468057632446289, "count": 1}, {"pred": "springs", "cond_log_prob": -18.0382022857666, "count": 1}, {"pred": "was", "cond_log_prob": -9.976869583129883, "count": 1}], "ancestral_samples": [{"pred": "Contents", "count": 1, "cond_log_prob": -18.126047134399414}, {"pred": "Nrouteglin", "count": 1, "cond_log_prob": -46.44512939453125}, {"pred": "Nui", "count": 38, "cond_log_prob": -0.31998634338378906}]}, "5": {"context": {"text": "Known as Rapa Nui", "log_prob": -29.707672119140625}, "original": {"pred": "to", "cond_log_prob": -6.3612518310546875}, "human": [{"pred": "the", "cond_log_prob": -5.466972351074219, "count": 12}, {"pred": "and", "cond_log_prob": -4.237571716308594, "count": 2}, {"pred": "he", "cond_log_prob": -7.062595367431641, "count": 2}, {"pred": "this", "cond_log_prob": -7.235221862792969, "count": 2}, {"pred": "----------------------------------------------------", "cond_log_prob": -16.03881072998047, "count": 1}, {"pred": ",", "cond_log_prob": -4.529994964599609, "count": 1}, {"pred": "a", "cond_log_prob": -6.6145477294921875, "count": 1}, {"pred": "ching", "cond_log_prob": -15.001708984375, "count": 1}, {"pred": "clan", "cond_log_prob": -11.704597473144531, "count": 1}, {"pred": "food", "cond_log_prob": -10.235050201416016, "count": 1}, {"pred": "from", "cond_log_prob": -6.322055816650391, "count": 1}, {"pred": "ignorance", "cond_log_prob": -15.176826477050781, "count": 1}, {"pred": "in", "cond_log_prob": -4.177452087402344, "count": 1}, {"pred": "is", "cond_log_prob": -5.792797088623047, "count": 1}, {"pred": "island", "cond_log_prob": -9.506309509277344, "count": 1}, {"pred": "jr", "cond_log_prob": -15.102531433105469, "count": 1}, {"pred": "junsta", "cond_log_prob": -20.035503387451172, "count": 1}, {"pred": "kai", "cond_log_prob": -11.743038177490234, "count": 1}, {"pred": "kui", "cond_log_prob": -13.937740325927734, "count": 1}, {"pred": "mu", "cond_log_prob": -11.376262664794922, "count": 1}, {"pred": "of", "cond_log_prob": -6.7994384765625, "count": 1}, {"pred": "she", "cond_log_prob": -7.366497039794922, "count": 1}, {"pred": "tango", "cond_log_prob": -12.582931518554688, "count": 1}, {"pred": "te", "cond_log_prob": -9.305061340332031, "count": 1}, {"pred": "to", "cond_log_prob": -6.361351013183594, "count": 1}, {"pred": "was", "cond_log_prob": -7.303737640380859, "count": 1}], "ancestral_samples": [{"pred": "Contents", "count": 1, "cond_log_prob": -14.797393798828125}, {"pred": "a", "count": 2, "cond_log_prob": -6.6145477294921875}, {"pred": "route", "count": 1, "cond_log_prob": -12.407379150390625}, {"pred": "she", "count": 4, "cond_log_prob": -7.366497039794922}, {"pred": "the", "count": 25, "cond_log_prob": -5.466972351074219}, {"pred": "this", "count": 7, "cond_log_prob": -7.235221862792969}]}, "6": {"context": {"text": "Known as Rapa Nui to", "log_prob": -36.06892395019531}, "original": {"pred": "the", "cond_log_prob": -2.1366806030273438}, "human": [{"pred": "the", "cond_log_prob": -2.1367721557617188, "count": 20}, {"pred": "his", "cond_log_prob": -3.7044677734375, "count": 9}, {"pred": "all", "cond_log_prob": -4.884864807128906, "count": 2}, {"pred": "locals", "cond_log_prob": -4.6360015869140625, "count": 2}, {"pred": "many", "cond_log_prob": -3.0096359252929688, "count": 2}, {"pred": "a", "cond_log_prob": -3.8954925537109375, "count": 1}, {"pred": "do", "cond_log_prob": -7.69989013671875, "count": 1}, {"pred": "everyone", "cond_log_prob": -5.4571533203125, "count": 1}, {"pred": "set", "cond_log_prob": -7.838935852050781, "count": 1}, {"pred": "some", "cond_log_prob": -3.6263046264648438, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.8954925537109375}, {"pred": "her", "count": 2, "cond_log_prob": -4.174980163574219}, {"pred": "his", "count": 1, "cond_log_prob": -3.7044677734375}, {"pred": "its", "count": 1, "cond_log_prob": -2.7628097534179688}, {"pred": "manyroute", "count": 1, "cond_log_prob": -25.299461364746094}, {"pred": "the", "count": 33, "cond_log_prob": -2.1367721557617188}]}, "7": {"context": {"text": "Known as Rapa Nui to the", "log_prob": -38.205604553222656}, "original": {"pred": "island's", "cond_log_prob": -7.788120269775391}, "human": [{"pred": "people", "cond_log_prob": -3.3011856079101562, "count": 13}, {"pred": "population", "cond_log_prob": -7.1753692626953125, "count": 3}, {"pred": "community", "cond_log_prob": -5.51214599609375, "count": 2}, {"pred": "locals", "cond_log_prob": -3.7184524536132812, "count": 2}, {"pred": "native", "cond_log_prob": -6.0722503662109375, "count": 2}, {"pred": "public", "cond_log_prob": -4.77777099609375, "count": 2}, {"pred": "world", "cond_log_prob": -5.0604400634765625, "count": 2}, {"pred": "asian", "cond_log_prob": -13.106754302978516, "count": 1}, {"pred": "chinese", "cond_log_prob": -9.472396850585938, "count": 1}, {"pred": "citizens", "cond_log_prob": -6.5423126220703125, "count": 1}, {"pred": "country", "cond_log_prob": -6.556060791015625, "count": 1}, {"pred": "french", "cond_log_prob": -9.475715637207031, "count": 1}, {"pred": "girl", "cond_log_prob": -8.789497375488281, "count": 1}, {"pred": "great", "cond_log_prob": -7.127357482910156, "count": 1}, {"pred": "hawaiian", "cond_log_prob": -14.591075897216797, "count": 1}, {"pred": "indian", "cond_log_prob": -12.726123809814453, "count": 1}, {"pred": "local", "cond_log_prob": -5.5249481201171875, "count": 1}, {"pred": "natives", "cond_log_prob": -4.7028656005859375, "count": 1}, {"pred": "next", "cond_log_prob": -8.544700622558594, "count": 1}, {"pred": "organization", "cond_log_prob": -10.901901245117188, "count": 1}, {"pred": "society", "cond_log_prob": -9.291603088378906, "count": 1}], "ancestral_samples": [{"pred": "American", "count": 2, "cond_log_prob": -4.8642578125}, {"pred": "Chinese", "count": 9, "cond_log_prob": -2.6653976440429688}, {"pred": "Dutch", "count": 1, "cond_log_prob": -5.484809875488281}, {"pred": "East", "count": 1, "cond_log_prob": -5.377899169921875}, {"pred": "Imperial", "count": 1, "cond_log_prob": -7.965202331542969}, {"pred": "Japanese", "count": 10, "cond_log_prob": -2.9979171752929688}, {"pred": "Japaneseroute", "count": 1, "cond_log_prob": -34.89745330810547}, {"pred": "North", "count": 1, "cond_log_prob": -4.899345397949219}, {"pred": "People", "count": 1, "cond_log_prob": -5.918388366699219}, {"pred": "Spanish", "count": 2, "cond_log_prob": -4.92425537109375}, {"pred": "Tang", "count": 1, "cond_log_prob": -7.720405578613281}, {"pred": "day", "count": 1, "cond_log_prob": -8.557952880859375}, {"pred": "most", "count": 1, "cond_log_prob": -6.545738220214844}, {"pred": "other", "count": 1, "cond_log_prob": -6.094291687011719}, {"pred": "people", "count": 2, "cond_log_prob": -3.3011856079101562}, {"pred": "rest", "count": 2, "cond_log_prob": -3.927947998046875}, {"pred": "west", "count": 2, "cond_log_prob": -5.097755432128906}, {"pred": "westThe", "count": 1, "cond_log_prob": -18.298847198486328}]}, "8": {"context": {"text": "Known as Rapa Nui to the island's", "log_prob": -45.99372482299805}, "original": {"pred": "inhabitants,", "cond_log_prob": -2.4064674377441406}, "human": [{"pred": "people", "cond_log_prob": -3.2612686157226562, "count": 12}, {"pred": "natives", "cond_log_prob": -3.2137069702148438, "count": 6}, {"pred": "of", "cond_log_prob": -8.973594665527344, "count": 6}, {"pred": "inhabitants", "cond_log_prob": -2.1555557250976562, "count": 4}, {"pred": "population", "cond_log_prob": -4.205406188964844, "count": 2}, {"pred": "beach", "cond_log_prob": -8.043510437011719, "count": 1}, {"pred": "children", "cond_log_prob": -6.949333190917969, "count": 1}, {"pred": "greatest", "cond_log_prob": -7.744209289550781, "count": 1}, {"pred": "home", "cond_log_prob": -8.486579895019531, "count": 1}, {"pred": "in", "cond_log_prob": -9.130455017089844, "count": 1}, {"pred": "largest", "cond_log_prob": -7.008003234863281, "count": 1}, {"pred": "leader", "cond_log_prob": -8.641677856445312, "count": 1}, {"pred": "native", "cond_log_prob": -3.3899154663085938, "count": 1}, {"pred": "residents", "cond_log_prob": -3.2165603637695312, "count": 1}, {"pred": "ruler", "cond_log_prob": -8.884239196777344, "count": 1}], "ancestral_samples": [{"pred": "Spanishspeaking", "count": 1, "cond_log_prob": -13.499107360839844}, {"pred": "indigenous", "count": 4, "cond_log_prob": -3.7843399047851562}, {"pred": "inhabitants", "count": 23, "cond_log_prob": -2.1555557250976562}, {"pred": "inhabitantsContents", "count": 2, "cond_log_prob": -15.212196350097656}, {"pred": "inhabitantsroute", "count": 1, "cond_log_prob": -22.217517852783203}, {"pred": "most", "count": 1, "cond_log_prob": -4.260993957519531}, {"pred": "natives", "count": 1, "cond_log_prob": -3.2137069702148438}, {"pred": "original", "count": 1, "cond_log_prob": -5.794395446777344}, {"pred": "other", "count": 1, "cond_log_prob": -5.962318420410156}, {"pred": "people", "count": 4, "cond_log_prob": -3.2612686157226562}, {"pred": "pirates", "count": 1, "cond_log_prob": -6.310340881347656}]}, "9": {"context": {"text": "Known as Rapa Nui to the island's inhabitants,", "log_prob": -48.40019226074219}, "original": {"pred": "Rongorongo", "cond_log_prob": -25.578811645507812}, "human": [{"pred": "he", "cond_log_prob": -5.035984039306641, "count": 14}, {"pred": "the", "cond_log_prob": -1.4876136779785156, "count": 11}, {"pred": "rapa", "cond_log_prob": -5.386192321777344, "count": 2}, {"pred": "this", "cond_log_prob": -2.0874366760253906, "count": 2}, {"pred": "but", "cond_log_prob": -7.382411956787109, "count": 1}, {"pred": "chief", "cond_log_prob": -10.98488998413086, "count": 1}, {"pred": "do", "cond_log_prob": -10.044902801513672, "count": 1}, {"pred": "in", "cond_log_prob": -6.108737945556641, "count": 1}, {"pred": "it", "cond_log_prob": -2.9122657775878906, "count": 1}, {"pred": "nui", "cond_log_prob": -7.8816375732421875, "count": 1}, {"pred": "professor", "cond_log_prob": -13.677043914794922, "count": 1}, {"pred": "santa", "cond_log_prob": -12.695850372314453, "count": 1}, {"pred": "steve", "cond_log_prob": -18.867660522460938, "count": 1}, {"pred": "there", "cond_log_prob": -5.134418487548828, "count": 1}, {"pred": "they", "cond_log_prob": -3.9886131286621094, "count": 1}], "ancestral_samples": [{"pred": "Rapa", "count": 4, "cond_log_prob": -1.5907783508300781}, {"pred": "she", "count": 4, "cond_log_prob": -4.204151153564453}, {"pred": "the", "count": 29, "cond_log_prob": -1.4876136779785156}, {"pred": "theroute", "count": 1, "cond_log_prob": -25.319976806640625}, {"pred": "they", "count": 1, "cond_log_prob": -3.9886131286621094}, {"pred": "this", "count": 1, "cond_log_prob": -2.0874366760253906}]}, "10": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo", "log_prob": -73.97900390625}, "original": {"pred": "is", "cond_log_prob": -1.1506271362304688}, "human": [{"pred": "is", "cond_log_prob": -1.1506805419921875, "count": 19}, {"pred": "was", "cond_log_prob": -3.0076751708984375, "count": 4}, {"pred": "did", "cond_log_prob": -7.8924713134765625, "count": 2}, {"pred": "to", "cond_log_prob": -7.745941162109375, "count": 2}, {"pred": "began", "cond_log_prob": -7.0945281982421875, "count": 1}, {"pred": "had", "cond_log_prob": -5.516143798828125, "count": 1}, {"pred": "has", "cond_log_prob": -3.031402587890625, "count": 1}, {"pred": "helped", "cond_log_prob": -9.366928100585938, "count": 1}, {"pred": "his", "cond_log_prob": -10.0889892578125, "count": 1}, {"pred": "island", "cond_log_prob": -7.416229248046875, "count": 1}, {"pred": "means", "cond_log_prob": -5.098419189453125, "count": 1}, {"pred": "nui", "cond_log_prob": -6.417030334472656, "count": 1}, {"pred": "nuiana", "cond_log_prob": -21.818328857421875, "count": 1}, {"pred": "quickly", "cond_log_prob": -8.676864624023438, "count": 1}, {"pred": "said", "cond_log_prob": -7.86859130859375, "count": 1}, {"pred": "the", "cond_log_prob": -6.438720703125, "count": 1}, {"pred": "volcano", "cond_log_prob": -9.384246826171875, "count": 1}], "ancestral_samples": [{"pred": "is", "count": 31, "cond_log_prob": -1.1506805419921875}, {"pred": "isroute", "count": 1, "cond_log_prob": -22.419891357421875}, {"pred": "s", "count": 1, "cond_log_prob": -8.07366943359375}, {"pred": "was", "count": 7, "cond_log_prob": -3.0076751708984375}]}, "11": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is", "log_prob": -75.12963104248047}, "original": {"pred": "a", "cond_log_prob": -1.065643310546875}, "human": [{"pred": "the", "cond_log_prob": -2.2555007934570312, "count": 19}, {"pred": "a", "cond_log_prob": -1.0657119750976562, "count": 8}, {"pred": "one", "cond_log_prob": -2.4572677612304688, "count": 3}, {"pred": "his", "cond_log_prob": -8.656929016113281, "count": 2}, {"pred": "known", "cond_log_prob": -4.084434509277344, "count": 2}, {"pred": "always", "cond_log_prob": -7.768257141113281, "count": 1}, {"pred": "famous", "cond_log_prob": -5.009040832519531, "count": 1}, {"pred": "how", "cond_log_prob": -10.179008483886719, "count": 1}, {"pred": "know", "cond_log_prob": -11.632469177246094, "count": 1}, {"pred": "loved", "cond_log_prob": -9.680442810058594, "count": 1}, {"pred": "named", "cond_log_prob": -6.037498474121094, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 31, "cond_log_prob": -1.0657119750976562}, {"pred": "also", "count": 1, "cond_log_prob": -4.486412048339844}, {"pred": "aroute", "count": 1, "cond_log_prob": -25.11571502685547}, {"pred": "home", "count": 1, "cond_log_prob": -3.0440292358398438}, {"pred": "one", "count": 3, "cond_log_prob": -2.4572677612304688}, {"pred": "the", "count": 3, "cond_log_prob": -2.2555007934570312}]}, "12": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a", "log_prob": -76.19527435302734}, "original": {"pred": "writing", "cond_log_prob": -11.459793090820312}, "human": [{"pred": "famous", "cond_log_prob": -5.993217468261719, "count": 4}, {"pred": "great", "cond_log_prob": -5.482658386230469, "count": 4}, {"pred": "volcano", "cond_log_prob": -5.594230651855469, "count": 3}, {"pred": "friend", "cond_log_prob": -9.843940734863281, "count": 2}, {"pred": "legend", "cond_log_prob": -8.442527770996094, "count": 2}, {"pred": "person", "cond_log_prob": -9.307487487792969, "count": 2}, {"pred": "very", "cond_log_prob": -5.313758850097656, "count": 2}, {"pred": "beautiful", "cond_log_prob": -4.403877258300781, "count": 1}, {"pred": "big", "cond_log_prob": -6.618598937988281, "count": 1}, {"pred": "doctor", "cond_log_prob": -11.999656677246094, "count": 1}, {"pred": "god", "cond_log_prob": -7.800056457519531, "count": 2}, {"pred": "helpful", "cond_log_prob": -10.895362854003906, "count": 1}, {"pred": "king", "cond_log_prob": -9.088874816894531, "count": 1}, {"pred": "known", "cond_log_prob": -7.843788146972656, "count": 1}, {"pred": "large", "cond_log_prob": -3.7348251342773438, "count": 1}, {"pred": "legendary", "cond_log_prob": -5.497383117675781, "count": 1}, {"pred": "mountain", "cond_log_prob": -5.905036926269531, "count": 1}, {"pred": "predator", "cond_log_prob": -10.192115783691406, "count": 1}, {"pred": "principle", "cond_log_prob": -11.353065490722656, "count": 1}, {"pred": "public", "cond_log_prob": -8.678123474121094, "count": 1}, {"pred": "rapping", "cond_log_prob": -13.815116882324219, "count": 1}, {"pred": "rock", "cond_log_prob": -6.488639831542969, "count": 1}, {"pred": "system", "cond_log_prob": -7.800010681152344, "count": 1}, {"pred": "title", "cond_log_prob": -8.996376037597656, "count": 1}, {"pred": "well", "cond_log_prob": -5.355644226074219, "count": 1}, {"pred": "wonderful", "cond_log_prob": -7.675682067871094, "count": 1}, {"pred": "word", "cond_log_prob": -7.968070983886719, "count": 1}], "ancestral_samples": [{"pred": "beautiful", "count": 1, "cond_log_prob": -4.403877258300781}, {"pred": "bustling", "count": 1, "cond_log_prob": -5.323753356933594}, {"pred": "city", "count": 2, "cond_log_prob": -4.592781066894531}, {"pred": "country", "count": 1, "cond_log_prob": -5.650688171386719}, {"pred": "giant", "count": 1, "cond_log_prob": -5.705482482910156}, {"pred": "great", "count": 3, "cond_log_prob": -5.482658386230469}, {"pred": "home", "count": 1, "cond_log_prob": -6.303993225097656}, {"pred": "land", "count": 2, "cond_log_prob": -5.002220153808594}, {"pred": "large", "count": 3, "cond_log_prob": -3.7348251342773438}, {"pred": "mighty", "count": 1, "cond_log_prob": -7.130485534667969}, {"pred": "monolith", "count": 1, "cond_log_prob": -10.050437927246094}, {"pred": "mystical", "count": 1, "cond_log_prob": -6.037773132324219}, {"pred": "place", "count": 2, "cond_log_prob": -4.434272766113281}, {"pred": "popular", "count": 3, "cond_log_prob": -3.9882583618164062}, {"pred": "small", "count": 8, "cond_log_prob": -3.3297348022460938}, {"pred": "smallroute", "count": 1, "cond_log_prob": -23.02228546142578}, {"pred": "strange", "count": 1, "cond_log_prob": -6.416862487792969}, {"pred": "thriving", "count": 1, "cond_log_prob": -5.739692687988281}, {"pred": "tiny", "count": 1, "cond_log_prob": -5.964134216308594}, {"pred": "tropical", "count": 1, "cond_log_prob": -3.3030929565429688}, {"pred": "very", "count": 2, "cond_log_prob": -5.313758850097656}, {"pred": "volcanic", "count": 1, "cond_log_prob": -3.7427139282226562}, {"pred": "wellknown", "count": 1, "cond_log_prob": -13.634300231933594}]}, "13": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing", "log_prob": -87.65506744384766}, "original": {"pred": "system", "cond_log_prob": -3.4583206176757812}, "human": [{"pred": "that", "cond_log_prob": -6.362510681152344, "count": 5}, {"pred": "a", "cond_log_prob": -8.004158020019531, "count": 4}, {"pred": "teacher", "cond_log_prob": -8.448448181152344, "count": 4}, {"pred": "style", "cond_log_prob": -4.234611511230469, "count": 3}, {"pred": "facility", "cond_log_prob": -5.805885314941406, "count": 2}, {"pred": "genius", "cond_log_prob": -9.292030334472656, "count": 2}, {"pred": "poet", "cond_log_prob": -8.800148010253906, "count": 2}, {"pred": "prodigy", "cond_log_prob": -11.478401184082031, "count": 2}, {"pred": "which", "cond_log_prob": -7.460273742675781, "count": 2}, {"pred": "assignment", "cond_log_prob": -9.165550231933594, "count": 1}, {"pred": "campaign", "cond_log_prob": -7.457603454589844, "count": 1}, {"pred": "fanatic", "cond_log_prob": -13.159934997558594, "count": 1}, {"pred": "fiend", "cond_log_prob": -11.643836975097656, "count": 1}, {"pred": "found", "cond_log_prob": -10.473548889160156, "count": 1}, {"pred": "in", "cond_log_prob": -5.170417785644531, "count": 1}, {"pred": "instrument", "cond_log_prob": -5.185859680175781, "count": 1}, {"pred": "lab", "cond_log_prob": -9.336479187011719, "count": 1}, {"pred": "of", "cond_log_prob": -4.661613464355469, "count": 1}, {"pred": "person", "cond_log_prob": -10.158943176269531, "count": 1}, {"pred": "professon", "cond_log_prob": -20.59632110595703, "count": 1}, {"pred": "similar", "cond_log_prob": -12.293296813964844, "count": 1}, {"pred": "system", "cond_log_prob": -3.4583969116210938, "count": 1}, {"pred": "tool", "cond_log_prob": -5.927436828613281, "count": 1}], "ancestral_samples": [{"pred": "Contents", "count": 1, "cond_log_prob": -24.05760955810547}, {"pred": "and", "count": 16, "cond_log_prob": -2.0394668579101562}, {"pred": "androute", "count": 1, "cond_log_prob": -21.772682189941406}, {"pred": "based", "count": 1, "cond_log_prob": -6.639411926269531}, {"pred": "community", "count": 1, "cond_log_prob": -3.6611099243164062}, {"pred": "language", "count": 16, "cond_log_prob": -3.1503982543945312}, {"pred": "society", "count": 2, "cond_log_prob": -4.312278747558594}, {"pred": "system", "count": 2, "cond_log_prob": -3.4583969116210938}]}, "14": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system", "log_prob": -91.11338806152344}, "original": {"pred": "comprised", "cond_log_prob": -5.823249816894531}, "human": [{"pred": "that", "cond_log_prob": -1.805877685546875, "count": 23}, {"pred": "in", "cond_log_prob": -2.863037109375, "count": 4}, {"pred": "used", "cond_log_prob": -3.9689178466796875, "count": 4}, {"pred": "based", "cond_log_prob": -2.8324737548828125, "count": 2}, {"pred": "of", "cond_log_prob": -2.6196136474609375, "count": 2}, {"pred": "which", "cond_log_prob": -3.3148193359375, "count": 2}, {"pred": "created", "cond_log_prob": -4.2850341796875, "count": 1}, {"pred": "established", "cond_log_prob": -6.1407012939453125, "count": 1}, {"pred": "teacher", "cond_log_prob": -13.913162231445312, "count": 1}], "ancestral_samples": [{"pred": "Contents", "count": 1, "cond_log_prob": -20.75677490234375}, {"pred": "based", "count": 1, "cond_log_prob": -2.8324737548828125}, {"pred": "constructed", "count": 1, "cond_log_prob": -6.214263916015625}, {"pred": "for", "count": 1, "cond_log_prob": -2.916259765625}, {"pred": "in", "count": 4, "cond_log_prob": -2.863037109375}, {"pred": "inhabited", "count": 1, "cond_log_prob": -5.4246826171875}, {"pred": "of", "count": 6, "cond_log_prob": -2.6196136474609375}, {"pred": "that", "count": 21, "cond_log_prob": -1.805877685546875}, {"pred": "thatroute", "count": 1, "cond_log_prob": -23.540939331054688}, {"pred": "where", "count": 1, "cond_log_prob": -3.1213836669921875}, {"pred": "which", "count": 1, "cond_log_prob": -3.3148193359375}, {"pred": "with", "count": 1, "cond_log_prob": -3.3574371337890625}]}, "15": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised", "log_prob": -96.93663787841797}, "original": {"pred": "of", "cond_log_prob": -0.109649658203125}, "human": [{"pred": "of", "cond_log_prob": -0.10973358154296875, "count": 37}, {"pred": "by", "cond_log_prob": -6.531944274902344, "count": 2}, {"pred": "to", "cond_log_prob": -8.506126403808594, "count": 1}], "ancestral_samples": [{"pred": "of", "count": 39, "cond_log_prob": -0.10974884033203125}, {"pred": "ofroute", "count": 1, "cond_log_prob": -20.64476776123047}]}, "16": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of", "log_prob": -97.0462875366211}, "original": {"pred": "pictographs.", "cond_log_prob": -12.060012817382812}, "human": [{"pred": "symbols", "cond_log_prob": -7.529396057128906, "count": 7}, {"pred": "many", "cond_log_prob": -4.751121520996094, "count": 4}, {"pred": "characters", "cond_log_prob": -5.577171325683594, "count": 3}, {"pred": "different", "cond_log_prob": -5.770301818847656, "count": 3}, {"pred": "letters", "cond_log_prob": -4.039176940917969, "count": 2}, {"pred": "multiple", "cond_log_prob": -4.893257141113281, "count": 2}, {"pred": "by", "cond_log_prob": -10.087303161621094, "count": 1}, {"pred": "english", "cond_log_prob": -10.712181091308594, "count": 1}, {"pred": "figures", "cond_log_prob": -9.482673645019531, "count": 1}, {"pred": "four", "cond_log_prob": -3.2197341918945312, "count": 1}, {"pred": "hundreds", "cond_log_prob": -5.303550720214844, "count": 1}, {"pred": "mainly", "cond_log_prob": -8.191581726074219, "count": 1}, {"pred": "methods", "cond_log_prob": -11.383903503417969, "count": 1}, {"pred": "new", "cond_log_prob": -8.534904479980469, "count": 1}, {"pred": "numerous", "cond_log_prob": -6.282814025878906, "count": 1}, {"pred": "only", "cond_log_prob": -6.736625671386719, "count": 1}, {"pred": "pictures", "cond_log_prob": -8.831916809082031, "count": 1}, {"pred": "several", "cond_log_prob": -4.226615905761719, "count": 1}, {"pred": "some", "cond_log_prob": -6.331214904785156, "count": 1}, {"pred": "syllables", "cond_log_prob": -6.534576416015625, "count": 1}, {"pred": "techniques", "cond_log_prob": -10.788307189941406, "count": 1}, {"pred": "ten", "cond_log_prob": -4.842353820800781, "count": 1}, {"pred": "three", "cond_log_prob": -2.9393539428710938, "count": 1}, {"pred": "two", "cond_log_prob": -3.4971694946289062, "count": 1}, {"pred": "words", "cond_log_prob": -4.465797424316406, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 16, "cond_log_prob": -2.8892898559570312}, {"pred": "five", "count": 2, "cond_log_prob": -3.6491622924804688}, {"pred": "four", "count": 4, "cond_log_prob": -3.2197341918945312}, {"pred": "many", "count": 1, "cond_log_prob": -4.751121520996094}, {"pred": "numerous", "count": 1, "cond_log_prob": -6.282814025878906}, {"pred": "phonetic", "count": 1, "cond_log_prob": -6.266578674316406}, {"pred": "six", "count": 2, "cond_log_prob": -3.9697341918945312}, {"pred": "the", "count": 1, "cond_log_prob": -3.6794967651367188}, {"pred": "three", "count": 5, "cond_log_prob": -2.9393539428710938}, {"pred": "threeroute", "count": 1, "cond_log_prob": -31.85913848876953}, {"pred": "two", "count": 3, "cond_log_prob": -3.4971694946289062}, {"pred": "words", "count": 3, "cond_log_prob": -4.465797424316406}]}, "17": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs.", "log_prob": -109.1063003540039}, "original": {"pred": "It", "cond_log_prob": -2.3984909057617188}, "human": [{"pred": "it", "cond_log_prob": -9.983428955078125, "count": 9}, {"pred": "the", "cond_log_prob": -8.294525146484375, "count": 6}, {"pred": "this", "cond_log_prob": -11.770248413085938, "count": 9}, {"pred": "rapa", "cond_log_prob": -12.566131591796875, "count": 2}, {"pred": "these", "cond_log_prob": -11.810760498046875, "count": 3}, {"pred": "?", "cond_log_prob": -11.871978759765625, "count": 1}, {"pred": "each", "cond_log_prob": -10.717605590820312, "count": 1}, {"pred": "its", "cond_log_prob": -10.89642333984375, "count": 1}, {"pred": "letters", "cond_log_prob": -14.703765869140625, "count": 1}, {"pred": "ok", "cond_log_prob": -18.113174438476562, "count": 1}, {"pred": "people", "cond_log_prob": -13.2611083984375, "count": 1}, {"pred": "psychology", "cond_log_prob": -20.646507263183594, "count": 1}, {"pred": "they", "cond_log_prob": -12.094818115234375, "count": 1}, {"pred": "used", "cond_log_prob": -12.677764892578125, "count": 1}, {"pred": "while", "cond_log_prob": -12.236740112304688, "count": 2}], "ancestral_samples": [{"pred": "Contents", "count": 1, "cond_log_prob": -10.889984130859375}, {"pred": "In", "count": 3, "cond_log_prob": -3.3430328369140625}, {"pred": "It", "count": 5, "cond_log_prob": -2.3986053466796875}, {"pred": "Itroute", "count": 1, "cond_log_prob": -24.310264587402344}, {"pred": "Rapa", "count": 1, "cond_log_prob": -2.937225341796875}, {"pred": "Rongorongo", "count": 1, "cond_log_prob": -3.7858428955078125}, {"pred": "The", "count": 27, "cond_log_prob": -1.74884033203125}, {"pred": "These", "count": 1, "cond_log_prob": -3.2187652587890625}]}, "18": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It", "log_prob": -111.50479125976562}, "original": {"pred": "has", "cond_log_prob": -2.6995925903320312}, "human": [{"pred": "is", "cond_log_prob": -0.9178695678710938, "count": 18}, {"pred": "has", "cond_log_prob": -2.6997299194335938, "count": 6}, {"pred": "was", "cond_log_prob": -1.8273391723632812, "count": 4}, {"pred": "allows", "cond_log_prob": -5.715797424316406, "count": 2}, {"pred": "does", "cond_log_prob": -6.296318054199219, "count": 2}, {"pred": "uses", "cond_log_prob": -5.275978088378906, "count": 2}, {"pred": "also", "cond_log_prob": -4.500328063964844, "count": 1}, {"pred": "can", "cond_log_prob": -4.100959777832031, "count": 1}, {"pred": "provides", "cond_log_prob": -5.962150573730469, "count": 1}, {"pred": "seemed", "cond_log_prob": -8.871391296386719, "count": 1}, {"pred": "tends", "cond_log_prob": -7.982978820800781, "count": 1}, {"pred": "works", "cond_log_prob": -7.748115539550781, "count": 1}], "ancestral_samples": [{"pred": "is", "count": 32, "cond_log_prob": -0.9178695678710938}, {"pred": "isroute", "count": 1, "cond_log_prob": -24.183258056640625}, {"pred": "was", "count": 7, "cond_log_prob": -1.8273391723632812}]}, "19": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has", "log_prob": -114.20438385009766}, "original": {"pred": "been", "cond_log_prob": -1.2182159423828125}, "human": [{"pred": "been", "cond_log_prob": -1.2183685302734375, "count": 8}, {"pred": "many", "cond_log_prob": -4.032623291015625, "count": 6}, {"pred": "a", "cond_log_prob": -1.9121246337890625, "count": 3}, {"pred": "the", "cond_log_prob": -3.9394378662109375, "count": 3}, {"pred": "become", "cond_log_prob": -3.8596649169921875, "count": 2}, {"pred": "functions", "cond_log_prob": -9.778427124023438, "count": 2}, {"pred": "elements", "cond_log_prob": -7.92498779296875, "count": 1}, {"pred": "fifty", "cond_log_prob": -9.013153076171875, "count": 1}, {"pred": "five", "cond_log_prob": -5.5144500732421875, "count": 1}, {"pred": "great", "cond_log_prob": -6.9759521484375, "count": 1}, {"pred": "helped", "cond_log_prob": -7.167327880859375, "count": 1}, {"pred": "improved", "cond_log_prob": -9.453811645507812, "count": 1}, {"pred": "lasted", "cond_log_prob": -7.755584716796875, "count": 1}, {"pred": "multiple", "cond_log_prob": -6.6710662841796875, "count": 1}, {"pred": "not", "cond_log_prob": -5.19488525390625, "count": 1}, {"pred": "numerous", "cond_log_prob": -5.9156341552734375, "count": 1}, {"pred": "over", "cond_log_prob": -5.748046875, "count": 1}, {"pred": "seventy", "cond_log_prob": -9.691070556640625, "count": 1}, {"pred": "several", "cond_log_prob": -4.7057342529296875, "count": 1}, {"pred": "ten", "cond_log_prob": -7.443145751953125, "count": 1}, {"pred": "twenty", "cond_log_prob": -8.32354736328125, "count": 1}, {"pred": "very", "cond_log_prob": -6.3386993408203125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 13, "cond_log_prob": -1.9121246337890625}, {"pred": "been", "count": 26, "cond_log_prob": -1.2183685302734375}, {"pred": "beenroute", "count": 1, "cond_log_prob": -23.808860778808594}]}, "20": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been", "log_prob": -115.42259979248047}, "original": {"pred": "found", "cond_log_prob": -4.763221740722656}, "human": [{"pred": "used", "cond_log_prob": -2.125701904296875, "count": 9}, {"pred": "known", "cond_log_prob": -3.1508026123046875, "count": 7}, {"pred": "the", "cond_log_prob": -3.7996673583984375, "count": 3}, {"pred": "an", "cond_log_prob": -5.1180267333984375, "count": 2}, {"pred": "called", "cond_log_prob": -4.0300750732421875, "count": 2}, {"pred": "proven", "cond_log_prob": -7.7330474853515625, "count": 2}, {"pred": "said", "cond_log_prob": -4.5494537353515625, "count": 2}, {"pred": "studied", "cond_log_prob": -5.269134521484375, "count": 2}, {"pred": "around", "cond_log_prob": -4.1598052978515625, "count": 1}, {"pred": "described", "cond_log_prob": -2.5638427734375, "count": 1}, {"pred": "designed", "cond_log_prob": -5.665496826171875, "count": 1}, {"pred": "developed", "cond_log_prob": -4.7665863037109375, "count": 1}, {"pred": "helping", "cond_log_prob": -10.568145751953125, "count": 1}, {"pred": "one", "cond_log_prob": -5.424835205078125, "count": 1}, {"pred": "recorded", "cond_log_prob": -4.9312896728515625, "count": 1}, {"pred": "shown", "cond_log_prob": -5.5013885498046875, "count": 1}, {"pred": "taught", "cond_log_prob": -7.8825531005859375, "count": 1}, {"pred": "traced", "cond_log_prob": -6.7725677490234375, "count": 1}, {"pred": "very", "cond_log_prob": -7.6385955810546875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -3.4121246337890625}, {"pred": "described", "count": 9, "cond_log_prob": -2.5638427734375}, {"pred": "inhabited", "count": 1, "cond_log_prob": -3.4958953857421875}, {"pred": "known", "count": 4, "cond_log_prob": -3.1508026123046875}, {"pred": "ruledroute", "count": 1, "cond_log_prob": -28.16254425048828}, {"pred": "said", "count": 3, "cond_log_prob": -4.5494537353515625}, {"pred": "the", "count": 1, "cond_log_prob": -3.7996673583984375}, {"pred": "used", "count": 18, "cond_log_prob": -2.125701904296875}]}, "21": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found", "log_prob": -120.18582153320312}, "original": {"pred": "carved", "cond_log_prob": -7.138099670410156}, "human": [{"pred": "to", "cond_log_prob": -1.5802230834960938, "count": 20}, {"pred": "in", "cond_log_prob": -1.4089279174804688, "count": 10}, {"pred": "that", "cond_log_prob": -2.1378250122070312, "count": 7}, {"pred": "all", "cond_log_prob": -6.126564025878906, "count": 1}, {"pred": "carved", "cond_log_prob": -7.138252258300781, "count": 1}, {"pred": "correctly", "cond_log_prob": -11.55450439453125, "count": 1}], "ancestral_samples": [{"pred": "in", "count": 18, "cond_log_prob": -1.4089279174804688}, {"pred": "that", "count": 11, "cond_log_prob": -2.1378250122070312}, {"pred": "thatroute", "count": 1, "cond_log_prob": -21.359588623046875}, {"pred": "to", "count": 10, "cond_log_prob": -1.5802230834960938}]}, "22": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved", "log_prob": -127.32392120361328}, "original": {"pred": "into", "cond_log_prob": -1.0332260131835938}, "human": [{"pred": "in", "cond_log_prob": -2.5174179077148438, "count": 18}, {"pred": "into", "cond_log_prob": -1.0334091186523438, "count": 11}, {"pred": "on", "cond_log_prob": -2.0788497924804688, "count": 7}, {"pred": "out", "cond_log_prob": -2.2502975463867188, "count": 2}, {"pred": "by", "cond_log_prob": -3.8738021850585938, "count": 1}, {"pred": "to", "cond_log_prob": -4.930229187011719, "count": 1}], "ancestral_samples": [{"pred": "in", "count": 4, "cond_log_prob": -2.5174179077148438}, {"pred": "into", "count": 26, "cond_log_prob": -1.0334091186523438}, {"pred": "intoroute", "count": 1, "cond_log_prob": -30.681724548339844}, {"pred": "on", "count": 5, "cond_log_prob": -2.0788497924804688}, {"pred": "onto", "count": 1, "cond_log_prob": -2.8722457885742188}, {"pred": "out", "count": 3, "cond_log_prob": -2.2502975463867188}]}, "23": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into", "log_prob": -128.35714721679688}, "original": {"pred": "many", "cond_log_prob": -3.364501953125}, "human": [{"pred": "the", "cond_log_prob": -1.0638427734375, "count": 14}, {"pred": "rocks", "cond_log_prob": -3.8509521484375, "count": 7}, {"pred": "cave", "cond_log_prob": -8.645050048828125, "count": 4}, {"pred": "rock", "cond_log_prob": -4.5393218994140625, "count": 3}, {"pred": "stone", "cond_log_prob": -3.6541290283203125, "count": 3}, {"pred": "wooden", "cond_log_prob": -5.446624755859375, "count": 2}, {"pred": "a", "cond_log_prob": -3.178497314453125, "count": 1}, {"pred": "caves", "cond_log_prob": -6.689849853515625, "count": 1}, {"pred": "numerous", "cond_log_prob": -5.349761962890625, "count": 1}, {"pred": "stones", "cond_log_prob": -5.693328857421875, "count": 1}, {"pred": "trees", "cond_log_prob": -4.94940185546875, "count": 1}, {"pred": "walls", "cond_log_prob": -3.91925048828125, "count": 1}, {"pred": "woods", "cond_log_prob": -9.765518188476562, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.178497314453125}, {"pred": "its", "count": 1, "cond_log_prob": -3.27978515625}, {"pred": "many", "count": 1, "cond_log_prob": -3.36468505859375}, {"pred": "manyroute", "count": 1, "cond_log_prob": -23.435699462890625}, {"pred": "the", "count": 36, "cond_log_prob": -1.0638427734375}]}, "24": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many", "log_prob": -131.72164916992188}, "original": {"pred": "oblong", "cond_log_prob": -11.671829223632812}, "human": [{"pred": "different", "cond_log_prob": -2.6097412109375, "count": 7}, {"pred": "rocks", "cond_log_prob": -4.2994384765625, "count": 7}, {"pred": "caves", "cond_log_prob": -6.079315185546875, "count": 6}, {"pred": "walls", "cond_log_prob": -4.887939453125, "count": 6}, {"pred": "cave", "cond_log_prob": -8.648162841796875, "count": 3}, {"pred": "stones", "cond_log_prob": -5.437347412109375, "count": 2}, {"pred": "ancient", "cond_log_prob": -4.930572509765625, "count": 1}, {"pred": "cliffs", "cond_log_prob": -6.2349853515625, "count": 1}, {"pred": "many", "cond_log_prob": -6.709442138671875, "count": 1}, {"pred": "of", "cond_log_prob": -1.966217041015625, "count": 1}, {"pred": "rock", "cond_log_prob": -4.57177734375, "count": 1}, {"pred": "rockfaces", "cond_log_prob": -13.3912353515625, "count": 1}, {"pred": "stone", "cond_log_prob": -4.201385498046875, "count": 1}, {"pred": "things", "cond_log_prob": -5.906524658203125, "count": 1}, {"pred": "trees", "cond_log_prob": -5.1817626953125, "count": 1}], "ancestral_samples": [{"pred": "different", "count": 7, "cond_log_prob": -2.6097412109375}, {"pred": "forms", "count": 1, "cond_log_prob": -4.31463623046875}, {"pred": "islands", "count": 3, "cond_log_prob": -3.248046875}, {"pred": "objects", "count": 1, "cond_log_prob": -4.091400146484375}, {"pred": "of", "count": 27, "cond_log_prob": -1.966217041015625}, {"pred": "ofroutes", "count": 1, "cond_log_prob": -22.877044677734375}]}, "25": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong", "log_prob": -143.3934783935547}, "original": {"pred": "wooden", "cond_log_prob": -4.8632049560546875}, "human": [{"pred": "rocks", "cond_log_prob": -4.4123992919921875, "count": 7}, {"pred": "shaped", "cond_log_prob": -6.7318267822265625, "count": 5}, {"pred": "stones", "cond_log_prob": -3.5593109130859375, "count": 5}, {"pred": "shapes", "cond_log_prob": -2.9526214599609375, "count": 3}, {"pred": "walls", "cond_log_prob": -4.6762847900390625, "count": 3}, {"pred": "objects", "cond_log_prob": -4.4483795166015625, "count": 2}, {"pred": "pieces", "cond_log_prob": -3.7484588623046875, "count": 2}, {"pred": "tablets", "cond_log_prob": -5.4972381591796875, "count": 2}, {"pred": "carvings", "cond_log_prob": -8.493789672851562, "count": 1}, {"pred": "crevaces", "cond_log_prob": -22.598129272460938, "count": 1}, {"pred": "inside", "cond_log_prob": -12.234756469726562, "count": 1}, {"pred": "island", "cond_log_prob": -8.060348510742188, "count": 1}, {"pred": "planks", "cond_log_prob": -8.928482055664062, "count": 1}, {"pred": "sculptures", "cond_log_prob": -5.5848846435546875, "count": 1}, {"pred": "slates", "cond_log_prob": -11.814834594726562, "count": 1}, {"pred": "structures", "cond_log_prob": -3.1752471923828125, "count": 1}, {"pred": "things", "cond_log_prob": -8.516281127929688, "count": 1}, {"pred": "trees", "cond_log_prob": -4.9855499267578125, "count": 1}, {"pred": "words", "cond_log_prob": -6.3548126220703125, "count": 1}], "ancestral_samples": [{"pred": "Contents", "count": 1, "cond_log_prob": -17.999160766601562}, {"pred": "and", "count": 8, "cond_log_prob": -3.3914337158203125}, {"pred": "androute", "count": 1, "cond_log_prob": -24.677291870117188}, {"pred": "cuneiform", "count": 1, "cond_log_prob": -6.5928192138671875}, {"pred": "curved", "count": 1, "cond_log_prob": -7.1320343017578125}, {"pred": "hieroglyphics", "count": 1, "cond_log_prob": -5.2028656005859375}, {"pred": "letters", "count": 1, "cond_log_prob": -3.9709320068359375}, {"pred": "lines", "count": 1, "cond_log_prob": -4.0300750732421875}, {"pred": "narrow", "count": 1, "cond_log_prob": -8.593154907226562}, {"pred": "objects", "count": 1, "cond_log_prob": -4.4483795166015625}, {"pred": "or", "count": 1, "cond_log_prob": -4.7478790283203125}, {"pred": "patterns", "count": 1, "cond_log_prob": -5.0210113525390625}, {"pred": "piecesR", "count": 1, "cond_log_prob": -21.270797729492188}, {"pred": "pillars", "count": 1, "cond_log_prob": -4.9074249267578125}, {"pred": "rocks", "count": 1, "cond_log_prob": -4.4123992919921875}, {"pred": "shapes", "count": 9, "cond_log_prob": -2.9526214599609375}, {"pred": "stones", "count": 1, "cond_log_prob": -3.5593109130859375}, {"pred": "structures", "count": 7, "cond_log_prob": -3.1752471923828125}, {"pred": "wooden", "count": 1, "cond_log_prob": -4.8633880615234375}]}, "26": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden", "log_prob": -148.25668334960938}, "original": {"pred": "tablets", "cond_log_prob": -4.1507415771484375}, "human": [{"pred": "planks", "cond_log_prob": -5.965789794921875, "count": 5}, {"pred": "boards", "cond_log_prob": -4.899566650390625, "count": 4}, {"pred": "trees", "cond_log_prob": -5.842376708984375, "count": 3}, {"pred": "blocks", "cond_log_prob": -2.64007568359375, "count": 2}, {"pred": "objects", "cond_log_prob": -4.302337646484375, "count": 2}, {"pred": "panels", "cond_log_prob": -4.817962646484375, "count": 2}, {"pred": "pieces", "cond_log_prob": -4.527923583984375, "count": 2}, {"pred": "tablets", "cond_log_prob": -4.15093994140625, "count": 2}, {"pred": "artifacts", "cond_log_prob": -8.178802490234375, "count": 1}, {"pred": "carvings", "cond_log_prob": -7.21612548828125, "count": 1}, {"pred": "items", "cond_log_prob": -7.634613037109375, "count": 1}, {"pred": "legs", "cond_log_prob": -7.771820068359375, "count": 1}, {"pred": "logs", "cond_log_prob": -5.1812744140625, "count": 1}, {"pred": "masks", "cond_log_prob": -8.327606201171875, "count": 1}, {"pred": "pallets", "cond_log_prob": -6.8309326171875, "count": 1}, {"pred": "people", "cond_log_prob": -10.558868408203125, "count": 1}, {"pred": "poles", "cond_log_prob": -4.28643798828125, "count": 1}, {"pred": "posts", "cond_log_prob": -3.664947509765625, "count": 1}, {"pred": "sculptures", "cond_log_prob": -4.8031005859375, "count": 1}, {"pred": "shapes", "cond_log_prob": -5.090484619140625, "count": 1}, {"pred": "slates", "cond_log_prob": -11.72869873046875, "count": 1}, {"pred": "sticks", "cond_log_prob": -5.514862060546875, "count": 1}, {"pred": "structures", "cond_log_prob": -2.49517822265625, "count": 1}, {"pred": "tools", "cond_log_prob": -7.410186767578125, "count": 1}, {"pred": "totems", "cond_log_prob": -8.4635009765625, "count": 1}, {"pred": "walls", "cond_log_prob": -4.151763916015625, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 1, "cond_log_prob": -4.38983154296875}, {"pred": "blocks", "count": 6, "cond_log_prob": -2.64007568359375}, {"pred": "buildings", "count": 2, "cond_log_prob": -3.305328369140625}, {"pred": "columns", "count": 1, "cond_log_prob": -3.94281005859375}, {"pred": "pillars", "count": 2, "cond_log_prob": -3.670318603515625}, {"pred": "poles", "count": 2, "cond_log_prob": -4.28643798828125}, {"pred": "structures", "count": 22, "cond_log_prob": -2.49517822265625}, {"pred": "structuresR", "count": 1, "cond_log_prob": -19.253936767578125}, {"pred": "structuresroute", "count": 1, "cond_log_prob": -25.054229736328125}, {"pred": "towers", "count": 1, "cond_log_prob": -4.333099365234375}, {"pred": "works", "count": 1, "cond_log_prob": -4.950225830078125}]}, "27": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets", "log_prob": -152.4074249267578}, "original": {"pred": "and", "cond_log_prob": -1.810394287109375}, "human": [{"pred": "that", "cond_log_prob": -3.1735992431640625, "count": 13}, {"pred": "and", "cond_log_prob": -1.8105926513671875, "count": 5}, {"pred": "used", "cond_log_prob": -5.5599212646484375, "count": 4}, {"pred": "along", "cond_log_prob": -5.2831878662109375, "count": 3}, {"pred": "in", "cond_log_prob": -3.1578216552734375, "count": 3}, {"pred": "all", "cond_log_prob": -7.1748504638671875, "count": 2}, {"pred": "found", "cond_log_prob": -4.7816009521484375, "count": 2}, {"pred": "around", "cond_log_prob": -5.7428436279296875, "count": 1}, {"pred": "as", "cond_log_prob": -4.5649261474609375, "count": 1}, {"pred": "by", "cond_log_prob": -3.9370574951171875, "count": 1}, {"pred": "dating", "cond_log_prob": -2.8545074462890625, "count": 1}, {"pred": "depicting", "cond_log_prob": -5.5691680908203125, "count": 1}, {"pred": "from", "cond_log_prob": -3.8950958251953125, "count": 1}, {"pred": "on", "cond_log_prob": -4.9152374267578125, "count": 1}, {"pred": "which", "cond_log_prob": -3.5437164306640625, "count": 1}], "ancestral_samples": [{"pred": "According", "count": 1, "cond_log_prob": -15.223342895507812}, {"pred": "Rong", "count": 1, "cond_log_prob": -13.388565063476562}, {"pred": "The", "count": 2, "cond_log_prob": -10.725540161132812}, {"pred": "a", "count": 1, "cond_log_prob": -8.261306762695312}, {"pred": "and", "count": 28, "cond_log_prob": -1.8105926513671875}, {"pred": "depictingroute", "count": 1, "cond_log_prob": -24.939010620117188}, {"pred": "including", "count": 1, "cond_log_prob": -5.8939056396484375}, {"pred": "that", "count": 1, "cond_log_prob": -3.1735992431640625}, {"pred": "which", "count": 3, "cond_log_prob": -3.5437164306640625}, {"pred": "with", "count": 1, "cond_log_prob": -4.0015716552734375}]}, "28": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and", "log_prob": -154.2178192138672}, "original": {"pred": "other", "cond_log_prob": -3.6222076416015625}, "human": [{"pred": "other", "cond_log_prob": -3.6224212646484375, "count": 3}, {"pred": "stones", "cond_log_prob": -5.9933624267578125, "count": 3}, {"pred": "has", "cond_log_prob": -3.7395477294921875, "count": 2}, {"pred": "in", "cond_log_prob": -3.6310272216796875, "count": 2}, {"pred": "it", "cond_log_prob": -5.0708770751953125, "count": 2}, {"pred": "on", "cond_log_prob": -4.5530853271484375, "count": 2}, {"pred": "stone", "cond_log_prob": -4.6518707275390625, "count": 2}, {"pred": "are", "cond_log_prob": -6.5265960693359375, "count": 1}, {"pred": "boards", "cond_log_prob": -8.712814331054688, "count": 1}, {"pred": "buildings", "cond_log_prob": -7.8561248779296875, "count": 1}, {"pred": "caves", "cond_log_prob": -8.322341918945312, "count": 1}, {"pred": "is", "cond_log_prob": -3.0551605224609375, "count": 1}, {"pred": "many", "cond_log_prob": -4.8639678955078125, "count": 1}, {"pred": "metal", "cond_log_prob": -6.2571563720703125, "count": 1}, {"pred": "ornaments", "cond_log_prob": -8.468063354492188, "count": 1}, {"pred": "painted", "cond_log_prob": -5.8859710693359375, "count": 1}, {"pred": "pens", "cond_log_prob": -8.635391235351562, "count": 1}, {"pred": "planks", "cond_log_prob": -9.772171020507812, "count": 1}, {"pred": "preserved", "cond_log_prob": -7.4548797607421875, "count": 1}, {"pred": "rock", "cond_log_prob": -7.0446929931640625, "count": 1}, {"pred": "rocks", "cond_log_prob": -6.9030303955078125, "count": 1}, {"pred": "sculptures", "cond_log_prob": -5.2226409912109375, "count": 1}, {"pred": "several", "cond_log_prob": -6.2411041259765625, "count": 1}, {"pred": "sheets", "cond_log_prob": -7.7291412353515625, "count": 1}, {"pred": "short", "cond_log_prob": -8.700027465820312, "count": 1}, {"pred": "statues", "cond_log_prob": -5.3959197998046875, "count": 1}, {"pred": "tall", "cond_log_prob": -8.975387573242188, "count": 1}, {"pred": "the", "cond_log_prob": -4.2537689208984375, "count": 1}, {"pred": "they", "cond_log_prob": -6.7238922119140625, "count": 1}, {"pred": "walls", "cond_log_prob": -6.5713653564453125, "count": 1}, {"pred": "wooden", "cond_log_prob": -5.2591094970703125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -4.1587066650390625}, {"pred": "also", "count": 2, "cond_log_prob": -4.5746307373046875}, {"pred": "carved", "count": 15, "cond_log_prob": -2.8262176513671875}, {"pred": "coins", "count": 1, "cond_log_prob": -5.6411895751953125}, {"pred": "cuneiform", "count": 1, "cond_log_prob": -6.4372100830078125}, {"pred": "in", "count": 3, "cond_log_prob": -3.6310272216796875}, {"pred": "is", "count": 4, "cond_log_prob": -3.0551605224609375}, {"pred": "many", "count": 1, "cond_log_prob": -4.8639678955078125}, {"pred": "manyroute", "count": 1, "cond_log_prob": -25.857864379882812}, {"pred": "numerous", "count": 1, "cond_log_prob": -6.2812347412109375}, {"pred": "other", "count": 4, "cond_log_prob": -3.6224212646484375}, {"pred": "script", "count": 1, "cond_log_prob": -6.4593048095703125}, {"pred": "the", "count": 1, "cond_log_prob": -4.2537689208984375}, {"pred": "was", "count": 1, "cond_log_prob": -4.3133392333984375}, {"pred": "written", "count": 1, "cond_log_prob": -4.0313568115234375}]}, "29": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other", "log_prob": -157.84002685546875}, "original": {"pred": "artifacts", "cond_log_prob": -2.946380615234375}, "human": [{"pred": "objects", "cond_log_prob": -1.740692138671875, "count": 5}, {"pred": "wooden", "cond_log_prob": -5.503753662109375, "count": 5}, {"pred": "things", "cond_log_prob": -6.879302978515625, "count": 4}, {"pred": "ancient", "cond_log_prob": -4.605010986328125, "count": 3}, {"pred": "items", "cond_log_prob": -4.0872802734375, "count": 3}, {"pred": "types", "cond_log_prob": -5.3658447265625, "count": 3}, {"pred": "artifacts", "cond_log_prob": -2.94659423828125, "count": 2}, {"pred": "natural", "cond_log_prob": -6.740692138671875, "count": 2}, {"pred": "places", "cond_log_prob": -6.648590087890625, "count": 2}, {"pred": "such", "cond_log_prob": -5.49395751953125, "count": 2}, {"pred": "surfaces", "cond_log_prob": -7.9365234375, "count": 2}, {"pred": "art", "cond_log_prob": -4.793060302734375, "count": 1}, {"pred": "different", "cond_log_prob": -8.475616455078125, "count": 1}, {"pred": "mediums", "cond_log_prob": -7.0501251220703125, "count": 1}, {"pred": "sources", "cond_log_prob": -5.617156982421875, "count": 1}, {"pred": "stone", "cond_log_prob": -4.95074462890625, "count": 1}, {"pred": "tablets", "cond_log_prob": -5.775238037109375, "count": 1}, {"pred": "writing", "cond_log_prob": -3.26287841796875, "count": 1}], "ancestral_samples": [{"pred": "artifacts", "count": 2, "cond_log_prob": -2.94659423828125}, {"pred": "artifactsIn", "count": 1, "cond_log_prob": -19.29205322265625}, {"pred": "artifactsThe", "count": 1, "cond_log_prob": -17.6314697265625}, {"pred": "objects", "count": 19, "cond_log_prob": -1.740692138671875}, {"pred": "objectsHistory", "count": 1, "cond_log_prob": -21.902923583984375}, {"pred": "objectsR", "count": 1, "cond_log_prob": -18.77276611328125}, {"pred": "objectsThe", "count": 2, "cond_log_prob": -16.269332885742188}, {"pred": "objectsThis", "count": 1, "cond_log_prob": -17.628082275390625}, {"pred": "objectsroute", "count": 1, "cond_log_prob": -25.03912353515625}, {"pred": "structures", "count": 1, "cond_log_prob": -3.716827392578125}, {"pred": "texts", "count": 1, "cond_log_prob": -4.361663818359375}, {"pred": "writing", "count": 3, "cond_log_prob": -3.26287841796875}, {"pred": "writings", "count": 5, "cond_log_prob": -3.025115966796875}, {"pred": "writingsThe", "count": 1, "cond_log_prob": -17.970672607421875}]}, "30": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts", "log_prob": -160.78640747070312}, "original": {"pred": "from", "cond_log_prob": -3.242095947265625}, "human": [{"pred": "found", "cond_log_prob": -4.449615478515625, "count": 8}, {"pred": "of", "cond_log_prob": -3.460174560546875, "count": 7}, {"pred": "from", "cond_log_prob": -3.242340087890625, "count": 3}, {"pred": "have", "cond_log_prob": -7.6948394775390625, "count": 3}, {"pred": "on", "cond_log_prob": -4.62835693359375, "count": 3}, {"pred": "that", "cond_log_prob": -3.2073822021484375, "count": 3}, {"pred": "around", "cond_log_prob": -5.0404510498046875, "count": 2}, {"pred": "which", "cond_log_prob": -4.4651031494140625, "count": 2}, {"pred": "----------------------------------------------------", "cond_log_prob": -19.93817138671875, "count": 1}, {"pred": "along", "cond_log_prob": -5.61883544921875, "count": 1}, {"pred": "back", "cond_log_prob": -10.261566162109375, "count": 1}, {"pred": "covered", "cond_log_prob": -10.1268310546875, "count": 1}, {"pred": "left", "cond_log_prob": -8.848236083984375, "count": 1}, {"pred": "native", "cond_log_prob": -11.070892333984375, "count": 1}, {"pred": "show", "cond_log_prob": -9.42230224609375, "count": 1}, {"pred": "such", "cond_log_prob": -5.1371917724609375, "count": 1}, {"pred": "the", "cond_log_prob": -7.83685302734375, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 2, "cond_log_prob": -12.395034790039062}, {"pred": "According", "count": 2, "cond_log_prob": -15.194137573242188}, {"pred": "Contents", "count": 2, "cond_log_prob": -20.769378662109375}, {"pred": "In", "count": 1, "cond_log_prob": -12.679168701171875}, {"pred": "It", "count": 3, "cond_log_prob": -12.792922973632812}, {"pred": "Known", "count": 1, "cond_log_prob": -15.235946655273438}, {"pred": "Rong", "count": 8, "cond_log_prob": -13.933624267578125}, {"pred": "The", "count": 10, "cond_log_prob": -10.960205078125}, {"pred": "There", "count": 1, "cond_log_prob": -14.01470947265625}, {"pred": "and", "count": 4, "cond_log_prob": -3.60723876953125}, {"pred": "but", "count": 1, "cond_log_prob": -6.472808837890625}, {"pred": "by", "count": 1, "cond_log_prob": -3.3822784423828125}, {"pred": "dating", "count": 1, "cond_log_prob": -2.3773651123046875}, {"pred": "depictingroute", "count": 1, "cond_log_prob": -25.113250732421875}, {"pred": "including", "count": 2, "cond_log_prob": -4.6989593505859375}]}, "31": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from", "log_prob": -164.02850341796875}, "original": {"pred": "the", "cond_log_prob": -0.9221343994140625}, "human": [{"pred": "the", "cond_log_prob": -0.92236328125, "count": 26}, {"pred": "that", "cond_log_prob": -5.7694244384765625, "count": 7}, {"pred": "ancient", "cond_log_prob": -3.397918701171875, "count": 2}, {"pred": "africa", "cond_log_prob": -13.153961181640625, "count": 1}, {"pred": "around", "cond_log_prob": -3.23809814453125, "count": 1}, {"pred": "different", "cond_log_prob": -4.477783203125, "count": 1}, {"pred": "life", "cond_log_prob": -9.181777954101562, "count": 1}, {"pred": "northern", "cond_log_prob": -6.067962646484375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.5431060791015625}, {"pred": "the", "count": 37, "cond_log_prob": -0.92236328125}, {"pred": "theroute", "count": 1, "cond_log_prob": -28.2447509765625}, {"pred": "various", "count": 1, "cond_log_prob": -3.205047607421875}]}, "32": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the", "log_prob": -164.9506378173828}, "original": {"pred": "island's", "cond_log_prob": -3.1194305419921875}, "human": [{"pred": "island", "cond_log_prob": -1.7729034423828125, "count": 12}, {"pred": "islands", "cond_log_prob": -4.35003662109375, "count": 4}, {"pred": "same", "cond_log_prob": -5.850555419921875, "count": 4}, {"pred": "ancient", "cond_log_prob": -3.2880096435546875, "count": 3}, {"pred": "different", "cond_log_prob": -7.5277557373046875, "count": 2}, {"pred": "time", "cond_log_prob": -2.83416748046875, "count": 2}, {"pred": "5th", "cond_log_prob": -6.198028564453125, "count": 1}, {"pred": "archeological", "cond_log_prob": -10.127426147460938, "count": 1}, {"pred": "area", "cond_log_prob": -4.756256103515625, "count": 1}, {"pred": "culture", "cond_log_prob": -7.6050872802734375, "count": 1}, {"pred": "era", "cond_log_prob": -4.9646759033203125, "count": 1}, {"pred": "homes", "cond_log_prob": -9.18316650390625, "count": 1}, {"pred": "inhabitants", "cond_log_prob": -7.5647430419921875, "count": 1}, {"pred": "jungle", "cond_log_prob": -7.441925048828125, "count": 1}, {"pred": "museum", "cond_log_prob": -9.65447998046875, "count": 1}, {"pred": "place", "cond_log_prob": -7.177581787109375, "count": 1}, {"pred": "rapa", "cond_log_prob": -12.736160278320312, "count": 1}, {"pred": "region", "cond_log_prob": -4.2522125244140625, "count": 1}, {"pred": "southern", "cond_log_prob": -6.565216064453125, "count": 1}], "ancestral_samples": [{"pred": "ancient", "count": 3, "cond_log_prob": -3.2880096435546875}, {"pred": "early", "count": 1, "cond_log_prob": -4.043975830078125}, {"pred": "island", "count": 9, "cond_log_prob": -1.7729034423828125}, {"pred": "islandContents", "count": 1, "cond_log_prob": -17.793441772460938}, {"pred": "islandHistory", "count": 1, "cond_log_prob": -18.35003662109375}, {"pred": "islandIn", "count": 1, "cond_log_prob": -17.243637084960938}, {"pred": "islandIt", "count": 1, "cond_log_prob": -17.256515502929688}, {"pred": "islandR", "count": 3, "cond_log_prob": -17.559036254882812}, {"pred": "islandThe", "count": 3, "cond_log_prob": -16.311126708984375}, {"pred": "islandroute", "count": 1, "cond_log_prob": -18.833709716796875}, {"pred": "islands", "count": 4, "cond_log_prob": -4.35003662109375}, {"pred": "islandsIt", "count": 1, "cond_log_prob": -18.242721557617188}, {"pred": "past", "count": 4, "cond_log_prob": -3.083526611328125}, {"pred": "pastThe", "count": 1, "cond_log_prob": -17.11944580078125}, {"pred": "time", "count": 6, "cond_log_prob": -2.83416748046875}]}, "33": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's", "log_prob": -168.070068359375}, "original": {"pred": "history.", "cond_log_prob": -3.20526123046875}, "human": [{"pred": "history", "cond_log_prob": -2.7091217041015625, "count": 5}, {"pred": "inhabitants", "cond_log_prob": -3.9853668212890625, "count": 4}, {"pred": "people", "cond_log_prob": -4.7140350341796875, "count": 4}, {"pred": "ancient", "cond_log_prob": -3.323944091796875, "count": 3}, {"pred": "caves", "cond_log_prob": -6.21539306640625, "count": 3}, {"pred": "land", "cond_log_prob": -6.9984588623046875, "count": 2}, {"pred": "ruins", "cond_log_prob": -5.2947540283203125, "count": 2}, {"pred": "artifacts", "cond_log_prob": -9.034011840820312, "count": 1}, {"pred": "center", "cond_log_prob": -8.51251220703125, "count": 1}, {"pred": "core", "cond_log_prob": -8.531341552734375, "count": 1}, {"pred": "culture", "cond_log_prob": -5.3478240966796875, "count": 1}, {"pred": "diverse", "cond_log_prob": -7.5706024169921875, "count": 1}, {"pred": "ecosystem", "cond_log_prob": -8.655731201171875, "count": 1}, {"pred": "mainland", "cond_log_prob": -6.5283355712890625, "count": 1}, {"pred": "museum", "cond_log_prob": -9.37481689453125, "count": 1}, {"pred": "natives", "cond_log_prob": -8.214767456054688, "count": 1}, {"pred": "natural", "cond_log_prob": -6.28155517578125, "count": 1}, {"pred": "nature", "cond_log_prob": -9.168045043945312, "count": 1}, {"pred": "previous", "cond_log_prob": -6.730804443359375, "count": 1}, {"pred": "regions", "cond_log_prob": -7.063446044921875, "count": 1}, {"pred": "shores", "cond_log_prob": -6.607025146484375, "count": 1}, {"pred": "sites", "cond_log_prob": -6.61773681640625, "count": 1}, {"pred": "soil", "cond_log_prob": -8.852569580078125, "count": 1}, {"pred": "surroundings", "cond_log_prob": -8.389541625976562, "count": 1}], "ancestral_samples": [{"pred": "ancient", "count": 1, "cond_log_prob": -3.323944091796875}, {"pred": "early", "count": 2, "cond_log_prob": -3.4269561767578125}, {"pred": "historyThe", "count": 1, "cond_log_prob": -16.91888427734375}, {"pred": "historyroute", "count": 1, "cond_log_prob": -23.264511108398438}, {"pred": "inhabitants", "count": 1, "cond_log_prob": -3.9853668212890625}, {"pred": "past", "count": 15, "cond_log_prob": -1.2398834228515625}, {"pred": "pastContents", "count": 1, "cond_log_prob": -16.032562255859375}, {"pred": "pastHistory", "count": 2, "cond_log_prob": -16.734466552734375}, {"pred": "pastIn", "count": 2, "cond_log_prob": -16.238540649414062}, {"pred": "pastIt", "count": 2, "cond_log_prob": -15.97625732421875}, {"pred": "pastR", "count": 4, "cond_log_prob": -16.479660034179688}, {"pred": "pastThe", "count": 7, "cond_log_prob": -14.789260864257812}, {"pred": "pastThis", "count": 1, "cond_log_prob": -16.747848510742188}]}, "34": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history.", "log_prob": -171.27532958984375}, "original": {"pred": "The", "cond_log_prob": -2.1300506591796875}, "human": [{"pred": "it", "cond_log_prob": -10.210067749023438, "count": 14}, {"pred": "the", "cond_log_prob": -8.716400146484375, "count": 7}, {"pred": "this", "cond_log_prob": -12.1356201171875, "count": 5}, {"pred": "i", "cond_log_prob": -11.67498779296875, "count": 2}, {"pred": "rongorongo", "cond_log_prob": -9.796966552734375, "count": 2}, {"pred": "?", "cond_log_prob": -11.586395263671875, "count": 1}, {"pred": "many", "cond_log_prob": -12.085311889648438, "count": 1}, {"pred": "next", "cond_log_prob": -15.1798095703125, "count": 1}, {"pred": "nui", "cond_log_prob": -14.77313232421875, "count": 1}, {"pred": "one", "cond_log_prob": -12.071945190429688, "count": 1}, {"pred": "people", "cond_log_prob": -12.905364990234375, "count": 1}, {"pred": "rapa", "cond_log_prob": -12.188583374023438, "count": 1}, {"pred": "there", "cond_log_prob": -12.468917846679688, "count": 1}, {"pred": "these", "cond_log_prob": -12.396820068359375, "count": 1}, {"pred": "they", "cond_log_prob": -12.99713134765625, "count": 1}], "ancestral_samples": [{"pred": "Contents", "count": 2, "cond_log_prob": -10.013458251953125}, {"pred": "History", "count": 1, "cond_log_prob": -8.968612670898438}, {"pred": "In", "count": 1, "cond_log_prob": -3.41705322265625}, {"pred": "It", "count": 1, "cond_log_prob": -2.6872100830078125}, {"pred": "Known", "count": 1, "cond_log_prob": -4.72174072265625}, {"pred": "Rongor", "count": 8, "cond_log_prob": -3.212371826171875}, {"pred": "The", "count": 25, "cond_log_prob": -2.1303253173828125}, {"pred": "route", "count": 1, "cond_log_prob": -18.282882690429688}]}, "35": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The", "log_prob": -173.40538024902344}, "original": {"pred": "art", "cond_log_prob": -5.3751220703125}, "human": [{"pred": "writing", "cond_log_prob": -3.46966552734375, "count": 5}, {"pred": "island", "cond_log_prob": -3.90936279296875, "count": 4}, {"pred": "people", "cond_log_prob": -6.0162506103515625, "count": 4}, {"pred": "system", "cond_log_prob": -4.1318359375, "count": 4}, {"pred": "artifacts", "cond_log_prob": -8.139266967773438, "count": 2}, {"pred": "language", "cond_log_prob": -4.386688232421875, "count": 2}, {"pred": "most", "cond_log_prob": -3.976776123046875, "count": 2}, {"pred": "pictographs", "cond_log_prob": -5.116058349609375, "count": 2}, {"pred": "purpose", "cond_log_prob": -7.6580963134765625, "count": 2}, {"pred": "best", "cond_log_prob": -6.8036346435546875, "count": 1}, {"pred": "characters", "cond_log_prob": -5.8851776123046875, "count": 1}, {"pred": "existence", "cond_log_prob": -6.3952178955078125, "count": 1}, {"pred": "fact", "cond_log_prob": -6.9351043701171875, "count": 1}, {"pred": "first", "cond_log_prob": -4.2242889404296875, "count": 1}, {"pred": "history", "cond_log_prob": -6.922149658203125, "count": 1}, {"pred": "inhabitants", "cond_log_prob": -5.8413848876953125, "count": 1}, {"pred": "islanders", "cond_log_prob": -8.136032104492188, "count": 1}, {"pred": "many", "cond_log_prob": -6.54913330078125, "count": 1}, {"pred": "person", "cond_log_prob": -7.7214202880859375, "count": 1}, {"pred": "result", "cond_log_prob": -8.232177734375, "count": 1}, {"pred": "rongorongo", "cond_log_prob": -6.0806732177734375, "count": 1}, {"pred": "writings", "cond_log_prob": -5.0814666748046875, "count": 1}], "ancestral_samples": [{"pred": "artisans", "count": 1, "cond_log_prob": -8.371200561523438}, {"pred": "artworks", "count": 1, "cond_log_prob": -7.9428253173828125}, {"pred": "earliest", "count": 8, "cond_log_prob": -3.6361083984375}, {"pred": "first", "count": 3, "cond_log_prob": -4.2242889404296875}, {"pred": "islands", "count": 2, "cond_log_prob": -6.5008544921875}, {"pred": "language", "count": 2, "cond_log_prob": -4.386688232421875}, {"pred": "most", "count": 4, "cond_log_prob": -3.976776123046875}, {"pred": "mostroute", "count": 1, "cond_log_prob": -29.607467651367188}, {"pred": "name", "count": 1, "cond_log_prob": -4.7533416748046875}, {"pred": "oldest", "count": 1, "cond_log_prob": -4.61962890625}, {"pred": "original", "count": 2, "cond_log_prob": -4.49774169921875}, {"pred": "script", "count": 1, "cond_log_prob": -5.7604827880859375}, {"pred": "shape", "count": 1, "cond_log_prob": -5.6869659423828125}, {"pred": "site", "count": 1, "cond_log_prob": -4.442596435546875}, {"pred": "term", "count": 1, "cond_log_prob": -5.6382598876953125}, {"pred": "texts", "count": 1, "cond_log_prob": -5.957855224609375}, {"pred": "works", "count": 1, "cond_log_prob": -6.9592437744140625}, {"pred": "writing", "count": 7, "cond_log_prob": -3.46966552734375}, {"pred": "writings", "count": 1, "cond_log_prob": -5.0814666748046875}]}, "36": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art", "log_prob": -178.78050231933594}, "original": {"pred": "of", "cond_log_prob": -1.3383331298828125}, "human": [{"pred": "of", "cond_log_prob": -1.3386383056640625, "count": 19}, {"pred": "has", "cond_log_prob": -3.9822540283203125, "count": 5}, {"pred": "is", "cond_log_prob": -2.5254364013671875, "count": 5}, {"pred": "form", "cond_log_prob": -3.11724853515625, "count": 2}, {"pred": "found", "cond_log_prob": -5.8770599365234375, "count": 2}, {"pred": "that", "cond_log_prob": -5.2819671630859375, "count": 2}, {"pred": "depicted", "cond_log_prob": -6.0594329833984375, "count": 1}, {"pred": "engraved", "cond_log_prob": -11.695846557617188, "count": 1}, {"pred": "from", "cond_log_prob": -6.4658966064453125, "count": 1}, {"pred": "pieces", "cond_log_prob": -7.1619110107421875, "count": 1}, {"pred": "shown", "cond_log_prob": -7.2717437744140625, "count": 1}], "ancestral_samples": [{"pred": "depictingroute", "count": 1, "cond_log_prob": -25.037216186523438}, {"pred": "depicts", "count": 1, "cond_log_prob": -4.2147674560546875}, {"pred": "form", "count": 1, "cond_log_prob": -3.11724853515625}, {"pred": "is", "count": 1, "cond_log_prob": -2.5254364013671875}, {"pred": "of", "count": 29, "cond_log_prob": -1.3386383056640625}, {"pred": "was", "count": 3, "cond_log_prob": -3.0523223876953125}, {"pred": "works", "count": 4, "cond_log_prob": -5.1086578369140625}]}, "37": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of", "log_prob": -180.11883544921875}, "original": {"pred": "writing", "cond_log_prob": -1.1252288818359375}, "human": [{"pred": "the", "cond_log_prob": -3.07635498046875, "count": 15}, {"pred": "rongorongo", "cond_log_prob": -5.472381591796875, "count": 8}, {"pred": "writing", "cond_log_prob": -1.125518798828125, "count": 5}, {"pred": "carving", "cond_log_prob": -4.868255615234375, "count": 3}, {"pred": "rapa", "cond_log_prob": -4.66339111328125, "count": 3}, {"pred": "drawing", "cond_log_prob": -4.9915771484375, "count": 1}, {"pred": "leaving", "cond_log_prob": -10.39501953125, "count": 1}, {"pred": "rongrorongo", "cond_log_prob": -16.24884033203125, "count": 1}, {"pred": "their", "cond_log_prob": -8.3524169921875, "count": 1}, {"pred": "wood", "cond_log_prob": -10.45281982421875, "count": 1}, {"pred": "writting", "cond_log_prob": -17.96478271484375, "count": 1}], "ancestral_samples": [{"pred": "Rapa", "count": 12, "cond_log_prob": -1.047393798828125}, {"pred": "Rongorongo", "count": 1, "cond_log_prob": -2.746124267578125}, {"pred": "the", "count": 1, "cond_log_prob": -3.07635498046875}, {"pred": "writing", "count": 25, "cond_log_prob": -1.125518798828125}, {"pred": "writingroute", "count": 1, "cond_log_prob": -20.751617431640625}]}, "38": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing", "log_prob": -181.2440643310547}, "original": {"pred": "was", "cond_log_prob": -2.364990234375}, "human": [{"pred": "has", "cond_log_prob": -2.1113128662109375, "count": 15}, {"pred": "is", "cond_log_prob": -1.2835845947265625, "count": 9}, {"pred": "in", "cond_log_prob": -2.9304351806640625, "count": 3}, {"pred": "pictographs", "cond_log_prob": -10.256607055664062, "count": 3}, {"pred": "rongorongo", "cond_log_prob": -10.635055541992188, "count": 3}, {"pred": "this", "cond_log_prob": -8.101730346679688, "count": 2}, {"pred": "keeps", "cond_log_prob": -9.274826049804688, "count": 1}, {"pred": "on", "cond_log_prob": -3.0140533447265625, "count": 1}, {"pred": "the", "cond_log_prob": -5.6448822021484375, "count": 1}, {"pred": "using", "cond_log_prob": -6.5977935791015625, "count": 1}, {"pred": "was", "cond_log_prob": -2.3653106689453125, "count": 1}], "ancestral_samples": [{"pred": "has", "count": 2, "cond_log_prob": -2.1113128662109375}, {"pred": "in", "count": 1, "cond_log_prob": -2.9304351806640625}, {"pred": "is", "count": 30, "cond_log_prob": -1.2835845947265625}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.787094116210938}, {"pred": "was", "count": 6, "cond_log_prob": -2.3653106689453125}]}, "39": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was", "log_prob": -183.6090545654297}, "original": {"pred": "not", "cond_log_prob": -3.676025390625}, "human": [{"pred": "first", "cond_log_prob": -1.9132537841796875, "count": 4}, {"pred": "created", "cond_log_prob": -5.0072174072265625, "count": 3}, {"pred": "lost", "cond_log_prob": -5.2292938232421875, "count": 3}, {"pred": "not", "cond_log_prob": -3.6763458251953125, "count": 3}, {"pred": "discovered", "cond_log_prob": -3.6243438720703125, "count": 2}, {"pred": "passed", "cond_log_prob": -6.3203582763671875, "count": 2}, {"pred": "used", "cond_log_prob": -3.8318023681640625, "count": 2}, {"pred": "a", "cond_log_prob": -3.7800445556640625, "count": 1}, {"pred": "considered", "cond_log_prob": -5.2064666748046875, "count": 1}, {"pred": "developed", "cond_log_prob": -3.2447357177734375, "count": 1}, {"pred": "found", "cond_log_prob": -4.0346527099609375, "count": 1}, {"pred": "founded", "cond_log_prob": -5.8936614990234375, "count": 1}, {"pred": "highly", "cond_log_prob": -5.6696319580078125, "count": 1}, {"pred": "important", "cond_log_prob": -6.2050323486328125, "count": 1}, {"pred": "invented", "cond_log_prob": -4.7006072998046875, "count": 1}, {"pred": "known", "cond_log_prob": -4.8350372314453125, "count": 1}, {"pred": "never", "cond_log_prob": -6.6887359619140625, "count": 1}, {"pred": "originally", "cond_log_prob": -3.9049530029296875, "count": 1}, {"pred": "prized", "cond_log_prob": -6.4884185791015625, "count": 1}, {"pred": "restricted", "cond_log_prob": -7.5383453369140625, "count": 1}, {"pred": "saved", "cond_log_prob": -10.843368530273438, "count": 1}, {"pred": "seen", "cond_log_prob": -5.9358367919921875, "count": 1}, {"pred": "something", "cond_log_prob": -7.4820098876953125, "count": 1}, {"pred": "the", "cond_log_prob": -4.4376983642578125, "count": 1}, {"pred": "thought", "cond_log_prob": -4.7227630615234375, "count": 1}, {"pred": "treasured", "cond_log_prob": -10.216781616210938, "count": 1}, {"pred": "valued", "cond_log_prob": -6.5043182373046875, "count": 1}, {"pred": "very", "cond_log_prob": -5.5901031494140625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.7800445556640625}, {"pred": "adopted", "count": 1, "cond_log_prob": -6.2152252197265625}, {"pred": "also", "count": 2, "cond_log_prob": -3.6070709228515625}, {"pred": "developed", "count": 3, "cond_log_prob": -3.2447357177734375}, {"pred": "discovered", "count": 2, "cond_log_prob": -3.6243438720703125}, {"pred": "first", "count": 25, "cond_log_prob": -1.9132537841796875}, {"pred": "firstroute", "count": 1, "cond_log_prob": -27.350234985351562}, {"pred": "most", "count": 1, "cond_log_prob": -5.2069854736328125}, {"pred": "not", "count": 1, "cond_log_prob": -3.6763458251953125}, {"pred": "used", "count": 2, "cond_log_prob": -3.8318023681640625}]}, "40": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not", "log_prob": -187.2850799560547}, "original": {"pred": "known", "cond_log_prob": -4.27923583984375}, "human": [{"pred": "a", "cond_log_prob": -3.9613494873046875, "count": 4}, {"pred": "discovered", "cond_log_prob": -3.8402862548828125, "count": 4}, {"pred": "common", "cond_log_prob": -4.5137176513671875, "count": 3}, {"pred": "created", "cond_log_prob": -4.7115936279296875, "count": 3}, {"pred": "known", "cond_log_prob": -4.2795562744140625, "count": 3}, {"pred": "used", "cond_log_prob": -5.5332183837890625, "count": 3}, {"pred": "developed", "cond_log_prob": -4.1700897216796875, "count": 2}, {"pred": "taught", "cond_log_prob": -6.5770721435546875, "count": 2}, {"pred": "the", "cond_log_prob": -4.0491180419921875, "count": 2}, {"pred": "very", "cond_log_prob": -5.2338714599609375, "count": 2}, {"pred": "yet", "cond_log_prob": -4.4574127197265625, "count": 2}, {"pred": "always", "cond_log_prob": -3.2156524658203125, "count": 1}, {"pred": "easy", "cond_log_prob": -4.6595306396484375, "count": 1}, {"pred": "established", "cond_log_prob": -5.6666717529296875, "count": 1}, {"pred": "formed", "cond_log_prob": -8.135421752929688, "count": 1}, {"pred": "introduced", "cond_log_prob": -5.8096771240234375, "count": 1}, {"pred": "invented", "cond_log_prob": -3.4277191162109375, "count": 1}, {"pred": "learned", "cond_log_prob": -6.8972930908203125, "count": 1}, {"pred": "lost", "cond_log_prob": -3.4973297119140625, "count": 1}, {"pred": "passed", "cond_log_prob": -7.9126739501953125, "count": 1}, {"pred": "produced", "cond_log_prob": -6.9624176025390625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 4, "cond_log_prob": -3.9613494873046875}, {"pred": "always", "count": 2, "cond_log_prob": -3.2156524658203125}, {"pred": "alwaysroute", "count": 1, "cond_log_prob": -27.313613891601562}, {"pred": "as", "count": 1, "cond_log_prob": -4.1363372802734375}, {"pred": "confined", "count": 1, "cond_log_prob": -3.9584197998046875}, {"pred": "developed", "count": 1, "cond_log_prob": -4.1700897216796875}, {"pred": "discovered", "count": 3, "cond_log_prob": -3.8402862548828125}, {"pred": "invented", "count": 2, "cond_log_prob": -3.4277191162109375}, {"pred": "known", "count": 1, "cond_log_prob": -4.2795562744140625}, {"pred": "limited", "count": 5, "cond_log_prob": -2.9815216064453125}, {"pred": "lost", "count": 3, "cond_log_prob": -3.4973297119140625}, {"pred": "new", "count": 1, "cond_log_prob": -4.3637847900390625}, {"pred": "only", "count": 12, "cond_log_prob": -2.9304351806640625}, {"pred": "the", "count": 2, "cond_log_prob": -4.0491180419921875}, {"pred": "yet", "count": 1, "cond_log_prob": -4.4574127197265625}]}, "41": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known", "log_prob": -191.56431579589844}, "original": {"pred": "in", "cond_log_prob": -2.1570281982421875}, "human": [{"pred": "to", "cond_log_prob": -1.8471221923828125, "count": 19}, {"pred": "until", "cond_log_prob": -0.9897003173828125, "count": 7}, {"pred": "by", "cond_log_prob": -4.3998565673828125, "count": 4}, {"pred": "for", "cond_log_prob": -2.3494415283203125, "count": 3}, {"pred": "as", "cond_log_prob": -3.7229461669921875, "count": 1}, {"pred": "at", "cond_log_prob": -3.9689788818359375, "count": 1}, {"pred": "from", "cond_log_prob": -4.4630889892578125, "count": 1}, {"pred": "in", "cond_log_prob": -2.1573638916015625, "count": 1}, {"pred": "previous", "cond_log_prob": -10.567276000976562, "count": 1}, {"pred": "untill", "cond_log_prob": -14.112533569335938, "count": 1}, {"pred": "well", "cond_log_prob": -6.3582916259765625, "count": 1}], "ancestral_samples": [{"pred": "for", "count": 1, "cond_log_prob": -2.3494415283203125}, {"pred": "in", "count": 3, "cond_log_prob": -2.1573638916015625}, {"pred": "to", "count": 7, "cond_log_prob": -1.8471221923828125}, {"pred": "until", "count": 28, "cond_log_prob": -0.9897003173828125}, {"pred": "untilroute", "count": 1, "cond_log_prob": -20.434188842773438}]}, "42": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in", "log_prob": -193.72134399414062}, "original": {"pred": "any", "cond_log_prob": -4.6568145751953125}, "human": [{"pred": "the", "cond_log_prob": -0.89788818359375, "count": 19}, {"pred": "many", "cond_log_prob": -5.012359619140625, "count": 6}, {"pred": "those", "cond_log_prob": -6.3968505859375, "count": 3}, {"pred": "ancient", "cond_log_prob": -3.8438720703125, "count": 2}, {"pred": "these", "cond_log_prob": -6.1566162109375, "count": 2}, {"pred": "this", "cond_log_prob": -3.85394287109375, "count": 2}, {"pred": "china", "cond_log_prob": -13.37628173828125, "count": 1}, {"pred": "earlier", "cond_log_prob": -5.957763671875, "count": 1}, {"pred": "length", "cond_log_prob": -10.149810791015625, "count": 1}, {"pred": "modern", "cond_log_prob": -5.7774658203125, "count": 1}, {"pred": "peru", "cond_log_prob": -18.579345703125, "count": 1}, {"pred": "that", "cond_log_prob": -6.082061767578125, "count": 1}], "ancestral_samples": [{"pred": "the", "count": 39, "cond_log_prob": -0.89788818359375}, {"pred": "theroute", "count": 1, "cond_log_prob": -28.25140380859375}]}, "43": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any", "log_prob": -198.37815856933594}, "original": {"pred": "nearby", "cond_log_prob": -8.636367797851562}, "human": [{"pred": "other", "cond_log_prob": -1.0959625244140625, "count": 14}, {"pred": "of", "cond_log_prob": -2.0457611083984375, "count": 8}, {"pred": "ancient", "cond_log_prob": -4.2715606689453125, "count": 2}, {"pred": "culture", "cond_log_prob": -4.9834442138671875, "count": 2}, {"pred": "cultures", "cond_log_prob": -6.4942169189453125, "count": 2}, {"pred": "area", "cond_log_prob": -6.2008514404296875, "count": 1}, {"pred": "country", "cond_log_prob": -4.8545379638671875, "count": 1}, {"pred": "earlier", "cond_log_prob": -6.3282623291015625, "count": 1}, {"pred": "form", "cond_log_prob": -2.5568084716796875, "count": 1}, {"pred": "island", "cond_log_prob": -4.2977142333984375, "count": 1}, {"pred": "language", "cond_log_prob": -4.0305328369140625, "count": 1}, {"pred": "part", "cond_log_prob": -3.8383026123046875, "count": 1}, {"pred": "parts", "cond_log_prob": -7.3281707763671875, "count": 1}, {"pred": "place", "cond_log_prob": -5.3804168701171875, "count": 1}, {"pred": "time", "cond_log_prob": -6.7740631103515625, "count": 1}, {"pred": "way", "cond_log_prob": -2.9265899658203125, "count": 1}, {"pred": "western", "cond_log_prob": -7.0352630615234375, "count": 1}], "ancestral_samples": [{"pred": "form", "count": 2, "cond_log_prob": -2.5568084716796875}, {"pred": "of", "count": 5, "cond_log_prob": -2.0457611083984375}, {"pred": "other", "count": 30, "cond_log_prob": -1.0959625244140625}, {"pred": "otherroute", "count": 1, "cond_log_prob": -19.324447631835938}, {"pred": "part", "count": 2, "cond_log_prob": -3.8383026123046875}]}, "44": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby", "log_prob": -207.0145263671875}, "original": {"pred": "islands", "cond_log_prob": -2.460906982421875}, "human": [{"pred": "islands", "cond_log_prob": -2.461273193359375, "count": 15}, {"pred": "island", "cond_log_prob": -2.4346923828125, "count": 5}, {"pred": "villages", "cond_log_prob": -4.58636474609375, "count": 5}, {"pred": "areas", "cond_log_prob": -4.577178955078125, "count": 3}, {"pred": "communities", "cond_log_prob": -5.6175537109375, "count": 2}, {"pred": "area", "cond_log_prob": -3.970733642578125, "count": 1}, {"pred": "city", "cond_log_prob": -3.95684814453125, "count": 1}, {"pred": "civilizations", "cond_log_prob": -4.813323974609375, "count": 1}, {"pred": "company", "cond_log_prob": -10.07373046875, "count": 1}, {"pred": "culture", "cond_log_prob": -4.0631103515625, "count": 1}, {"pred": "cultures", "cond_log_prob": -4.36492919921875, "count": 1}, {"pred": "place", "cond_log_prob": -5.06549072265625, "count": 1}, {"pred": "places", "cond_log_prob": -5.7854766845703125, "count": 1}, {"pred": "town", "cond_log_prob": -5.20025634765625, "count": 1}, {"pred": "village", "cond_log_prob": -5.258697509765625, "count": 1}], "ancestral_samples": [{"pred": "community", "count": 1, "cond_log_prob": -5.295379638671875}, {"pred": "country", "count": 9, "cond_log_prob": -2.605621337890625}, {"pred": "countryR", "count": 1, "cond_log_prob": -18.77752685546875}, {"pred": "culture", "count": 1, "cond_log_prob": -4.0631103515625}, {"pred": "inhabited", "count": 1, "cond_log_prob": -3.950103759765625}, {"pred": "island", "count": 5, "cond_log_prob": -2.4346923828125}, {"pred": "islands", "count": 15, "cond_log_prob": -2.461273193359375}, {"pred": "islandsR", "count": 1, "cond_log_prob": -19.96978759765625}, {"pred": "islandsThe", "count": 1, "cond_log_prob": -17.968658447265625}, {"pred": "language", "count": 1, "cond_log_prob": -3.814422607421875}, {"pred": "nationroute", "count": 1, "cond_log_prob": -22.991790771484375}, {"pred": "other", "count": 1, "cond_log_prob": -5.217926025390625}, {"pred": "settlements", "count": 1, "cond_log_prob": -5.3492431640625}, {"pred": "tribes", "count": 1, "cond_log_prob": -4.823638916015625}]}, "45": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands", "log_prob": -209.47543334960938}, "original": {"pred": "and", "cond_log_prob": -3.0092620849609375}, "human": [{"pred": "or", "cond_log_prob": -4.30328369140625, "count": 9}, {"pred": "so", "cond_log_prob": -6.42242431640625, "count": 4}, {"pred": "for", "cond_log_prob": -4.255157470703125, "count": 3}, {"pred": "that", "cond_log_prob": -6.338836669921875, "count": 3}, {"pred": "until", "cond_log_prob": -1.09246826171875, "count": 3}, {"pred": "and", "cond_log_prob": -3.0096435546875, "count": 2}, {"pred": "because", "cond_log_prob": -6.058624267578125, "count": 2}, {"pred": "around", "cond_log_prob": -7.085693359375, "count": 1}, {"pred": "at", "cond_log_prob": -4.77484130859375, "count": 1}, {"pred": "before", "cond_log_prob": -2.171966552734375, "count": 1}, {"pred": "but", "cond_log_prob": -4.1103515625, "count": 1}, {"pred": "close", "cond_log_prob": -10.534759521484375, "count": 1}, {"pred": "communities", "cond_log_prob": -13.202789306640625, "count": 1}, {"pred": "during", "cond_log_prob": -4.477264404296875, "count": 1}, {"pred": "except", "cond_log_prob": -4.7828369140625, "count": 1}, {"pred": "found", "cond_log_prob": -10.710357666015625, "count": 1}, {"pred": "history", "cond_log_prob": -11.06219482421875, "count": 1}, {"pred": "of", "cond_log_prob": -4.308258056640625, "count": 1}, {"pred": "surrounding", "cond_log_prob": -9.334136962890625, "count": 1}, {"pred": "therefore", "cond_log_prob": -12.494537353515625, "count": 1}, {"pred": "untill", "cond_log_prob": -15.3857421875, "count": 1}], "ancestral_samples": [{"pred": "According", "count": 1, "cond_log_prob": -17.02191162109375}, {"pred": "The", "count": 1, "cond_log_prob": -11.331634521484375}, {"pred": "and", "count": 1, "cond_log_prob": -3.0096435546875}, {"pred": "before", "count": 3, "cond_log_prob": -2.171966552734375}, {"pred": "but", "count": 4, "cond_log_prob": -4.1103515625}, {"pred": "however", "count": 1, "cond_log_prob": -8.52154541015625}, {"pred": "until", "count": 28, "cond_log_prob": -1.09246826171875}, {"pred": "untilroute", "count": 1, "cond_log_prob": -19.8656005859375}]}, "46": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and", "log_prob": -212.4846954345703}, "original": {"pred": "the", "cond_log_prob": -2.322845458984375}, "human": [{"pred": "was", "cond_log_prob": -2.2747650146484375, "count": 9}, {"pred": "the", "cond_log_prob": -2.3232269287109375, "count": 5}, {"pred": "is", "cond_log_prob": -3.0077667236328125, "count": 4}, {"pred": "it", "cond_log_prob": -2.6674957275390625, "count": 4}, {"pred": "did", "cond_log_prob": -6.0573883056640625, "count": 3}, {"pred": "they", "cond_log_prob": -4.7055511474609375, "count": 3}, {"pred": "in", "cond_log_prob": -4.3558502197265625, "count": 2}, {"pred": "as", "cond_log_prob": -5.1789093017578125, "count": 1}, {"pred": "communities", "cond_log_prob": -8.749801635742188, "count": 1}, {"pred": "forests", "cond_log_prob": -10.948898315429688, "count": 1}, {"pred": "found", "cond_log_prob": -7.3095550537109375, "count": 1}, {"pred": "inhabitants", "cond_log_prob": -8.790115356445312, "count": 1}, {"pred": "nearby", "cond_log_prob": -10.600509643554688, "count": 1}, {"pred": "not", "cond_log_prob": -6.2281951904296875, "count": 1}, {"pred": "still", "cond_log_prob": -6.3818206787109375, "count": 1}, {"pred": "that", "cond_log_prob": -5.8555450439453125, "count": 1}, {"pred": "villages", "cond_log_prob": -9.882522583007812, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.9339752197265625}, {"pred": "is", "count": 3, "cond_log_prob": -3.0077667236328125}, {"pred": "it", "count": 4, "cond_log_prob": -2.6674957275390625}, {"pred": "its", "count": 1, "cond_log_prob": -3.9226226806640625}, {"pred": "many", "count": 1, "cond_log_prob": -4.1114044189453125}, {"pred": "manyroute", "count": 1, "cond_log_prob": -23.173629760742188}, {"pred": "most", "count": 1, "cond_log_prob": -4.3578033447265625}, {"pred": "the", "count": 9, "cond_log_prob": -2.3232269287109375}, {"pred": "was", "count": 19, "cond_log_prob": -2.2747650146484375}]}, "47": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and the", "log_prob": -214.8075408935547}, "original": {"pred": "script's", "cond_log_prob": -11.607467651367188}, "human": [{"pred": "people", "cond_log_prob": -4.3008575439453125, "count": 9}, {"pred": "inhabitants", "cond_log_prob": -4.4423675537109375, "count": 5}, {"pred": "writing", "cond_log_prob": -2.3138275146484375, "count": 3}, {"pred": "carvings", "cond_log_prob": -10.373336791992188, "count": 2}, {"pred": "art", "cond_log_prob": -3.9759674072265625, "count": 1}, {"pred": "artifacts", "cond_log_prob": -7.5394744873046875, "count": 1}, {"pred": "best", "cond_log_prob": -6.3326568603515625, "count": 1}, {"pred": "dialect", "cond_log_prob": -7.0995330810546875, "count": 1}, {"pred": "diverse", "cond_log_prob": -9.995468139648438, "count": 1}, {"pred": "fact", "cond_log_prob": -5.9810943603515625, "count": 1}, {"pred": "first", "cond_log_prob": -5.3507537841796875, "count": 1}, {"pred": "island", "cond_log_prob": -3.3496551513671875, "count": 1}, {"pred": "islanders", "cond_log_prob": -6.2798614501953125, "count": 1}, {"pred": "language", "cond_log_prob": -3.2199249267578125, "count": 1}, {"pred": "main", "cond_log_prob": -5.9952850341796875, "count": 1}, {"pred": "many", "cond_log_prob": -6.8039093017578125, "count": 1}, {"pred": "most", "cond_log_prob": -4.8684234619140625, "count": 1}, {"pred": "old", "cond_log_prob": -7.8492584228515625, "count": 1}, {"pred": "other", "cond_log_prob": -7.4351043701171875, "count": 1}, {"pred": "prince", "cond_log_prob": -11.192245483398438, "count": 1}, {"pred": "rapa", "cond_log_prob": -9.554672241210938, "count": 1}, {"pred": "surrounding", "cond_log_prob": -7.1564788818359375, "count": 1}, {"pred": "system", "cond_log_prob": -5.4011688232421875, "count": 1}, {"pred": "use", "cond_log_prob": -5.0338592529296875, "count": 1}, {"pred": "writings", "cond_log_prob": -4.4917449951171875, "count": 1}], "ancestral_samples": [{"pred": "art", "count": 4, "cond_log_prob": -3.9759674072265625}, {"pred": "earliest", "count": 1, "cond_log_prob": -4.1442108154296875}, {"pred": "islands", "count": 1, "cond_log_prob": -5.6697845458984375}, {"pred": "language", "count": 4, "cond_log_prob": -3.2199249267578125}, {"pred": "most", "count": 1, "cond_log_prob": -4.8684234619140625}, {"pred": "only", "count": 1, "cond_log_prob": -4.2187042236328125}, {"pred": "original", "count": 1, "cond_log_prob": -5.1831512451171875}, {"pred": "writing", "count": 26, "cond_log_prob": -2.3138275146484375}, {"pred": "writingroute", "count": 1, "cond_log_prob": -22.081588745117188}]}, "48": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and the script's", "log_prob": -226.41500854492188}, "original": {"pred": "mere", "cond_log_prob": -8.84686279296875}, "human": [{"pred": "of", "cond_log_prob": -8.076751708984375, "count": 4}, {"pred": "pictographs", "cond_log_prob": -7.674285888671875, "count": 4}, {"pred": "were", "cond_log_prob": -6.868865966796875, "count": 4}, {"pred": "did", "cond_log_prob": -10.1510009765625, "count": 3}, {"pred": "form", "cond_log_prob": -5.70269775390625, "count": 2}, {"pred": "found", "cond_log_prob": -7.476165771484375, "count": 2}, {"pred": "meaning", "cond_log_prob": -3.92803955078125, "count": 2}, {"pred": "are", "cond_log_prob": -6.895416259765625, "count": 1}, {"pred": "characters", "cond_log_prob": -6.549072265625, "count": 1}, {"pred": "design", "cond_log_prob": -5.5400390625, "count": 1}, {"pred": "dialect", "cond_log_prob": -8.24285888671875, "count": 1}, {"pred": "difficult", "cond_log_prob": -8.920867919921875, "count": 1}, {"pred": "doctrine", "cond_log_prob": -12.147308349609375, "count": 1}, {"pred": "have", "cond_log_prob": -7.6180419921875, "count": 1}, {"pred": "history", "cond_log_prob": -4.372589111328125, "count": 1}, {"pred": "individual", "cond_log_prob": -8.00762939453125, "count": 1}, {"pred": "kept", "cond_log_prob": -10.7166748046875, "count": 1}, {"pred": "lexicon", "cond_log_prob": -9.103057861328125, "count": 1}, {"pred": "origin", "cond_log_prob": -3.6405029296875, "count": 1}, {"pred": "origins", "cond_log_prob": -3.475830078125, "count": 1}, {"pred": "style", "cond_log_prob": -5.271392822265625, "count": 1}, {"pred": "symbols", "cond_log_prob": -6.8765869140625, "count": 1}, {"pred": "text", "cond_log_prob": -5.878570556640625, "count": 1}, {"pred": "unusual", "cond_log_prob": -7.20037841796875, "count": 1}, {"pred": "writer", "cond_log_prob": -8.154510498046875, "count": 1}, {"pred": "writings", "cond_log_prob": -6.423797607421875, "count": 1}], "ancestral_samples": [{"pred": "ability", "count": 3, "cond_log_prob": -4.739013671875}, {"pred": "earliest", "count": 1, "cond_log_prob": -4.08819580078125}, {"pred": "existence", "count": 4, "cond_log_prob": -3.8587646484375}, {"pred": "function", "count": 1, "cond_log_prob": -5.413848876953125}, {"pred": "importance", "count": 2, "cond_log_prob": -4.4599609375}, {"pred": "influence", "count": 1, "cond_log_prob": -4.318023681640625}, {"pred": "meaning", "count": 1, "cond_log_prob": -3.92803955078125}, {"pred": "most", "count": 1, "cond_log_prob": -5.025726318359375}, {"pred": "origin", "count": 3, "cond_log_prob": -3.6405029296875}, {"pred": "original", "count": 3, "cond_log_prob": -3.997833251953125}, {"pred": "origins", "count": 5, "cond_log_prob": -3.475830078125}, {"pred": "originsroute", "count": 1, "cond_log_prob": -23.139251708984375}, {"pred": "shape", "count": 1, "cond_log_prob": -5.083770751953125}, {"pred": "significance", "count": 2, "cond_log_prob": -4.717132568359375}, {"pred": "use", "count": 10, "cond_log_prob": -3.103485107421875}, {"pred": "writing", "count": 1, "cond_log_prob": -4.379425048828125}]}, "49": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and the script's mere", "log_prob": -235.26187133789062}, "original": {"pred": "existence", "cond_log_prob": -0.7936248779296875}, "human": [{"pred": "existence", "cond_log_prob": -0.794036865234375, "count": 10}, {"pred": "presence", "cond_log_prob": -1.940826416015625, "count": 6}, {"pred": "complexity", "cond_log_prob": -8.783843994140625, "count": 2}, {"pred": "mention", "cond_log_prob": -3.789154052734375, "count": 2}, {"pred": "appearance", "cond_log_prob": -2.29150390625, "count": 1}, {"pred": "art", "cond_log_prob": -8.25640869140625, "count": 1}, {"pred": "beginnings", "cond_log_prob": -7.83685302734375, "count": 1}, {"pred": "copy", "cond_log_prob": -8.834869384765625, "count": 1}, {"pred": "exposure", "cond_log_prob": -7.67620849609375, "count": 1}, {"pred": "form", "cond_log_prob": -6.1082763671875, "count": 1}, {"pred": "history", "cond_log_prob": -8.361053466796875, "count": 1}, {"pred": "intricacy", "cond_log_prob": -11.115570068359375, "count": 1}, {"pred": "location", "cond_log_prob": -7.27032470703125, "count": 1}, {"pred": "look", "cond_log_prob": -8.844940185546875, "count": 1}, {"pred": "looks", "cond_log_prob": -10.416290283203125, "count": 1}, {"pred": "meaning", "cond_log_prob": -8.21337890625, "count": 1}, {"pred": "pictographs", "cond_log_prob": -10.559783935546875, "count": 1}, {"pred": "pictures", "cond_log_prob": -11.22735595703125, "count": 1}, {"pred": "purpose", "cond_log_prob": -9.233001708984375, "count": 1}, {"pred": "quality", "cond_log_prob": -8.93865966796875, "count": 1}, {"pred": "size", "cond_log_prob": -6.807952880859375, "count": 1}, {"pred": "style", "cond_log_prob": -10.170501708984375, "count": 1}, {"pred": "symbols", "cond_log_prob": -9.4312744140625, "count": 1}, {"pred": "writings", "cond_log_prob": -9.41448974609375, "count": 1}], "ancestral_samples": [{"pred": "appearance", "count": 1, "cond_log_prob": -2.29150390625}, {"pred": "existence", "count": 36, "cond_log_prob": -0.794036865234375}, {"pred": "existenceroute", "count": 1, "cond_log_prob": -30.007904052734375}, {"pred": "presence", "count": 2, "cond_log_prob": -1.940826416015625}]}, "50": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and the script's mere existence", "log_prob": -236.0554962158203}, "original": {"pred": "is", "cond_log_prob": -1.9896240234375}, "human": [{"pred": "is", "cond_log_prob": -1.9900360107421875, "count": 19}, {"pred": "was", "cond_log_prob": -1.7898101806640625, "count": 8}, {"pred": "proves", "cond_log_prob": -5.8124237060546875, "count": 2}, {"pred": "allowed", "cond_log_prob": -5.2763824462890625, "count": 1}, {"pred": "allows", "cond_log_prob": -6.7661895751953125, "count": 1}, {"pred": "and", "cond_log_prob": -5.2849884033203125, "count": 1}, {"pred": "continues", "cond_log_prob": -7.6535797119140625, "count": 1}, {"pred": "creates", "cond_log_prob": -7.4203643798828125, "count": 1}, {"pred": "on", "cond_log_prob": -5.7677154541015625, "count": 1}, {"pred": "proved", "cond_log_prob": -5.6864776611328125, "count": 1}, {"pred": "puzzles", "cond_log_prob": -10.443984985351562, "count": 1}, {"pred": "shows", "cond_log_prob": -6.6150665283203125, "count": 1}, {"pred": "stumped", "cond_log_prob": -10.1552734375, "count": 1}, {"pred": "were", "cond_log_prob": -7.5689239501953125, "count": 1}], "ancestral_samples": [{"pred": "did", "count": 1, "cond_log_prob": -3.8669586181640625}, {"pred": "has", "count": 5, "cond_log_prob": -2.2988128662109375}, {"pred": "is", "count": 15, "cond_log_prob": -1.9900360107421875}, {"pred": "isroute", "count": 1, "cond_log_prob": -27.948440551757812}, {"pred": "was", "count": 18, "cond_log_prob": -1.7898101806640625}]}, "51": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and the script's mere existence is", "log_prob": -238.0451202392578}, "original": {"pred": "sufficient", "cond_log_prob": -7.5143890380859375}, "human": [{"pred": "a", "cond_log_prob": -2.35760498046875, "count": 14}, {"pred": "evidence", "cond_log_prob": -5.0951080322265625, "count": 2}, {"pred": "proof", "cond_log_prob": -5.6416473388671875, "count": 2}, {"pred": "very", "cond_log_prob": -5.6607208251953125, "count": 2}, {"pred": "an", "cond_log_prob": -3.9480438232421875, "count": 1}, {"pred": "astonishing", "cond_log_prob": -8.440231323242188, "count": 1}, {"pred": "astounding", "cond_log_prob": -9.071609497070312, "count": 1}, {"pred": "barely", "cond_log_prob": -7.0480804443359375, "count": 1}, {"pred": "confounding", "cond_log_prob": -11.863601684570312, "count": 1}, {"pred": "enough", "cond_log_prob": -6.3086700439453125, "count": 1}, {"pred": "inspiration", "cond_log_prob": -13.866546630859375, "count": 1}, {"pred": "monumental", "cond_log_prob": -11.858383178710938, "count": 1}, {"pred": "only", "cond_log_prob": -4.4724884033203125, "count": 1}, {"pred": "pretty", "cond_log_prob": -8.135879516601562, "count": 1}, {"pred": "profound", "cond_log_prob": -11.62640380859375, "count": 1}, {"pred": "questioned", "cond_log_prob": -5.5961151123046875, "count": 1}, {"pred": "remarkable", "cond_log_prob": -7.1455230712890625, "count": 1}, {"pred": "symbolic", "cond_log_prob": -5.9987335205078125, "count": 1}, {"pred": "the", "cond_log_prob": -4.2032928466796875, "count": 1}, {"pred": "though", "cond_log_prob": -10.963088989257812, "count": 1}, {"pred": "treacherous", "cond_log_prob": -13.215255737304688, "count": 1}, {"pred": "unheard", "cond_log_prob": -7.7082672119140625, "count": 1}, {"pred": "untraceable", "cond_log_prob": -11.115066528320312, "count": 1}, {"pred": "used", "cond_log_prob": -6.407989501953125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 15, "cond_log_prob": -2.35760498046875}, {"pred": "believed", "count": 2, "cond_log_prob": -2.7831573486328125}, {"pred": "believedroute", "count": 1, "cond_log_prob": -25.930374145507812}, {"pred": "considered", "count": 2, "cond_log_prob": -2.861724853515625}, {"pred": "known", "count": 1, "cond_log_prob": -4.2840118408203125}, {"pred": "not", "count": 15, "cond_log_prob": -2.5198211669921875}, {"pred": "said", "count": 1, "cond_log_prob": -4.4181976318359375}, {"pred": "thought", "count": 1, "cond_log_prob": -3.275665283203125}, {"pred": "unknownHistory", "count": 1, "cond_log_prob": -17.60479736328125}, {"pred": "unknownIt", "count": 1, "cond_log_prob": -17.822128295898438}]}, "52": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and the script's mere existence is sufficient", "log_prob": -245.55950927734375}, "original": {"pred": "to", "cond_log_prob": -0.884613037109375}, "human": [{"pred": "to", "cond_log_prob": -0.885040283203125, "count": 22}, {"pred": "enough", "cond_log_prob": -6.4619140625, "count": 6}, {"pred": "evidence", "cond_log_prob": -1.272552490234375, "count": 6}, {"pred": "in", "cond_log_prob": -6.131195068359375, "count": 2}, {"pred": "data", "cond_log_prob": -9.29290771484375, "count": 1}, {"pred": "grounds", "cond_log_prob": -4.792144775390625, "count": 1}, {"pred": "proof", "cond_log_prob": -1.8487548828125, "count": 1}, {"pred": "that", "cond_log_prob": -7.771240234375, "count": 1}], "ancestral_samples": [{"pred": "evidence", "count": 12, "cond_log_prob": -1.272552490234375}, {"pred": "proof", "count": 1, "cond_log_prob": -1.8487548828125}, {"pred": "to", "count": 26, "cond_log_prob": -0.885040283203125}, {"pred": "toroute", "count": 1, "cond_log_prob": -28.686248779296875}]}, "53": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and the script's mere existence is sufficient to", "log_prob": -246.44412231445312}, "original": {"pred": "confound", "cond_log_prob": -8.108596801757812}, "human": [{"pred": "prove", "cond_log_prob": -4.12506103515625, "count": 10}, {"pred": "show", "cond_log_prob": -4.988037109375, "count": 4}, {"pred": "say", "cond_log_prob": -6.71954345703125, "count": 3}, {"pred": "the", "cond_log_prob": -7.100799560546875, "count": 3}, {"pred": "conclude", "cond_log_prob": -7.5726318359375, "count": 2}, {"pred": "know", "cond_log_prob": -8.0980224609375, "count": 2}, {"pred": "allows", "cond_log_prob": -12.3995361328125, "count": 1}, {"pred": "assume", "cond_log_prob": -7.9490966796875, "count": 1}, {"pred": "be", "cond_log_prob": -4.73291015625, "count": 1}, {"pred": "claim", "cond_log_prob": -5.813720703125, "count": 1}, {"pred": "describe", "cond_log_prob": -5.528717041015625, "count": 1}, {"pred": "determine", "cond_log_prob": -5.476043701171875, "count": 1}, {"pred": "estimate", "cond_log_prob": -9.801177978515625, "count": 1}, {"pred": "excite", "cond_log_prob": -7.776519775390625, "count": 1}, {"pred": "explain", "cond_log_prob": -2.11029052734375, "count": 1}, {"pred": "help", "cond_log_prob": -5.376251220703125, "count": 1}, {"pred": "keep", "cond_log_prob": -4.31988525390625, "count": 1}, {"pred": "last", "cond_log_prob": -8.48992919921875, "count": 1}, {"pred": "suggest", "cond_log_prob": -3.783294677734375, "count": 1}, {"pred": "teach", "cond_log_prob": -6.30145263671875, "count": 1}, {"pred": "translate", "cond_log_prob": -7.381011962890625, "count": 1}, {"pred": "warrant", "cond_log_prob": -3.882415771484375, "count": 1}], "ancestral_samples": [{"pred": "allow", "count": 1, "cond_log_prob": -4.09857177734375}, {"pred": "convey", "count": 1, "cond_log_prob": -6.123565673828125}, {"pred": "describe", "count": 1, "cond_log_prob": -5.528717041015625}, {"pred": "explain", "count": 22, "cond_log_prob": -2.11029052734375}, {"pred": "explainroute", "count": 1, "cond_log_prob": -20.584014892578125}, {"pred": "generate", "count": 1, "cond_log_prob": -5.685546875}, {"pred": "indicate", "count": 2, "cond_log_prob": -4.11590576171875}, {"pred": "justify", "count": 1, "cond_log_prob": -3.912261962890625}, {"pred": "make", "count": 6, "cond_log_prob": -2.742889404296875}, {"pred": "prevent", "count": 1, "cond_log_prob": -4.9664306640625}, {"pred": "suggest", "count": 2, "cond_log_prob": -3.783294677734375}, {"pred": "warrant", "count": 1, "cond_log_prob": -3.882415771484375}]}, "54": {"context": {"text": "Known as Rapa Nui to the island's inhabitants, Rongorongo is a writing system comprised of pictographs. It has been found carved into many oblong wooden tablets and other artifacts from the island's history. The art of writing was not known in any nearby islands and the script's mere existence is sufficient to confound", "log_prob": -254.55271911621094}, "original": {"pred": "anthropologists.", "cond_log_prob": -7.7935943603515625}, "human": [{"pred": "the", "cond_log_prob": -1.4553375244140625, "count": 18}, {"pred": "any", "cond_log_prob": -2.5837249755859375, "count": 4}, {"pred": "historians", "cond_log_prob": -3.7417144775390625, "count": 4}, {"pred": "scholars", "cond_log_prob": -2.7678070068359375, "count": 3}, {"pred": "many", "cond_log_prob": -2.8817901611328125, "count": 2}, {"pred": "scientists", "cond_log_prob": -6.6968536376953125, "count": 2}, {"pred": "all", "cond_log_prob": -4.2631072998046875, "count": 1}, {"pred": "even", "cond_log_prob": -3.9534149169921875, "count": 1}, {"pred": "history", "cond_log_prob": -6.4153289794921875, "count": 1}, {"pred": "newer", "cond_log_prob": -9.707351684570312, "count": 1}, {"pred": "research", "cond_log_prob": -7.3166351318359375, "count": 1}, {"pred": "researchers", "cond_log_prob": -5.0163116455078125, "count": 1}, {"pred": "what", "cond_log_prob": -6.3527984619140625, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -8.166824340820312}, {"pred": "a", "count": 1, "cond_log_prob": -4.9400787353515625}, {"pred": "any", "count": 1, "cond_log_prob": -2.5837249755859375}, {"pred": "anyoneIt", "count": 1, "cond_log_prob": -21.056350708007812}, {"pred": "investigatorsIn", "count": 1, "cond_log_prob": -22.399612426757812}, {"pred": "many", "count": 1, "cond_log_prob": -2.8817901611328125}, {"pred": "manyroutes", "count": 1, "cond_log_prob": -27.138351440429688}, {"pred": "most", "count": 1, "cond_log_prob": -3.1638641357421875}, {"pred": "scholarsRap", "count": 1, "cond_log_prob": -22.756546020507812}, {"pred": "scholarsThe", "count": 2, "cond_log_prob": -17.581527709960938}, {"pred": "the", "count": 29, "cond_log_prob": -1.4553375244140625}]}}, "12": {"2": {"context": {"text": "Some", "log_prob": -11.533941268920898}, "original": {"pred": "months", "cond_log_prob": -6.870216369628906}, "human": [{"pred": "people", "cond_log_prob": -2.187307357788086, "count": 29}, {"pred": "times", "cond_log_prob": -7.153547286987305, "count": 3}, {"pred": "animals", "cond_log_prob": -7.745328903198242, "count": 1}, {"pred": "buddy", "cond_log_prob": -13.758695602416992, "count": 1}, {"pred": "cats", "cond_log_prob": -8.57740592956543, "count": 1}, {"pred": "dinosaurs", "cond_log_prob": -9.831205368041992, "count": 1}, {"pred": "of", "cond_log_prob": -1.880727767944336, "count": 1}, {"pred": "other", "cond_log_prob": -5.214681625366211, "count": 1}, {"pred": "peanuts", "cond_log_prob": -12.378767013549805, "count": 1}, {"pred": "thing", "cond_log_prob": -9.011472702026367, "count": 1}, {"pred": "things", "cond_log_prob": -4.28834342956543, "count": 1}, {"pred": "travelers", "cond_log_prob": -9.347219467163086, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 2, "cond_log_prob": -8.203222274780273}, {"pred": "a", "count": 1, "cond_log_prob": -8.01087760925293}, {"pred": "and", "count": 2, "cond_log_prob": -7.181119918823242}, {"pred": "are", "count": 3, "cond_log_prob": -4.969869613647461}, {"pred": "have", "count": 1, "cond_log_prob": -4.79072380065918}, {"pred": "is", "count": 1, "cond_log_prob": -7.405813217163086}, {"pred": "its", "count": 1, "cond_log_prob": -10.528371810913086}, {"pred": "of", "count": 22, "cond_log_prob": -1.880727767944336}, {"pred": "ofroutes", "count": 1, "cond_log_prob": -23.49263572692871}, {"pred": "the", "count": 3, "cond_log_prob": -7.513364791870117}, {"pred": "to", "count": 3, "cond_log_prob": -7.319921493530273}]}, "3": {"context": {"text": "Some months", "log_prob": -18.404157638549805}, "original": {"pred": "later,", "cond_log_prob": -3.0822067260742188}, "human": [{"pred": "ago", "cond_log_prob": -0.45750999450683594, "count": 12}, {"pred": "are", "cond_log_prob": -6.379247665405273, "count": 11}, {"pred": "of", "cond_log_prob": -6.424795150756836, "count": 5}, {"pred": "i", "cond_log_prob": -10.961263656616211, "count": 4}, {"pred": "later", "cond_log_prob": -2.833669662475586, "count": 3}, {"pred": "go", "cond_log_prob": -7.620817184448242, "count": 2}, {"pred": "have", "cond_log_prob": -4.632543563842773, "count": 2}, {"pred": "after", "cond_log_prob": -2.702108383178711, "count": 1}, {"pred": "it", "cond_log_prob": -6.589345932006836, "count": 1}, {"pred": "take", "cond_log_prob": -10.438451766967773, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 2, "cond_log_prob": -5.797918319702148}, {"pred": "a", "count": 1, "cond_log_prob": -7.390554428100586}, {"pred": "after", "count": 6, "cond_log_prob": -2.702108383178711}, {"pred": "afterroute", "count": 1, "cond_log_prob": -24.041730880737305}, {"pred": "ago", "count": 7, "cond_log_prob": -0.45750999450683594}, {"pred": "hes", "count": 1, "cond_log_prob": -15.034811019897461}, {"pred": "later", "count": 20, "cond_log_prob": -2.833669662475586}, {"pred": "she", "count": 1, "cond_log_prob": -8.645330429077148}, {"pred": "the", "count": 1, "cond_log_prob": -6.998952865600586}]}, "4": {"context": {"text": "Some months later,", "log_prob": -21.486364364624023}, "original": {"pred": "Michael", "cond_log_prob": -7.032979965209961}, "human": [{"pred": "the", "cond_log_prob": -2.3592777252197266, "count": 10}, {"pred": "he", "cond_log_prob": -2.9952030181884766, "count": 4}, {"pred": "i", "cond_log_prob": -7.905168533325195, "count": 4}, {"pred": "she", "cond_log_prob": -3.957712173461914, "count": 4}, {"pred": "a", "cond_log_prob": -3.3546085357666016, "count": 3}, {"pred": "there", "cond_log_prob": -5.132577896118164, "count": 3}, {"pred": "it", "cond_log_prob": -3.855325698852539, "count": 2}, {"pred": "we", "cond_log_prob": -3.548776626586914, "count": 2}, {"pred": "ca", "cond_log_prob": -12.701074600219727, "count": 1}, {"pred": "carol", "cond_log_prob": -15.670923233032227, "count": 1}, {"pred": "everyone", "cond_log_prob": -8.441385269165039, "count": 1}, {"pred": "janie", "cond_log_prob": -24.165971755981445, "count": 1}, {"pred": "life", "cond_log_prob": -9.706232070922852, "count": 1}, {"pred": "mary", "cond_log_prob": -16.183610916137695, "count": 1}, {"pred": "my", "cond_log_prob": -4.523820877075195, "count": 1}, {"pred": "they", "cond_log_prob": -4.552095413208008, "count": 1}, {"pred": "travelers", "cond_log_prob": -13.028894424438477, "count": 1}, {"pred": "you", "cond_log_prob": -5.470926284790039, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 6, "cond_log_prob": -2.264619827270508}, {"pred": "a", "count": 4, "cond_log_prob": -3.3546085357666016}, {"pred": "after", "count": 2, "cond_log_prob": -3.5102787017822266}, {"pred": "afterroute", "count": 1, "cond_log_prob": -24.077341079711914}, {"pred": "he", "count": 8, "cond_log_prob": -2.9952030181884766}, {"pred": "in", "count": 3, "cond_log_prob": -3.1602420806884766}, {"pred": "my", "count": 1, "cond_log_prob": -4.523820877075195}, {"pred": "she", "count": 2, "cond_log_prob": -3.957712173461914}, {"pred": "the", "count": 10, "cond_log_prob": -2.3592777252197266}, {"pred": "they", "count": 1, "cond_log_prob": -4.552095413208008}, {"pred": "when", "count": 2, "cond_log_prob": -3.296548843383789}]}, "5": {"context": {"text": "Some months later, Michael", "log_prob": -28.519344329833984}, "original": {"pred": "Larson", "cond_log_prob": -10.353565216064453}, "human": [{"pred": "went", "cond_log_prob": -8.571231842041016, "count": 5}, {"pred": "had", "cond_log_prob": -5.385936737060547, "count": 3}, {"pred": "ran", "cond_log_prob": -10.031688690185547, "count": 3}, {"pred": "returned", "cond_log_prob": -9.649646759033203, "count": 3}, {"pred": "began", "cond_log_prob": -8.24594497680664, "count": 2}, {"pred": "found", "cond_log_prob": -8.116230010986328, "count": 2}, {"pred": "saw", "cond_log_prob": -8.29922103881836, "count": 2}, {"pred": "angelo", "cond_log_prob": -19.110679626464844, "count": 1}, {"pred": "ate", "cond_log_prob": -12.15328598022461, "count": 1}, {"pred": "buble", "cond_log_prob": -24.019245147705078, "count": 1}, {"pred": "came", "cond_log_prob": -7.225040435791016, "count": 1}, {"pred": "continued", "cond_log_prob": -8.108470916748047, "count": 1}, {"pred": "decided", "cond_log_prob": -8.397777557373047, "count": 1}, {"pred": "did", "cond_log_prob": -7.823848724365234, "count": 1}, {"pred": "discovered", "cond_log_prob": -10.524402618408203, "count": 1}, {"pred": "got", "cond_log_prob": -8.03872299194336, "count": 1}, {"pred": "green", "cond_log_prob": -13.290752410888672, "count": 1}, {"pred": "jackson", "cond_log_prob": -14.641399383544922, "count": 2}, {"pred": "jumped", "cond_log_prob": -10.719356536865234, "count": 1}, {"pred": "khor", "cond_log_prob": -21.960952758789062, "count": 1}, {"pred": "realized", "cond_log_prob": -10.785648345947266, "count": 1}, {"pred": "says", "cond_log_prob": -6.158985137939453, "count": 1}, {"pred": "still", "cond_log_prob": -8.67947769165039, "count": 1}, {"pred": "thought", "cond_log_prob": -9.97860336303711, "count": 1}, {"pred": "walked", "cond_log_prob": -9.613033294677734, "count": 1}, {"pred": "wanted", "cond_log_prob": -9.493175506591797, "count": 1}, {"pred": "was", "cond_log_prob": -4.440280914306641, "count": 1}, {"pred": "would", "cond_log_prob": -6.292263031005859, "count": 1}], "ancestral_samples": [{"pred": "DAntonio", "count": 1, "cond_log_prob": -18.114891052246094}, {"pred": "Flynn", "count": 1, "cond_log_prob": -4.426593780517578}, {"pred": "I", "count": 1, "cond_log_prob": -7.608440399169922}, {"pred": "Jordan", "count": 1, "cond_log_prob": -3.8368797302246094}, {"pred": "K", "count": 1, "cond_log_prob": -4.236454010009766}, {"pred": "Lacy", "count": 1, "cond_log_prob": -9.725364685058594}, {"pred": "ONeill", "count": 2, "cond_log_prob": -26.81673812866211}, {"pred": "and", "count": 9, "cond_log_prob": -3.951099395751953}, {"pred": "androute", "count": 1, "cond_log_prob": -26.192340850830078}, {"pred": "had", "count": 3, "cond_log_prob": -5.385936737060547}, {"pred": "is", "count": 1, "cond_log_prob": -4.862415313720703}, {"pred": "participated", "count": 1, "cond_log_prob": -11.469829559326172}, {"pred": "s", "count": 3, "cond_log_prob": -11.797008514404297}, {"pred": "said", "count": 5, "cond_log_prob": -5.303256988525391}, {"pred": "was", "count": 9, "cond_log_prob": -4.440280914306641}]}, "6": {"context": {"text": "Some months later, Michael Larson", "log_prob": -38.87290954589844}, "original": {"pred": "saw", "cond_log_prob": -6.668998718261719}, "human": [{"pred": "was", "cond_log_prob": -2.4329681396484375, "count": 8}, {"pred": "decided", "cond_log_prob": -5.564277648925781, "count": 4}, {"pred": "went", "cond_log_prob": -5.166053771972656, "count": 4}, {"pred": "found", "cond_log_prob": -4.706520080566406, "count": 3}, {"pred": "ate", "cond_log_prob": -9.828041076660156, "count": 2}, {"pred": "became", "cond_log_prob": -5.090110778808594, "count": 2}, {"pred": "began", "cond_log_prob": -5.925361633300781, "count": 2}, {"pred": "returned", "cond_log_prob": -5.6860809326171875, "count": 2}, {"pred": "saw", "cond_log_prob": -6.6690826416015625, "count": 2}, {"pred": "still", "cond_log_prob": -6.6608428955078125, "count": 2}, {"pred": "came", "cond_log_prob": -4.5566558837890625, "count": 1}, {"pred": "died", "cond_log_prob": -5.912269592285156, "count": 1}, {"pred": "discovered", "cond_log_prob": -5.991424560546875, "count": 1}, {"pred": "finally", "cond_log_prob": -5.801826477050781, "count": 1}, {"pred": "go", "cond_log_prob": -12.052772521972656, "count": 1}, {"pred": "had", "cond_log_prob": -3.872833251953125, "count": 1}, {"pred": "played", "cond_log_prob": -6.892425537109375, "count": 1}, {"pred": "ran", "cond_log_prob": -6.467597961425781, "count": 1}, {"pred": "showed", "cond_log_prob": -5.9868621826171875, "count": 1}, {"pred": "took", "cond_log_prob": -4.2530975341796875, "count": 1}, {"pred": "wants", "cond_log_prob": -7.879646301269531, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 20, "cond_log_prob": -8.133674621582031}, {"pred": "an", "count": 1, "cond_log_prob": -10.202003479003906}, {"pred": "participated", "count": 1, "cond_log_prob": -8.938980102539062}, {"pred": "routes", "count": 1, "cond_log_prob": -15.269462585449219}, {"pred": "the", "count": 9, "cond_log_prob": -8.092796325683594}, {"pred": "then", "count": 1, "cond_log_prob": -8.470207214355469}, {"pred": "was", "count": 5, "cond_log_prob": -2.4329681396484375}, {"pred": "who", "count": 2, "cond_log_prob": -7.8149871826171875}]}, "7": {"context": {"text": "Some months later, Michael Larson saw", "log_prob": -45.541908264160156}, "original": {"pred": "another", "cond_log_prob": -4.6819915771484375}, "human": [{"pred": "a", "cond_log_prob": -1.4490814208984375, "count": 21}, {"pred": "her", "cond_log_prob": -4.957130432128906, "count": 5}, {"pred": "the", "cond_log_prob": -1.9489212036132812, "count": 4}, {"pred": "his", "cond_log_prob": -1.8233413696289062, "count": 3}, {"pred": "that", "cond_log_prob": -3.4805221557617188, "count": 3}, {"pred": "as", "cond_log_prob": -6.956993103027344, "count": 1}, {"pred": "how", "cond_log_prob": -5.783851623535156, "count": 1}, {"pred": "katie", "cond_log_prob": -21.19629669189453, "count": 1}, {"pred": "one", "cond_log_prob": -4.6620330810546875, "count": 1}, {"pred": "some", "cond_log_prob": -4.462898254394531, "count": 1}, {"pred": "what", "cond_log_prob": -4.401329040527344, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -10.235786437988281}, {"pred": "a", "count": 23, "cond_log_prob": -1.4490814208984375}, {"pred": "anroutecom", "count": 1, "cond_log_prob": -38.74138641357422}, {"pred": "his", "count": 7, "cond_log_prob": -1.8233413696289062}, {"pred": "the", "count": 8, "cond_log_prob": -1.9489212036132812}]}, "8": {"context": {"text": "Some months later, Michael Larson saw another", "log_prob": -50.223899841308594}, "original": {"pred": "opportunity", "cond_log_prob": -5.068931579589844}, "human": [{"pred": "girl", "cond_log_prob": -5.4973602294921875, "count": 5}, {"pred": "person", "cond_log_prob": -4.73095703125, "count": 4}, {"pred": "student", "cond_log_prob": -5.413604736328125, "count": 4}, {"pred": "man", "cond_log_prob": -3.4552383422851562, "count": 2}, {"pred": "monkey", "cond_log_prob": -9.489089965820312, "count": 2}, {"pred": "thing", "cond_log_prob": -5.4668426513671875, "count": 2}, {"pred": "woman", "cond_log_prob": -3.9165267944335938, "count": 2}, {"pred": "accident", "cond_log_prob": -6.8952484130859375, "count": 1}, {"pred": "bird", "cond_log_prob": -8.614837646484375, "count": 1}, {"pred": "change", "cond_log_prob": -6.5052337646484375, "count": 1}, {"pred": "cow", "cond_log_prob": -9.448921203613281, "count": 1}, {"pred": "crazy", "cond_log_prob": -8.263771057128906, "count": 1}, {"pred": "deer", "cond_log_prob": -8.106956481933594, "count": 1}, {"pred": "dinosaur", "cond_log_prob": -8.866378784179688, "count": 1}, {"pred": "example", "cond_log_prob": -4.8331451416015625, "count": 1}, {"pred": "female", "cond_log_prob": -7.071693420410156, "count": 1}, {"pred": "hot", "cond_log_prob": -8.412223815917969, "count": 1}, {"pred": "human", "cond_log_prob": -7.1862030029296875, "count": 1}, {"pred": "lady", "cond_log_prob": -7.49517822265625, "count": 1}, {"pred": "light", "cond_log_prob": -6.4650115966796875, "count": 1}, {"pred": "michael", "cond_log_prob": -15.055763244628906, "count": 1}, {"pred": "nasty", "cond_log_prob": -9.542076110839844, "count": 1}, {"pred": "psychology", "cond_log_prob": -10.883651733398438, "count": 1}, {"pred": "shark", "cond_log_prob": -7.985626220703125, "count": 1}, {"pred": "sign", "cond_log_prob": -4.126708984375, "count": 1}, {"pred": "ufo", "cond_log_prob": -16.750755310058594, "count": 2}, {"pred": "whale", "cond_log_prob": -8.7705078125, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -10.641868591308594}, {"pred": "baby", "count": 1, "cond_log_prob": -6.3602752685546875}, {"pred": "bombshell", "count": 1, "cond_log_prob": -8.8955078125}, {"pred": "child", "count": 1, "cond_log_prob": -5.2845458984375}, {"pred": "day", "count": 1, "cond_log_prob": -6.2920074462890625}, {"pred": "example", "count": 1, "cond_log_prob": -4.8331451416015625}, {"pred": "incident", "count": 1, "cond_log_prob": -5.457038879394531}, {"pred": "incidentroute", "count": 1, "cond_log_prob": -27.27984619140625}, {"pred": "letter", "count": 1, "cond_log_prob": -6.297119140625}, {"pred": "man", "count": 10, "cond_log_prob": -3.4552383422851562}, {"pred": "one", "count": 3, "cond_log_prob": -4.0440826416015625}, {"pred": "opportunity", "count": 1, "cond_log_prob": -5.0690155029296875}, {"pred": "part", "count": 1, "cond_log_prob": -6.058891296386719}, {"pred": "picture", "count": 1, "cond_log_prob": -4.709541320800781}, {"pred": "report", "count": 1, "cond_log_prob": -5.4600830078125}, {"pred": "scenario", "count": 1, "cond_log_prob": -7.460868835449219}, {"pred": "sign", "count": 3, "cond_log_prob": -4.126708984375}, {"pred": "strange", "count": 1, "cond_log_prob": -5.866607666015625}, {"pred": "thing", "count": 1, "cond_log_prob": -5.4668426513671875}, {"pred": "video", "count": 1, "cond_log_prob": -4.3896942138671875}, {"pred": "white", "count": 1, "cond_log_prob": -5.841392517089844}, {"pred": "woman", "count": 4, "cond_log_prob": -3.9165267944335938}, {"pred": "young", "count": 2, "cond_log_prob": -4.5401153564453125}]}, "9": {"context": {"text": "Some months later, Michael Larson saw another opportunity", "log_prob": -55.29283142089844}, "original": {"pred": "to", "cond_log_prob": -0.7211532592773438}, "human": [{"pred": "to", "cond_log_prob": -0.72125244140625, "count": 31}, {"pred": "for", "cond_log_prob": -2.549102783203125, "count": 8}, {"pred": "come", "cond_log_prob": -6.503593444824219, "count": 1}, {"pred": "coming", "cond_log_prob": -6.640922546386719, "count": 1}, {"pred": "in", "cond_log_prob": -3.0183792114257812, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 3, "cond_log_prob": -10.752281188964844}, {"pred": "I", "count": 2, "cond_log_prob": -9.144874572753906}, {"pred": "On", "count": 1, "cond_log_prob": -13.502693176269531}, {"pred": "to", "count": 33, "cond_log_prob": -0.72125244140625}, {"pred": "toroute", "count": 1, "cond_log_prob": -29.217506408691406}]}, "10": {"context": {"text": "Some months later, Michael Larson saw another opportunity to", "log_prob": -56.01398468017578}, "original": {"pred": "stack", "cond_log_prob": -9.525665283203125}, "human": [{"pred": "become", "cond_log_prob": -4.863868713378906, "count": 3}, {"pred": "find", "cond_log_prob": -5.602333068847656, "count": 3}, {"pred": "make", "cond_log_prob": -2.8108139038085938, "count": 3}, {"pred": "ask", "cond_log_prob": -6.643836975097656, "count": 2}, {"pred": "do", "cond_log_prob": -3.5025863647460938, "count": 2}, {"pred": "eat", "cond_log_prob": -8.067817687988281, "count": 2}, {"pred": "get", "cond_log_prob": -3.3928909301757812, "count": 2}, {"pred": "talk", "cond_log_prob": -5.926902770996094, "count": 2}, {"pred": "advance", "cond_log_prob": -6.280372619628906, "count": 1}, {"pred": "apply", "cond_log_prob": -7.227622985839844, "count": 1}, {"pred": "build", "cond_log_prob": -4.676170349121094, "count": 1}, {"pred": "buy", "cond_log_prob": -5.246818542480469, "count": 1}, {"pred": "capitalize", "cond_log_prob": -5.727989196777344, "count": 1}, {"pred": "date", "cond_log_prob": -9.106101989746094, "count": 1}, {"pred": "fight", "cond_log_prob": -5.676475524902344, "count": 1}, {"pred": "forego", "cond_log_prob": -11.399261474609375, "count": 1}, {"pred": "further", "cond_log_prob": -6.460731506347656, "count": 1}, {"pred": "go", "cond_log_prob": -5.137428283691406, "count": 1}, {"pred": "help", "cond_log_prob": -4.011619567871094, "count": 1}, {"pred": "improve", "cond_log_prob": -4.678703308105469, "count": 1}, {"pred": "learn", "cond_log_prob": -5.721977233886719, "count": 1}, {"pred": "overcome", "cond_log_prob": -7.483497619628906, "count": 1}, {"pred": "play", "cond_log_prob": -4.736625671386719, "count": 1}, {"pred": "pursue", "cond_log_prob": -6.063957214355469, "count": 1}, {"pred": "regain", "cond_log_prob": -6.996315002441406, "count": 1}, {"pred": "research", "cond_log_prob": -8.775810241699219, "count": 1}, {"pred": "show", "cond_log_prob": -3.7930221557617188, "count": 1}, {"pred": "sleep", "cond_log_prob": -8.987525939941406, "count": 1}, {"pred": "study", "cond_log_prob": -7.184593200683594, "count": 1}, {"pred": "succeed", "cond_log_prob": -6.450370788574219, "count": 1}, {"pred": "travel", "cond_log_prob": -7.747596740722656, "count": 1}], "ancestral_samples": [{"pred": "bringroute", "count": 1, "cond_log_prob": -26.383453369140625}, {"pred": "challenge", "count": 1, "cond_log_prob": -5.167472839355469}, {"pred": "change", "count": 5, "cond_log_prob": -4.486152648925781}, {"pred": "demonstrate", "count": 1, "cond_log_prob": -5.232521057128906}, {"pred": "do", "count": 2, "cond_log_prob": -3.5025863647460938}, {"pred": "get", "count": 4, "cond_log_prob": -3.3928909301757812}, {"pred": "go", "count": 1, "cond_log_prob": -5.137428283691406}, {"pred": "help", "count": 3, "cond_log_prob": -4.011619567871094}, {"pred": "improve", "count": 2, "cond_log_prob": -4.678703308105469}, {"pred": "make", "count": 10, "cond_log_prob": -2.8108139038085938}, {"pred": "raise", "count": 1, "cond_log_prob": -5.242485046386719}, {"pred": "show", "count": 5, "cond_log_prob": -3.7930221557617188}, {"pred": "succeed", "count": 1, "cond_log_prob": -6.450370788574219}, {"pred": "take", "count": 3, "cond_log_prob": -3.8020553588867188}]}, "11": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack", "log_prob": -65.5396499633789}, "original": {"pred": "the", "cond_log_prob": -1.49761962890625}, "human": [{"pred": "the", "cond_log_prob": -1.4976730346679688, "count": 10}, {"pred": "his", "cond_log_prob": -1.6079177856445312, "count": 9}, {"pred": "up", "cond_log_prob": -1.182891845703125, "count": 8}, {"pred": "a", "cond_log_prob": -3.0133209228515625, "count": 3}, {"pred": "papers", "cond_log_prob": -8.682182312011719, "count": 3}, {"pred": "cups", "cond_log_prob": -10.574180603027344, "count": 2}, {"pred": "another", "cond_log_prob": -7.447486877441406, "count": 1}, {"pred": "books", "cond_log_prob": -9.471305847167969, "count": 1}, {"pred": "cards", "cond_log_prob": -8.282997131347656, "count": 1}, {"pred": "chairs", "cond_log_prob": -8.691261291503906, "count": 1}, {"pred": "hay", "cond_log_prob": -8.991996765136719, "count": 1}, {"pred": "more", "cond_log_prob": -5.800315856933594, "count": 1}, {"pred": "pancakes", "cond_log_prob": -9.888343811035156, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.0133209228515625}, {"pred": "her", "count": 1, "cond_log_prob": -4.975334167480469}, {"pred": "his", "count": 7, "cond_log_prob": -1.6079177856445312}, {"pred": "the", "count": 13, "cond_log_prob": -1.4976730346679688}, {"pred": "up", "count": 16, "cond_log_prob": -1.182891845703125}, {"pred": "uproute", "count": 1, "cond_log_prob": -25.129898071289062}]}, "12": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the", "log_prob": -67.03726959228516}, "original": {"pred": "odds", "cond_log_prob": -5.502830505371094}, "human": [{"pred": "cards", "cond_log_prob": -5.642852783203125, "count": 9}, {"pred": "odds", "cond_log_prob": -5.5029296875, "count": 7}, {"pred": "deck", "cond_log_prob": -0.2886810302734375, "count": 3}, {"pred": "chairs", "cond_log_prob": -8.921928405761719, "count": 2}, {"pred": "dishes", "cond_log_prob": -10.121345520019531, "count": 2}, {"pred": "papers", "cond_log_prob": -10.361160278320312, "count": 2}, {"pred": "bacon", "cond_log_prob": -11.806617736816406, "count": 1}, {"pred": "bodies", "cond_log_prob": -11.66632080078125, "count": 1}, {"pred": "books", "cond_log_prob": -5.9159088134765625, "count": 1}, {"pred": "bricks", "cond_log_prob": -8.738754272460938, "count": 1}, {"pred": "bunch", "cond_log_prob": -11.38104248046875, "count": 1}, {"pred": "chances", "cond_log_prob": -11.955459594726562, "count": 1}, {"pred": "crayons", "cond_log_prob": -15.022209167480469, "count": 1}, {"pred": "grades", "cond_log_prob": -12.510482788085938, "count": 1}, {"pred": "hall", "cond_log_prob": -12.627960205078125, "count": 1}, {"pred": "hay", "cond_log_prob": -9.086135864257812, "count": 1}, {"pred": "macaroni", "cond_log_prob": -13.856559753417969, "count": 1}, {"pred": "money", "cond_log_prob": -8.635772705078125, "count": 1}, {"pred": "punches", "cond_log_prob": -9.912361145019531, "count": 1}, {"pred": "results", "cond_log_prob": -9.86956787109375, "count": 1}, {"pred": "tables", "cond_log_prob": -9.448165893554688, "count": 1}, {"pred": "winnings", "cond_log_prob": -10.496315002441406, "count": 1}, {"pred": "wood", "cond_log_prob": -10.002426147460938, "count": 1}], "ancestral_samples": [{"pred": "deck", "count": 39, "cond_log_prob": -0.28864288330078125}, {"pred": "deckroute", "count": 1, "cond_log_prob": -20.573699951171875}]}, "13": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds", "log_prob": -72.54010009765625}, "original": {"pred": "in", "cond_log_prob": -3.3094329833984375}, "human": [{"pred": "in", "cond_log_prob": -3.3095550537109375, "count": 19}, {"pred": "against", "cond_log_prob": -0.6410675048828125, "count": 16}, {"pred": "of", "cond_log_prob": -3.8749847412109375, "count": 3}, {"pred": "and", "cond_log_prob": -3.797393798828125, "count": 1}, {"pred": "for", "cond_log_prob": -3.5273818969726562, "count": 1}, {"pred": "towards", "cond_log_prob": -8.897262573242188, "count": 1}, {"pred": "up", "cond_log_prob": -6.5387725830078125, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -12.103065490722656}, {"pred": "Hed", "count": 1, "cond_log_prob": -15.674789428710938}, {"pred": "I", "count": 3, "cond_log_prob": -10.241676330566406}, {"pred": "against", "count": 33, "cond_log_prob": -0.6410980224609375}, {"pred": "againstroute", "count": 1, "cond_log_prob": -22.36756134033203}, {"pred": "on", "count": 1, "cond_log_prob": -2.5583572387695312}]}, "14": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in", "log_prob": -75.84953308105469}, "original": {"pred": "his", "cond_log_prob": -0.631591796875}, "human": [{"pred": "his", "cond_log_prob": -0.6317062377929688, "count": 24}, {"pred": "favor", "cond_log_prob": -2.6217041015625, "count": 6}, {"pred": "a", "cond_log_prob": -2.816253662109375, "count": 3}, {"pred": "the", "cond_log_prob": -2.6468582153320312, "count": 3}, {"pred": "alphabetical", "cond_log_prob": -13.61981201171875, "count": 1}, {"pred": "getting", "cond_log_prob": -9.55499267578125, "count": 1}, {"pred": "playing", "cond_log_prob": -9.825401306152344, "count": 1}, {"pred": "poker", "cond_log_prob": -10.607841491699219, "count": 1}, {"pred": "politics", "cond_log_prob": -8.087043762207031, "count": 1}, {"pred": "winning", "cond_log_prob": -8.558647155761719, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -11.545494079589844}, {"pred": "a", "count": 2, "cond_log_prob": -2.816253662109375}, {"pred": "favor", "count": 1, "cond_log_prob": -2.6217041015625}, {"pred": "her", "count": 2, "cond_log_prob": -4.7296142578125}, {"pred": "his", "count": 33, "cond_log_prob": -0.6317062377929688}, {"pred": "hisroute", "count": 1, "cond_log_prob": -23.024185180664062}]}, "15": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his", "log_prob": -76.48112487792969}, "original": {"pred": "favor", "cond_log_prob": -0.37337493896484375}, "human": [{"pred": "favor", "cond_log_prob": -0.37349700927734375, "count": 36}, {"pred": "life", "cond_log_prob": -6.344261169433594, "count": 2}, {"pred": "lottery", "cond_log_prob": -11.25360107421875, "count": 1}, {"pred": "pocket", "cond_log_prob": -5.5067138671875, "count": 1}, {"pred": "poker", "cond_log_prob": -10.249183654785156, "count": 1}, {"pred": "test", "cond_log_prob": -9.564590454101562, "count": 1}], "ancestral_samples": [{"pred": "favor", "count": 37, "cond_log_prob": -0.37349700927734375}, {"pred": "favorIn", "count": 1, "cond_log_prob": -16.713714599609375}, {"pred": "favorroute", "count": 1, "cond_log_prob": -22.866432189941406}, {"pred": "favour", "count": 1, "cond_log_prob": -2.0137710571289062}]}, "16": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor", "log_prob": -76.85449981689453}, "original": {"pred": "with", "cond_log_prob": -3.7623138427734375}, "human": [{"pred": "and", "cond_log_prob": -3.3985748291015625, "count": 13}, {"pred": "in", "cond_log_prob": -3.6796188354492188, "count": 5}, {"pred": "for", "cond_log_prob": -4.436798095703125, "count": 4}, {"pred": "so", "cond_log_prob": -7.280952453613281, "count": 4}, {"pred": "by", "cond_log_prob": -3.1675643920898438, "count": 3}, {"pred": "against", "cond_log_prob": -3.2806472778320312, "count": 2}, {"pred": "but", "cond_log_prob": -7.5950775146484375, "count": 2}, {"pred": "to", "cond_log_prob": -5.408653259277344, "count": 2}, {"pred": "----------------------------------------------------", "cond_log_prob": -21.54914093017578, "count": 1}, {"pred": "always", "cond_log_prob": -14.205001831054688, "count": 1}, {"pred": "he", "cond_log_prob": -9.480278015136719, "count": 2}, {"pred": "once", "cond_log_prob": -6.409141540527344, "count": 1}, {"pred": "permanatly", "cond_log_prob": -26.09229278564453, "count": 1}, {"pred": "when", "cond_log_prob": -3.631011962890625, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 3, "cond_log_prob": -12.065406799316406}, {"pred": "After", "count": 1, "cond_log_prob": -13.256462097167969}, {"pred": "He", "count": 4, "cond_log_prob": -13.191123962402344}, {"pred": "Hed", "count": 2, "cond_log_prob": -17.663330078125}, {"pred": "I", "count": 22, "cond_log_prob": -10.481887817382812}, {"pred": "In", "count": 2, "cond_log_prob": -12.482147216796875}, {"pred": "It", "count": 1, "cond_log_prob": -14.398307800292969}, {"pred": "Larson", "count": 2, "cond_log_prob": -18.96546173095703}, {"pred": "On", "count": 1, "cond_log_prob": -13.719253540039062}, {"pred": "by", "count": 1, "cond_log_prob": -3.1675643920898438}, {"pred": "routecom", "count": 1, "cond_log_prob": -35.345977783203125}]}, "17": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with", "log_prob": -80.61681365966797}, "original": {"pred": "a", "cond_log_prob": -1.2325057983398438}, "human": [{"pred": "the", "cond_log_prob": -1.8572311401367188, "count": 12}, {"pred": "his", "cond_log_prob": -2.6776504516601562, "count": 9}, {"pred": "a", "cond_log_prob": -1.2326431274414062, "count": 6}, {"pred": "her", "cond_log_prob": -7.313270568847656, "count": 2}, {"pred": "some", "cond_log_prob": -4.609382629394531, "count": 2}, {"pred": "alison", "cond_log_prob": -16.317337036132812, "count": 1}, {"pred": "assasination", "cond_log_prob": -17.828598022460938, "count": 1}, {"pred": "dating", "cond_log_prob": -11.730659484863281, "count": 1}, {"pred": "hard", "cond_log_prob": -10.061180114746094, "count": 1}, {"pred": "money", "cond_log_prob": -7.944633483886719, "count": 1}, {"pred": "more", "cond_log_prob": -6.008209228515625, "count": 1}, {"pred": "one", "cond_log_prob": -4.196037292480469, "count": 1}, {"pred": "out", "cond_log_prob": -9.256294250488281, "count": 1}, {"pred": "putting", "cond_log_prob": -11.127433776855469, "count": 1}, {"pred": "school", "cond_log_prob": -10.476791381835938, "count": 1}, {"pred": "to", "cond_log_prob": -9.346946716308594, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 32, "cond_log_prob": -1.2326431274414062}, {"pred": "aroute", "count": 1, "cond_log_prob": -25.659957885742188}, {"pred": "his", "count": 1, "cond_log_prob": -2.6776504516601562}, {"pred": "the", "count": 6, "cond_log_prob": -1.8572311401367188}]}, "18": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a", "log_prob": -81.84931945800781}, "original": {"pred": "dash", "cond_log_prob": -9.471000671386719}, "human": [{"pred": "new", "cond_log_prob": -3.7196807861328125, "count": 8}, {"pred": "chance", "cond_log_prob": -5.6521148681640625, "count": 2}, {"pred": "job", "cond_log_prob": -5.895591735839844, "count": 2}, {"pred": "woman", "cond_log_prob": -7.185386657714844, "count": 2}, {"pred": "bet", "cond_log_prob": -5.7001495361328125, "count": 1}, {"pred": "call", "cond_log_prob": -5.940177917480469, "count": 1}, {"pred": "certain", "cond_log_prob": -7.8026885986328125, "count": 1}, {"pred": "chess", "cond_log_prob": -9.691184997558594, "count": 1}, {"pred": "date", "cond_log_prob": -7.9880218505859375, "count": 1}, {"pred": "deal", "cond_log_prob": -5.156829833984375, "count": 1}, {"pred": "dinosaur", "cond_log_prob": -10.602241516113281, "count": 1}, {"pred": "discovery", "cond_log_prob": -9.98968505859375, "count": 1}, {"pred": "friend", "cond_log_prob": -5.889739990234375, "count": 1}, {"pred": "giant", "cond_log_prob": -7.9425201416015625, "count": 1}, {"pred": "girl", "cond_log_prob": -8.875030517578125, "count": 1}, {"pred": "guy", "cond_log_prob": -7.2606048583984375, "count": 1}, {"pred": "huge", "cond_log_prob": -6.345008850097656, "count": 1}, {"pred": "knife", "cond_log_prob": -9.462417602539062, "count": 1}, {"pred": "lady", "cond_log_prob": -11.6064453125, "count": 1}, {"pred": "large", "cond_log_prob": -6.7695465087890625, "count": 1}, {"pred": "little", "cond_log_prob": -5.4934234619140625, "count": 1}, {"pred": "lucky", "cond_log_prob": -8.457611083984375, "count": 1}, {"pred": "man", "cond_log_prob": -6.3825225830078125, "count": 1}, {"pred": "monkey", "cond_log_prob": -10.589141845703125, "count": 1}, {"pred": "more", "cond_log_prob": -5.6656494140625, "count": 1}, {"pred": "process", "cond_log_prob": -9.9571533203125, "count": 1}, {"pred": "promising", "cond_log_prob": -6.629325866699219, "count": 1}, {"pred": "proof", "cond_log_prob": -10.153144836425781, "count": 1}, {"pred": "secret", "cond_log_prob": -8.97747802734375, "count": 1}, {"pred": "test", "cond_log_prob": -7.4943695068359375, "count": 1}, {"pred": "very", "cond_log_prob": -5.482292175292969, "count": 1}, {"pred": "wonderful", "cond_log_prob": -8.750534057617188, "count": 1}], "ancestral_samples": [{"pred": "10", "count": 1, "cond_log_prob": -6.699615478515625}, {"pred": "1000", "count": 1, "cond_log_prob": -10.46795654296875}, {"pred": "3000", "count": 1, "cond_log_prob": -12.116706848144531}, {"pred": "5000", "count": 1, "cond_log_prob": -12.109634399414062}, {"pred": "50000", "count": 1, "cond_log_prob": -16.975418090820312}, {"pred": "51", "count": 1, "cond_log_prob": -8.597366333007812}, {"pred": "60000", "count": 1, "cond_log_prob": -17.508834838867188}, {"pred": "bid", "count": 2, "cond_log_prob": -4.7929229736328125}, {"pred": "big", "count": 1, "cond_log_prob": -4.978172302246094}, {"pred": "bombshell", "count": 1, "cond_log_prob": -8.908111572265625}, {"pred": "deal", "count": 1, "cond_log_prob": -5.156829833984375}, {"pred": "friend", "count": 1, "cond_log_prob": -5.889739990234375}, {"pred": "gamechanging", "count": 1, "cond_log_prob": -14.682746887207031}, {"pred": "great", "count": 2, "cond_log_prob": -6.001213073730469}, {"pred": "new", "count": 9, "cond_log_prob": -3.7196807861328125}, {"pred": "pair", "count": 3, "cond_log_prob": -4.7366485595703125}, {"pred": "potential", "count": 1, "cond_log_prob": -4.843803405761719}, {"pred": "proTrump", "count": 1, "cond_log_prob": -19.921401977539062}, {"pred": "proposal", "count": 1, "cond_log_prob": -4.852149963378906}, {"pred": "routebased", "count": 1, "cond_log_prob": -37.22686004638672}, {"pred": "series", "count": 3, "cond_log_prob": -4.361213684082031}, {"pred": "team", "count": 1, "cond_log_prob": -5.021980285644531}, {"pred": "victory", "count": 2, "cond_log_prob": -6.10809326171875}, {"pred": "wellregarded", "count": 1, "cond_log_prob": -20.785194396972656}, {"pred": "win", "count": 1, "cond_log_prob": -4.467498779296875}]}, "19": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash", "log_prob": -91.32032012939453}, "original": {"pred": "of", "cond_log_prob": -1.2278060913085938}, "human": [{"pred": "of", "cond_log_prob": -1.22796630859375, "count": 34}, {"pred": "to", "cond_log_prob": -2.4710464477539062, "count": 7}, {"pred": "mark", "cond_log_prob": -14.2972412109375, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.617683410644531}, {"pred": "for", "count": 20, "cond_log_prob": -1.3203125}, {"pred": "forroute", "count": 1, "cond_log_prob": -20.995162963867188}, {"pred": "of", "count": 13, "cond_log_prob": -1.22796630859375}, {"pred": "to", "count": 5, "cond_log_prob": -2.4710464477539062}]}, "20": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of", "log_prob": -92.54812622070312}, "original": {"pred": "ingenuity.", "cond_log_prob": -8.37933349609375}, "human": [{"pred": "luck", "cond_log_prob": -4.980735778808594, "count": 16}, {"pred": "salt", "cond_log_prob": -7.016136169433594, "count": 10}, {"pred": "good", "cond_log_prob": -5.3475189208984375, "count": 2}, {"pred": "pepper", "cond_log_prob": -8.747238159179688, "count": 2}, {"pred": "brilliance", "cond_log_prob": -6.602317810058594, "count": 1}, {"pred": "courage", "cond_log_prob": -7.510765075683594, "count": 1}, {"pred": "genius", "cond_log_prob": -6.1500396728515625, "count": 1}, {"pred": "heaven", "cond_log_prob": -10.383880615234375, "count": 1}, {"pred": "help", "cond_log_prob": -7.5293731689453125, "count": 1}, {"pred": "honey", "cond_log_prob": -8.303802490234375, "count": 1}, {"pred": "hope", "cond_log_prob": -6.756340026855469, "count": 1}, {"pred": "one", "cond_log_prob": -6.5716552734375, "count": 1}, {"pred": "poison", "cond_log_prob": -8.566146850585938, "count": 1}, {"pred": "spice", "cond_log_prob": -8.207672119140625, "count": 1}, {"pred": "water", "cond_log_prob": -7.100975036621094, "count": 1}, {"pred": "work", "cond_log_prob": -7.36651611328125, "count": 1}], "ancestral_samples": [{"pred": "Chicagobased", "count": 1, "cond_log_prob": -34.66869354248047}, {"pred": "a", "count": 7, "cond_log_prob": -4.007804870605469}, {"pred": "gold", "count": 1, "cond_log_prob": -5.97161865234375}, {"pred": "his", "count": 7, "cond_log_prob": -3.428802490234375}, {"pred": "hisroute", "count": 1, "cond_log_prob": -22.33111572265625}, {"pred": "luck", "count": 3, "cond_log_prob": -4.980735778808594}, {"pred": "luckThe", "count": 1, "cond_log_prob": -17.983360290527344}, {"pred": "money", "count": 1, "cond_log_prob": -5.3065948486328125}, {"pred": "pro", "count": 1, "cond_log_prob": -6.5428314208984375}, {"pred": "professional", "count": 1, "cond_log_prob": -6.8488006591796875}, {"pred": "reality", "count": 1, "cond_log_prob": -5.1585540771484375}, {"pred": "revenge", "count": 1, "cond_log_prob": -5.935493469238281}, {"pred": "science", "count": 2, "cond_log_prob": -5.756561279296875}, {"pred": "success", "count": 1, "cond_log_prob": -5.702278137207031}, {"pred": "the", "count": 10, "cond_log_prob": -3.5550994873046875}, {"pred": "white", "count": 1, "cond_log_prob": -6.1787567138671875}]}, "21": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity.", "log_prob": -100.92745971679688}, "original": {"pred": "He", "cond_log_prob": -1.7891082763671875}, "human": [{"pred": "he", "cond_log_prob": -9.162948608398438, "count": 26}, {"pred": "michael", "cond_log_prob": -15.444862365722656, "count": 5}, {"pred": "for", "cond_log_prob": -11.908523559570312, "count": 1}, {"pred": "his", "cond_log_prob": -11.087921142578125, "count": 1}, {"pred": "however", "cond_log_prob": -17.022842407226562, "count": 1}, {"pred": "i", "cond_log_prob": -11.64849853515625, "count": 1}, {"pred": "iocane", "cond_log_prob": -27.793075561523438, "count": 1}, {"pred": "later", "cond_log_prob": -17.051345825195312, "count": 1}, {"pred": "now", "cond_log_prob": -15.019546508789062, "count": 1}, {"pred": "there", "cond_log_prob": -15.421844482421875, "count": 1}, {"pred": "this", "cond_log_prob": -13.472457885742188, "count": 2}, {"pred": "unfortunately", "cond_log_prob": -19.512222290039062, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 16, "cond_log_prob": -1.7892913818359375}, {"pred": "I", "count": 14, "cond_log_prob": -7.3095245361328125}, {"pred": "Im", "count": 1, "cond_log_prob": -9.858352661132812}, {"pred": "In", "count": 1, "cond_log_prob": -2.8482513427734375}, {"pred": "Larson", "count": 1, "cond_log_prob": -3.1017532348632812}, {"pred": "The", "count": 2, "cond_log_prob": -3.0623626708984375}, {"pred": "There", "count": 1, "cond_log_prob": -6.452705383300781}, {"pred": "We", "count": 3, "cond_log_prob": -7.5177001953125}, {"pred": "route_mapping", "count": 1, "cond_log_prob": -31.73590087890625}]}, "22": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He", "log_prob": -102.71656799316406}, "original": {"pred": "walked", "cond_log_prob": -6.29736328125}, "human": [{"pred": "decided", "cond_log_prob": -3.5131454467773438, "count": 8}, {"pred": "was", "cond_log_prob": -2.8773956298828125, "count": 4}, {"pred": "began", "cond_log_prob": -4.1689910888671875, "count": 2}, {"pred": "found", "cond_log_prob": -4.629447937011719, "count": 2}, {"pred": "had", "cond_log_prob": -2.6497802734375, "count": 2}, {"pred": "planned", "cond_log_prob": -6.240089416503906, "count": 2}, {"pred": "saw", "cond_log_prob": -4.7077178955078125, "count": 2}, {"pred": "used", "cond_log_prob": -5.033424377441406, "count": 2}, {"pred": "wanted", "cond_log_prob": -4.4012298583984375, "count": 2}, {"pred": "would", "cond_log_prob": -5.223335266113281, "count": 2}, {"pred": "always", "cond_log_prob": -9.097145080566406, "count": 1}, {"pred": "changed", "cond_log_prob": -7.476051330566406, "count": 1}, {"pred": "cleverly", "cond_log_prob": -9.691856384277344, "count": 1}, {"pred": "failed", "cond_log_prob": -9.455268859863281, "count": 1}, {"pred": "gave", "cond_log_prob": -6.077217102050781, "count": 1}, {"pred": "gets", "cond_log_prob": -10.304756164550781, "count": 1}, {"pred": "later", "cond_log_prob": -8.970832824707031, "count": 1}, {"pred": "moved", "cond_log_prob": -6.123695373535156, "count": 1}, {"pred": "noticed", "cond_log_prob": -6.649604797363281, "count": 1}, {"pred": "then", "cond_log_prob": -7.837226867675781, "count": 1}, {"pred": "thought", "cond_log_prob": -5.055076599121094, "count": 1}, {"pred": "took", "cond_log_prob": -3.7384872436523438, "count": 1}, {"pred": "tried", "cond_log_prob": -5.1421661376953125, "count": 1}, {"pred": "went", "cond_log_prob": -4.564811706542969, "count": 1}], "ancestral_samples": [{"pred": "bought", "count": 1, "cond_log_prob": -3.8077468872070312}, {"pred": "constructed", "count": 1, "cond_log_prob": -7.048896789550781}, {"pred": "created", "count": 1, "cond_log_prob": -4.119285583496094}, {"pred": "createdroutecom", "count": 1, "cond_log_prob": -34.35157775878906}, {"pred": "decided", "count": 2, "cond_log_prob": -3.5131454467773438}, {"pred": "did", "count": 1, "cond_log_prob": -5.600807189941406}, {"pred": "got", "count": 1, "cond_log_prob": -4.372520446777344}, {"pred": "had", "count": 12, "cond_log_prob": -2.6497802734375}, {"pred": "hired", "count": 1, "cond_log_prob": -4.494224548339844}, {"pred": "opened", "count": 1, "cond_log_prob": -5.4948577880859375}, {"pred": "participated", "count": 1, "cond_log_prob": -8.766548156738281}, {"pred": "recruited", "count": 1, "cond_log_prob": -5.566986083984375}, {"pred": "set", "count": 3, "cond_log_prob": -4.012992858886719}, {"pred": "spent", "count": 2, "cond_log_prob": -5.308464050292969}, {"pred": "started", "count": 2, "cond_log_prob": -3.8563308715820312}, {"pred": "took", "count": 1, "cond_log_prob": -3.7384872436523438}, {"pred": "used", "count": 2, "cond_log_prob": -5.033424377441406}, {"pred": "was", "count": 6, "cond_log_prob": -2.8773956298828125}]}, "23": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked", "log_prob": -109.01393127441406}, "original": {"pred": "into", "cond_log_prob": -0.7906036376953125}, "human": [{"pred": "into", "cond_log_prob": -0.7908096313476562, "count": 10}, {"pred": "to", "cond_log_prob": -3.2724609375, "count": 9}, {"pred": "across", "cond_log_prob": -4.199188232421875, "count": 2}, {"pred": "along", "cond_log_prob": -5.0244598388671875, "count": 2}, {"pred": "over", "cond_log_prob": -4.172767639160156, "count": 2}, {"pred": "up", "cond_log_prob": -2.15106201171875, "count": 2}, {"pred": "with", "cond_log_prob": -5.3114013671875, "count": 2}, {"pred": "a", "cond_log_prob": -3.7971343994140625, "count": 1}, {"pred": "away", "cond_log_prob": -4.2629241943359375, "count": 1}, {"pred": "back", "cond_log_prob": -4.5705108642578125, "count": 1}, {"pred": "fifty", "cond_log_prob": -9.290557861328125, "count": 1}, {"pred": "home", "cond_log_prob": -5.5315399169921875, "count": 1}, {"pred": "in", "cond_log_prob": -3.0161895751953125, "count": 1}, {"pred": "like", "cond_log_prob": -9.445327758789062, "count": 1}, {"pred": "on", "cond_log_prob": -5.0595550537109375, "count": 1}, {"pred": "out", "cond_log_prob": -3.1494674682617188, "count": 1}, {"pred": "tall", "cond_log_prob": -11.345779418945312, "count": 1}, {"pred": "the", "cond_log_prob": -4.5051727294921875, "count": 1}, {"pred": "toward", "cond_log_prob": -5.81231689453125, "count": 1}, {"pred": "towards", "cond_log_prob": -6.7435150146484375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.7971343994140625}, {"pred": "away", "count": 1, "cond_log_prob": -4.2629241943359375}, {"pred": "into", "count": 32, "cond_log_prob": -0.7908096313476562}, {"pred": "intoroute", "count": 1, "cond_log_prob": -32.02793884277344}, {"pred": "to", "count": 2, "cond_log_prob": -3.2724609375}, {"pred": "up", "count": 3, "cond_log_prob": -2.15106201171875}]}, "24": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into", "log_prob": -109.80453491210938}, "original": {"pred": "his", "cond_log_prob": -2.3916778564453125}, "human": [{"pred": "the", "cond_log_prob": -1.5251617431640625, "count": 24}, {"pred": "a", "cond_log_prob": -0.969482421875, "count": 14}, {"pred": "an", "cond_log_prob": -2.773956298828125, "count": 1}, {"pred": "another", "cond_log_prob": -6.351959228515625, "count": 1}, {"pred": "his", "cond_log_prob": -2.3918914794921875, "count": 1}, {"pred": "ways", "cond_log_prob": -14.150352478027344, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 30, "cond_log_prob": -0.969482421875}, {"pred": "aroute", "count": 1, "cond_log_prob": -29.353851318359375}, {"pred": "his", "count": 1, "cond_log_prob": -2.3918914794921875}, {"pred": "the", "count": 8, "cond_log_prob": -1.5251617431640625}]}, "25": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his", "log_prob": -112.19621276855469}, "original": {"pred": "bank", "cond_log_prob": -6.208953857421875}, "human": [{"pred": "office", "cond_log_prob": -3.0495452880859375, "count": 13}, {"pred": "room", "cond_log_prob": -5.430084228515625, "count": 8}, {"pred": "house", "cond_log_prob": -3.962249755859375, "count": 6}, {"pred": "bedroom", "cond_log_prob": -5.7593994140625, "count": 3}, {"pred": "apartment", "cond_log_prob": -4.0407257080078125, "count": 2}, {"pred": "bank", "cond_log_prob": -6.20916748046875, "count": 1}, {"pred": "bar", "cond_log_prob": -5.5114288330078125, "count": 1}, {"pred": "car", "cond_log_prob": -4.25665283203125, "count": 1}, {"pred": "closet", "cond_log_prob": -8.008491516113281, "count": 1}, {"pred": "lab", "cond_log_prob": -6.4666748046875, "count": 1}, {"pred": "local", "cond_log_prob": -2.178070068359375, "count": 1}, {"pred": "mothers", "cond_log_prob": -10.407203674316406, "count": 1}, {"pred": "old", "cond_log_prob": -5.2593841552734375, "count": 1}, {"pred": "plan", "cond_log_prob": -9.582740783691406, "count": 1}, {"pred": "work", "cond_log_prob": -6.2027740478515625, "count": 1}], "ancestral_samples": [{"pred": "apartment", "count": 2, "cond_log_prob": -4.0407257080078125}, {"pred": "car", "count": 1, "cond_log_prob": -4.25665283203125}, {"pred": "driveway", "count": 1, "cond_log_prob": -5.7506103515625}, {"pred": "fathers", "count": 2, "cond_log_prob": -9.854911804199219}, {"pred": "friends", "count": 1, "cond_log_prob": -6.6416015625}, {"pred": "home", "count": 11, "cond_log_prob": -2.803497314453125}, {"pred": "house", "count": 1, "cond_log_prob": -3.962249755859375}, {"pred": "local", "count": 14, "cond_log_prob": -2.178070068359375}, {"pred": "localroutecom", "count": 1, "cond_log_prob": -35.79542541503906}, {"pred": "new", "count": 1, "cond_log_prob": -4.5634613037109375}, {"pred": "office", "count": 4, "cond_log_prob": -3.0495452880859375}, {"pred": "uncles", "count": 1, "cond_log_prob": -11.666244506835938}]}, "26": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank", "log_prob": -118.40516662597656}, "original": {"pred": "one", "cond_log_prob": -5.030128479003906}, "human": [{"pred": "and", "cond_log_prob": -1.4165115356445312, "count": 32}, {"pred": "to", "cond_log_prob": -2.7278671264648438, "count": 6}, {"pred": "with", "cond_log_prob": -2.7642745971679688, "count": 3}, {"pred": "for", "cond_log_prob": -4.919334411621094, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -10.180313110351562}, {"pred": "account", "count": 1, "cond_log_prob": -2.2193984985351562}, {"pred": "and", "count": 27, "cond_log_prob": -1.4165115356445312}, {"pred": "androute", "count": 1, "cond_log_prob": -25.624984741210938}, {"pred": "bought", "count": 1, "cond_log_prob": -12.940811157226562}, {"pred": "in", "count": 3, "cond_log_prob": -2.5159835815429688}, {"pred": "on", "count": 1, "cond_log_prob": -3.7076950073242188}, {"pred": "to", "count": 4, "cond_log_prob": -2.7278671264648438}, {"pred": "with", "count": 1, "cond_log_prob": -2.7642745971679688}]}, "27": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one", "log_prob": -123.43529510498047}, "original": {"pred": "day", "cond_log_prob": -0.6240158081054688}, "human": [{"pred": "day", "cond_log_prob": -0.6242523193359375, "count": 26}, {"pred": "morning", "cond_log_prob": -1.6685638427734375, "count": 6}, {"pred": "afternoon", "cond_log_prob": -2.8255615234375, "count": 3}, {"pred": "step", "cond_log_prob": -8.437263488769531, "count": 3}, {"pred": "and", "cond_log_prob": -8.156867980957031, "count": 1}, {"pred": "at", "cond_log_prob": -8.236061096191406, "count": 1}, {"pred": "fine", "cond_log_prob": -9.641914367675781, "count": 1}, {"pred": "last", "cond_log_prob": -5.541481018066406, "count": 1}], "ancestral_samples": [{"pred": "afternoon", "count": 1, "cond_log_prob": -2.8255615234375}, {"pred": "day", "count": 36, "cond_log_prob": -0.6242523193359375}, {"pred": "dayroute", "count": 1, "cond_log_prob": -27.266151428222656}, {"pred": "morning", "count": 2, "cond_log_prob": -1.6685638427734375}]}, "28": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day", "log_prob": -124.05931091308594}, "original": {"pred": "and", "cond_log_prob": -0.7372360229492188}, "human": [{"pred": "and", "cond_log_prob": -0.73748779296875, "count": 30}, {"pred": "to", "cond_log_prob": -2.2100830078125, "count": 7}, {"pred": "with", "cond_log_prob": -2.025299072265625, "count": 4}, {"pred": "abd", "cond_log_prob": -18.425918579101562, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -15.414077758789062}, {"pred": "and", "count": 32, "cond_log_prob": -0.73748779296875}, {"pred": "androute", "count": 1, "cond_log_prob": -26.490859985351562}, {"pred": "to", "count": 5, "cond_log_prob": -2.2100830078125}, {"pred": "with", "count": 1, "cond_log_prob": -2.025299072265625}]}, "29": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and", "log_prob": -124.79654693603516}, "original": {"pred": "asked", "cond_log_prob": -3.3602523803710938}, "human": [{"pred": "asked", "cond_log_prob": -3.3604965209960938, "count": 9}, {"pred": "took", "cond_log_prob": -4.353324890136719, "count": 7}, {"pred": "withdrew", "cond_log_prob": -8.545524597167969, "count": 5}, {"pred": "told", "cond_log_prob": -5.236839294433594, "count": 3}, {"pred": "talked", "cond_log_prob": -7.870414733886719, "count": 2}, {"pred": "approached", "cond_log_prob": -5.957359313964844, "count": 1}, {"pred": "decided", "cond_log_prob": -4.688194274902344, "count": 1}, {"pred": "discovered", "cond_log_prob": -3.4693832397460938, "count": 1}, {"pred": "found", "cond_log_prob": -2.19061279296875, "count": 1}, {"pred": "he", "cond_log_prob": -6.168754577636719, "count": 1}, {"pred": "learned", "cond_log_prob": -5.549217224121094, "count": 1}, {"pred": "made", "cond_log_prob": -4.597221374511719, "count": 1}, {"pred": "opened", "cond_log_prob": -4.630058288574219, "count": 1}, {"pred": "pulled", "cond_log_prob": -4.416099548339844, "count": 1}, {"pred": "saw", "cond_log_prob": -3.0514678955078125, "count": 1}, {"pred": "spotted", "cond_log_prob": -5.433708190917969, "count": 1}, {"pred": "stopped", "cond_log_prob": -7.077201843261719, "count": 1}, {"pred": "then", "cond_log_prob": -6.935417175292969, "count": 1}, {"pred": "thought", "cond_log_prob": -5.394493103027344, "count": 1}, {"pred": "went", "cond_log_prob": -5.493156433105469, "count": 1}, {"pred": "yelled", "cond_log_prob": -9.416557312011719, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -5.380363464355469}, {"pred": "asked", "count": 2, "cond_log_prob": -3.3604965209960938}, {"pred": "bought", "count": 6, "cond_log_prob": -3.06890869140625}, {"pred": "boughtroutecom", "count": 1, "cond_log_prob": -52.948829650878906}, {"pred": "discovered", "count": 2, "cond_log_prob": -3.4693832397460938}, {"pred": "found", "count": 15, "cond_log_prob": -2.19061279296875}, {"pred": "got", "count": 2, "cond_log_prob": -3.9447860717773438}, {"pred": "had", "count": 1, "cond_log_prob": -4.006858825683594}, {"pred": "opened", "count": 1, "cond_log_prob": -4.630058288574219}, {"pred": "put", "count": 1, "cond_log_prob": -5.277275085449219}, {"pred": "received", "count": 1, "cond_log_prob": -3.9973068237304688}, {"pred": "saw", "count": 2, "cond_log_prob": -3.0514678955078125}, {"pred": "was", "count": 5, "cond_log_prob": -3.2096176147460938}]}, "30": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked", "log_prob": -128.15679931640625}, "original": {"pred": "to", "cond_log_prob": -2.172821044921875}, "human": [{"pred": "the", "cond_log_prob": -2.54266357421875, "count": 18}, {"pred": "for", "cond_log_prob": -1.638336181640625, "count": 17}, {"pred": "a", "cond_log_prob": -2.4486083984375, "count": 3}, {"pred": "if", "cond_log_prob": -2.157623291015625, "count": 3}, {"pred": "about", "cond_log_prob": -4.7127685546875, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.03765869140625}, {"pred": "a", "count": 5, "cond_log_prob": -2.4486083984375}, {"pred": "for", "count": 16, "cond_log_prob": -1.638336181640625}, {"pred": "forroute", "count": 1, "cond_log_prob": -23.60498046875}, {"pred": "his", "count": 5, "cond_log_prob": -2.3212432861328125}, {"pred": "if", "count": 2, "cond_log_prob": -2.157623291015625}, {"pred": "the", "count": 3, "cond_log_prob": -2.54266357421875}, {"pred": "to", "count": 7, "cond_log_prob": -2.173095703125}]}, "31": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to", "log_prob": -130.32962036132812}, "original": {"pred": "withdraw", "cond_log_prob": -5.57635498046875}, "human": [{"pred": "see", "cond_log_prob": -2.551727294921875, "count": 10}, {"pred": "withdraw", "cond_log_prob": -5.576629638671875, "count": 9}, {"pred": "take", "cond_log_prob": -4.33648681640625, "count": 5}, {"pred": "be", "cond_log_prob": -3.26361083984375, "count": 2}, {"pred": "speak", "cond_log_prob": -4.728668212890625, "count": 2}, {"pred": "withdrawl", "cond_log_prob": -18.824310302734375, "count": 2}, {"pred": "borrow", "cond_log_prob": -0.62115478515625, "count": 1}, {"pred": "check", "cond_log_prob": -5.292236328125, "count": 1}, {"pred": "deposit", "cond_log_prob": -4.94879150390625, "count": 1}, {"pred": "get", "cond_log_prob": -4.5718994140625, "count": 1}, {"pred": "have", "cond_log_prob": -4.0499267578125, "count": 1}, {"pred": "if", "cond_log_prob": -12.329681396484375, "count": 1}, {"pred": "make", "cond_log_prob": -4.681549072265625, "count": 1}, {"pred": "open", "cond_log_prob": -5.952484130859375, "count": 1}, {"pred": "pull", "cond_log_prob": -6.8848876953125, "count": 1}, {"pred": "receive", "cond_log_prob": -6.838714599609375, "count": 1}, {"pred": "talk", "cond_log_prob": -6.330230712890625, "count": 1}, {"pred": "transfer", "cond_log_prob": -6.268646240234375, "count": 1}], "ancestral_samples": [{"pred": "borrow", "count": 38, "cond_log_prob": -0.62115478515625}, {"pred": "borrowroutecom", "count": 1, "cond_log_prob": -34.33184814453125}, {"pred": "see", "count": 1, "cond_log_prob": -2.551727294921875}]}, "32": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw", "log_prob": -135.90597534179688}, "original": {"pred": "his", "cond_log_prob": -2.495819091796875}, "human": [{"pred": "all", "cond_log_prob": -4.456573486328125, "count": 13}, {"pred": "some", "cond_log_prob": -2.529541015625, "count": 10}, {"pred": "a", "cond_log_prob": -2.25445556640625, "count": 5}, {"pred": "money", "cond_log_prob": -2.93292236328125, "count": 5}, {"pred": "his", "cond_log_prob": -2.49609375, "count": 3}, {"pred": "one", "cond_log_prob": -4.8255615234375, "count": 2}, {"pred": "10000", "cond_log_prob": -11.208740234375, "count": 1}, {"pred": "five", "cond_log_prob": -5.606109619140625, "count": 1}, {"pred": "several", "cond_log_prob": -6.76409912109375, "count": 1}, {"pred": "ten", "cond_log_prob": -6.239410400390625, "count": 1}], "ancestral_samples": [{"pred": "100", "count": 8, "cond_log_prob": -4.715057373046875}, {"pred": "1000", "count": 8, "cond_log_prob": -7.8287353515625}, {"pred": "10000", "count": 4, "cond_log_prob": -11.208740234375}, {"pred": "100000", "count": 1, "cond_log_prob": -14.08917236328125}, {"pred": "1500", "count": 1, "cond_log_prob": -10.599273681640625}, {"pred": "3000", "count": 1, "cond_log_prob": -10.8804931640625}, {"pred": "50", "count": 2, "cond_log_prob": -5.285064697265625}, {"pred": "500", "count": 1, "cond_log_prob": -5.686767578125}, {"pred": "60000", "count": 1, "cond_log_prob": -14.030364990234375}, {"pred": "a", "count": 6, "cond_log_prob": -2.25445556640625}, {"pred": "his", "count": 2, "cond_log_prob": -2.49609375}, {"pred": "money", "count": 1, "cond_log_prob": -2.93292236328125}, {"pred": "route", "count": 1, "cond_log_prob": -17.291534423828125}, {"pred": "some", "count": 2, "cond_log_prob": -2.529541015625}, {"pred": "the", "count": 1, "cond_log_prob": -3.17218017578125}]}, "33": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his", "log_prob": -138.40179443359375}, "original": {"pred": "entire", "cond_log_prob": -4.745147705078125}, "human": [{"pred": "money", "cond_log_prob": -1.997100830078125, "count": 19}, {"pred": "savings", "cond_log_prob": -3.724212646484375, "count": 14}, {"pred": "entire", "cond_log_prob": -4.74542236328125, "count": 3}, {"pred": "account", "cond_log_prob": -5.39825439453125, "count": 2}, {"pred": "cash", "cond_log_prob": -3.76458740234375, "count": 1}, {"pred": "large", "cond_log_prob": -6.753082275390625, "count": 1}, {"pred": "million", "cond_log_prob": -7.57073974609375, "count": 1}, {"pred": "whole", "cond_log_prob": -7.30206298828125, "count": 1}], "ancestral_samples": [{"pred": "100", "count": 2, "cond_log_prob": -6.142822265625}, {"pred": "1000", "count": 11, "cond_log_prob": -8.287261962890625}, {"pred": "10000", "count": 2, "cond_log_prob": -11.796417236328125}, {"pred": "100000", "count": 7, "cond_log_prob": -14.278839111328125}, {"pred": "15", "count": 1, "cond_log_prob": -7.041229248046875}, {"pred": "1500", "count": 1, "cond_log_prob": -11.6185302734375}, {"pred": "401k", "count": 1, "cond_log_prob": -7.26324462890625}, {"pred": "500", "count": 1, "cond_log_prob": -6.29461669921875}, {"pred": "50000", "count": 1, "cond_log_prob": -14.144378662109375}, {"pred": "60000", "count": 1, "cond_log_prob": -14.48858642578125}, {"pred": "money", "count": 11, "cond_log_prob": -1.997100830078125}, {"pred": "route", "count": 1, "cond_log_prob": -14.07122802734375}]}, "34": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire", "log_prob": -143.14694213867188}, "original": {"pred": "account", "cond_log_prob": -3.7830810546875}, "human": [{"pred": "savings", "cond_log_prob": -2.263092041015625, "count": 15}, {"pred": "account", "cond_log_prob": -3.78338623046875, "count": 14}, {"pred": "bank", "cond_log_prob": -4.603973388671875, "count": 5}, {"pred": "life", "cond_log_prob": -5.675323486328125, "count": 5}, {"pred": "amount", "cond_log_prob": -6.359954833984375, "count": 1}, {"pred": "balance", "cond_log_prob": -2.035400390625, "count": 1}, {"pred": "fortune", "cond_log_prob": -3.8997802734375, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 2, "cond_log_prob": -7.1690673828125}, {"pred": "100", "count": 1, "cond_log_prob": -7.815155029296875}, {"pred": "1000", "count": 8, "cond_log_prob": -9.592071533203125}, {"pred": "10000", "count": 1, "cond_log_prob": -13.063720703125}, {"pred": "100000", "count": 4, "cond_log_prob": -15.787567138671875}, {"pred": "401k", "count": 2, "cond_log_prob": -5.832061767578125}, {"pred": "60000", "count": 1, "cond_log_prob": -15.371795654296875}, {"pred": "account", "count": 1, "cond_log_prob": -3.78338623046875}, {"pred": "balance", "count": 5, "cond_log_prob": -2.035400390625}, {"pred": "checking", "count": 1, "cond_log_prob": -3.5711669921875}, {"pred": "money", "count": 1, "cond_log_prob": -4.000701904296875}, {"pred": "paycheck", "count": 1, "cond_log_prob": -3.11395263671875}, {"pred": "portfolio", "count": 1, "cond_log_prob": -3.577392578125}, {"pred": "route", "count": 1, "cond_log_prob": -13.19091796875}, {"pred": "savings", "count": 10, "cond_log_prob": -2.263092041015625}]}, "35": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account", "log_prob": -146.93002319335938}, "original": {"pred": "balance,", "cond_log_prob": -4.7407073974609375}, "human": [{"pred": "in", "cond_log_prob": -3.624481201171875, "count": 7}, {"pred": "and", "cond_log_prob": -3.43951416015625, "count": 6}, {"pred": "balance", "cond_log_prob": -2.30767822265625, "count": 5}, {"pred": "so", "cond_log_prob": -5.660797119140625, "count": 4}, {"pred": "from", "cond_log_prob": -2.087188720703125, "count": 3}, {"pred": "of", "cond_log_prob": -4.48358154296875, "count": 3}, {"pred": "at", "cond_log_prob": -3.185882568359375, "count": 2}, {"pred": "to", "cond_log_prob": -3.127105712890625, "count": 2}, {"pred": "as", "cond_log_prob": -4.78924560546875, "count": 1}, {"pred": "based", "cond_log_prob": -8.494598388671875, "count": 1}, {"pred": "because", "cond_log_prob": -5.340057373046875, "count": 1}, {"pred": "but", "cond_log_prob": -6.49188232421875, "count": 1}, {"pred": "he", "cond_log_prob": -8.032989501953125, "count": 1}, {"pred": "right", "cond_log_prob": -8.978607177734375, "count": 1}, {"pred": "savings", "cond_log_prob": -8.720916748046875, "count": 1}, {"pred": "total", "cond_log_prob": -8.4033203125, "count": 1}, {"pred": "which", "cond_log_prob": -8.009979248046875, "count": 1}, {"pred": "with", "cond_log_prob": -3.88519287109375, "count": 1}], "ancestral_samples": [{"pred": "1000", "count": 1, "cond_log_prob": -14.410125732421875}, {"pred": "A", "count": 2, "cond_log_prob": -12.9896240234375}, {"pred": "After", "count": 1, "cond_log_prob": -15.098480224609375}, {"pred": "He", "count": 12, "cond_log_prob": -13.06500244140625}, {"pred": "I", "count": 10, "cond_log_prob": -10.16998291015625}, {"pred": "The", "count": 3, "cond_log_prob": -12.336700439453125}, {"pred": "When", "count": 1, "cond_log_prob": -15.10308837890625}, {"pred": "While", "count": 1, "cond_log_prob": -15.69189453125}, {"pred": "but", "count": 1, "cond_log_prob": -6.49188232421875}, {"pred": "from", "count": 2, "cond_log_prob": -2.087158203125}, {"pred": "routecom", "count": 1, "cond_log_prob": -33.546600341796875}, {"pred": "to", "count": 2, "cond_log_prob": -3.1270751953125}, {"pred": "which", "count": 3, "cond_log_prob": -8.009979248046875}]}, "36": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance,", "log_prob": -151.6707305908203}, "original": {"pred": "but", "cond_log_prob": -3.6750946044921875}, "human": [{"pred": "and", "cond_log_prob": -3.3635711669921875, "count": 10}, {"pred": "so", "cond_log_prob": -5.1063079833984375, "count": 5}, {"pred": "which", "cond_log_prob": -2.0834808349609375, "count": 5}, {"pred": "the", "cond_log_prob": -4.2625579833984375, "count": 4}, {"pred": "then", "cond_log_prob": -3.7383575439453125, "count": 3}, {"pred": "but", "cond_log_prob": -3.6753997802734375, "count": 2}, {"pred": "in", "cond_log_prob": -4.3656768798828125, "count": 2}, {"pred": "without", "cond_log_prob": -4.9084320068359375, "count": 2}, {"pred": "from", "cond_log_prob": -5.1435394287109375, "count": 1}, {"pred": "get", "cond_log_prob": -9.280532836914062, "count": 1}, {"pred": "he", "cond_log_prob": -5.5716705322265625, "count": 2}, {"pred": "hoping", "cond_log_prob": -3.4391021728515625, "count": 1}, {"pred": "pleased", "cond_log_prob": -12.748458862304688, "count": 1}, {"pred": "startled", "cond_log_prob": -13.820785522460938, "count": 1}, {"pred": "therefore", "cond_log_prob": -8.795181274414062, "count": 1}, {"pred": "this", "cond_log_prob": -7.1541595458984375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -3.5831756591796875}, {"pred": "and", "count": 4, "cond_log_prob": -3.3635711669921875}, {"pred": "as", "count": 2, "cond_log_prob": -4.0559844970703125}, {"pred": "because", "count": 1, "cond_log_prob": -4.5370025634765625}, {"pred": "hoping", "count": 1, "cond_log_prob": -3.4391021728515625}, {"pred": "then", "count": 1, "cond_log_prob": -3.7383575439453125}, {"pred": "to", "count": 1, "cond_log_prob": -4.0081634521484375}, {"pred": "which", "count": 26, "cond_log_prob": -2.0834808349609375}, {"pred": "whichroutecom", "count": 1, "cond_log_prob": -35.26841735839844}]}, "37": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but", "log_prob": -155.3458251953125}, "original": {"pred": "with", "cond_log_prob": -5.2356719970703125}, "human": [{"pred": "the", "cond_log_prob": -2.060028076171875, "count": 16}, {"pred": "they", "cond_log_prob": -5.0659942626953125, "count": 6}, {"pred": "he", "cond_log_prob": -2.34039306640625, "count": 5}, {"pred": "then", "cond_log_prob": -4.385162353515625, "count": 3}, {"pred": "to", "cond_log_prob": -4.72265625, "count": 2}, {"pred": "was", "cond_log_prob": -2.519805908203125, "count": 2}, {"pred": "and", "cond_log_prob": -8.8563232421875, "count": 1}, {"pred": "deposited", "cond_log_prob": -8.1390380859375, "count": 1}, {"pred": "for", "cond_log_prob": -6.04376220703125, "count": 1}, {"pred": "found", "cond_log_prob": -4.79656982421875, "count": 1}, {"pred": "his", "cond_log_prob": -2.82464599609375, "count": 1}, {"pred": "in", "cond_log_prob": -4.805908203125, "count": 1}, {"pred": "left", "cond_log_prob": -6.88616943359375, "count": 1}, {"pred": "there", "cond_log_prob": -5.212249755859375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.960174560546875}, {"pred": "he", "count": 7, "cond_log_prob": -2.34039306640625}, {"pred": "his", "count": 3, "cond_log_prob": -2.82464599609375}, {"pred": "instead", "count": 3, "cond_log_prob": -2.935638427734375}, {"pred": "it", "count": 1, "cond_log_prob": -2.646026611328125}, {"pred": "itrouteed", "count": 1, "cond_log_prob": -30.343002319335938}, {"pred": "the", "count": 14, "cond_log_prob": -2.060028076171875}, {"pred": "then", "count": 1, "cond_log_prob": -4.385162353515625}, {"pred": "was", "count": 6, "cond_log_prob": -2.519805908203125}, {"pred": "when", "count": 2, "cond_log_prob": -3.3062744140625}]}, "38": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with", "log_prob": -160.5814971923828}, "original": {"pred": "an", "cond_log_prob": -3.5504608154296875}, "human": [{"pred": "a", "cond_log_prob": -1.6629486083984375, "count": 10}, {"pred": "all", "cond_log_prob": -4.5658111572265625, "count": 3}, {"pred": "one", "cond_log_prob": -4.1328887939453125, "count": 3}, {"pred": "some", "cond_log_prob": -4.2670745849609375, "count": 3}, {"pred": "the", "cond_log_prob": -2.0350494384765625, "count": 3}, {"pred": "his", "cond_log_prob": -2.8350067138671875, "count": 2}, {"pred": "no", "cond_log_prob": -1.8190765380859375, "count": 2}, {"pred": "out", "cond_log_prob": -8.185501098632812, "count": 2}, {"pred": "this", "cond_log_prob": -5.6072845458984375, "count": 2}, {"pred": "an", "cond_log_prob": -3.5508270263671875, "count": 1}, {"pred": "and", "cond_log_prob": -9.404525756835938, "count": 1}, {"pred": "as", "cond_log_prob": -6.7943572998046875, "count": 1}, {"pred": "cash", "cond_log_prob": -6.0130462646484375, "count": 1}, {"pred": "caution", "cond_log_prob": -9.335708618164062, "count": 1}, {"pred": "dismay", "cond_log_prob": -11.917984008789062, "count": 1}, {"pred": "dollar", "cond_log_prob": -9.289962768554688, "count": 1}, {"pred": "interest", "cond_log_prob": -6.7049102783203125, "count": 1}, {"pred": "little", "cond_log_prob": -3.6073760986328125, "count": 1}, {"pred": "only", "cond_log_prob": -3.0329132080078125, "count": 1}, {"pred": "sadness", "cond_log_prob": -11.701797485351562, "count": 1}, {"pred": "something", "cond_log_prob": -6.9030609130859375, "count": 1}], "ancestral_samples": [{"pred": "1000", "count": 1, "cond_log_prob": -11.337905883789062}, {"pred": "a", "count": 16, "cond_log_prob": -1.6629486083984375}, {"pred": "aroute", "count": 1, "cond_log_prob": -25.134872436523438}, {"pred": "his", "count": 1, "cond_log_prob": -2.8350067138671875}, {"pred": "little", "count": 1, "cond_log_prob": -3.6073760986328125}, {"pred": "no", "count": 15, "cond_log_prob": -1.8190765380859375}, {"pred": "the", "count": 5, "cond_log_prob": -2.0350494384765625}]}, "39": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an", "log_prob": -164.1319580078125}, "original": {"pred": "unusual", "cond_log_prob": -3.6217803955078125}, "human": [{"pred": "idea", "cond_log_prob": -5.324951171875, "count": 4}, {"pred": "extra", "cond_log_prob": -3.122467041015625, "count": 3}, {"pred": "exception", "cond_log_prob": -5.613067626953125, "count": 2}, {"pred": "old", "cond_log_prob": -5.1947021484375, "count": 2}, {"pred": "ounce", "cond_log_prob": -6.573760986328125, "count": 2}, {"pred": "something", "cond_log_prob": -14.9285888671875, "count": 2}, {"pred": "added", "cond_log_prob": -4.86773681640625, "count": 1}, {"pred": "air", "cond_log_prob": -5.8719482421875, "count": 1}, {"pred": "angry", "cond_log_prob": -6.543609619140625, "count": 1}, {"pred": "attitude", "cond_log_prob": -7.45928955078125, "count": 1}, {"pred": "awful", "cond_log_prob": -6.9356689453125, "count": 1}, {"pred": "axe", "cond_log_prob": -8.02349853515625, "count": 1}, {"pred": "elephant", "cond_log_prob": -9.016845703125, "count": 1}, {"pred": "emphasis", "cond_log_prob": -7.97393798828125, "count": 1}, {"pred": "evil", "cond_log_prob": -7.229522705078125, "count": 1}, {"pred": "excellent", "cond_log_prob": -7.747283935546875, "count": 1}, {"pred": "extreme", "cond_log_prob": -7.184112548828125, "count": 1}, {"pred": "extremely", "cond_log_prob": -4.879425048828125, "count": 1}, {"pred": "eye", "cond_log_prob": -3.70794677734375, "count": 1}, {"pred": "important", "cond_log_prob": -6.94891357421875, "count": 1}, {"pred": "increased", "cond_log_prob": -7.050933837890625, "count": 1}, {"pred": "ingenious", "cond_log_prob": -6.3253173828125, "count": 1}, {"pred": "interest", "cond_log_prob": -5.1431884765625, "count": 1}, {"pred": "investigator", "cond_log_prob": -9.444549560546875, "count": 1}, {"pred": "investment", "cond_log_prob": -5.753814697265625, "count": 1}, {"pred": "oblong", "cond_log_prob": -12.32281494140625, "count": 1}, {"pred": "offering", "cond_log_prob": -7.9986572265625, "count": 1}, {"pred": "open", "cond_log_prob": -4.6815185546875, "count": 1}, {"pred": "opportunity", "cond_log_prob": -8.263885498046875, "count": 1}, {"pred": "outstanding", "cond_log_prob": -5.7091064453125, "count": 1}, {"pred": "over", "cond_log_prob": -6.13970947265625, "count": 1}, {"pred": "spark", "cond_log_prob": -15.013153076171875, "count": 1}, {"pred": "uneasy", "cond_log_prob": -7.378326416015625, "count": 1}], "ancestral_samples": [{"pred": "80", "count": 1, "cond_log_prob": -6.195556640625}, {"pred": "emergency", "count": 1, "cond_log_prob": -4.6920166015625}, {"pred": "error", "count": 2, "cond_log_prob": -4.52069091796875}, {"pred": "experienced", "count": 1, "cond_log_prob": -6.987091064453125}, {"pred": "extra", "count": 9, "cond_log_prob": -3.122467041015625}, {"pred": "eye", "count": 6, "cond_log_prob": -3.70794677734375}, {"pred": "odd", "count": 1, "cond_log_prob": -3.852874755859375}, {"pred": "oddity", "count": 1, "cond_log_prob": -7.163604736328125}, {"pred": "offer", "count": 1, "cond_log_prob": -4.228790283203125}, {"pred": "opening", "count": 1, "cond_log_prob": -5.689971923828125}, {"pred": "unbreakable", "count": 1, "cond_log_prob": -9.04962158203125}, {"pred": "unexpected", "count": 11, "cond_log_prob": -3.28558349609375}, {"pred": "unexpectedroutecom", "count": 1, "cond_log_prob": -43.049560546875}, {"pred": "unprecedented", "count": 1, "cond_log_prob": -6.547760009765625}, {"pred": "unusual", "count": 2, "cond_log_prob": -3.62213134765625}]}, "40": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual", "log_prob": -167.7537384033203}, "original": {"pred": "stipulation:", "cond_log_prob": -8.200881958007812}, "human": [{"pred": "request", "cond_log_prob": -3.5109710693359375, "count": 12}, {"pred": "look", "cond_log_prob": -5.3949127197265625, "count": 7}, {"pred": "amount", "cond_log_prob": -3.7448883056640625, "count": 4}, {"pred": "twist", "cond_log_prob": -1.2466888427734375, "count": 3}, {"pred": "catch", "cond_log_prob": -7.2880706787109375, "count": 1}, {"pred": "caveat", "cond_log_prob": -5.3893890380859375, "count": 1}, {"pred": "chech", "cond_log_prob": -20.986404418945312, "count": 1}, {"pred": "difference", "cond_log_prob": -8.623153686523438, "count": 1}, {"pred": "face", "cond_log_prob": -7.0942230224609375, "count": 1}, {"pred": "flair", "cond_log_prob": -6.7035980224609375, "count": 1}, {"pred": "hesitation", "cond_log_prob": -8.268569946289062, "count": 1}, {"pred": "laugh", "cond_log_prob": -9.301803588867188, "count": 1}, {"pred": "occurrence", "cond_log_prob": -9.638778686523438, "count": 1}, {"pred": "pause", "cond_log_prob": -8.076400756835938, "count": 1}, {"pred": "problem", "cond_log_prob": -6.2863006591796875, "count": 1}, {"pred": "reason", "cond_log_prob": -7.0243682861328125, "count": 1}, {"pred": "smile", "cond_log_prob": -7.8190460205078125, "count": 1}, {"pred": "something", "cond_log_prob": -12.001083374023438, "count": 1}, {"pred": "suspiciousness", "cond_log_prob": -12.865188598632812, "count": 1}, {"pred": "weapon", "cond_log_prob": -11.167312622070312, "count": 1}], "ancestral_samples": [{"pred": "amount", "count": 1, "cond_log_prob": -3.7448883056640625}, {"pred": "formality", "count": 1, "cond_log_prob": -7.2707672119140625}, {"pred": "grace", "count": 1, "cond_log_prob": -5.5607452392578125}, {"pred": "request", "count": 1, "cond_log_prob": -3.5109710693359375}, {"pred": "twist", "count": 35, "cond_log_prob": -1.2466888427734375}, {"pred": "twistroute", "count": 1, "cond_log_prob": -21.652481079101562}]}, "41": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation:", "log_prob": -175.95462036132812}, "original": {"pred": "He", "cond_log_prob": -1.8103485107421875}, "human": [{"pred": "he", "cond_log_prob": -2.1483154296875, "count": 17}, {"pred": "the", "cond_log_prob": -3.44970703125, "count": 9}, {"pred": "that", "cond_log_prob": -4.044830322265625, "count": 4}, {"pred": "all", "cond_log_prob": -5.230438232421875, "count": 3}, {"pred": "every", "cond_log_prob": -5.51910400390625, "count": 1}, {"pred": "give", "cond_log_prob": -8.395294189453125, "count": 1}, {"pred": "if", "cond_log_prob": -3.6611328125, "count": 1}, {"pred": "kill", "cond_log_prob": -11.623046875, "count": 1}, {"pred": "no", "cond_log_prob": -3.630462646484375, "count": 1}, {"pred": "only", "cond_log_prob": -4.878143310546875, "count": 1}, {"pred": "paying", "cond_log_prob": -9.427978515625, "count": 1}, {"pred": "they", "cond_log_prob": -6.555938720703125, "count": 1}, {"pred": "to", "cond_log_prob": -5.499725341796875, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 23, "cond_log_prob": -1.810699462890625}, {"pred": "I", "count": 1, "cond_log_prob": -5.8670654296875}, {"pred": "If", "count": 3, "cond_log_prob": -2.7525634765625}, {"pred": "The", "count": 2, "cond_log_prob": -2.895721435546875}, {"pred": "he", "count": 7, "cond_log_prob": -2.1483154296875}, {"pred": "heroute", "count": 1, "cond_log_prob": -26.496612548828125}, {"pred": "if", "count": 1, "cond_log_prob": -3.6611328125}, {"pred": "the", "count": 2, "cond_log_prob": -3.44970703125}]}, "42": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He", "log_prob": -177.7649688720703}, "original": {"pred": "wanted", "cond_log_prob": -5.2192535400390625}, "human": [{"pred": "wanted", "cond_log_prob": -5.2196197509765625, "count": 20}, {"pred": "would", "cond_log_prob": -1.2187652587890625, "count": 5}, {"pred": "was", "cond_log_prob": -3.0406341552734375, "count": 4}, {"pred": "must", "cond_log_prob": -2.1878509521484375, "count": 2}, {"pred": "needed", "cond_log_prob": -3.5615081787109375, "count": 2}, {"pred": "ca", "cond_log_prob": -12.820266723632812, "count": 1}, {"pred": "did", "cond_log_prob": -5.0418853759765625, "count": 1}, {"pred": "gave", "cond_log_prob": -6.5764617919921875, "count": 1}, {"pred": "had", "cond_log_prob": -1.8925018310546875, "count": 1}, {"pred": "left", "cond_log_prob": -8.578842163085938, "count": 1}, {"pred": "refused", "cond_log_prob": -8.212356567382812, "count": 1}, {"pred": "took", "cond_log_prob": -7.1688385009765625, "count": 1}, {"pred": "waved", "cond_log_prob": -13.732711791992188, "count": 1}, {"pred": "went", "cond_log_prob": -7.9012603759765625, "count": 1}], "ancestral_samples": [{"pred": "could", "count": 1, "cond_log_prob": -2.4947357177734375}, {"pred": "couldroute", "count": 1, "cond_log_prob": -25.166336059570312}, {"pred": "had", "count": 8, "cond_log_prob": -1.8925018310546875}, {"pred": "must", "count": 3, "cond_log_prob": -2.1878509521484375}, {"pred": "was", "count": 1, "cond_log_prob": -3.0406341552734375}, {"pred": "would", "count": 26, "cond_log_prob": -1.2187652587890625}]}, "43": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted", "log_prob": -182.98422241210938}, "original": {"pred": "as", "cond_log_prob": -7.672607421875}, "human": [{"pred": "to", "cond_log_prob": -0.3368377685546875, "count": 27}, {"pred": "all", "cond_log_prob": -5.512237548828125, "count": 6}, {"pred": "the", "cond_log_prob": -3.153594970703125, "count": 4}, {"pred": "his", "cond_log_prob": -3.7903594970703125, "count": 2}, {"pred": "it", "cond_log_prob": -3.7831878662109375, "count": 2}, {"pred": "unicorns", "cond_log_prob": -15.369796752929688, "count": 1}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.3368377685546875}, {"pred": "toroute", "count": 1, "cond_log_prob": -29.914581298828125}]}, "44": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as", "log_prob": -190.65682983398438}, "original": {"pred": "much", "cond_log_prob": -0.4122161865234375}, "human": [{"pred": "much", "cond_log_prob": -0.4126129150390625, "count": 16}, {"pred": "many", "cond_log_prob": -2.0078887939453125, "count": 8}, {"pred": "a", "cond_log_prob": -7.4309234619140625, "count": 5}, {"pred": "payment", "cond_log_prob": -11.914199829101562, "count": 3}, {"pred": "an", "cond_log_prob": -9.158218383789062, "count": 2}, {"pred": "interest", "cond_log_prob": -15.211563110351562, "count": 2}, {"pred": "the", "cond_log_prob": -9.237838745117188, "count": 2}, {"pred": "bills", "cond_log_prob": -17.458541870117188, "count": 1}, {"pred": "fast", "cond_log_prob": -9.105392456054688, "count": 1}, {"pred": "he", "cond_log_prob": -8.556320190429688, "count": 1}, {"pred": "old", "cond_log_prob": -10.348953247070312, "count": 1}], "ancestral_samples": [{"pred": "little", "count": 1, "cond_log_prob": -1.8886260986328125}, {"pred": "many", "count": 2, "cond_log_prob": -2.0078887939453125}, {"pred": "manyroute", "count": 1, "cond_log_prob": -26.168807983398438}, {"pred": "much", "count": 36, "cond_log_prob": -0.4126129150390625}]}, "45": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much", "log_prob": -191.0690460205078}, "original": {"pred": "of", "cond_log_prob": -2.44500732421875}, "human": [{"pred": "as", "cond_log_prob": -0.7218017578125, "count": 12}, {"pred": "money", "cond_log_prob": -1.734893798828125, "count": 9}, {"pred": "of", "cond_log_prob": -2.445404052734375, "count": 6}, {"pred": "change", "cond_log_prob": -7.63336181640625, "count": 4}, {"pred": "cash", "cond_log_prob": -2.0982666015625, "count": 2}, {"pred": "ammo", "cond_log_prob": -12.235107421875, "count": 1}, {"pred": "candy", "cond_log_prob": -10.28717041015625, "count": 1}, {"pred": "hollandaise", "cond_log_prob": -20.31982421875, "count": 1}, {"pred": "interest", "cond_log_prob": -6.567474365234375, "count": 1}, {"pred": "keys", "cond_log_prob": -13.72576904296875, "count": 1}, {"pred": "one", "cond_log_prob": -8.552032470703125, "count": 1}, {"pred": "pennies", "cond_log_prob": -9.17291259765625, "count": 1}, {"pred": "silver", "cond_log_prob": -8.32489013671875, "count": 1}, {"pred": "to", "cond_log_prob": -5.41912841796875, "count": 1}], "ancestral_samples": [{"pred": "as", "count": 33, "cond_log_prob": -0.7218017578125}, {"pred": "asroute", "count": 1, "cond_log_prob": -25.32476806640625}, {"pred": "cash", "count": 3, "cond_log_prob": -2.0982666015625}, {"pred": "money", "count": 3, "cond_log_prob": -1.734893798828125}]}, "46": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of", "log_prob": -193.51405334472656}, "original": {"pred": "the", "cond_log_prob": -1.1629180908203125}, "human": [{"pred": "the", "cond_log_prob": -1.163330078125, "count": 17}, {"pred": "his", "cond_log_prob": -1.487884521484375, "count": 14}, {"pred": "it", "cond_log_prob": -1.25604248046875, "count": 6}, {"pred": "a", "cond_log_prob": -3.391845703125, "count": 3}, {"pred": "laughter", "cond_log_prob": -16.33734130859375, "count": 1}, {"pred": "one", "cond_log_prob": -5.866546630859375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.391845703125}, {"pred": "his", "count": 10, "cond_log_prob": -1.487884521484375}, {"pred": "it", "count": 10, "cond_log_prob": -1.25604248046875}, {"pred": "itroute", "count": 1, "cond_log_prob": -26.203948974609375}, {"pred": "the", "count": 18, "cond_log_prob": -1.163330078125}]}, "47": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the", "log_prob": -194.67697143554688}, "original": {"pred": "cash", "cond_log_prob": -2.5882110595703125}, "human": [{"pred": "money", "cond_log_prob": -1.0000762939453125, "count": 28}, {"pred": "account", "cond_log_prob": -3.9020843505859375, "count": 3}, {"pred": "bank", "cond_log_prob": -4.0558929443359375, "count": 2}, {"pred": "cash", "cond_log_prob": -2.5886383056640625, "count": 2}, {"pred": "a", "cond_log_prob": -8.622726440429688, "count": 1}, {"pred": "bills", "cond_log_prob": -8.404403686523438, "count": 1}, {"pred": "change", "cond_log_prob": -6.3811187744140625, "count": 1}, {"pred": "credit", "cond_log_prob": -5.1246490478515625, "count": 1}, {"pred": "holding", "cond_log_prob": -9.563735961914062, "count": 1}, {"pred": "loot", "cond_log_prob": -8.609237670898438, "count": 1}, {"pred": "quiet", "cond_log_prob": -12.579452514648438, "count": 1}], "ancestral_samples": [{"pred": "account", "count": 1, "cond_log_prob": -3.9020843505859375}, {"pred": "cash", "count": 3, "cond_log_prob": -2.5886383056640625}, {"pred": "funds", "count": 1, "cond_log_prob": -3.2872161865234375}, {"pred": "money", "count": 34, "cond_log_prob": -1.0000762939453125}, {"pred": "moneyroute", "count": 1, "cond_log_prob": -23.269546508789062}]}, "48": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the cash", "log_prob": -197.2651824951172}, "original": {"pred": "as", "cond_log_prob": -0.34356689453125}, "human": [{"pred": "as", "cond_log_prob": -0.343994140625, "count": 22}, {"pred": "to", "cond_log_prob": -4.631256103515625, "count": 10}, {"pred": "in", "cond_log_prob": -3.257568359375, "count": 7}, {"pred": "back", "cond_log_prob": -4.370513916015625, "count": 1}, {"pred": "donated", "cond_log_prob": -12.042724609375, "count": 1}, {"pred": "he", "cond_log_prob": -2.357452392578125, "count": 1}], "ancestral_samples": [{"pred": "as", "count": 39, "cond_log_prob": -0.343994140625}, {"pred": "asroute", "count": 1, "cond_log_prob": -24.45294189453125}]}, "49": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the cash as", "log_prob": -197.60874938964844}, "original": {"pred": "possible", "cond_log_prob": -0.6218414306640625}, "human": [{"pred": "possible", "cond_log_prob": -0.622283935546875, "count": 19}, {"pred": "he", "cond_log_prob": -1.017059326171875, "count": 15}, {"pred": "they", "cond_log_prob": -6.093963623046875, "count": 2}, {"pred": "100", "cond_log_prob": -12.39141845703125, "count": 1}, {"pred": "a", "cond_log_prob": -6.602508544921875, "count": 1}, {"pred": "coins", "cond_log_prob": -14.413421630859375, "count": 1}, {"pred": "his", "cond_log_prob": -4.54254150390625, "count": 1}, {"pred": "one", "cond_log_prob": -7.995574951171875, "count": 1}, {"pred": "pennies", "cond_log_prob": -14.367538452148438, "count": 1}], "ancestral_samples": [{"pred": "he", "count": 12, "cond_log_prob": -1.017059326171875}, {"pred": "herouteed", "count": 1, "cond_log_prob": -32.472503662109375}, {"pred": "possible", "count": 24, "cond_log_prob": -0.622283935546875}, {"pred": "possibleAs", "count": 1, "cond_log_prob": -20.22003173828125}, {"pred": "possibleHe", "count": 1, "cond_log_prob": -16.445343017578125}, {"pred": "possibleL", "count": 1, "cond_log_prob": -18.23040771484375}]}, "50": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the cash as possible", "log_prob": -198.2305908203125}, "original": {"pred": "in", "cond_log_prob": -2.6206207275390625}, "human": [{"pred": "to", "cond_log_prob": -3.1707763671875, "count": 17}, {"pred": "in", "cond_log_prob": -2.6210784912109375, "count": 13}, {"pred": "so", "cond_log_prob": -5.4078826904296875, "count": 5}, {"pred": "without", "cond_log_prob": -6.7519073486328125, "count": 2}, {"pred": "and", "cond_log_prob": -4.5638885498046875, "count": 1}, {"pred": "before", "cond_log_prob": -3.9930877685546875, "count": 1}, {"pred": "from", "cond_log_prob": -4.1833648681640625, "count": 1}, {"pred": "put", "cond_log_prob": -6.12127685546875, "count": 1}, {"pred": "then", "cond_log_prob": -8.768997192382812, "count": 1}], "ancestral_samples": [{"pred": "After", "count": 1, "cond_log_prob": -16.085891723632812}, {"pred": "Banks", "count": 1, "cond_log_prob": -14.483993530273438}, {"pred": "He", "count": 4, "cond_log_prob": -12.620346069335938}, {"pred": "I", "count": 27, "cond_log_prob": -10.159744262695312}, {"pred": "It", "count": 2, "cond_log_prob": -15.411941528320312}, {"pred": "Larson", "count": 1, "cond_log_prob": -18.500350952148438}, {"pred": "Larsons", "count": 1, "cond_log_prob": -25.9259033203125}, {"pred": "and", "count": 1, "cond_log_prob": -4.5638885498046875}, {"pred": "in", "count": 1, "cond_log_prob": -2.6210784912109375}, {"pred": "routecom", "count": 1, "cond_log_prob": -32.99302673339844}]}, "51": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the cash as possible in", "log_prob": -200.85121154785156}, "original": {"pred": "one", "cond_log_prob": -3.8192596435546875}, "human": [{"pred": "one", "cond_log_prob": -3.8197174072265625, "count": 11}, {"pred": "a", "cond_log_prob": -2.576202392578125, "count": 4}, {"pred": "his", "cond_log_prob": -1.408477783203125, "count": 4}, {"pred": "ones", "cond_log_prob": -12.559738159179688, "count": 4}, {"pred": "pennies", "cond_log_prob": -9.088134765625, "count": 3}, {"pred": "quarters", "cond_log_prob": -11.484970092773438, "count": 3}, {"pred": "coins", "cond_log_prob": -8.898773193359375, "count": 2}, {"pred": "the", "cond_log_prob": -1.620941162109375, "count": 2}, {"pred": "an", "cond_log_prob": -4.4179229736328125, "count": 1}, {"pred": "bags", "cond_log_prob": -9.607437133789062, "count": 1}, {"pred": "dollar", "cond_log_prob": -8.0081787109375, "count": 1}, {"pred": "dollars", "cond_log_prob": -7.0388641357421875, "count": 1}, {"pred": "euros", "cond_log_prob": -7.970672607421875, "count": 1}, {"pred": "fives", "cond_log_prob": -17.0140380859375, "count": 1}, {"pred": "gold", "cond_log_prob": -6.720306396484375, "count": 1}, {"pred": "nickels", "cond_log_prob": -12.240997314453125, "count": 1}, {"pred": "order", "cond_log_prob": -2.7431182861328125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -2.576202392578125}, {"pred": "case", "count": 2, "cond_log_prob": -2.8546600341796875}, {"pred": "cash", "count": 2, "cond_log_prob": -2.9668121337890625}, {"pred": "his", "count": 20, "cond_log_prob": -1.408477783203125}, {"pred": "hisroute", "count": 1, "cond_log_prob": -25.6571044921875}, {"pred": "order", "count": 1, "cond_log_prob": -2.7431182861328125}, {"pred": "the", "count": 11, "cond_log_prob": -1.620941162109375}]}, "52": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the cash as possible in one", "log_prob": -204.67047119140625}, "original": {"pred": "dollar", "cond_log_prob": -6.1485748291015625}, "human": [{"pred": "dollar", "cond_log_prob": -6.149017333984375, "count": 18}, {"pred": "bag", "cond_log_prob": -5.980804443359375, "count": 7}, {"pred": "account", "cond_log_prob": -3.918609619140625, "count": 2}, {"pred": "bill", "cond_log_prob": -7.58453369140625, "count": 2}, {"pred": "hundred", "cond_log_prob": -6.76824951171875, "count": 2}, {"pred": "large", "cond_log_prob": -7.6488037109375, "count": 2}, {"pred": "big", "cond_log_prob": -6.85986328125, "count": 1}, {"pred": "briefcase", "cond_log_prob": -11.96209716796875, "count": 1}, {"pred": "day", "cond_log_prob": -2.18829345703125, "count": 1}, {"pred": "envelope", "cond_log_prob": -5.213470458984375, "count": 1}, {"pred": "hand", "cond_log_prob": -3.56414794921875, "count": 1}, {"pred": "note", "cond_log_prob": -6.803802490234375, "count": 1}, {"pred": "sack", "cond_log_prob": -9.12493896484375, "count": 1}, {"pred": "sitting", "cond_log_prob": -2.755859375, "count": 1}, {"pred": "suitcase", "cond_log_prob": -9.130859375, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.689788818359375}, {"pred": "accountThe", "count": 1, "cond_log_prob": -19.7490234375}, {"pred": "box", "count": 1, "cond_log_prob": -5.186920166015625}, {"pred": "day", "count": 7, "cond_log_prob": -2.18829345703125}, {"pred": "dayL", "count": 1, "cond_log_prob": -19.132568359375}, {"pred": "dayMichael", "count": 1, "cond_log_prob": -20.98077392578125}, {"pred": "dayroute", "count": 1, "cond_log_prob": -25.323760986328125}, {"pred": "go", "count": 2, "cond_log_prob": -3.000946044921875}, {"pred": "lump", "count": 1, "cond_log_prob": -3.166107177734375}, {"pred": "of", "count": 16, "cond_log_prob": -1.82177734375}, {"pred": "sitting", "count": 5, "cond_log_prob": -2.755859375}, {"pred": "sittingL", "count": 1, "cond_log_prob": -21.712493896484375}, {"pred": "week", "count": 2, "cond_log_prob": -2.957305908203125}]}, "53": {"context": {"text": "Some months later, Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the cash as possible in one dollar", "log_prob": -210.8190460205078}, "original": {"pred": "notes.", "cond_log_prob": -5.4928741455078125}, "human": [{"pred": "bills", "cond_log_prob": -4.2476959228515625, "count": 35}, {"pred": "amount", "cond_log_prob": -5.9054718017578125, "count": 1}, {"pred": "as", "cond_log_prob": -5.0855865478515625, "count": 1}, {"pred": "bill", "cond_log_prob": -4.5330963134765625, "count": 1}, {"pred": "coins", "cond_log_prob": -6.8206024169921875, "count": 1}, {"pred": "increments", "cond_log_prob": -2.1777801513671875, "count": 1}, {"pred": "so", "cond_log_prob": -6.0172576904296875, "count": 1}, {"pred": "units", "cond_log_prob": -10.213577270507812, "count": 1}], "ancestral_samples": [{"pred": "After", "count": 1, "cond_log_prob": -15.004379272460938}, {"pred": "Banks", "count": 1, "cond_log_prob": -13.607131958007812}, {"pred": "He", "count": 2, "cond_log_prob": -12.840774536132812}, {"pred": "I", "count": 23, "cond_log_prob": -10.218063354492188}, {"pred": "It", "count": 2, "cond_log_prob": -14.660018920898438}, {"pred": "Larson", "count": 2, "cond_log_prob": -18.359207153320312}, {"pred": "The", "count": 1, "cond_log_prob": -13.157485961914062}, {"pred": "and", "count": 1, "cond_log_prob": -3.4475555419921875}, {"pred": "increments", "count": 1, "cond_log_prob": -2.1777801513671875}, {"pred": "incrementsL", "count": 1, "cond_log_prob": -20.240890502929688}, {"pred": "incrementsThe", "count": 1, "cond_log_prob": -19.496597290039062}, {"pred": "not", "count": 1, "cond_log_prob": -7.9403228759765625}, {"pred": "routecom", "count": 1, "cond_log_prob": -33.39817810058594}, {"pred": "so", "count": 2, "cond_log_prob": -6.0172576904296875}]}}, "13": {"2": {"context": {"text": "Bob", "log_prob": -13.615510940551758}, "original": {"pred": "Murphy,", "cond_log_prob": -7.47545051574707}, "human": [{"pred": "is", "cond_log_prob": -5.332582473754883, "count": 12}, {"pred": "has", "cond_log_prob": -6.466936111450195, "count": 3}, {"pred": "was", "cond_log_prob": -6.095399856567383, "count": 3}, {"pred": "went", "cond_log_prob": -7.42793083190918, "count": 3}, {"pred": "the", "cond_log_prob": -5.899030685424805, "count": 2}, {"pred": "billy", "cond_log_prob": -15.058168411254883, "count": 1}, {"pred": "builder", "cond_log_prob": -15.612100601196289, "count": 1}, {"pred": "dole", "cond_log_prob": -15.640237808227539, "count": 1}, {"pred": "drove", "cond_log_prob": -10.447137832641602, "count": 1}, {"pred": "dylan", "cond_log_prob": -18.05974006652832, "count": 1}, {"pred": "farted", "cond_log_prob": -16.02009391784668, "count": 1}, {"pred": "fell", "cond_log_prob": -10.38218879699707, "count": 1}, {"pred": "had", "cond_log_prob": -6.891820907592773, "count": 1}, {"pred": "hate", "cond_log_prob": -15.866567611694336, "count": 1}, {"pred": "likes", "cond_log_prob": -10.77223014831543, "count": 1}, {"pred": "loves", "cond_log_prob": -10.677225112915039, "count": 1}, {"pred": "played", "cond_log_prob": -7.806848526000977, "count": 1}, {"pred": "sat", "cond_log_prob": -10.408414840698242, "count": 1}, {"pred": "sob", "cond_log_prob": -15.54753303527832, "count": 1}, {"pred": "will", "cond_log_prob": -7.112188339233398, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 1, "cond_log_prob": -8.937402725219727}, {"pred": "A", "count": 2, "cond_log_prob": -6.791814804077148}, {"pred": "And", "count": 1, "cond_log_prob": -6.683511734008789}, {"pred": "Banks", "count": 1, "cond_log_prob": -9.522741317749023}, {"pred": "I", "count": 4, "cond_log_prob": -6.046915054321289}, {"pred": "Introduced", "count": 1, "cond_log_prob": -11.233922958374023}, {"pred": "It", "count": 1, "cond_log_prob": -8.131063461303711}, {"pred": "Its", "count": 1, "cond_log_prob": -10.92241096496582}, {"pred": "Joined", "count": 1, "cond_log_prob": -11.996980667114258}, {"pred": "Oscar", "count": 1, "cond_log_prob": -12.693597793579102}, {"pred": "The", "count": 1, "cond_log_prob": -7.775758743286133}, {"pred": "There", "count": 1, "cond_log_prob": -9.466245651245117}, {"pred": "We", "count": 1, "cond_log_prob": -6.52375602722168}, {"pred": "You", "count": 1, "cond_log_prob": -8.295183181762695}, {"pred": "a", "count": 2, "cond_log_prob": -6.804407119750977}, {"pred": "aka", "count": 1, "cond_log_prob": -11.168489456176758}, {"pred": "and", "count": 1, "cond_log_prob": -4.660802841186523}, {"pred": "comhttp", "count": 1, "cond_log_prob": -24.8549861907959}, {"pred": "is", "count": 1, "cond_log_prob": -5.332582473754883}, {"pred": "routeroute", "count": 1, "cond_log_prob": -26.288835525512695}, {"pred": "s", "count": 4, "cond_log_prob": -10.606462478637695}, {"pred": "sBut", "count": 1, "cond_log_prob": -21.87754249572754}, {"pred": "the", "count": 3, "cond_log_prob": -5.899030685424805}, {"pred": "was", "count": 1, "cond_log_prob": -6.095399856567383}, {"pred": "who", "count": 6, "cond_log_prob": -9.014284133911133}]}, "3": {"context": {"text": "Bob Murphy,", "log_prob": -21.090961456298828}, "original": {"pred": "the", "cond_log_prob": -2.572479248046875}, "human": [{"pred": "a", "cond_log_prob": -2.4750709533691406, "count": 12}, {"pred": "is", "cond_log_prob": -6.782810211181641, "count": 6}, {"pred": "the", "cond_log_prob": -2.572498321533203, "count": 5}, {"pred": "was", "cond_log_prob": -7.785022735595703, "count": 2}, {"pred": "who", "cond_log_prob": -3.0072364807128906, "count": 2}, {"pred": "builds", "cond_log_prob": -14.755542755126953, "count": 1}, {"pred": "do", "cond_log_prob": -9.916324615478516, "count": 1}, {"pred": "founder", "cond_log_prob": -5.221416473388672, "count": 1}, {"pred": "has", "cond_log_prob": -7.620761871337891, "count": 1}, {"pred": "however", "cond_log_prob": -8.267345428466797, "count": 1}, {"pred": "i", "cond_log_prob": -8.75942611694336, "count": 1}, {"pred": "my", "cond_log_prob": -8.23227310180664, "count": 1}, {"pred": "principal", "cond_log_prob": -7.732700347900391, "count": 1}, {"pred": "thanks", "cond_log_prob": -9.979267120361328, "count": 1}, {"pred": "went", "cond_log_prob": -10.743305206298828, "count": 1}, {"pred": "will", "cond_log_prob": -9.025150299072266, "count": 1}], "ancestral_samples": [{"pred": "Joe", "count": 1, "cond_log_prob": -7.128452301025391}, {"pred": "a", "count": 16, "cond_log_prob": -2.4750709533691406}, {"pred": "the", "count": 4, "cond_log_prob": -2.572498321533203}, {"pred": "who", "count": 17, "cond_log_prob": -3.0072364807128906}, {"pred": "whoroute", "count": 1, "cond_log_prob": -33.171730041503906}, {"pred": "whose", "count": 1, "cond_log_prob": -5.475650787353516}]}, "4": {"context": {"text": "Bob Murphy, the", "log_prob": -23.663440704345703}, "original": {"pred": "Senior", "cond_log_prob": -8.305889129638672}, "human": [{"pred": "man", "cond_log_prob": -3.917682647705078, "count": 3}, {"pred": "builder", "cond_log_prob": -8.668323516845703, "count": 2}, {"pred": "greatest", "cond_log_prob": -8.49240493774414, "count": 2}, {"pred": "teacher", "cond_log_prob": -8.289844512939453, "count": 2}, {"pred": "town", "cond_log_prob": -7.149448394775391, "count": 2}, {"pred": "well", "cond_log_prob": -7.613483428955078, "count": 2}, {"pred": "actor", "cond_log_prob": -5.621196746826172, "count": 1}, {"pred": "comedian", "cond_log_prob": -6.869571685791016, "count": 1}, {"pred": "comic", "cond_log_prob": -8.319049835205078, "count": 1}, {"pred": "custodian", "cond_log_prob": -10.150382995605469, "count": 1}, {"pred": "doctor", "cond_log_prob": -8.228771209716797, "count": 1}, {"pred": "father", "cond_log_prob": -5.103015899658203, "count": 1}, {"pred": "first", "cond_log_prob": -5.083255767822266, "count": 1}, {"pred": "founder", "cond_log_prob": -4.228214263916016, "count": 1}, {"pred": "great", "cond_log_prob": -7.187267303466797, "count": 1}, {"pred": "highest", "cond_log_prob": -7.683620452880859, "count": 1}, {"pred": "known", "cond_log_prob": -9.237834930419922, "count": 1}, {"pred": "local", "cond_log_prob": -6.303150177001953, "count": 1}, {"pred": "mailman", "cond_log_prob": -11.54318618774414, "count": 1}, {"pred": "mechanic", "cond_log_prob": -10.505176544189453, "count": 1}, {"pred": "next", "cond_log_prob": -7.720310211181641, "count": 1}, {"pred": "one", "cond_log_prob": -7.112842559814453, "count": 1}, {"pred": "person", "cond_log_prob": -7.128284454345703, "count": 1}, {"pred": "plummer", "cond_log_prob": -20.700725555419922, "count": 1}, {"pred": "president", "cond_log_prob": -3.659961700439453, "count": 1}, {"pred": "psychiatrist", "cond_log_prob": -9.35007095336914, "count": 1}, {"pred": "same", "cond_log_prob": -7.534397125244141, "count": 1}, {"pred": "scientist", "cond_log_prob": -9.08908462524414, "count": 1}, {"pred": "subway", "cond_log_prob": -11.596599578857422, "count": 1}, {"pred": "tallest", "cond_log_prob": -10.595539093017578, "count": 1}, {"pred": "world", "cond_log_prob": -6.442768096923828, "count": 1}], "ancestral_samples": [{"pred": "Chicago", "count": 1, "cond_log_prob": -6.639308929443359}, {"pred": "Libertarian", "count": 1, "cond_log_prob": -6.846683502197266}, {"pred": "Texas", "count": 1, "cond_log_prob": -6.497882843017578}, {"pred": "author", "count": 1, "cond_log_prob": -4.390781402587891}, {"pred": "chairman", "count": 2, "cond_log_prob": -4.380062103271484}, {"pred": "companys", "count": 1, "cond_log_prob": -15.667896270751953}, {"pred": "congressman", "count": 1, "cond_log_prob": -7.858547210693359}, {"pred": "executive", "count": 1, "cond_log_prob": -4.634449005126953}, {"pred": "former", "count": 24, "cond_log_prob": -2.352588653564453}, {"pred": "formerroutecom", "count": 1, "cond_log_prob": -36.55283737182617}, {"pred": "founder", "count": 2, "cond_log_prob": -4.228214263916016}, {"pred": "head", "count": 3, "cond_log_prob": -4.063953399658203}, {"pred": "president", "count": 1, "cond_log_prob": -3.659961700439453}]}, "5": {"context": {"text": "Bob Murphy, the Senior", "log_prob": -31.969329833984375}, "original": {"pred": "PGA", "cond_log_prob": -12.627143859863281}, "human": [{"pred": "vice", "cond_log_prob": -6.908897399902344, "count": 6}, {"pred": "executive", "cond_log_prob": -9.370803833007812, "count": 3}, {"pred": "is", "cond_log_prob": -9.741989135742188, "count": 3}, {"pred": "president", "cond_log_prob": -10.289451599121094, "count": 4}, {"pred": "advisor", "cond_log_prob": -8.904533386230469, "count": 2}, {"pred": "at", "cond_log_prob": -7.504768371582031, "count": 2}, {"pred": "editor", "cond_log_prob": -7.143562316894531, "count": 3}, {"pred": "body", "cond_log_prob": -14.992218017578125, "count": 1}, {"pred": "chief", "cond_log_prob": -13.439186096191406, "count": 1}, {"pred": "citizen", "cond_log_prob": -10.432754516601562, "count": 1}, {"pred": "class", "cond_log_prob": -13.382896423339844, "count": 1}, {"pred": "companion", "cond_log_prob": -15.394935607910156, "count": 1}, {"pred": "director", "cond_log_prob": -7.975227355957031, "count": 1}, {"pred": "member", "cond_log_prob": -10.06634521484375, "count": 1}, {"pred": "missionary", "cond_log_prob": -15.139015197753906, "count": 1}, {"pred": "of", "cond_log_prob": -8.018592834472656, "count": 1}, {"pred": "officer", "cond_log_prob": -11.610771179199219, "count": 1}, {"pred": "olympic", "cond_log_prob": -17.67546844482422, "count": 1}, {"pred": "partner", "cond_log_prob": -9.741203308105469, "count": 1}, {"pred": "senator", "cond_log_prob": -11.468467712402344, "count": 2}, {"pred": "was", "cond_log_prob": -10.671516418457031, "count": 1}], "ancestral_samples": [{"pred": "Contributor", "count": 1, "cond_log_prob": -6.592967987060547}, {"pred": "Director", "count": 3, "cond_log_prob": -2.7888641357421875}, {"pred": "Editor", "count": 2, "cond_log_prob": -2.965728759765625}, {"pred": "Editorroute", "count": 1, "cond_log_prob": -23.140750885009766}, {"pred": "Managing", "count": 1, "cond_log_prob": -4.232574462890625}, {"pred": "VP", "count": 1, "cond_log_prob": -3.6578369140625}, {"pred": "Vice", "count": 31, "cond_log_prob": -1.2662277221679688}]}, "6": {"context": {"text": "Bob Murphy, the Senior PGA", "log_prob": -44.596473693847656}, "original": {"pred": "Tour", "cond_log_prob": -0.5416679382324219}, "human": [{"pred": "of", "cond_log_prob": -5.96417236328125, "count": 8}, {"pred": "golfer", "cond_log_prob": -7.282562255859375, "count": 4}, {"pred": "golf", "cond_log_prob": -7.262672424316406, "count": 3}, {"pred": "tour", "cond_log_prob": -7.465095520019531, "count": 4}, {"pred": "is", "cond_log_prob": -7.542579650878906, "count": 2}, {"pred": "will", "cond_log_prob": -9.1248779296875, "count": 2}, {"pred": "advisor", "cond_log_prob": -10.187210083007812, "count": 1}, {"pred": "at", "cond_log_prob": -6.367668151855469, "count": 1}, {"pred": "athlete", "cond_log_prob": -9.873344421386719, "count": 1}, {"pred": "champion", "cond_log_prob": -6.995124816894531, "count": 2}, {"pred": "director", "cond_log_prob": -7.701904296875, "count": 1}, {"pred": "from", "cond_log_prob": -9.129364013671875, "count": 1}, {"pred": "grand", "cond_log_prob": -11.842323303222656, "count": 1}, {"pred": "hall", "cond_log_prob": -12.304794311523438, "count": 1}, {"pred": "owner", "cond_log_prob": -8.736564636230469, "count": 1}, {"pred": "player", "cond_log_prob": -6.821083068847656, "count": 1}, {"pred": "president", "cond_log_prob": -8.261711120605469, "count": 2}, {"pred": "tournament", "cond_log_prob": -8.588417053222656, "count": 1}, {"pred": "was", "cond_log_prob": -8.318794250488281, "count": 1}], "ancestral_samples": [{"pred": "Tour", "count": 39, "cond_log_prob": -0.5417861938476562}, {"pred": "Tourroute", "count": 1, "cond_log_prob": -18.923583984375}]}, "7": {"context": {"text": "Bob Murphy, the Senior PGA Tour", "log_prob": -45.13814163208008}, "original": {"pred": "money", "cond_log_prob": -12.96328353881836}, "human": [{"pred": "champion", "cond_log_prob": -5.638759613037109, "count": 8}, {"pred": "golfer", "cond_log_prob": -8.153278350830078, "count": 3}, {"pred": "manager", "cond_log_prob": -5.838199615478516, "count": 4}, {"pred": "winner", "cond_log_prob": -8.515727996826172, "count": 3}, {"pred": "advisor", "cond_log_prob": -7.520687103271484, "count": 3}, {"pred": "director", "cond_log_prob": -4.423999786376953, "count": 2}, {"pred": "golf", "cond_log_prob": -8.578807830810547, "count": 2}, {"pred": "guide", "cond_log_prob": -8.102664947509766, "count": 3}, {"pred": "and", "cond_log_prob": -3.535846710205078, "count": 1}, {"pred": "contestant", "cond_log_prob": -8.55117416381836, "count": 1}, {"pred": "coordinator", "cond_log_prob": -8.090518951416016, "count": 1}, {"pred": "leader", "cond_log_prob": -5.972064971923828, "count": 1}, {"pred": "legal", "cond_log_prob": -8.93807601928711, "count": 1}, {"pred": "organizer", "cond_log_prob": -6.975070953369141, "count": 1}, {"pred": "player", "cond_log_prob": -3.9472694396972656, "count": 1}, {"pred": "president", "cond_log_prob": -5.413455963134766, "count": 1}, {"pred": "representative", "cond_log_prob": -4.863185882568359, "count": 1}, {"pred": "vice", "cond_log_prob": -5.717357635498047, "count": 1}], "ancestral_samples": [{"pred": "Champion", "count": 1, "cond_log_prob": -4.209606170654297}, {"pred": "Commissioner", "count": 1, "cond_log_prob": -4.513622283935547}, {"pred": "Contributor", "count": 1, "cond_log_prob": -7.018360137939453}, {"pred": "Director", "count": 13, "cond_log_prob": -2.7695045471191406}, {"pred": "Editor", "count": 1, "cond_log_prob": -4.434810638427734}, {"pred": "Editorroute", "count": 1, "cond_log_prob": -26.394947052001953}, {"pred": "Executive", "count": 3, "cond_log_prob": -3.338550567626953}, {"pred": "General", "count": 1, "cond_log_prob": -4.914272308349609}, {"pred": "I", "count": 1, "cond_log_prob": -9.942142486572266}, {"pred": "Manager", "count": 4, "cond_log_prob": -3.9070472717285156}, {"pred": "Officer", "count": 1, "cond_log_prob": -5.473194122314453}, {"pred": "Placer", "count": 1, "cond_log_prob": -9.174602508544922}, {"pred": "Player", "count": 3, "cond_log_prob": -3.579792022705078}, {"pred": "President", "count": 2, "cond_log_prob": -3.481060028076172}, {"pred": "and", "count": 2, "cond_log_prob": -3.535846710205078}, {"pred": "official", "count": 2, "cond_log_prob": -3.647846221923828}, {"pred": "pro", "count": 1, "cond_log_prob": -7.047527313232422}, {"pred": "professional", "count": 1, "cond_log_prob": -6.333705902099609}]}, "8": {"context": {"text": "Bob Murphy, the Senior PGA Tour money", "log_prob": -58.10142517089844}, "original": {"pred": "leader", "cond_log_prob": -5.5413360595703125}, "human": [{"pred": "manager", "cond_log_prob": -0.8034896850585938, "count": 6}, {"pred": "maker", "cond_log_prob": -4.993682861328125, "count": 5}, {"pred": "winner", "cond_log_prob": -4.472015380859375, "count": 4}, {"pred": "handler", "cond_log_prob": -7.431327819824219, "count": 3}, {"pred": "leader", "cond_log_prob": -5.541435241699219, "count": 3}, {"pred": "of", "cond_log_prob": -8.914794921875, "count": 2}, {"pred": "adviser", "cond_log_prob": -6.431976318359375, "count": 1}, {"pred": "advisor", "cond_log_prob": -7.4026947021484375, "count": 1}, {"pred": "as", "cond_log_prob": -10.570465087890625, "count": 1}, {"pred": "collector", "cond_log_prob": -7.0863800048828125, "count": 1}, {"pred": "director", "cond_log_prob": -4.59375, "count": 1}, {"pred": "financer", "cond_log_prob": -15.157760620117188, "count": 1}, {"pred": "is", "cond_log_prob": -9.56988525390625, "count": 1}, {"pred": "organizer", "cond_log_prob": -9.518714904785156, "count": 1}, {"pred": "pro", "cond_log_prob": -10.000228881835938, "count": 1}, {"pred": "sponsor", "cond_log_prob": -10.762283325195312, "count": 1}, {"pred": "supervisor", "cond_log_prob": -8.609954833984375, "count": 1}, {"pred": "that", "cond_log_prob": -8.239891052246094, "count": 1}, {"pred": "theif", "cond_log_prob": -20.459693908691406, "count": 1}, {"pred": "will", "cond_log_prob": -9.802146911621094, "count": 1}, {"pred": "with", "cond_log_prob": -9.366470336914062, "count": 1}], "ancestral_samples": [{"pred": "loser", "count": 5, "cond_log_prob": -7.62127685546875}, {"pred": "manager", "count": 34, "cond_log_prob": -0.8034896850585938}, {"pred": "managerroute", "count": 1, "cond_log_prob": -25.619590759277344}]}, "9": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader", "log_prob": -63.64276123046875}, "original": {"pred": "with", "cond_log_prob": -4.448486328125}, "human": [{"pred": "is", "cond_log_prob": -5.713050842285156, "count": 10}, {"pred": "was", "cond_log_prob": -6.544670104980469, "count": 4}, {"pred": "has", "cond_log_prob": -4.879364013671875, "count": 3}, {"pred": "will", "cond_log_prob": -6.603828430175781, "count": 3}, {"pred": "in", "cond_log_prob": -3.9745330810546875, "count": 2}, {"pred": "of", "cond_log_prob": -4.534912109375, "count": 2}, {"pred": ",", "cond_log_prob": -6.992103576660156, "count": 1}, {"pred": "a", "cond_log_prob": -9.460945129394531, "count": 1}, {"pred": "at", "cond_log_prob": -3.5329971313476562, "count": 1}, {"pred": "came", "cond_log_prob": -8.614295959472656, "count": 1}, {"pred": "can", "cond_log_prob": -9.096763610839844, "count": 1}, {"pred": "did", "cond_log_prob": -9.687568664550781, "count": 1}, {"pred": "drives", "cond_log_prob": -12.688941955566406, "count": 1}, {"pred": "had", "cond_log_prob": -7.242347717285156, "count": 1}, {"pred": "maker", "cond_log_prob": -12.755241394042969, "count": 1}, {"pred": "ran", "cond_log_prob": -11.039710998535156, "count": 1}, {"pred": "said", "cond_log_prob": -4.7022247314453125, "count": 1}, {"pred": "the", "cond_log_prob": -8.133094787597656, "count": 1}, {"pred": "this", "cond_log_prob": -7.190773010253906, "count": 1}, {"pred": "wins", "cond_log_prob": -10.965797424316406, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -12.590904235839844}, {"pred": "and", "count": 4, "cond_log_prob": -1.9797134399414062}, {"pred": "has", "count": 1, "cond_log_prob": -4.879364013671875}, {"pred": "route", "count": 1, "cond_log_prob": -17.104713439941406}, {"pred": "said", "count": 28, "cond_log_prob": -4.7022247314453125}, {"pred": "sat", "count": 1, "cond_log_prob": -9.774330139160156}, {"pred": "told", "count": 1, "cond_log_prob": -5.800346374511719}, {"pred": "who", "count": 3, "cond_log_prob": -2.8586273193359375}]}, "10": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with", "log_prob": -68.09124755859375}, "original": {"pred": "seven", "cond_log_prob": -5.601737976074219}, "human": [{"pred": "the", "cond_log_prob": -1.9172744750976562, "count": 12}, {"pred": "a", "cond_log_prob": -2.6363449096679688, "count": 6}, {"pred": "his", "cond_log_prob": -4.543220520019531, "count": 2}, {"pred": "many", "cond_log_prob": -7.287666320800781, "count": 2}, {"pred": "tiger", "cond_log_prob": -13.200126647949219, "count": 2}, {"pred": "around", "cond_log_prob": -7.421638488769531, "count": 1}, {"pred": "experience", "cond_log_prob": -6.994438171386719, "count": 1}, {"pred": "lots", "cond_log_prob": -9.318031311035156, "count": 1}, {"pred": "man", "cond_log_prob": -11.180046081542969, "count": 1}, {"pred": "millions", "cond_log_prob": -7.764091491699219, "count": 1}, {"pred": "money", "cond_log_prob": -7.052711486816406, "count": 1}, {"pred": "number", "cond_log_prob": -8.827033996582031, "count": 1}, {"pred": "one", "cond_log_prob": -5.492118835449219, "count": 1}, {"pred": "our", "cond_log_prob": -8.363227844238281, "count": 1}, {"pred": "out", "cond_log_prob": -8.081291198730469, "count": 1}, {"pred": "ten", "cond_log_prob": -7.868659973144531, "count": 1}, {"pred": "trophies", "cond_log_prob": -11.641136169433594, "count": 1}, {"pred": "two", "cond_log_prob": -5.155204772949219, "count": 1}, {"pred": "tyhe", "cond_log_prob": -22.58173370361328, "count": 1}], "ancestral_samples": [{"pred": "11", "count": 1, "cond_log_prob": -4.616264343261719}, {"pred": "13", "count": 1, "cond_log_prob": -5.291618347167969}, {"pred": "35", "count": 1, "cond_log_prob": -6.408958435058594}, {"pred": "60", "count": 1, "cond_log_prob": -6.523963928222656}, {"pred": "a", "count": 6, "cond_log_prob": -2.6363449096679688}, {"pred": "the", "count": 29, "cond_log_prob": -1.9172744750976562}, {"pred": "theroute", "count": 1, "cond_log_prob": -27.61974334716797}]}, "11": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven", "log_prob": -73.69298553466797}, "original": {"pred": "hundred", "cond_log_prob": -6.7387542724609375}, "human": [{"pred": "million", "cond_log_prob": -5.593414306640625, "count": 6}, {"pred": "titles", "cond_log_prob": -3.4122314453125, "count": 4}, {"pred": "wins", "cond_log_prob": -1.9975738525390625, "count": 3}, {"pred": "children", "cond_log_prob": -6.7975921630859375, "count": 2}, {"pred": "different", "cond_log_prob": -6.01788330078125, "count": 2}, {"pred": "kids", "cond_log_prob": -8.356857299804688, "count": 2}, {"pred": "other", "cond_log_prob": -5.1187591552734375, "count": 2}, {"pred": "years", "cond_log_prob": -2.9290008544921875, "count": 2}, {"pred": "awards", "cond_log_prob": -6.638641357421875, "count": 1}, {"pred": "birdies", "cond_log_prob": -8.684173583984375, "count": 1}, {"pred": "cars", "cond_log_prob": -9.7467041015625, "count": 1}, {"pred": "championship", "cond_log_prob": -5.5084381103515625, "count": 1}, {"pred": "championships", "cond_log_prob": -4.61590576171875, "count": 1}, {"pred": "cups", "cond_log_prob": -8.965438842773438, "count": 1}, {"pred": "heads", "cond_log_prob": -9.989501953125, "count": 1}, {"pred": "hot", "cond_log_prob": -9.938186645507812, "count": 1}, {"pred": "of", "cond_log_prob": -3.8607635498046875, "count": 1}, {"pred": "pga", "cond_log_prob": -18.412765502929688, "count": 1}, {"pred": "points", "cond_log_prob": -5.6790313720703125, "count": 1}, {"pred": "powerful", "cond_log_prob": -11.569076538085938, "count": 1}, {"pred": "swans", "cond_log_prob": -11.3251953125, "count": 1}, {"pred": "tour", "cond_log_prob": -5.867401123046875, "count": 1}, {"pred": "trophies", "cond_log_prob": -7.927642822265625, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.411781311035156}, {"pred": "Masters", "count": 3, "cond_log_prob": -3.8041610717773438}, {"pred": "figure", "count": 1, "cond_log_prob": -10.046653747558594}, {"pred": "major", "count": 1, "cond_log_prob": -3.8440475463867188}, {"pred": "majors", "count": 1, "cond_log_prob": -4.318046569824219}, {"pred": "nationalroute", "count": 1, "cond_log_prob": -27.159507751464844}, {"pred": "prorated", "count": 1, "cond_log_prob": -15.13421630859375}, {"pred": "titles", "count": 3, "cond_log_prob": -3.4122772216796875}, {"pred": "top10", "count": 1, "cond_log_prob": -13.853347778320312}, {"pred": "victories", "count": 4, "cond_log_prob": -3.2876739501953125}, {"pred": "wins", "count": 17, "cond_log_prob": -1.9976043701171875}, {"pred": "winsBut", "count": 1, "cond_log_prob": -20.579910278320312}, {"pred": "years", "count": 5, "cond_log_prob": -2.9290313720703125}]}, "12": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred", "log_prob": -80.4317398071289}, "original": {"pred": "thousand,", "cond_log_prob": -7.795997619628906}, "human": [{"pred": "thousand", "cond_log_prob": -3.7922515869140625, "count": 17}, {"pred": "dollars", "cond_log_prob": -2.4304046630859375, "count": 3}, {"pred": "million", "cond_log_prob": -3.7592315673828125, "count": 2}, {"pred": "titles", "cond_log_prob": -6.8832244873046875, "count": 2}, {"pred": "wins", "cond_log_prob": -3.9745025634765625, "count": 2}, {"pred": "awards", "cond_log_prob": -9.0345458984375, "count": 1}, {"pred": "companies", "cond_log_prob": -8.347076416015625, "count": 1}, {"pred": "competitors", "cond_log_prob": -7.7598876953125, "count": 1}, {"pred": "employees", "cond_log_prob": -8.62762451171875, "count": 1}, {"pred": "golf", "cond_log_prob": -6.3562164306640625, "count": 1}, {"pred": "hot", "cond_log_prob": -11.816329956054688, "count": 1}, {"pred": "hours", "cond_log_prob": -7.0179901123046875, "count": 1}, {"pred": "points", "cond_log_prob": -4.9373931884765625, "count": 1}, {"pred": "tournament", "cond_log_prob": -6.862030029296875, "count": 1}, {"pred": "trillion", "cond_log_prob": -10.15069580078125, "count": 1}, {"pred": "under", "cond_log_prob": -8.581283569335938, "count": 1}, {"pred": "years", "cond_log_prob": -5.865814208984375, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 38, "cond_log_prob": -0.6715621948242188}, {"pred": "androute", "count": 1, "cond_log_prob": -23.86864471435547}, {"pred": "dollars", "count": 1, "cond_log_prob": -2.4304275512695312}]}, "13": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand,", "log_prob": -88.22773742675781}, "original": {"pred": "says", "cond_log_prob": -3.7348098754882812}, "human": [{"pred": "dollars", "cond_log_prob": -8.995277404785156, "count": 10}, {"pred": "is", "cond_log_prob": -2.1836090087890625, "count": 6}, {"pred": "was", "cond_log_prob": -2.83270263671875, "count": 4}, {"pred": "has", "cond_log_prob": -1.7623291015625, "count": 3}, {"pred": "will", "cond_log_prob": -4.361000061035156, "count": 3}, {"pred": "wins", "cond_log_prob": -6.229972839355469, "count": 3}, {"pred": "and", "cond_log_prob": -3.6445846557617188, "count": 1}, {"pred": "gone", "cond_log_prob": -11.527229309082031, "count": 1}, {"pred": "had", "cond_log_prob": -3.8272628784179688, "count": 1}, {"pred": "landed", "cond_log_prob": -8.755088806152344, "count": 1}, {"pred": "left", "cond_log_prob": -6.316688537597656, "count": 1}, {"pred": "ran", "cond_log_prob": -6.921501159667969, "count": 1}, {"pred": "six", "cond_log_prob": -7.077491760253906, "count": 1}, {"pred": "things", "cond_log_prob": -12.217300415039062, "count": 1}, {"pred": "told", "cond_log_prob": -4.379096984863281, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -5.493537902832031}, {"pred": "and", "count": 4, "cond_log_prob": -3.6445846557617188}, {"pred": "had", "count": 1, "cond_log_prob": -3.8272628784179688}, {"pred": "has", "count": 6, "cond_log_prob": -1.7623291015625}, {"pred": "is", "count": 7, "cond_log_prob": -2.1836090087890625}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.44678497314453}, {"pred": "participated", "count": 1, "cond_log_prob": -7.784370422363281}, {"pred": "said", "count": 12, "cond_log_prob": -3.0010147094726562}, {"pred": "the", "count": 1, "cond_log_prob": -5.1769866943359375}, {"pred": "told", "count": 1, "cond_log_prob": -4.379096984863281}, {"pred": "was", "count": 5, "cond_log_prob": -2.83270263671875}]}, "14": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says", "log_prob": -91.9625473022461}, "original": {"pred": "heat", "cond_log_prob": -11.974960327148438}, "human": [{"pred": "that", "cond_log_prob": -1.602813720703125, "count": 27}, {"pred": "he", "cond_log_prob": -1.85699462890625, "count": 6}, {"pred": "hello", "cond_log_prob": -10.91693115234375, "count": 1}, {"pred": "hey", "cond_log_prob": -11.28424072265625, "count": 1}, {"pred": "i", "cond_log_prob": -9.904769897460938, "count": 1}, {"pred": "money", "cond_log_prob": -6.813873291015625, "count": 1}, {"pred": "to", "cond_log_prob": -5.77301025390625, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 2, "cond_log_prob": -6.0260162353515625}, {"pred": "Its", "count": 5, "cond_log_prob": -14.873863220214844}, {"pred": "The", "count": 2, "cond_log_prob": -7.63726806640625}, {"pred": "We", "count": 1, "cond_log_prob": -10.32989501953125}, {"pred": "When", "count": 1, "cond_log_prob": -12.180976867675781}, {"pred": "a", "count": 1, "cond_log_prob": -4.7242279052734375}, {"pred": "he", "count": 3, "cond_log_prob": -1.85699462890625}, {"pred": "hes", "count": 3, "cond_log_prob": -11.526473999023438}, {"pred": "that", "count": 16, "cond_log_prob": -1.602813720703125}, {"pred": "thatroute", "count": 1, "cond_log_prob": -20.691505432128906}, {"pred": "the", "count": 5, "cond_log_prob": -2.27392578125}]}, "15": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat", "log_prob": -103.93750762939453}, "original": {"pred": "shouldn't", "cond_log_prob": -7.195243835449219}, "human": [{"pred": "is", "cond_log_prob": -1.6778945922851562, "count": 18}, {"pred": "and", "cond_log_prob": -3.3339309692382812, "count": 3}, {"pred": "will", "cond_log_prob": -4.104896545410156, "count": 3}, {"pred": "has", "cond_log_prob": -3.6266555786132812, "count": 2}, {"pred": "destroys", "cond_log_prob": -9.817985534667969, "count": 1}, {"pred": "he", "cond_log_prob": -7.930397033691406, "count": 1}, {"pred": "increases", "cond_log_prob": -6.960853576660156, "count": 1}, {"pred": "influences", "cond_log_prob": -10.057044982910156, "count": 1}, {"pred": "on", "cond_log_prob": -5.347663879394531, "count": 1}, {"pred": "plays", "cond_log_prob": -6.489234924316406, "count": 1}, {"pred": "prevents", "cond_log_prob": -10.944114685058594, "count": 1}, {"pred": "radiates", "cond_log_prob": -10.471549987792969, "count": 1}, {"pred": "stroke", "cond_log_prob": -3.0510025024414062, "count": 1}, {"pred": "up", "cond_log_prob": -5.760490417480469, "count": 1}, {"pred": "was", "cond_log_prob": -4.271385192871094, "count": 1}, {"pred": "waves", "cond_log_prob": -3.4486160278320312, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -12.654563903808594}, {"pred": "and", "count": 3, "cond_log_prob": -3.3339309692382812}, {"pred": "is", "count": 28, "cond_log_prob": -1.6778945922851562}, {"pred": "isroute", "count": 1, "cond_log_prob": -26.04206085205078}, {"pred": "stroke", "count": 4, "cond_log_prob": -3.0510025024414062}, {"pred": "was", "count": 1, "cond_log_prob": -4.271385192871094}, {"pred": "waves", "count": 2, "cond_log_prob": -3.4486160278320312}]}, "16": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't", "log_prob": -111.13275146484375}, "original": {"pred": "be", "cond_log_prob": -0.4988861083984375}, "human": [{"pred": "be", "cond_log_prob": -0.498992919921875, "count": 12}, {"pred": "affect", "cond_log_prob": -3.827484130859375, "count": 7}, {"pred": "play", "cond_log_prob": -4.9650115966796875, "count": 3}, {"pred": "effect", "cond_log_prob": -8.428726196289062, "count": 2}, {"pred": "have", "cond_log_prob": -3.2057342529296875, "count": 2}, {"pred": "impact", "cond_log_prob": -5.9188232421875, "count": 2}, {"pred": "keep", "cond_log_prob": -5.823455810546875, "count": 2}, {"pred": "change", "cond_log_prob": -6.220428466796875, "count": 1}, {"pred": "distract", "cond_log_prob": -6.5774383544921875, "count": 1}, {"pred": "exist", "cond_log_prob": -7.190673828125, "count": 1}, {"pred": "interfere", "cond_log_prob": -5.4672393798828125, "count": 1}, {"pred": "melt", "cond_log_prob": -9.241378784179688, "count": 1}, {"pred": "snow", "cond_log_prob": -11.744644165039062, "count": 1}, {"pred": "stay", "cond_log_prob": -7.862579345703125, "count": 1}, {"pred": "stop", "cond_log_prob": -4.5999298095703125, "count": 1}], "ancestral_samples": [{"pred": "be", "count": 39, "cond_log_prob": -0.498992919921875}, {"pred": "beroute", "count": 1, "cond_log_prob": -30.765380859375}]}, "17": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be", "log_prob": -111.63163757324219}, "original": {"pred": "a", "cond_log_prob": -1.445159912109375}, "human": [{"pred": "a", "cond_log_prob": -1.4452667236328125, "count": 21}, {"pred": "an", "cond_log_prob": -2.3960418701171875, "count": 8}, {"pred": "the", "cond_log_prob": -2.6678619384765625, "count": 4}, {"pred": "able", "cond_log_prob": -7.4355621337890625, "count": 1}, {"pred": "bad", "cond_log_prob": -6.863067626953125, "count": 1}, {"pred": "forced", "cond_log_prob": -7.438995361328125, "count": 1}, {"pred": "in", "cond_log_prob": -5.382354736328125, "count": 1}, {"pred": "relevant", "cond_log_prob": -8.790542602539062, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 32, "cond_log_prob": -1.4452667236328125}, {"pred": "an", "count": 3, "cond_log_prob": -2.3960418701171875}, {"pred": "anroute", "count": 1, "cond_log_prob": -26.445526123046875}, {"pred": "the", "count": 2, "cond_log_prob": -2.6678619384765625}, {"pred": "used", "count": 2, "cond_log_prob": -3.2720184326171875}]}, "18": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a", "log_prob": -113.07679748535156}, "original": {"pred": "factor.", "cond_log_prob": -3.1435546875}, "human": [{"pred": "factor", "cond_log_prob": -1.3873291015625, "count": 20}, {"pred": "problem", "cond_log_prob": -1.3229827880859375, "count": 9}, {"pred": "issue", "cond_log_prob": -5.2266845703125, "count": 2}, {"pred": "barrier", "cond_log_prob": -4.1431884765625, "count": 1}, {"pred": "big", "cond_log_prob": -3.401214599609375, "count": 1}, {"pred": "concern", "cond_log_prob": -2.5607757568359375, "count": 1}, {"pred": "deciding", "cond_log_prob": -5.0810699462890625, "count": 1}, {"pred": "determining", "cond_log_prob": -6.465545654296875, "count": 1}, {"pred": "distraction", "cond_log_prob": -5.828704833984375, "count": 1}, {"pred": "reason", "cond_log_prob": -3.6999664306640625, "count": 1}], "ancestral_samples": [{"pred": "factor", "count": 17, "cond_log_prob": -1.3873214721679688}, {"pred": "major", "count": 3, "cond_log_prob": -3.1867752075195312}, {"pred": "problem", "count": 19, "cond_log_prob": -1.3229751586914062}, {"pred": "problemroute", "count": 1, "cond_log_prob": -23.168746948242188}]}, "19": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor.", "log_prob": -116.22035217285156}, "original": {"pred": "\"I", "cond_log_prob": -4.24359130859375}, "human": [{"pred": "he", "cond_log_prob": -9.307579040527344, "count": 15}, {"pred": "the", "cond_log_prob": -9.529838562011719, "count": 4}, {"pred": "but", "cond_log_prob": -10.533103942871094, "count": 3}, {"pred": "in", "cond_log_prob": -9.791557312011719, "count": 4}, {"pred": "?", "cond_log_prob": -9.692710876464844, "count": 1}, {"pred": "end", "cond_log_prob": -16.039932250976562, "count": 1}, {"pred": "golfers", "cond_log_prob": -18.148574829101562, "count": 1}, {"pred": "heat", "cond_log_prob": -14.541366577148438, "count": 1}, {"pred": "however", "cond_log_prob": -14.549606323242188, "count": 1}, {"pred": "it", "cond_log_prob": -11.782363891601562, "count": 1}, {"pred": "next", "cond_log_prob": -15.611068725585938, "count": 1}, {"pred": "only", "cond_log_prob": -13.581497192382812, "count": 1}, {"pred": "there", "cond_log_prob": -13.348495483398438, "count": 1}, {"pred": "this", "cond_log_prob": -12.299850463867188, "count": 1}, {"pred": "with", "cond_log_prob": -11.075027465820312, "count": 1}, {"pred": "you", "cond_log_prob": -12.335556030273438, "count": 1}], "ancestral_samples": [{"pred": "Golf", "count": 1, "cond_log_prob": -8.089431762695312}, {"pred": "He", "count": 2, "cond_log_prob": -2.8502960205078125}, {"pred": "Heat", "count": 2, "cond_log_prob": -7.811920166015625}, {"pred": "I", "count": 3, "cond_log_prob": -6.1270599365234375}, {"pred": "If", "count": 1, "cond_log_prob": -5.8970794677734375}, {"pred": "Im", "count": 2, "cond_log_prob": -10.886619567871094}, {"pred": "In", "count": 2, "cond_log_prob": -4.335670471191406}, {"pred": "Its", "count": 14, "cond_log_prob": -9.341102600097656}, {"pred": "No", "count": 1, "cond_log_prob": -6.623046875}, {"pred": "The", "count": 2, "cond_log_prob": -3.7270889282226562}, {"pred": "Theres", "count": 2, "cond_log_prob": -16.137680053710938}, {"pred": "To", "count": 1, "cond_log_prob": -6.644523620605469}, {"pred": "We", "count": 1, "cond_log_prob": -6.199851989746094}, {"pred": "Were", "count": 3, "cond_log_prob": -10.604240417480469}, {"pred": "You", "count": 1, "cond_log_prob": -6.4307861328125}, {"pred": "Youre", "count": 1, "cond_log_prob": -18.323867797851562}, {"pred": "route", "count": 1, "cond_log_prob": -19.754806518554688}]}, "20": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I", "log_prob": -120.46394348144531}, "original": {"pred": "don't", "cond_log_prob": -1.9754791259765625}, "human": [{"pred": "do", "cond_log_prob": -4.638458251953125, "count": 11}, {"pred": "know", "cond_log_prob": -3.6094970703125, "count": 5}, {"pred": "am", "cond_log_prob": -4.7796783447265625, "count": 4}, {"pred": "have", "cond_log_prob": -4.0579376220703125, "count": 4}, {"pred": "think", "cond_log_prob": -1.214324951171875, "count": 4}, {"pred": "feel", "cond_log_prob": -4.629974365234375, "count": 2}, {"pred": "played", "cond_log_prob": -7.99810791015625, "count": 2}, {"pred": "would", "cond_log_prob": -3.3208465576171875, "count": 2}, {"pred": "always", "cond_log_prob": -5.26904296875, "count": 1}, {"pred": "believe", "cond_log_prob": -3.699371337890625, "count": 1}, {"pred": "can", "cond_log_prob": -4.2551116943359375, "count": 1}, {"pred": "plan", "cond_log_prob": -9.161941528320312, "count": 1}], "ancestral_samples": [{"pred": "can", "count": 1, "cond_log_prob": -4.2551116943359375}, {"pred": "dont", "count": 10, "cond_log_prob": -9.39373779296875}, {"pred": "m", "count": 2, "cond_log_prob": -12.00933837890625}, {"pred": "think", "count": 25, "cond_log_prob": -1.214324951171875}, {"pred": "thinkroute", "count": 1, "cond_log_prob": -24.395431518554688}, {"pred": "ve", "count": 1, "cond_log_prob": -13.536209106445312}]}, "21": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't", "log_prob": -122.43942260742188}, "original": {"pred": "think", "cond_log_prob": -0.672821044921875}, "human": [{"pred": "think", "cond_log_prob": -0.6729583740234375, "count": 20}, {"pred": "believe", "cond_log_prob": -2.6493988037109375, "count": 8}, {"pred": "know", "cond_log_prob": -2.545928955078125, "count": 3}, {"pred": "see", "cond_log_prob": -2.63653564453125, "count": 3}, {"pred": "anticipate", "cond_log_prob": -8.52947998046875, "count": 1}, {"pred": "care", "cond_log_prob": -4.3080902099609375, "count": 1}, {"pred": "ever", "cond_log_prob": -6.371490478515625, "count": 1}, {"pred": "mind", "cond_log_prob": -6.159637451171875, "count": 1}], "ancestral_samples": [{"pred": "know", "count": 1, "cond_log_prob": -2.545928955078125}, {"pred": "see", "count": 1, "cond_log_prob": -2.63653564453125}, {"pred": "think", "count": 37, "cond_log_prob": -0.6729583740234375}, {"pred": "thinkroute", "count": 1, "cond_log_prob": -23.52362060546875}]}, "22": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think", "log_prob": -123.11224365234375}, "original": {"pred": "you're", "cond_log_prob": -5.1564788818359375}, "human": [{"pred": "that", "cond_log_prob": -2.3831939697265625, "count": 22}, {"pred": "heat", "cond_log_prob": -3.145263671875, "count": 8}, {"pred": "the", "cond_log_prob": -2.9225616455078125, "count": 2}, {"pred": "about", "cond_log_prob": -5.815948486328125, "count": 1}, {"pred": "i", "cond_log_prob": -11.0369873046875, "count": 2}, {"pred": "much", "cond_log_prob": -6.950439453125, "count": 1}, {"pred": "talent", "cond_log_prob": -11.317047119140625, "count": 1}, {"pred": "there", "cond_log_prob": -2.8327484130859375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.453887939453125}, {"pred": "it", "count": 3, "cond_log_prob": -1.17706298828125}, {"pred": "itroute", "count": 1, "cond_log_prob": -29.2601318359375}, {"pred": "its", "count": 25, "cond_log_prob": -6.806640625}, {"pred": "people", "count": 1, "cond_log_prob": -3.5010833740234375}, {"pred": "thats", "count": 1, "cond_log_prob": -10.988983154296875}, {"pred": "the", "count": 2, "cond_log_prob": -2.9225616455078125}, {"pred": "theres", "count": 1, "cond_log_prob": -15.745086669921875}, {"pred": "you", "count": 4, "cond_log_prob": -2.8113555908203125}, {"pred": "youll", "count": 1, "cond_log_prob": -15.86065673828125}]}, "23": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're", "log_prob": -128.2687225341797}, "original": {"pred": "going", "cond_log_prob": -0.5416412353515625}, "human": [{"pred": "going", "cond_log_prob": -0.5418243408203125, "count": 12}, {"pred": "a", "cond_log_prob": -6.0518341064453125, "count": 5}, {"pred": "able", "cond_log_prob": -5.5081939697265625, "count": 3}, {"pred": "really", "cond_log_prob": -4.8744354248046875, "count": 2}, {"pred": "trying", "cond_log_prob": -4.9738922119140625, "count": 2}, {"pred": "any", "cond_log_prob": -7.4125213623046875, "count": 1}, {"pred": "being", "cond_log_prob": -6.0780181884765625, "count": 1}, {"pred": "excuse", "cond_log_prob": -14.809310913085938, "count": 1}, {"pred": "good", "cond_log_prob": -7.6519012451171875, "count": 1}, {"pred": "here", "cond_log_prob": -7.8784942626953125, "count": 1}, {"pred": "not", "cond_log_prob": -6.4111175537109375, "count": 1}, {"pred": "performance", "cond_log_prob": -12.943191528320312, "count": 1}, {"pred": "playing", "cond_log_prob": -5.3614349365234375, "count": 1}, {"pred": "primary", "cond_log_prob": -13.969924926757812, "count": 1}, {"pred": "serious", "cond_log_prob": -10.277603149414062, "count": 1}, {"pred": "stupid", "cond_log_prob": -8.362899780273438, "count": 1}, {"pred": "thinking", "cond_log_prob": -6.6560821533203125, "count": 1}, {"pred": "understanding", "cond_log_prob": -10.211502075195312, "count": 1}, {"pred": "used", "cond_log_prob": -7.2609710693359375, "count": 1}], "ancestral_samples": [{"pred": "ever", "count": 1, "cond_log_prob": -2.9599456787109375}, {"pred": "going", "count": 37, "cond_log_prob": -0.5418243408203125}, {"pred": "goingroute", "count": 1, "cond_log_prob": -22.373733520507812}, {"pred": "seeing", "count": 1, "cond_log_prob": -3.9538421630859375}]}, "24": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going", "log_prob": -128.81036376953125}, "original": {"pred": "to", "cond_log_prob": -0.0099639892578125}, "human": [{"pred": "to", "cond_log_prob": -0.0101318359375, "count": 38}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.0101318359375}, {"pred": "toroute", "count": 1, "cond_log_prob": -34.957489013671875}]}, "25": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to", "log_prob": -128.82032775878906}, "original": {"pred": "have", "cond_log_prob": -2.9603118896484375}, "human": [{"pred": "be", "cond_log_prob": -3.2997283935546875, "count": 8}, {"pred": "win", "cond_log_prob": -4.4063262939453125, "count": 7}, {"pred": "see", "cond_log_prob": -1.1542205810546875, "count": 4}, {"pred": "need", "cond_log_prob": -5.5257720947265625, "count": 3}, {"pred": "feel", "cond_log_prob": -5.5659637451171875, "count": 2}, {"pred": "enjoy", "cond_log_prob": -7.6833953857421875, "count": 1}, {"pred": "find", "cond_log_prob": -2.3633270263671875, "count": 1}, {"pred": "hate", "cond_log_prob": -7.9794769287109375, "count": 1}, {"pred": "have", "cond_log_prob": -2.9604949951171875, "count": 1}, {"pred": "hurt", "cond_log_prob": -7.6396636962890625, "count": 1}, {"pred": "last", "cond_log_prob": -9.483840942382812, "count": 1}, {"pred": "lose", "cond_log_prob": -4.7012786865234375, "count": 1}, {"pred": "love", "cond_log_prob": -8.014694213867188, "count": 1}, {"pred": "make", "cond_log_prob": -4.7124481201171875, "count": 1}, {"pred": "pass", "cond_log_prob": -8.238571166992188, "count": 1}, {"pred": "perform", "cond_log_prob": -9.184616088867188, "count": 1}, {"pred": "play", "cond_log_prob": -5.8928985595703125, "count": 1}, {"pred": "sweat", "cond_log_prob": -7.4166107177734375, "count": 1}, {"pred": "withstand", "cond_log_prob": -11.936264038085938, "count": 1}], "ancestral_samples": [{"pred": "find", "count": 4, "cond_log_prob": -2.3633270263671875}, {"pred": "get", "count": 14, "cond_log_prob": -1.6060638427734375}, {"pred": "have", "count": 3, "cond_log_prob": -2.9604949951171875}, {"pred": "see", "count": 18, "cond_log_prob": -1.1542205810546875}, {"pred": "seeroute", "count": 1, "cond_log_prob": -35.45503234863281}]}, "26": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have", "log_prob": -131.7806396484375}, "original": {"pred": "a", "cond_log_prob": -1.229156494140625}, "human": [{"pred": "a", "cond_log_prob": -1.2293701171875, "count": 18}, {"pred": "to", "cond_log_prob": -3.00677490234375, "count": 7}, {"pred": "any", "cond_log_prob": -2.54058837890625, "count": 6}, {"pred": "much", "cond_log_prob": -4.525787353515625, "count": 2}, {"pred": "many", "cond_log_prob": -5.303924560546875, "count": 1}, {"pred": "problems", "cond_log_prob": -6.798614501953125, "count": 1}, {"pred": "success", "cond_log_prob": -7.273590087890625, "count": 1}, {"pred": "that", "cond_log_prob": -3.55133056640625, "count": 1}, {"pred": "trouble", "cond_log_prob": -7.291900634765625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 37, "cond_log_prob": -1.2293701171875}, {"pred": "aroute", "count": 1, "cond_log_prob": -26.060272216796875}, {"pred": "the", "count": 1, "cond_log_prob": -2.961212158203125}, {"pred": "to", "count": 1, "cond_log_prob": -3.00677490234375}]}, "27": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a", "log_prob": -133.00979614257812}, "original": {"pred": "heat", "cond_log_prob": -4.74774169921875}, "human": [{"pred": "problem", "cond_log_prob": -3.05047607421875, "count": 14}, {"pred": "hard", "cond_log_prob": -4.9046630859375, "count": 4}, {"pred": "chance", "cond_log_prob": -5.42462158203125, "count": 3}, {"pred": "very", "cond_log_prob": -4.2449951171875, "count": 2}, {"pred": "fair", "cond_log_prob": -5.18463134765625, "count": 1}, {"pred": "good", "cond_log_prob": -4.074798583984375, "count": 1}, {"pred": "harder", "cond_log_prob": -7.7244873046875, "count": 1}, {"pred": "heat", "cond_log_prob": -4.747955322265625, "count": 1}, {"pred": "lot", "cond_log_prob": -2.7645263671875, "count": 1}, {"pred": "meltdown", "cond_log_prob": -8.15478515625, "count": 1}, {"pred": "more", "cond_log_prob": -5.542205810546875, "count": 1}, {"pred": "negative", "cond_log_prob": -5.5009765625, "count": 1}, {"pred": "pga", "cond_log_prob": -16.738677978515625, "count": 1}, {"pred": "standing", "cond_log_prob": -9.1610107421875, "count": 1}, {"pred": "story", "cond_log_prob": -7.12811279296875, "count": 1}, {"pred": "success", "cond_log_prob": -7.457977294921875, "count": 1}, {"pred": "successful", "cond_log_prob": -7.413543701171875, "count": 1}, {"pred": "sweating", "cond_log_prob": -9.60546875, "count": 1}, {"pred": "worse", "cond_log_prob": -6.829833984375, "count": 1}], "ancestral_samples": [{"pred": "big", "count": 1, "cond_log_prob": -3.93939208984375}, {"pred": "day", "count": 1, "cond_log_prob": -6.392364501953125}, {"pred": "golfroute", "count": 1, "cond_log_prob": -23.073883056640625}, {"pred": "great", "count": 3, "cond_log_prob": -4.256866455078125}, {"pred": "hot", "count": 1, "cond_log_prob": -4.590087890625}, {"pred": "lot", "count": 17, "cond_log_prob": -2.7645263671875}, {"pred": "player", "count": 1, "cond_log_prob": -3.8074951171875}, {"pred": "pro", "count": 1, "cond_log_prob": -6.827362060546875}, {"pred": "problem", "count": 8, "cond_log_prob": -3.05047607421875}, {"pred": "situation", "count": 3, "cond_log_prob": -4.016571044921875}, {"pred": "team", "count": 1, "cond_log_prob": -4.87890625}, {"pred": "very", "count": 2, "cond_log_prob": -4.2449951171875}]}, "28": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat", "log_prob": -137.75753784179688}, "original": {"pred": "wave", "cond_log_prob": -3.42431640625}, "human": [{"pred": "stroke", "cond_log_prob": -3.14923095703125, "count": 16}, {"pred": "issue", "cond_log_prob": -3.00274658203125, "count": 7}, {"pred": "problem", "cond_log_prob": -2.4200439453125, "count": 7}, {"pred": "wave", "cond_log_prob": -3.424530029296875, "count": 6}, {"pred": "ball", "cond_log_prob": -7.557037353515625, "count": 1}, {"pred": "streak", "cond_log_prob": -8.191436767578125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.031829833984375}, {"pred": "deficit", "count": 1, "cond_log_prob": -5.454193115234375}, {"pred": "free", "count": 1, "cond_log_prob": -8.6151123046875}, {"pred": "in", "count": 1, "cond_log_prob": -3.8548583984375}, {"pred": "issue", "count": 8, "cond_log_prob": -3.00274658203125}, {"pred": "map", "count": 1, "cond_log_prob": -3.94342041015625}, {"pred": "problem", "count": 16, "cond_log_prob": -2.4200439453125}, {"pred": "related", "count": 1, "cond_log_prob": -7.337677001953125}, {"pred": "stroke", "count": 1, "cond_log_prob": -3.14923095703125}, {"pred": "that", "count": 1, "cond_log_prob": -2.37060546875}, {"pred": "thatroute", "count": 1, "cond_log_prob": -28.88214111328125}, {"pred": "thats", "count": 6, "cond_log_prob": -11.782806396484375}, {"pred": "wave", "count": 1, "cond_log_prob": -3.424530029296875}]}, "29": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave", "log_prob": -141.18185424804688}, "original": {"pred": "I'm", "cond_log_prob": -11.570709228515625}, "human": [{"pred": "in", "cond_log_prob": -2.51507568359375, "count": 9}, {"pred": "this", "cond_log_prob": -4.959869384765625, "count": 9}, {"pred": "at", "cond_log_prob": -3.880096435546875, "count": 2}, {"pred": "here", "cond_log_prob": -4.50140380859375, "count": 2}, {"pred": "over", "cond_log_prob": -5.398284912109375, "count": 2}, {"pred": "that", "cond_log_prob": -2.77801513671875, "count": 2}, {"pred": "and", "cond_log_prob": -3.968109130859375, "count": 1}, {"pred": "anytime", "cond_log_prob": -5.035003662109375, "count": 1}, {"pred": "during", "cond_log_prob": -5.6427001953125, "count": 1}, {"pred": "influence", "cond_log_prob": -12.8192138671875, "count": 1}, {"pred": "issue", "cond_log_prob": -10.26617431640625, "count": 1}, {"pred": "knock", "cond_log_prob": -11.82220458984375, "count": 1}, {"pred": "on", "cond_log_prob": -3.791107177734375, "count": 1}, {"pred": "problem", "cond_log_prob": -9.828582763671875, "count": 1}, {"pred": "severe", "cond_log_prob": -12.44903564453125, "count": 1}, {"pred": "unlike", "cond_log_prob": -8.416107177734375, "count": 1}, {"pred": "when", "cond_log_prob": -3.956939697265625, "count": 1}, {"pred": "where", "cond_log_prob": -4.0706787109375, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.917449951171875}, {"pred": "Its", "count": 1, "cond_log_prob": -19.72296142578125}, {"pred": "Youre", "count": 3, "cond_log_prob": -21.106231689453125}, {"pred": "because", "count": 4, "cond_log_prob": -3.36529541015625}, {"pred": "but", "count": 2, "cond_log_prob": -5.85662841796875}, {"pred": "he", "count": 8, "cond_log_prob": -10.28704833984375}, {"pred": "here", "count": 1, "cond_log_prob": -4.50140380859375}, {"pred": "if", "count": 3, "cond_log_prob": -2.855560302734375}, {"pred": "in", "count": 8, "cond_log_prob": -2.51507568359375}, {"pred": "like", "count": 3, "cond_log_prob": -3.12725830078125}, {"pred": "or", "count": 1, "cond_log_prob": -3.176605224609375}, {"pred": "that", "count": 2, "cond_log_prob": -2.77801513671875}, {"pred": "thatroute", "count": 1, "cond_log_prob": -28.704620361328125}, {"pred": "thats", "count": 1, "cond_log_prob": -12.76458740234375}, {"pred": "where", "count": 1, "cond_log_prob": -4.0706787109375}]}, "30": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm", "log_prob": -152.7525634765625}, "original": {"pred": "not", "cond_log_prob": -0.7398834228515625}, "human": [{"pred": "going", "cond_log_prob": -4.036407470703125, "count": 7}, {"pred": "sure", "cond_log_prob": -2.087493896484375, "count": 7}, {"pred": "not", "cond_log_prob": -0.7401123046875, "count": 3}, {"pred": "pretty", "cond_log_prob": -4.634979248046875, "count": 3}, {"pred": "certain", "cond_log_prob": -5.488616943359375, "count": 2}, {"pred": "confident", "cond_log_prob": -5.269195556640625, "count": 2}, {"pred": "guessing", "cond_log_prob": -5.730499267578125, "count": 2}, {"pred": "affected", "cond_log_prob": -10.177947998046875, "count": 1}, {"pred": "almost", "cond_log_prob": -7.166107177734375, "count": 1}, {"pred": "always", "cond_log_prob": -7.6182861328125, "count": 1}, {"pred": "aware", "cond_log_prob": -3.246856689453125, "count": 1}, {"pred": "feeling", "cond_log_prob": -8.60430908203125, "count": 1}, {"pred": "having", "cond_log_prob": -6.895263671875, "count": 1}, {"pred": "in", "cond_log_prob": -6.0958251953125, "count": 1}, {"pred": "seeing", "cond_log_prob": -5.80072021484375, "count": 1}, {"pred": "the", "cond_log_prob": -7.68804931640625, "count": 1}, {"pred": "there", "cond_log_prob": -7.926116943359375, "count": 1}, {"pred": "too", "cond_log_prob": -7.343170166015625, "count": 1}, {"pred": "worried", "cond_log_prob": -4.714630126953125, "count": 1}], "ancestral_samples": [{"pred": "happy", "count": 1, "cond_log_prob": -4.67828369140625}, {"pred": "not", "count": 37, "cond_log_prob": -0.7401123046875}, {"pred": "notroute", "count": 1, "cond_log_prob": -26.034515380859375}, {"pred": "sure", "count": 1, "cond_log_prob": -2.087493896484375}]}, "31": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not", "log_prob": -153.49244689941406}, "original": {"pred": "going", "cond_log_prob": -2.268798828125}, "human": [{"pred": "ready", "cond_log_prob": -5.2740325927734375, "count": 6}, {"pred": "worried", "cond_log_prob": -3.7422027587890625, "count": 5}, {"pred": "sure", "cond_log_prob": -1.6644439697265625, "count": 3}, {"pred": "a", "cond_log_prob": -3.6918487548828125, "count": 2}, {"pred": "able", "cond_log_prob": -4.9412689208984375, "count": 2}, {"pred": "certain", "cond_log_prob": -6.2183685302734375, "count": 2}, {"pred": "going", "cond_log_prob": -2.2690277099609375, "count": 2}, {"pred": "saying", "cond_log_prob": -3.7208099365234375, "count": 2}, {"pred": "seeing", "cond_log_prob": -4.3708038330078125, "count": 2}, {"pred": "afraid", "cond_log_prob": -4.7874908447265625, "count": 1}, {"pred": "allowed", "cond_log_prob": -7.5359954833984375, "count": 1}, {"pred": "an", "cond_log_prob": -6.2762908935546875, "count": 1}, {"pred": "available", "cond_log_prob": -9.457809448242188, "count": 1}, {"pred": "even", "cond_log_prob": -3.4870758056640625, "count": 1}, {"pred": "feeling", "cond_log_prob": -6.9781951904296875, "count": 1}, {"pred": "grammaring", "cond_log_prob": -27.340225219726562, "count": 1}, {"pred": "in", "cond_log_prob": -4.4286041259765625, "count": 1}, {"pred": "kidding", "cond_log_prob": -6.8944244384765625, "count": 1}, {"pred": "planning", "cond_log_prob": -8.491470336914062, "count": 1}, {"pred": "prepared", "cond_log_prob": -4.8654022216796875, "count": 1}, {"pred": "really", "cond_log_prob": -5.8409576416015625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.6918487548828125}, {"pred": "aware", "count": 2, "cond_log_prob": -2.6802520751953125}, {"pred": "convinced", "count": 2, "cond_log_prob": -3.9491119384765625}, {"pred": "familiar", "count": 4, "cond_log_prob": -2.8220062255859375}, {"pred": "going", "count": 8, "cond_log_prob": -2.2690277099609375}, {"pred": "happy", "count": 1, "cond_log_prob": -4.1804351806640625}, {"pred": "scared", "count": 1, "cond_log_prob": -5.8345794677734375}, {"pred": "seeing", "count": 1, "cond_log_prob": -4.3708038330078125}, {"pred": "sure", "count": 18, "cond_log_prob": -1.6644439697265625}, {"pred": "sureroute", "count": 1, "cond_log_prob": -24.192794799804688}, {"pred": "worried", "count": 1, "cond_log_prob": -3.7422027587890625}]}, "32": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going", "log_prob": -155.76124572753906}, "original": {"pred": "to", "cond_log_prob": -0.002899169921875}, "human": [{"pred": "to", "cond_log_prob": -0.0031280517578125, "count": 38}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.0031280517578125}, {"pred": "toroute", "count": 1, "cond_log_prob": -35.64268493652344}]}, "33": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to", "log_prob": -155.76414489746094}, "original": {"pred": "be", "cond_log_prob": -2.1013641357421875}, "human": [{"pred": "be", "cond_log_prob": -2.1016082763671875, "count": 9}, {"pred": "worry", "cond_log_prob": -3.8875579833984375, "count": 4}, {"pred": "believe", "cond_log_prob": -3.1352691650390625, "count": 2}, {"pred": "do", "cond_log_prob": -5.0524749755859375, "count": 2}, {"pred": "give", "cond_log_prob": -5.3395233154296875, "count": 2}, {"pred": "play", "cond_log_prob": -5.8380889892578125, "count": 2}, {"pred": "cancel", "cond_log_prob": -10.592941284179688, "count": 1}, {"pred": "deal", "cond_log_prob": -4.5855255126953125, "count": 1}, {"pred": "drive", "cond_log_prob": -6.7572784423828125, "count": 1}, {"pred": "enjoy", "cond_log_prob": -7.1764678955078125, "count": 1}, {"pred": "feel", "cond_log_prob": -4.8463287353515625, "count": 1}, {"pred": "fund", "cond_log_prob": -9.431625366210938, "count": 1}, {"pred": "go", "cond_log_prob": -3.6540985107421875, "count": 1}, {"pred": "handle", "cond_log_prob": -8.148239135742188, "count": 1}, {"pred": "have", "cond_log_prob": -3.0120391845703125, "count": 1}, {"pred": "lie", "cond_log_prob": -6.9472808837890625, "count": 1}, {"pred": "like", "cond_log_prob": -4.7820281982421875, "count": 1}, {"pred": "lose", "cond_log_prob": -5.3631439208984375, "count": 1}, {"pred": "make", "cond_log_prob": -5.0910797119140625, "count": 1}, {"pred": "say", "cond_log_prob": -3.6008148193359375, "count": 1}, {"pred": "tell", "cond_log_prob": -4.8036041259765625, "count": 1}, {"pred": "think", "cond_log_prob": -3.8293914794921875, "count": 1}, {"pred": "use", "cond_log_prob": -5.4096527099609375, "count": 1}], "ancestral_samples": [{"pred": "be", "count": 14, "cond_log_prob": -2.1016082763671875}, {"pred": "believe", "count": 3, "cond_log_prob": -3.1352691650390625}, {"pred": "believeMur", "count": 1, "cond_log_prob": -24.196365356445312}, {"pred": "deal", "count": 1, "cond_log_prob": -4.5855255126953125}, {"pred": "experience", "count": 1, "cond_log_prob": -4.5874786376953125}, {"pred": "get", "count": 2, "cond_log_prob": -3.0356903076171875}, {"pred": "go", "count": 1, "cond_log_prob": -3.6540985107421875}, {"pred": "have", "count": 3, "cond_log_prob": -3.0120391845703125}, {"pred": "haveroute", "count": 1, "cond_log_prob": -26.939376831054688}, {"pred": "put", "count": 1, "cond_log_prob": -5.0143585205078125}, {"pred": "see", "count": 12, "cond_log_prob": -2.0222625732421875}]}, "34": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be", "log_prob": -157.86550903320312}, "original": {"pred": "able", "cond_log_prob": -1.6308135986328125}, "human": [{"pred": "able", "cond_log_prob": -1.631072998046875, "count": 9}, {"pred": "there", "cond_log_prob": -5.36224365234375, "count": 6}, {"pred": "a", "cond_log_prob": -3.546966552734375, "count": 4}, {"pred": "affected", "cond_log_prob": -5.780731201171875, "count": 4}, {"pred": "worried", "cond_log_prob": -3.676055908203125, "count": 3}, {"pred": "surprised", "cond_log_prob": -2.42724609375, "count": 2}, {"pred": "ashamed", "cond_log_prob": -7.773834228515625, "count": 1}, {"pred": "certain", "cond_log_prob": -8.57354736328125, "count": 1}, {"pred": "concerned", "cond_log_prob": -3.693328857421875, "count": 1}, {"pred": "critical", "cond_log_prob": -7.70697021484375, "count": 1}, {"pred": "happy", "cond_log_prob": -3.812469482421875, "count": 1}, {"pred": "here", "cond_log_prob": -5.4237060546875, "count": 1}, {"pred": "suffering", "cond_log_prob": -9.217742919921875, "count": 1}, {"pred": "the", "cond_log_prob": -4.776763916015625, "count": 1}, {"pred": "using", "cond_log_prob": -6.83953857421875, "count": 1}, {"pred": "worrying", "cond_log_prob": -7.753753662109375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -3.546966552734375}, {"pred": "able", "count": 24, "cond_log_prob": -1.631072998046875}, {"pred": "ableroute", "count": 1, "cond_log_prob": -41.07586669921875}, {"pred": "happy", "count": 2, "cond_log_prob": -3.812469482421875}, {"pred": "here", "count": 1, "cond_log_prob": -5.4237060546875}, {"pred": "in", "count": 3, "cond_log_prob": -3.11590576171875}, {"pred": "scared", "count": 1, "cond_log_prob": -4.652252197265625}, {"pred": "seeing", "count": 1, "cond_log_prob": -4.745269775390625}, {"pred": "shocked", "count": 1, "cond_log_prob": -3.994476318359375}, {"pred": "surprised", "count": 3, "cond_log_prob": -2.42724609375}]}, "35": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able", "log_prob": -159.49632263183594}, "original": {"pred": "to", "cond_log_prob": -0.00103759765625}, "human": [{"pred": "to", "cond_log_prob": -0.0012969970703125, "count": 38}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.0012969970703125}, {"pred": "toroute", "count": 1, "cond_log_prob": -33.20317077636719}]}, "36": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to", "log_prob": -159.4973602294922}, "original": {"pred": "handle,\"", "cond_log_prob": -4.845245361328125}, "human": [{"pred": "handle", "cond_log_prob": -3.6702423095703125, "count": 7}, {"pred": "play", "cond_log_prob": -5.6219635009765625, "count": 7}, {"pred": "make", "cond_log_prob": -4.8554229736328125, "count": 3}, {"pred": "control", "cond_log_prob": -4.7570648193359375, "count": 2}, {"pred": "arrive", "cond_log_prob": -11.170700073242188, "count": 1}, {"pred": "attend", "cond_log_prob": -7.1779022216796875, "count": 1}, {"pred": "be", "cond_log_prob": -5.4860076904296875, "count": 1}, {"pred": "cancel", "cond_log_prob": -8.796981811523438, "count": 1}, {"pred": "come", "cond_log_prob": -6.1545562744140625, "count": 1}, {"pred": "conquer", "cond_log_prob": -8.271011352539062, "count": 1}, {"pred": "continue", "cond_log_prob": -6.9358062744140625, "count": 1}, {"pred": "do", "cond_log_prob": -4.2410430908203125, "count": 1}, {"pred": "fart", "cond_log_prob": -14.824417114257812, "count": 1}, {"pred": "fix", "cond_log_prob": -4.9673919677734375, "count": 1}, {"pred": "follow", "cond_log_prob": -7.0485687255859375, "count": 1}, {"pred": "go", "cond_log_prob": -4.7278900146484375, "count": 1}, {"pred": "golf", "cond_log_prob": -9.797195434570312, "count": 1}, {"pred": "help", "cond_log_prob": -5.1085052490234375, "count": 1}, {"pred": "move", "cond_log_prob": -7.6742095947265625, "count": 1}, {"pred": "prove", "cond_log_prob": -5.3484344482421875, "count": 1}, {"pred": "use", "cond_log_prob": -6.6830596923828125, "count": 1}, {"pred": "withstand", "cond_log_prob": -4.9790802001953125, "count": 1}, {"pred": "worry", "cond_log_prob": -6.6249542236328125, "count": 1}], "ancestral_samples": [{"pred": "deal", "count": 10, "cond_log_prob": -2.7355499267578125}, {"pred": "dealroute", "count": 1, "cond_log_prob": -28.340072631835938}, {"pred": "describe", "count": 2, "cond_log_prob": -4.4236297607421875}, {"pred": "fix", "count": 1, "cond_log_prob": -4.9673919677734375}, {"pred": "generate", "count": 1, "cond_log_prob": -6.4548492431640625}, {"pred": "handle", "count": 1, "cond_log_prob": -3.6702423095703125}, {"pred": "predict", "count": 6, "cond_log_prob": -2.8177032470703125}, {"pred": "predictThe", "count": 2, "cond_log_prob": -17.859329223632812}, {"pred": "prevent", "count": 1, "cond_log_prob": -5.3751068115234375}, {"pred": "put", "count": 2, "cond_log_prob": -4.3714447021484375}, {"pred": "see", "count": 13, "cond_log_prob": -2.3654937744140625}]}, "37": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\"", "log_prob": -164.3426055908203}, "original": {"pred": "he", "cond_log_prob": -0.47601318359375}, "human": [{"pred": "he", "cond_log_prob": -0.4763031005859375, "count": 14}, {"pred": "says", "cond_log_prob": -2.4170989990234375, "count": 5}, {"pred": "murphy", "cond_log_prob": -12.636245727539062, "count": 4}, {"pred": "said", "cond_log_prob": -4.0718536376953125, "count": 3}, {"pred": "bob", "cond_log_prob": -12.317092895507812, "count": 2}, {"pred": "the", "cond_log_prob": -5.5701141357421875, "count": 3}, {"pred": "a", "cond_log_prob": -8.085983276367188, "count": 1}, {"pred": "because", "cond_log_prob": -9.544876098632812, "count": 1}, {"pred": "heart", "cond_log_prob": -15.988052368164062, "count": 1}, {"pred": "his", "cond_log_prob": -7.1867523193359375, "count": 1}, {"pred": "if", "cond_log_prob": -9.934280395507812, "count": 1}, {"pred": "that", "cond_log_prob": -8.928787231445312, "count": 1}, {"pred": "this", "cond_log_prob": -9.107406616210938, "count": 1}], "ancestral_samples": [{"pred": "Murphy", "count": 8, "cond_log_prob": -1.5820770263671875}, {"pred": "he", "count": 30, "cond_log_prob": -0.4763031005859375}, {"pred": "heroute", "count": 1, "cond_log_prob": -28.965927124023438}, {"pred": "she", "count": 1, "cond_log_prob": -5.8343048095703125}]}, "38": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he", "log_prob": -164.81861877441406}, "original": {"pred": "said.", "cond_log_prob": -1.5843658447265625}, "human": [{"pred": "said", "cond_log_prob": -1.3350067138671875, "count": 20}, {"pred": "says", "cond_log_prob": -0.583770751953125, "count": 4}, {"pred": "loves", "cond_log_prob": -12.419326782226562, "count": 2}, {"pred": "stated", "cond_log_prob": -7.361083984375, "count": 2}, {"pred": "also", "cond_log_prob": -10.280410766601562, "count": 1}, {"pred": "claimed", "cond_log_prob": -9.909255981445312, "count": 1}, {"pred": "claims", "cond_log_prob": -8.064834594726562, "count": 1}, {"pred": "comments", "cond_log_prob": -8.718032836914062, "count": 1}, {"pred": "cried", "cond_log_prob": -12.270538330078125, "count": 1}, {"pred": "exclaimed", "cond_log_prob": -9.11279296875, "count": 1}, {"pred": "is", "cond_log_prob": -7.2845916748046875, "count": 1}, {"pred": "should", "cond_log_prob": -11.859832763671875, "count": 1}, {"pred": "states", "cond_log_prob": -7.08331298828125, "count": 1}, {"pred": "then", "cond_log_prob": -11.383834838867188, "count": 1}], "ancestral_samples": [{"pred": "said", "count": 7, "cond_log_prob": -1.3350067138671875}, {"pred": "says", "count": 31, "cond_log_prob": -0.583770751953125}, {"pred": "saysIn", "count": 1, "cond_log_prob": -16.093109130859375}, {"pred": "saysroute", "count": 1, "cond_log_prob": -25.360992431640625}]}, "39": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said.", "log_prob": -166.40298461914062}, "original": {"pred": "\"Everybody", "cond_log_prob": -6.627349853515625}, "human": [{"pred": "he", "cond_log_prob": -9.571014404296875, "count": 8}, {"pred": "i", "cond_log_prob": -11.619903564453125, "count": 5}, {"pred": "murphy", "cond_log_prob": -17.263427734375, "count": 3}, {"pred": "the", "cond_log_prob": -9.344970703125, "count": 3}, {"pred": "bob", "cond_log_prob": -13.86322021484375, "count": 2}, {"pred": NaN, "cond_log_prob": -18.60101318359375, "count": 0}, {"pred": "also", "cond_log_prob": -12.547515869140625, "count": 1}, {"pred": "basically", "cond_log_prob": -17.180633544921875, "count": 1}, {"pred": "because", "cond_log_prob": -11.834503173828125, "count": 1}, {"pred": "heat", "cond_log_prob": -13.02886962890625, "count": 1}, {"pred": "his", "cond_log_prob": -11.08868408203125, "count": 1}, {"pred": "in", "cond_log_prob": -9.829376220703125, "count": 1}, {"pred": "lets", "cond_log_prob": -16.39544677734375, "count": 1}, {"pred": "next", "cond_log_prob": -14.336151123046875, "count": 1}, {"pred": "then", "cond_log_prob": -13.3248291015625, "count": 2}, {"pred": "this", "cond_log_prob": -12.188262939453125, "count": 2}, {"pred": "what", "cond_log_prob": -12.716949462890625, "count": 1}, {"pred": "when", "cond_log_prob": -11.57110595703125, "count": 1}, {"pred": "yeah", "cond_log_prob": -15.538421630859375, "count": 1}, {"pred": "yes", "cond_log_prob": -14.357757568359375, "count": 1}], "ancestral_samples": [{"pred": "And", "count": 1, "cond_log_prob": -5.8597412109375}, {"pred": "But", "count": 3, "cond_log_prob": -4.528167724609375}, {"pred": "I", "count": 15, "cond_log_prob": -6.678985595703125}, {"pred": "If", "count": 1, "cond_log_prob": -6.789337158203125}, {"pred": "Im", "count": 2, "cond_log_prob": -11.4012451171875}, {"pred": "In", "count": 1, "cond_log_prob": -5.144378662109375}, {"pred": "Its", "count": 7, "cond_log_prob": -10.703033447265625}, {"pred": "So", "count": 1, "cond_log_prob": -6.59881591796875}, {"pred": "The", "count": 1, "cond_log_prob": -4.685638427734375}, {"pred": "Theres", "count": 1, "cond_log_prob": -17.185943603515625}, {"pred": "To", "count": 1, "cond_log_prob": -7.03204345703125}, {"pred": "Were", "count": 2, "cond_log_prob": -10.99627685546875}, {"pred": "You", "count": 1, "cond_log_prob": -7.2537841796875}, {"pred": "Youre", "count": 2, "cond_log_prob": -18.48388671875}, {"pred": "route", "count": 1, "cond_log_prob": -18.9859619140625}]}, "40": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody", "log_prob": -173.03033447265625}, "original": {"pred": "treats", "cond_log_prob": -9.28961181640625}, "human": [{"pred": "has", "cond_log_prob": -2.43414306640625, "count": 9}, {"pred": "should", "cond_log_prob": -3.595855712890625, "count": 8}, {"pred": "is", "cond_log_prob": -2.440887451171875, "count": 6}, {"pred": "needs", "cond_log_prob": -3.24517822265625, "count": 3}, {"pred": "loves", "cond_log_prob": -5.331268310546875, "count": 2}, {"pred": "better", "cond_log_prob": -8.66070556640625, "count": 1}, {"pred": "can", "cond_log_prob": -4.260894775390625, "count": 1}, {"pred": "claims", "cond_log_prob": -8.827789306640625, "count": 1}, {"pred": "deals", "cond_log_prob": -8.4769287109375, "count": 1}, {"pred": "deserves", "cond_log_prob": -6.269287109375, "count": 1}, {"pred": "get", "cond_log_prob": -8.801513671875, "count": 1}, {"pred": "here", "cond_log_prob": -5.881134033203125, "count": 1}, {"pred": "might", "cond_log_prob": -7.5518798828125, "count": 1}, {"pred": "who", "cond_log_prob": -3.9268798828125, "count": 1}, {"pred": "will", "cond_log_prob": -4.2576904296875, "count": 1}], "ancestral_samples": [{"pred": "gets", "count": 1, "cond_log_prob": -3.677978515625}, {"pred": "has", "count": 3, "cond_log_prob": -2.43414306640625}, {"pred": "is", "count": 4, "cond_log_prob": -2.440887451171875}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.439727783203125}, {"pred": "knows", "count": 5, "cond_log_prob": -2.727294921875}, {"pred": "s", "count": 22, "cond_log_prob": -9.56072998046875}, {"pred": "wants", "count": 2, "cond_log_prob": -3.109527587890625}, {"pred": "whos", "count": 2, "cond_log_prob": -15.42828369140625}]}, "41": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats", "log_prob": -182.3199462890625}, "original": {"pred": "it", "cond_log_prob": -1.6674041748046875}, "human": [{"pred": "me", "cond_log_prob": -5.143646240234375, "count": 12}, {"pred": "heat", "cond_log_prob": -1.3739013671875, "count": 8}, {"pred": "the", "cond_log_prob": -2.066864013671875, "count": 8}, {"pred": "it", "cond_log_prob": -1.667755126953125, "count": 3}, {"pred": "this", "cond_log_prob": -4.244476318359375, "count": 3}, {"pred": "golf", "cond_log_prob": -5.386199951171875, "count": 2}, {"pred": "others", "cond_log_prob": -8.406005859375, "count": 1}, {"pred": "us", "cond_log_prob": -4.945709228515625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.921478271484375}, {"pred": "heat", "count": 21, "cond_log_prob": -1.3739013671875}, {"pred": "it", "count": 10, "cond_log_prob": -1.667755126953125}, {"pred": "itroute", "count": 1, "cond_log_prob": -27.52935791015625}, {"pred": "the", "count": 5, "cond_log_prob": -2.066864013671875}, {"pred": "their", "count": 2, "cond_log_prob": -2.800262451171875}]}, "42": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it", "log_prob": -183.9873504638672}, "original": {"pred": "differently.", "cond_log_prob": -3.227691650390625}, "human": [{"pred": "like", "cond_log_prob": -0.8967742919921875, "count": 30}, {"pred": "as", "cond_log_prob": -2.1968536376953125, "count": 4}, {"pred": "differently", "cond_log_prob": -2.3866119384765625, "count": 3}, {"pred": "so", "cond_log_prob": -5.7787628173828125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.600372314453125}, {"pred": "as", "count": 4, "cond_log_prob": -2.1968536376953125}, {"pred": "differently", "count": 1, "cond_log_prob": -2.3865966796875}, {"pred": "differentlyThe", "count": 1, "cond_log_prob": -18.633148193359375}, {"pred": "like", "count": 28, "cond_log_prob": -0.8967742919921875}, {"pred": "likeroute", "count": 1, "cond_log_prob": -34.10406494140625}, {"pred": "the", "count": 4, "cond_log_prob": -1.9668426513671875}]}, "43": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently.", "log_prob": -187.2150421142578}, "original": {"pred": "My", "cond_log_prob": -5.6977081298828125}, "human": [{"pred": "i", "cond_log_prob": -12.894989013671875, "count": 18}, {"pred": "but", "cond_log_prob": -11.74908447265625, "count": 8}, {"pred": "00 puq", "cond_log_prob": -36.105865478515625, "count": 1}, {"pred": "?", "cond_log_prob": -12.913360595703125, "count": 1}, {"pred": "and", "cond_log_prob": -9.987213134765625, "count": 1}, {"pred": "do", "cond_log_prob": -14.775726318359375, "count": 1}, {"pred": "for", "cond_log_prob": -11.362503051757812, "count": 1}, {"pred": "it", "cond_log_prob": -10.64532470703125, "count": 1}, {"pred": "no", "cond_log_prob": -13.4403076171875, "count": 1}, {"pred": "so", "cond_log_prob": -13.413421630859375, "count": 1}, {"pred": "the", "cond_log_prob": -9.4542236328125, "count": 1}, {"pred": "there", "cond_log_prob": -12.251022338867188, "count": 1}, {"pred": "what", "cond_log_prob": -13.49896240234375, "count": 1}, {"pred": "why", "cond_log_prob": -15.404800415039062, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 2, "cond_log_prob": -2.19854736328125}, {"pred": "If", "count": 1, "cond_log_prob": -2.8624267578125}, {"pred": "Im", "count": 4, "cond_log_prob": -11.027587890625}, {"pred": "Itroute", "count": 1, "cond_log_prob": -29.12677001953125}, {"pred": "Its", "count": 15, "cond_log_prob": -8.64910888671875}, {"pred": "Ive", "count": 2, "cond_log_prob": -14.524215698242188}, {"pred": "People", "count": 1, "cond_log_prob": -3.786102294921875}, {"pred": "The", "count": 4, "cond_log_prob": -3.0986785888671875}, {"pred": "Theyre", "count": 1, "cond_log_prob": -17.26177978515625}, {"pred": "Were", "count": 3, "cond_log_prob": -9.776153564453125}, {"pred": "You", "count": 3, "cond_log_prob": -2.481689453125}, {"pred": "Youre", "count": 3, "cond_log_prob": -15.551727294921875}]}, "44": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My", "log_prob": -192.91275024414062}, "original": {"pred": "son", "cond_log_prob": -5.216888427734375}, "human": [{"pred": "opinion", "cond_log_prob": -3.3023223876953125, "count": 6}, {"pred": "personal", "cond_log_prob": -3.9098968505859375, "count": 6}, {"pred": "approach", "cond_log_prob": -4.912872314453125, "count": 2}, {"pred": "philosophy", "cond_log_prob": -7.5311279296875, "count": 2}, {"pred": "body", "cond_log_prob": -5.03985595703125, "count": 1}, {"pred": "brother", "cond_log_prob": -5.8856658935546875, "count": 1}, {"pred": "concern", "cond_log_prob": -4.6327056884765625, "count": 1}, {"pred": "ego", "cond_log_prob": -7.4225921630859375, "count": 1}, {"pred": "experience", "cond_log_prob": -3.9439239501953125, "count": 1}, {"pred": "favorite", "cond_log_prob": -4.35577392578125, "count": 1}, {"pred": "feelings", "cond_log_prob": -7.853271484375, "count": 1}, {"pred": "love", "cond_log_prob": -7.709716796875, "count": 1}, {"pred": "main", "cond_log_prob": -4.6439208984375, "count": 1}, {"pred": "money", "cond_log_prob": -6.7937469482421875, "count": 1}, {"pred": "motto", "cond_log_prob": -7.756439208984375, "count": 1}, {"pred": "only", "cond_log_prob": -4.945892333984375, "count": 1}, {"pred": "parents", "cond_log_prob": -6.53253173828125, "count": 1}, {"pred": "performance", "cond_log_prob": -7.8374786376953125, "count": 1}, {"pred": "problem", "cond_log_prob": -4.7952880859375, "count": 1}, {"pred": "research", "cond_log_prob": -7.7042388916015625, "count": 1}, {"pred": "son", "cond_log_prob": -5.2172698974609375, "count": 1}, {"pred": "strategy", "cond_log_prob": -6.300567626953125, "count": 1}, {"pred": "take", "cond_log_prob": -5.886260986328125, "count": 1}, {"pred": "training", "cond_log_prob": -6.71966552734375, "count": 1}, {"pred": "view", "cond_log_prob": -4.0996551513671875, "count": 1}, {"pred": "way", "cond_log_prob": -6.311767578125, "count": 1}], "ancestral_samples": [{"pred": "advice", "count": 5, "cond_log_prob": -3.5776519775390625}, {"pred": "clients", "count": 1, "cond_log_prob": -5.6388702392578125}, {"pred": "experience", "count": 2, "cond_log_prob": -3.9439239501953125}, {"pred": "favorite", "count": 2, "cond_log_prob": -4.35577392578125}, {"pred": "first", "count": 1, "cond_log_prob": -4.4543304443359375}, {"pred": "focus", "count": 1, "cond_log_prob": -5.132965087890625}, {"pred": "goal", "count": 6, "cond_log_prob": -3.52197265625}, {"pred": "heart", "count": 1, "cond_log_prob": -4.9213714599609375}, {"pred": "kids", "count": 2, "cond_log_prob": -3.9747772216796875}, {"pred": "opinion", "count": 2, "cond_log_prob": -3.3023223876953125}, {"pred": "point", "count": 1, "cond_log_prob": -3.978759765625}, {"pred": "pro", "count": 1, "cond_log_prob": -7.4156951904296875}, {"pred": "team", "count": 1, "cond_log_prob": -5.071929931640625}, {"pred": "understandingroute", "count": 1, "cond_log_prob": -29.918228149414062}, {"pred": "view", "count": 1, "cond_log_prob": -4.0996551513671875}, {"pred": "wife", "count": 12, "cond_log_prob": -2.9494476318359375}]}, "45": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son", "log_prob": -198.129638671875}, "original": {"pred": "Ronnie,", "cond_log_prob": -12.34820556640625}, "human": [{"pred": "is", "cond_log_prob": -1.923248291015625, "count": 14}, {"pred": "has", "cond_log_prob": -2.7608642578125, "count": 8}, {"pred": "and", "cond_log_prob": -3.12078857421875, "count": 3}, {"pred": "does", "cond_log_prob": -4.8419342041015625, "count": 3}, {"pred": "always", "cond_log_prob": -5.0384521484375, "count": 2}, {"pred": "ca", "cond_log_prob": -12.27056884765625, "count": 1}, {"pred": "even", "cond_log_prob": -7.8562164306640625, "count": 1}, {"pred": "never", "cond_log_prob": -6.1957244873046875, "count": 1}, {"pred": "plays", "cond_log_prob": -4.8612060546875, "count": 1}, {"pred": "said", "cond_log_prob": -5.15045166015625, "count": 1}, {"pred": "says", "cond_log_prob": -4.5009307861328125, "count": 1}, {"pred": "thinks", "cond_log_prob": -5.7910003662109375, "count": 1}, {"pred": "was", "cond_log_prob": -2.8733367919921875, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 2, "cond_log_prob": -3.12078857421875}, {"pred": "gets", "count": 1, "cond_log_prob": -4.4006195068359375}, {"pred": "had", "count": 1, "cond_log_prob": -3.970062255859375}, {"pred": "hes", "count": 2, "cond_log_prob": -11.793716430664062}, {"pred": "is", "count": 19, "cond_log_prob": -1.923248291015625}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.540603637695312}, {"pred": "my", "count": 1, "cond_log_prob": -7.637786865234375}, {"pred": "s", "count": 7, "cond_log_prob": -9.841751098632812}, {"pred": "was", "count": 4, "cond_log_prob": -2.8733367919921875}, {"pred": "who", "count": 1, "cond_log_prob": -6.0228729248046875}, {"pred": "will", "count": 1, "cond_log_prob": -3.910125732421875}]}, "46": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son Ronnie,", "log_prob": -210.47784423828125}, "original": {"pred": "his", "cond_log_prob": -2.6035308837890625}, "human": [{"pred": "he", "cond_log_prob": -2.3728485107421875, "count": 6}, {"pred": "a", "cond_log_prob": -3.5757904052734375, "count": 4}, {"pred": "has", "cond_log_prob": -5.6377716064453125, "count": 4}, {"pred": "is", "cond_log_prob": -4.5860748291015625, "count": 4}, {"pred": "the", "cond_log_prob": -3.6530609130859375, "count": 4}, {"pred": "who", "cond_log_prob": -1.5074920654296875, "count": 3}, {"pred": "does", "cond_log_prob": -6.7690277099609375, "count": 2}, {"pred": "for", "cond_log_prob": -3.9748992919921875, "count": 2}, {"pred": "likes", "cond_log_prob": -9.296920776367188, "count": 2}, {"pred": "aaa", "cond_log_prob": -18.171035766601562, "count": 1}, {"pred": "played", "cond_log_prob": -6.7834320068359375, "count": 1}, {"pred": "plays", "cond_log_prob": -7.1980743408203125, "count": 1}, {"pred": "said", "cond_log_prob": -8.063491821289062, "count": 1}, {"pred": "says", "cond_log_prob": -6.6481475830078125, "count": 1}, {"pred": "thinks", "cond_log_prob": -8.919662475585938, "count": 1}, {"pred": "told", "cond_log_prob": -8.800643920898438, "count": 1}], "ancestral_samples": [{"pred": "Ive", "count": 1, "cond_log_prob": -14.026260375976562}, {"pred": "a", "count": 3, "cond_log_prob": -3.5757904052734375}, {"pred": "hes", "count": 4, "cond_log_prob": -11.070297241210938}, {"pred": "his", "count": 1, "cond_log_prob": -2.6039276123046875}, {"pred": "my", "count": 4, "cond_log_prob": -2.4737701416015625}, {"pred": "the", "count": 1, "cond_log_prob": -3.6530609130859375}, {"pred": "who", "count": 18, "cond_log_prob": -1.5074920654296875}, {"pred": "whoroute", "count": 1, "cond_log_prob": -33.37297058105469}, {"pred": "whos", "count": 7, "cond_log_prob": -13.674484252929688}]}, "47": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son Ronnie, his", "log_prob": -213.0813751220703}, "original": {"pred": "caddie,", "cond_log_prob": -12.549163818359375}, "human": [{"pred": "friend", "cond_log_prob": -4.31512451171875, "count": 4}, {"pred": "game", "cond_log_prob": -7.433746337890625, "count": 3}, {"pred": "wife", "cond_log_prob": -2.053619384765625, "count": 3}, {"pred": "body", "cond_log_prob": -7.448822021484375, "count": 2}, {"pred": "favorite", "cond_log_prob": -5.64129638671875, "count": 2}, {"pred": "heat", "cond_log_prob": -10.51434326171875, "count": 2}, {"pred": "view", "cond_log_prob": -10.60772705078125, "count": 2}, {"pred": "aaa", "cond_log_prob": -16.422882080078125, "count": 1}, {"pred": "actions", "cond_log_prob": -10.9952392578125, "count": 1}, {"pred": "belief", "cond_log_prob": -11.948883056640625, "count": 1}, {"pred": "brother", "cond_log_prob": -2.85369873046875, "count": 1}, {"pred": "dad", "cond_log_prob": -3.030548095703125, "count": 1}, {"pred": "dog", "cond_log_prob": -5.69873046875, "count": 1}, {"pred": "family", "cond_log_prob": -4.241546630859375, "count": 1}, {"pred": "friends", "cond_log_prob": -5.130401611328125, "count": 1}, {"pred": "girlfriend", "cond_log_prob": -4.052398681640625, "count": 1}, {"pred": "golf", "cond_log_prob": -5.864990234375, "count": 1}, {"pred": "greatest", "cond_log_prob": -8.0985107421875, "count": 1}, {"pred": "guitar", "cond_log_prob": -9.668853759765625, "count": 1}, {"pred": "method", "cond_log_prob": -11.441131591796875, "count": 1}, {"pred": "mother", "cond_log_prob": -3.986846923828125, "count": 1}, {"pred": "name", "cond_log_prob": -7.101318359375, "count": 1}, {"pred": "only", "cond_log_prob": -6.33746337890625, "count": 1}, {"pred": "opinion", "cond_log_prob": -9.81585693359375, "count": 1}, {"pred": "reaction", "cond_log_prob": -9.6156005859375, "count": 1}, {"pred": "time", "cond_log_prob": -8.37255859375, "count": 1}, {"pred": "way", "cond_log_prob": -8.06549072265625, "count": 1}], "ancestral_samples": [{"pred": "baby", "count": 1, "cond_log_prob": -6.341461181640625}, {"pred": "brother", "count": 4, "cond_log_prob": -2.853729248046875}, {"pred": "dad", "count": 3, "cond_log_prob": -3.030548095703125}, {"pred": "daughter", "count": 4, "cond_log_prob": -2.960235595703125}, {"pred": "family", "count": 1, "cond_log_prob": -4.241546630859375}, {"pred": "friend", "count": 1, "cond_log_prob": -4.31512451171875}, {"pred": "older", "count": 1, "cond_log_prob": -4.466033935546875}, {"pred": "son", "count": 7, "cond_log_prob": -2.629791259765625}, {"pred": "wife", "count": 17, "cond_log_prob": -2.053619384765625}, {"pred": "wiferoute", "count": 1, "cond_log_prob": -36.0601806640625}]}, "48": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son Ronnie, his caddie,", "log_prob": -225.6305389404297}, "original": {"pred": "and", "cond_log_prob": -2.850341796875}, "human": [{"pred": "and", "cond_log_prob": -2.85076904296875, "count": 15}, {"pred": "is", "cond_log_prob": -2.833038330078125, "count": 10}, {"pred": "has", "cond_log_prob": -3.528411865234375, "count": 2}, {"pred": "always", "cond_log_prob": -5.363189697265625, "count": 1}, {"pred": "does", "cond_log_prob": -5.436798095703125, "count": 1}, {"pred": "helps", "cond_log_prob": -7.442901611328125, "count": 1}, {"pred": "it", "cond_log_prob": -4.905548095703125, "count": 1}, {"pred": "loves", "cond_log_prob": -5.1395263671875, "count": 1}, {"pred": "never", "cond_log_prob": -6.38690185546875, "count": 1}, {"pred": "steve", "cond_log_prob": -16.5452880859375, "count": 1}, {"pred": "told", "cond_log_prob": -6.71240234375, "count": 1}, {"pred": "was", "cond_log_prob": -4.064483642578125, "count": 1}, {"pred": "went", "cond_log_prob": -5.894317626953125, "count": 1}, {"pred": "will", "cond_log_prob": -5.059295654296875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.591094970703125}, {"pred": "and", "count": 8, "cond_log_prob": -2.85076904296875}, {"pred": "hes", "count": 8, "cond_log_prob": -11.063446044921875}, {"pred": "his", "count": 16, "cond_log_prob": -2.044342041015625}, {"pred": "is", "count": 1, "cond_log_prob": -2.833038330078125}, {"pred": "isroute", "count": 1, "cond_log_prob": -26.319000244140625}, {"pred": "my", "count": 2, "cond_log_prob": -3.1268310546875}, {"pred": "the", "count": 1, "cond_log_prob": -3.670135498046875}, {"pred": "was", "count": 1, "cond_log_prob": -4.064483642578125}, {"pred": "whos", "count": 1, "cond_log_prob": -13.930999755859375}]}, "49": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son Ronnie, his caddie, and", "log_prob": -228.4808807373047}, "original": {"pred": "I", "cond_log_prob": -1.9798126220703125}, "human": [{"pred": "his", "cond_log_prob": -1.5264892578125, "count": 14}, {"pred": "i", "cond_log_prob": -9.05352783203125, "count": 10}, {"pred": "a", "cond_log_prob": -4.004180908203125, "count": 2}, {"pred": "my", "cond_log_prob": -2.023284912109375, "count": 2}, {"pred": "myself", "cond_log_prob": -3.8668212890625, "count": 2}, {"pred": "and", "cond_log_prob": -8.228668212890625, "count": 1}, {"pred": "best", "cond_log_prob": -8.965850830078125, "count": 1}, {"pred": "coach", "cond_log_prob": -7.14788818359375, "count": 1}, {"pred": "driver", "cond_log_prob": -10.729583740234375, "count": 1}, {"pred": "friend", "cond_log_prob": -7.107757568359375, "count": 1}, {"pred": "lacy", "cond_log_prob": -16.08868408203125, "count": 1}, {"pred": "others", "cond_log_prob": -6.0452880859375, "count": 1}, {"pred": "the", "cond_log_prob": -3.0772705078125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 7, "cond_log_prob": -1.980255126953125}, {"pred": "a", "count": 1, "cond_log_prob": -4.004180908203125}, {"pred": "hes", "count": 1, "cond_log_prob": -13.36700439453125}, {"pred": "his", "count": 17, "cond_log_prob": -1.5264892578125}, {"pred": "hisroute", "count": 1, "cond_log_prob": -23.92083740234375}, {"pred": "me", "count": 1, "cond_log_prob": -4.296722412109375}, {"pred": "my", "count": 9, "cond_log_prob": -2.023284912109375}, {"pred": "our", "count": 1, "cond_log_prob": -3.70068359375}, {"pred": "the", "count": 2, "cond_log_prob": -3.0772705078125}]}, "50": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son Ronnie, his caddie, and I", "log_prob": -230.460693359375}, "original": {"pred": "won't", "cond_log_prob": -7.1641693115234375}, "human": [{"pred": "are", "cond_log_prob": -2.2819671630859375, "count": 12}, {"pred": "do", "cond_log_prob": -4.0236663818359375, "count": 4}, {"pred": "all", "cond_log_prob": -2.1167755126953125, "count": 3}, {"pred": "have", "cond_log_prob": -1.9922943115234375, "count": 3}, {"pred": "went", "cond_log_prob": -4.6788177490234375, "count": 3}, {"pred": "think", "cond_log_prob": -5.8180389404296875, "count": 2}, {"pred": "were", "cond_log_prob": -3.3197174072265625, "count": 2}, {"pred": "will", "cond_log_prob": -4.5717010498046875, "count": 2}, {"pred": "am", "cond_log_prob": -8.091720581054688, "count": 1}, {"pred": "both", "cond_log_prob": -4.7967071533203125, "count": 1}, {"pred": "can", "cond_log_prob": -4.5778961181640625, "count": 1}, {"pred": "love", "cond_log_prob": -4.9351348876953125, "count": 1}, {"pred": "play", "cond_log_prob": -5.4249420166015625, "count": 1}, {"pred": "spend", "cond_log_prob": -6.5357513427734375, "count": 1}, {"pred": "want", "cond_log_prob": -5.0506439208984375, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -8.310317993164062}, {"pred": "all", "count": 7, "cond_log_prob": -2.1167755126953125}, {"pred": "are", "count": 12, "cond_log_prob": -2.2819671630859375}, {"pred": "dont", "count": 3, "cond_log_prob": -11.054122924804688}, {"pred": "had", "count": 1, "cond_log_prob": -3.9778594970703125}, {"pred": "have", "count": 12, "cond_log_prob": -1.9922943115234375}, {"pred": "haveroute", "count": 1, "cond_log_prob": -29.177093505859375}, {"pred": "treat", "count": 1, "cond_log_prob": -3.8726654052734375}, {"pred": "were", "count": 2, "cond_log_prob": -3.3197174072265625}]}, "51": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son Ronnie, his caddie, and I won't", "log_prob": -237.62486267089844}, "original": {"pred": "be", "cond_log_prob": -0.9439544677734375}, "human": [{"pred": "be", "cond_log_prob": -0.944427490234375, "count": 10}, {"pred": "let", "cond_log_prob": -2.8978271484375, "count": 5}, {"pred": "have", "cond_log_prob": -3.226959228515625, "count": 3}, {"pred": "back", "cond_log_prob": -7.01116943359375, "count": 2}, {"pred": "go", "cond_log_prob": -3.11944580078125, "count": 2}, {"pred": "worry", "cond_log_prob": -6.5462646484375, "count": 2}, {"pred": "agree", "cond_log_prob": -7.452667236328125, "count": 1}, {"pred": "allow", "cond_log_prob": -4.67730712890625, "count": 1}, {"pred": "do", "cond_log_prob": -4.450042724609375, "count": 1}, {"pred": "enjoy", "cond_log_prob": -8.38958740234375, "count": 1}, {"pred": "fail", "cond_log_prob": -8.920684814453125, "count": 1}, {"pred": "feel", "cond_log_prob": -6.13360595703125, "count": 1}, {"pred": "give", "cond_log_prob": -4.2513427734375, "count": 1}, {"pred": "mind", "cond_log_prob": -5.63299560546875, "count": 1}, {"pred": "need", "cond_log_prob": -5.930877685546875, "count": 1}, {"pred": "participate", "cond_log_prob": -8.32464599609375, "count": 1}, {"pred": "play", "cond_log_prob": -4.371429443359375, "count": 1}, {"pred": "quit", "cond_log_prob": -7.326324462890625, "count": 1}, {"pred": "step", "cond_log_prob": -7.958465576171875, "count": 1}, {"pred": "stop", "cond_log_prob": -5.09747314453125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -10.970703125}, {"pred": "be", "count": 35, "cond_log_prob": -0.944427490234375}, {"pred": "beroute", "count": 1, "cond_log_prob": -28.357986450195312}, {"pred": "go", "count": 1, "cond_log_prob": -3.11944580078125}, {"pred": "have", "count": 1, "cond_log_prob": -3.226959228515625}, {"pred": "put", "count": 1, "cond_log_prob": -4.3272705078125}]}, "52": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son Ronnie, his caddie, and I won't be", "log_prob": -238.56881713867188}, "original": {"pred": "riding", "cond_log_prob": -7.2098541259765625}, "human": [{"pred": "able", "cond_log_prob": -0.7039337158203125, "count": 5}, {"pred": "affected", "cond_log_prob": -6.5587921142578125, "count": 4}, {"pred": "going", "cond_log_prob": -4.3073577880859375, "count": 3}, {"pred": "worried", "cond_log_prob": -6.9622344970703125, "count": 3}, {"pred": "any", "cond_log_prob": -6.8412017822265625, "count": 2}, {"pred": "worrying", "cond_log_prob": -9.099258422851562, "count": 2}, {"pred": "anything", "cond_log_prob": -8.886459350585938, "count": 1}, {"pred": "attending", "cond_log_prob": -7.3284149169921875, "count": 1}, {"pred": "checking", "cond_log_prob": -10.465438842773438, "count": 1}, {"pred": "coming", "cond_log_prob": -5.9514312744140625, "count": 1}, {"pred": "deterred", "cond_log_prob": -7.9545440673828125, "count": 1}, {"pred": "discouraged", "cond_log_prob": -8.812973022460938, "count": 1}, {"pred": "effected", "cond_log_prob": -10.165969848632812, "count": 1}, {"pred": "found", "cond_log_prob": -9.648666381835938, "count": 1}, {"pred": "having", "cond_log_prob": -4.4316864013671875, "count": 1}, {"pred": "in", "cond_log_prob": -3.8139190673828125, "count": 1}, {"pred": "intimidated", "cond_log_prob": -5.3388824462890625, "count": 1}, {"pred": "missing", "cond_log_prob": -8.036087036132812, "count": 1}, {"pred": "out", "cond_log_prob": -4.5818634033203125, "count": 1}, {"pred": "playing", "cond_log_prob": -4.4850921630859375, "count": 1}, {"pred": "stopped", "cond_log_prob": -9.531814575195312, "count": 1}, {"pred": "taking", "cond_log_prob": -5.0800628662109375, "count": 1}, {"pred": "there", "cond_log_prob": -5.3980560302734375, "count": 1}, {"pred": "troubled", "cond_log_prob": -10.770614624023438, "count": 1}, {"pred": "upset", "cond_log_prob": -6.6100616455078125, "count": 1}], "ancestral_samples": [{"pred": "able", "count": 39, "cond_log_prob": -0.7039337158203125}, {"pred": "ableroute", "count": 1, "cond_log_prob": -38.065277099609375}]}, "53": {"context": {"text": "Bob Murphy, the Senior PGA Tour money leader with seven hundred thousand, says heat shouldn't be a factor. \"I don't think you're going to have a heat wave I'm not going to be able to handle,\" he said. \"Everybody treats it differently. My son Ronnie, his caddie, and I won't be riding", "log_prob": -245.77867126464844}, "original": {"pred": "carts.", "cond_log_prob": -12.671127319335938}, "human": [{"pred": "the", "cond_log_prob": -2.520263671875, "count": 9}, {"pred": "in", "cond_log_prob": -2.238433837890625, "count": 7}, {"pred": "a", "cond_log_prob": -2.43695068359375, "count": 4}, {"pred": "out", "cond_log_prob": -4.657135009765625, "count": 3}, {"pred": "on", "cond_log_prob": -3.109039306640625, "count": 2}, {"pred": "this", "cond_log_prob": -3.6568603515625, "count": 2}, {"pred": "together", "cond_log_prob": -5.6885986328125, "count": 2}, {"pred": "along", "cond_log_prob": -6.947296142578125, "count": 1}, {"pred": "any", "cond_log_prob": -3.077117919921875, "count": 1}, {"pred": "back", "cond_log_prob": -6.335479736328125, "count": 1}, {"pred": "carts", "cond_log_prob": -10.478744506835938, "count": 1}, {"pred": "horses", "cond_log_prob": -5.79150390625, "count": 1}, {"pred": "into", "cond_log_prob": -6.0498504638671875, "count": 1}, {"pred": "slow", "cond_log_prob": -9.511093139648438, "count": 1}, {"pred": "slower", "cond_log_prob": -9.601699829101562, "count": 1}, {"pred": "when", "cond_log_prob": -6.5118408203125, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -7.32733154296875}, {"pred": "a", "count": 9, "cond_log_prob": -2.43695068359375}, {"pred": "in", "count": 13, "cond_log_prob": -2.238433837890625}, {"pred": "my", "count": 1, "cond_log_prob": -4.3371124267578125}, {"pred": "on", "count": 1, "cond_log_prob": -3.109039306640625}, {"pred": "our", "count": 2, "cond_log_prob": -4.0979766845703125}, {"pred": "that", "count": 2, "cond_log_prob": -2.8227386474609375}, {"pred": "thatroute", "count": 1, "cond_log_prob": -20.360061645507812}, {"pred": "the", "count": 7, "cond_log_prob": -2.520263671875}, {"pred": "this", "count": 1, "cond_log_prob": -3.6568603515625}, {"pred": "with", "count": 2, "cond_log_prob": -3.0744171142578125}]}}, "14": {"2": {"context": {"text": "With", "log_prob": -10.691495895385742}, "original": {"pred": "schools", "cond_log_prob": -9.361547470092773}, "human": [{"pred": "a", "cond_log_prob": -2.8061771392822266, "count": 5}, {"pred": "the", "cond_log_prob": -1.6274127960205078, "count": 6}, {"pred": "all", "cond_log_prob": -3.636720657348633, "count": 2}, {"pred": "each", "cond_log_prob": -5.146547317504883, "count": 2}, {"pred": "great", "cond_log_prob": -6.596872329711914, "count": 2}, {"pred": "many", "cond_log_prob": -5.597589492797852, "count": 2}, {"pred": "out", "cond_log_prob": -8.384897232055664, "count": 2}, {"pred": "asw", "cond_log_prob": -19.67503547668457, "count": 1}, {"pred": "caution", "cond_log_prob": -11.498712539672852, "count": 1}, {"pred": "depression", "cond_log_prob": -10.726648330688477, "count": 1}, {"pred": "every", "cond_log_prob": -5.153268814086914, "count": 1}, {"pred": "everything", "cond_log_prob": -6.724390029907227, "count": 1}, {"pred": "her", "cond_log_prob": -5.273073196411133, "count": 1}, {"pred": "love", "cond_log_prob": -8.110719680786133, "count": 1}, {"pred": "me", "cond_log_prob": -7.81071662902832, "count": 1}, {"pred": "much", "cond_log_prob": -6.356500625610352, "count": 1}, {"pred": "my", "cond_log_prob": -5.441308975219727, "count": 1}, {"pred": "new", "cond_log_prob": -5.758768081665039, "count": 1}, {"pred": "nothing", "cond_log_prob": -7.674318313598633, "count": 1}, {"pred": "nowhere", "cond_log_prob": -9.208917617797852, "count": 1}, {"pred": "regard", "cond_log_prob": -6.319116592407227, "count": 1}, {"pred": "time", "cond_log_prob": -6.832696914672852, "count": 1}, {"pred": "what", "cond_log_prob": -6.461694717407227, "count": 1}, {"pred": "whom", "cond_log_prob": -9.051797866821289, "count": 1}, {"pred": "you", "cond_log_prob": -7.360040664672852, "count": 1}], "ancestral_samples": [{"pred": "Banks", "count": 1, "cond_log_prob": -12.977838516235352}, {"pred": "a", "count": 10, "cond_log_prob": -2.8061771392822266}, {"pred": "my", "count": 1, "cond_log_prob": -5.441308975219727}, {"pred": "the", "count": 26, "cond_log_prob": -1.6274127960205078}, {"pred": "theroutemake", "count": 1, "cond_log_prob": -39.73588562011719}, {"pred": "your", "count": 1, "cond_log_prob": -5.383218765258789}]}, "3": {"context": {"text": "With schools", "log_prob": -20.053043365478516}, "original": {"pred": "still", "cond_log_prob": -4.720237731933594}, "human": [{"pred": "in", "cond_log_prob": -2.835987091064453, "count": 14}, {"pred": "that", "cond_log_prob": -4.719226837158203, "count": 4}, {"pred": "and", "cond_log_prob": -2.702167510986328, "count": 2}, {"pred": "becoming", "cond_log_prob": -5.511493682861328, "count": 2}, {"pred": "one", "cond_log_prob": -7.827548980712891, "count": 2}, {"pred": "teaching", "cond_log_prob": -5.639942169189453, "count": 2}, {"pred": "attempting", "cond_log_prob": -8.380359649658203, "count": 1}, {"pred": "being", "cond_log_prob": -3.873737335205078, "count": 1}, {"pred": "come", "cond_log_prob": -8.708805084228516, "count": 1}, {"pred": "containing", "cond_log_prob": -9.071170806884766, "count": 1}, {"pred": "going", "cond_log_prob": -5.320919036865234, "count": 1}, {"pred": "having", "cond_log_prob": -4.331127166748047, "count": 1}, {"pred": "increasing", "cond_log_prob": -6.282909393310547, "count": 1}, {"pred": "kids", "cond_log_prob": -9.641536712646484, "count": 1}, {"pred": "so", "cond_log_prob": -5.047473907470703, "count": 1}, {"pred": "teachers", "cond_log_prob": -10.074779510498047, "count": 1}, {"pred": "there", "cond_log_prob": -7.798160552978516, "count": 1}, {"pred": "these", "cond_log_prob": -8.726520538330078, "count": 1}, {"pred": "until", "cond_log_prob": -9.554752349853516, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -14.120052337646484}, {"pred": "and", "count": 12, "cond_log_prob": -2.702167510986328}, {"pred": "being", "count": 1, "cond_log_prob": -3.873737335205078}, {"pred": "educators", "count": 1, "cond_log_prob": -12.644939422607422}, {"pred": "in", "count": 2, "cond_log_prob": -2.835987091064453}, {"pred": "parents", "count": 2, "cond_log_prob": -10.985980987548828}, {"pred": "that", "count": 6, "cond_log_prob": -4.719226837158203}, {"pred": "thatroute", "count": 1, "cond_log_prob": -23.85030746459961}, {"pred": "the", "count": 4, "cond_log_prob": -5.648876190185547}, {"pred": "to", "count": 9, "cond_log_prob": -5.343769073486328}, {"pred": "we", "count": 1, "cond_log_prob": -8.74935531616211}]}, "4": {"context": {"text": "With schools still", "log_prob": -24.77328109741211}, "original": {"pred": "closed,", "cond_log_prob": -5.690816879272461}, "human": [{"pred": "in", "cond_log_prob": -3.1506080627441406, "count": 4}, {"pred": "teaching", "cond_log_prob": -5.441295623779297, "count": 4}, {"pred": "open", "cond_log_prob": -5.469417572021484, "count": 3}, {"pred": "struggling", "cond_log_prob": -2.2949867248535156, "count": 2}, {"pred": "using", "cond_log_prob": -5.514255523681641, "count": 2}, {"pred": "around", "cond_log_prob": -6.683071136474609, "count": 1}, {"pred": "being", "cond_log_prob": -4.336490631103516, "count": 1}, {"pred": "enrolling", "cond_log_prob": -8.06081771850586, "count": 1}, {"pred": "exist", "cond_log_prob": -12.962421417236328, "count": 1}, {"pred": "failing", "cond_log_prob": -4.298801422119141, "count": 1}, {"pred": "fighting", "cond_log_prob": -5.828220367431641, "count": 1}, {"pred": "finding", "cond_log_prob": -6.186534881591797, "count": 1}, {"pred": "fixing", "cond_log_prob": -9.74423599243164, "count": 1}, {"pred": "having", "cond_log_prob": -4.630947113037109, "count": 1}, {"pred": "implementing", "cond_log_prob": -7.551418304443359, "count": 1}, {"pred": "involved", "cond_log_prob": -7.953197479248047, "count": 1}, {"pred": "lacking", "cond_log_prob": -6.195217132568359, "count": 1}, {"pred": "letting", "cond_log_prob": -7.246822357177734, "count": 1}, {"pred": "not", "cond_log_prob": -4.318210601806641, "count": 1}, {"pred": "operating", "cond_log_prob": -5.035045623779297, "count": 1}, {"pred": "participating", "cond_log_prob": -8.092830657958984, "count": 1}, {"pred": "paying", "cond_log_prob": -5.809093475341797, "count": 1}, {"pred": "people", "cond_log_prob": -10.701274871826172, "count": 1}, {"pred": "requiring", "cond_log_prob": -6.720745086669922, "count": 1}, {"pred": "shutting", "cond_log_prob": -7.312847137451172, "count": 1}, {"pred": "sitting", "cond_log_prob": -7.156261444091797, "count": 1}, {"pred": "studying", "cond_log_prob": -7.152744293212891, "count": 1}, {"pred": "trying", "cond_log_prob": -4.758205413818359, "count": 2}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -5.518222808837891}, {"pred": "allowed", "count": 1, "cond_log_prob": -5.929973602294922}, {"pred": "being", "count": 2, "cond_log_prob": -4.336490631103516}, {"pred": "in", "count": 8, "cond_log_prob": -3.1506080627441406}, {"pred": "not", "count": 3, "cond_log_prob": -4.318210601806641}, {"pred": "relying", "count": 1, "cond_log_prob": -6.400325775146484}, {"pred": "seeing", "count": 1, "cond_log_prob": -6.079540252685547}, {"pred": "struggling", "count": 14, "cond_log_prob": -2.2949867248535156}, {"pred": "strugglingroute", "count": 1, "cond_log_prob": -25.72854232788086}, {"pred": "to", "count": 3, "cond_log_prob": -6.548206329345703}, {"pred": "trying", "count": 1, "cond_log_prob": -4.758205413818359}, {"pred": "under", "count": 2, "cond_log_prob": -3.6811485290527344}, {"pred": "underfunded", "count": 2, "cond_log_prob": -5.650825500488281}]}, "5": {"context": {"text": "With schools still closed,", "log_prob": -30.46409797668457}, "original": {"pred": "cars", "cond_log_prob": -8.251974105834961}, "human": [{"pred": "the", "cond_log_prob": -2.6280956268310547, "count": 15}, {"pred": "students", "cond_log_prob": -2.866750717163086, "count": 7}, {"pred": "we", "cond_log_prob": -5.381650924682617, "count": 5}, {"pred": "there", "cond_log_prob": -3.7577342987060547, "count": 3}, {"pred": "all", "cond_log_prob": -5.955495834350586, "count": 1}, {"pred": "and", "cond_log_prob": -4.02491569519043, "count": 1}, {"pred": "because", "cond_log_prob": -8.861173629760742, "count": 1}, {"pred": "due", "cond_log_prob": -9.195859909057617, "count": 1}, {"pred": "he", "cond_log_prob": -6.810033798217773, "count": 2}, {"pred": "it", "cond_log_prob": -4.251005172729492, "count": 1}, {"pred": "kids", "cond_log_prob": -5.230039596557617, "count": 1}, {"pred": "weather", "cond_log_prob": -10.213644027709961, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -4.273786544799805}, {"pred": "hospitals", "count": 1, "cond_log_prob": -7.524839401245117}, {"pred": "many", "count": 3, "cond_log_prob": -2.8969554901123047}, {"pred": "manyroute", "count": 1, "cond_log_prob": -23.659696578979492}, {"pred": "most", "count": 1, "cond_log_prob": -4.67487907409668}, {"pred": "parents", "count": 1, "cond_log_prob": -4.14271354675293}, {"pred": "some", "count": 3, "cond_log_prob": -3.416074752807617}, {"pred": "students", "count": 4, "cond_log_prob": -2.866750717163086}, {"pred": "the", "count": 23, "cond_log_prob": -2.6280956268310547}, {"pred": "they", "count": 1, "cond_log_prob": -5.384145736694336}]}, "6": {"context": {"text": "With schools still closed, cars", "log_prob": -38.71607208251953}, "original": {"pred": "still", "cond_log_prob": -2.7632522583007812}, "human": [{"pred": "are", "cond_log_prob": -1.2351531982421875, "count": 13}, {"pred": "will", "cond_log_prob": -4.5151214599609375, "count": 6}, {"pred": "can", "cond_log_prob": -4.7098236083984375, "count": 3}, {"pred": "and", "cond_log_prob": -2.7364654541015625, "count": 2}, {"pred": "have", "cond_log_prob": -3.4714584350585938, "count": 2}, {"pred": "should", "cond_log_prob": -8.289443969726562, "count": 2}, {"pred": "still", "cond_log_prob": -2.76336669921875, "count": 2}, {"pred": "were", "cond_log_prob": -3.6029205322265625, "count": 2}, {"pred": "cant", "cond_log_prob": -11.11279296875, "count": 1}, {"pred": "did", "cond_log_prob": -9.375030517578125, "count": 1}, {"pred": "do", "cond_log_prob": -7.164833068847656, "count": 1}, {"pred": "drove", "cond_log_prob": -8.111862182617188, "count": 1}, {"pred": "not", "cond_log_prob": -6.0517120361328125, "count": 1}, {"pred": "re", "cond_log_prob": -7.7652435302734375, "count": 1}, {"pred": "tend", "cond_log_prob": -7.023185729980469, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 5, "cond_log_prob": -2.7364654541015625}, {"pred": "are", "count": 15, "cond_log_prob": -1.2351531982421875}, {"pred": "on", "count": 1, "cond_log_prob": -3.77001953125}, {"pred": "parked", "count": 1, "cond_log_prob": -3.6092453002929688}, {"pred": "remain", "count": 1, "cond_log_prob": -3.9068222045898438}, {"pred": "still", "count": 1, "cond_log_prob": -2.76336669921875}, {"pred": "were", "count": 15, "cond_log_prob": -3.6029205322265625}, {"pred": "wereroute", "count": 1, "cond_log_prob": -27.212417602539062}]}, "7": {"context": {"text": "With schools still closed, cars still", "log_prob": -41.47932434082031}, "original": {"pred": "buried", "cond_log_prob": -9.268882751464844}, "human": [{"pred": "are", "cond_log_prob": -6.4102935791015625, "count": 5}, {"pred": "drive", "cond_log_prob": -5.46368408203125, "count": 4}, {"pred": "not", "cond_log_prob": -5.14752197265625, "count": 3}, {"pred": "ca", "cond_log_prob": -11.962844848632812, "count": 2}, {"pred": "could", "cond_log_prob": -10.292282104492188, "count": 2}, {"pred": "will", "cond_log_prob": -10.019073486328125, "count": 2}, {"pred": "can", "cond_log_prob": -8.555198669433594, "count": 1}, {"pred": "cant", "cond_log_prob": -11.930618286132812, "count": 1}, {"pred": "cover", "cond_log_prob": -11.106430053710938, "count": 1}, {"pred": "dead", "cond_log_prob": -9.687484741210938, "count": 1}, {"pred": "do", "cond_log_prob": -8.118560791015625, "count": 1}, {"pred": "drove", "cond_log_prob": -9.367439270019531, "count": 1}, {"pred": "go", "cond_log_prob": -6.947425842285156, "count": 1}, {"pred": "have", "cond_log_prob": -5.966636657714844, "count": 2}, {"pred": "hit", "cond_log_prob": -7.8158721923828125, "count": 1}, {"pred": "need", "cond_log_prob": -8.880477905273438, "count": 1}, {"pred": "on", "cond_log_prob": -3.1255340576171875, "count": 1}, {"pred": "park", "cond_log_prob": -7.992668151855469, "count": 1}, {"pred": "piled", "cond_log_prob": -6.6097412109375, "count": 1}, {"pred": "run", "cond_log_prob": -5.876861572265625, "count": 1}, {"pred": "sit", "cond_log_prob": -8.389419555664062, "count": 1}, {"pred": "stand", "cond_log_prob": -8.466583251953125, "count": 1}, {"pred": "stuck", "cond_log_prob": -4.10333251953125, "count": 1}, {"pred": "transport", "cond_log_prob": -10.623245239257812, "count": 1}, {"pred": "try", "cond_log_prob": -11.613006591796875, "count": 1}, {"pred": "were", "cond_log_prob": -7.747108459472656, "count": 1}], "ancestral_samples": [{"pred": "in", "count": 1, "cond_log_prob": -3.4007568359375}, {"pred": "on", "count": 1, "cond_log_prob": -3.1255340576171875}, {"pred": "parked", "count": 37, "cond_log_prob": -1.4063491821289062}, {"pred": "parkedroute", "count": 1, "cond_log_prob": -23.04773712158203}]}, "8": {"context": {"text": "With schools still closed, cars still buried", "log_prob": -50.748207092285156}, "original": {"pred": "and", "cond_log_prob": -3.1102981567382812}, "human": [{"pred": "in", "cond_log_prob": -1.0542068481445312, "count": 24}, {"pred": "under", "cond_log_prob": -2.1071929931640625, "count": 6}, {"pred": "and", "cond_log_prob": -3.1104354858398438, "count": 3}, {"pred": "beneath", "cond_log_prob": -3.3910140991210938, "count": 1}, {"pred": "into", "cond_log_prob": -7.694122314453125, "count": 1}, {"pred": "to", "cond_log_prob": -6.108650207519531, "count": 1}, {"pred": "traffic", "cond_log_prob": -10.961296081542969, "count": 1}, {"pred": "underneath", "cond_log_prob": -5.185127258300781, "count": 1}, {"pred": "with", "cond_log_prob": -5.289360046386719, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -12.61834716796875}, {"pred": "and", "count": 5, "cond_log_prob": -3.1104354858398438}, {"pred": "beneath", "count": 1, "cond_log_prob": -3.3910140991210938}, {"pred": "in", "count": 22, "cond_log_prob": -1.0542068481445312}, {"pred": "the", "count": 1, "cond_log_prob": -7.8525238037109375}, {"pred": "under", "count": 9, "cond_log_prob": -2.1071929931640625}, {"pred": "underroute", "count": 1, "cond_log_prob": -21.560638427734375}]}, "9": {"context": {"text": "With schools still closed, cars still buried and", "log_prob": -53.85850524902344}, "original": {"pred": "streets", "cond_log_prob": -5.877464294433594}, "human": [{"pred": "people", "cond_log_prob": -4.7212677001953125, "count": 4}, {"pred": "houses", "cond_log_prob": -5.102928161621094, "count": 3}, {"pred": "snow", "cond_log_prob": -7.1221771240234375, "count": 3}, {"pred": "stuck", "cond_log_prob": -9.211006164550781, "count": 3}, {"pred": "buses", "cond_log_prob": -4.611640930175781, "count": 2}, {"pred": "homes", "cond_log_prob": -4.571022033691406, "count": 3}, {"pred": "sidewalks", "cond_log_prob": -6.3677215576171875, "count": 2}, {"pred": "abandoned", "cond_log_prob": -5.606819152832031, "count": 1}, {"pred": "buildings", "cond_log_prob": -5.468360900878906, "count": 1}, {"pred": "covered", "cond_log_prob": -8.833694458007812, "count": 1}, {"pred": "frozen", "cond_log_prob": -8.620246887207031, "count": 1}, {"pred": "inaccessible", "cond_log_prob": -9.001960754394531, "count": 1}, {"pred": "jammed", "cond_log_prob": -10.512214660644531, "count": 1}, {"pred": "kids", "cond_log_prob": -4.607780456542969, "count": 1}, {"pred": "left", "cond_log_prob": -8.320396423339844, "count": 1}, {"pred": "not", "cond_log_prob": -6.808555603027344, "count": 1}, {"pred": "parents", "cond_log_prob": -5.317741394042969, "count": 1}, {"pred": "power", "cond_log_prob": -6.576026916503906, "count": 1}, {"pred": "snowed", "cond_log_prob": -13.55517578125, "count": 1}, {"pred": "still", "cond_log_prob": -6.920448303222656, "count": 1}, {"pred": "street", "cond_log_prob": -6.712554931640625, "count": 1}, {"pred": "streets", "cond_log_prob": -5.877616882324219, "count": 1}, {"pred": "the", "cond_log_prob": -2.9597244262695312, "count": 1}, {"pred": "trapped", "cond_log_prob": -8.636062622070312, "count": 1}, {"pred": "unable", "cond_log_prob": -9.108726501464844, "count": 1}, {"pred": "unusable", "cond_log_prob": -9.297523498535156, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -4.140007019042969}, {"pred": "abandoned", "count": 1, "cond_log_prob": -5.606819152832031}, {"pred": "abandonedroute", "count": 1, "cond_log_prob": -24.380149841308594}, {"pred": "businesses", "count": 1, "cond_log_prob": -5.5158233642578125}, {"pred": "cars", "count": 4, "cond_log_prob": -4.320274353027344}, {"pred": "children", "count": 4, "cond_log_prob": -4.059135437011719}, {"pred": "families", "count": 1, "cond_log_prob": -4.2637786865234375}, {"pred": "garbage", "count": 1, "cond_log_prob": -6.2411346435546875}, {"pred": "homes", "count": 1, "cond_log_prob": -4.571022033691406}, {"pred": "hospitals", "count": 1, "cond_log_prob": -6.171623229980469}, {"pred": "kids", "count": 1, "cond_log_prob": -4.607780456542969}, {"pred": "many", "count": 1, "cond_log_prob": -4.4773101806640625}, {"pred": "no", "count": 2, "cond_log_prob": -4.908287048339844}, {"pred": "people", "count": 2, "cond_log_prob": -4.7212677001953125}, {"pred": "schools", "count": 7, "cond_log_prob": -2.3886032104492188}, {"pred": "the", "count": 9, "cond_log_prob": -2.9597244262695312}]}, "10": {"context": {"text": "With schools still closed, cars still buried and streets", "log_prob": -59.73596954345703}, "original": {"pred": "still", "cond_log_prob": -1.7791633605957031}, "human": [{"pred": "still", "cond_log_prob": -1.77935791015625, "count": 17}, {"pred": "covered", "cond_log_prob": -4.9618072509765625, "count": 8}, {"pred": "blocked", "cond_log_prob": -3.2804183959960938, "count": 2}, {"pred": "are", "cond_log_prob": -7.4060516357421875, "count": 1}, {"pred": "dangerous", "cond_log_prob": -8.395278930664062, "count": 1}, {"pred": "destoyed", "cond_log_prob": -21.2054443359375, "count": 1}, {"pred": "empty", "cond_log_prob": -3.8218994140625, "count": 1}, {"pred": "iced", "cond_log_prob": -10.866981506347656, "count": 1}, {"pred": "icy", "cond_log_prob": -9.788856506347656, "count": 1}, {"pred": "in", "cond_log_prob": -4.673866271972656, "count": 1}, {"pred": "not", "cond_log_prob": -5.032814025878906, "count": 1}, {"pred": "packed", "cond_log_prob": -5.1678924560546875, "count": 1}, {"pred": "slippery", "cond_log_prob": -9.554924011230469, "count": 1}, {"pred": "too", "cond_log_prob": -6.782905578613281, "count": 1}, {"pred": "unplowed", "cond_log_prob": -10.593620300292969, "count": 1}], "ancestral_samples": [{"pred": "blocked", "count": 3, "cond_log_prob": -3.2804183959960938}, {"pred": "closed", "count": 3, "cond_log_prob": -4.038887023925781}, {"pred": "filled", "count": 2, "cond_log_prob": -3.3862762451171875}, {"pred": "littered", "count": 9, "cond_log_prob": -2.2647857666015625}, {"pred": "still", "count": 22, "cond_log_prob": -1.77935791015625}, {"pred": "stillroute", "count": 1, "cond_log_prob": -23.71599578857422}]}, "11": {"context": {"text": "With schools still closed, cars still buried and streets still", "log_prob": -61.515132904052734}, "original": {"pred": "blocked", "cond_log_prob": -2.6420555114746094}, "human": [{"pred": "covered", "cond_log_prob": -4.441539764404297, "count": 18}, {"pred": "closed", "cond_log_prob": -4.366786956787109, "count": 4}, {"pred": "blocked", "cond_log_prob": -2.6422996520996094, "count": 3}, {"pred": "empty", "cond_log_prob": -3.730884552001953, "count": 2}, {"pred": "icy", "cond_log_prob": -8.122806549072266, "count": 2}, {"pred": "are", "cond_log_prob": -10.516414642333984, "count": 1}, {"pred": "dangerous", "cond_log_prob": -6.630611419677734, "count": 1}, {"pred": "lay", "cond_log_prob": -10.415416717529297, "count": 1}, {"pred": "littered", "cond_log_prob": -1.9196586608886719, "count": 1}, {"pred": "open", "cond_log_prob": -4.498775482177734, "count": 1}, {"pred": "packed", "cond_log_prob": -4.451770782470703, "count": 1}, {"pred": "ruined", "cond_log_prob": -6.778728485107422, "count": 1}, {"pred": "under", "cond_log_prob": -4.777309417724609, "count": 1}, {"pred": "unplowed", "cond_log_prob": -10.49002456665039, "count": 1}, {"pred": "will", "cond_log_prob": -11.861408233642578, "count": 1}], "ancestral_samples": [{"pred": "being", "count": 1, "cond_log_prob": -4.217258453369141}, {"pred": "blocked", "count": 5, "cond_log_prob": -2.6422996520996094}, {"pred": "closed", "count": 1, "cond_log_prob": -4.366786956787109}, {"pred": "filled", "count": 3, "cond_log_prob": -3.3279991149902344}, {"pred": "lined", "count": 1, "cond_log_prob": -3.281261444091797}, {"pred": "lit", "count": 1, "cond_log_prob": -4.689960479736328}, {"pred": "littered", "count": 25, "cond_log_prob": -1.9196586608886719}, {"pred": "litteredroute", "count": 1, "cond_log_prob": -25.239124298095703}, {"pred": "paved", "count": 2, "cond_log_prob": -3.380535125732422}]}, "12": {"context": {"text": "With schools still closed, cars still buried and streets still blocked", "log_prob": -64.15718841552734}, "original": {"pred": "by", "cond_log_prob": -1.60418701171875}, "human": [{"pred": "the", "cond_log_prob": -6.60504150390625, "count": 9}, {"pred": "with", "cond_log_prob": -2.07806396484375, "count": 7}, {"pred": "by", "cond_log_prob": -1.6043930053710938, "count": 7}, {"pred": "off", "cond_log_prob": -3.3164596557617188, "count": 3}, {"pred": "there", "cond_log_prob": -7.1786346435546875, "count": 3}, {"pred": "it", "cond_log_prob": -7.371368408203125, "count": 2}, {"pred": "accidents", "cond_log_prob": -17.866195678710938, "count": 1}, {"pred": "from", "cond_log_prob": -3.8173599243164062, "count": 1}, {"pred": "in", "cond_log_prob": -1.9942169189453125, "count": 1}, {"pred": "many", "cond_log_prob": -9.649734497070312, "count": 1}, {"pred": "residents", "cond_log_prob": -12.245025634765625, "count": 1}, {"pred": "stay", "cond_log_prob": -15.571365356445312, "count": 1}, {"pred": "transportation", "cond_log_prob": -14.901519775390625, "count": 1}, {"pred": "we", "cond_log_prob": -8.398941040039062, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -10.148101806640625}, {"pred": "We", "count": 1, "cond_log_prob": -12.29852294921875}, {"pred": "a", "count": 1, "cond_log_prob": -7.2018280029296875}, {"pred": "by", "count": 5, "cond_log_prob": -1.6043930053710938}, {"pred": "in", "count": 1, "cond_log_prob": -1.9942169189453125}, {"pred": "its", "count": 1, "cond_log_prob": -10.182991027832031}, {"pred": "law", "count": 1, "cond_log_prob": -14.992774963378906}, {"pred": "many", "count": 1, "cond_log_prob": -9.649734497070312}, {"pred": "offBut", "count": 1, "cond_log_prob": -18.73548126220703}, {"pred": "residents", "count": 1, "cond_log_prob": -12.245025634765625}, {"pred": "route", "count": 1, "cond_log_prob": -13.013496398925781}, {"pred": "so", "count": 1, "cond_log_prob": -8.005180358886719}, {"pred": "the", "count": 19, "cond_log_prob": -6.60504150390625}, {"pred": "there", "count": 2, "cond_log_prob": -7.1786346435546875}, {"pred": "theres", "count": 1, "cond_log_prob": -20.885910034179688}, {"pred": "with", "count": 2, "cond_log_prob": -2.07806396484375}]}, "13": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by", "log_prob": -65.7613754272461}, "original": {"pred": "the", "cond_log_prob": -2.886749267578125}, "human": [{"pred": "snow", "cond_log_prob": -5.22113037109375, "count": 21}, {"pred": "the", "cond_log_prob": -2.8869552612304688, "count": 12}, {"pred": "debris", "cond_log_prob": -3.824920654296875, "count": 2}, {"pred": "accidents", "cond_log_prob": -8.548477172851562, "count": 1}, {"pred": "feet", "cond_log_prob": -7.623970031738281, "count": 1}, {"pred": "ice", "cond_log_prob": -7.1043548583984375, "count": 1}, {"pred": "trees", "cond_log_prob": -4.38299560546875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -3.7116241455078125}, {"pred": "cars", "count": 6, "cond_log_prob": -3.4747085571289062}, {"pred": "debris", "count": 3, "cond_log_prob": -3.824951171875}, {"pred": "piles", "count": 1, "cond_log_prob": -6.740486145019531}, {"pred": "police", "count": 13, "cond_log_prob": -2.725982666015625}, {"pred": "policeBut", "count": 1, "cond_log_prob": -19.071624755859375}, {"pred": "the", "count": 8, "cond_log_prob": -2.8869857788085938}, {"pred": "theroute", "count": 1, "cond_log_prob": -35.33636474609375}, {"pred": "traffic", "count": 2, "cond_log_prob": -3.1916427612304688}, {"pred": "trees", "count": 1, "cond_log_prob": -4.383049011230469}, {"pred": "weeds", "count": 1, "cond_log_prob": -5.145210266113281}]}, "14": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the", "log_prob": -68.64812469482422}, "original": {"pred": "widespread", "cond_log_prob": -10.642967224121094}, "human": [{"pred": "snow", "cond_log_prob": -5.1745147705078125, "count": 23}, {"pred": "police", "cond_log_prob": -5.118415832519531, "count": 2}, {"pred": "big", "cond_log_prob": -7.0713348388671875, "count": 1}, {"pred": "cars", "cond_log_prob": -6.3640899658203125, "count": 1}, {"pred": "damage", "cond_log_prob": -7.537109375, "count": 1}, {"pred": "debris", "cond_log_prob": -5.2394561767578125, "count": 1}, {"pred": "entrance", "cond_log_prob": -8.806549072265625, "count": 1}, {"pred": "excess", "cond_log_prob": -9.851226806640625, "count": 1}, {"pred": "garbage", "cond_log_prob": -7.985801696777344, "count": 1}, {"pred": "government", "cond_log_prob": -6.005218505859375, "count": 1}, {"pred": "impending", "cond_log_prob": -8.156173706054688, "count": 1}, {"pred": "large", "cond_log_prob": -7.400054931640625, "count": 1}, {"pred": "snowfall", "cond_log_prob": -9.692085266113281, "count": 1}, {"pred": "thick", "cond_log_prob": -5.762420654296875, "count": 1}, {"pred": "traffic", "cond_log_prob": -4.647979736328125, "count": 1}, {"pred": "wreckage", "cond_log_prob": -6.251228332519531, "count": 1}], "ancestral_samples": [{"pred": "Chicago", "count": 1, "cond_log_prob": -8.071548461914062}, {"pred": "TMobile", "count": 1, "cond_log_prob": -18.041481018066406}, {"pred": "bridge", "count": 1, "cond_log_prob": -5.9495391845703125}, {"pred": "busy", "count": 1, "cond_log_prob": -5.373146057128906}, {"pred": "carriding", "count": 1, "cond_log_prob": -24.71550750732422}, {"pred": "city", "count": 1, "cond_log_prob": -3.7527847290039062}, {"pred": "citys", "count": 9, "cond_log_prob": -13.931144714355469}, {"pred": "day", "count": 1, "cond_log_prob": -6.378303527832031}, {"pred": "debris", "count": 2, "cond_log_prob": -5.2394561767578125}, {"pred": "fire", "count": 1, "cond_log_prob": -5.11419677734375}, {"pred": "floodwaters", "count": 1, "cond_log_prob": -5.809501647949219}, {"pred": "heavyroute", "count": 1, "cond_log_prob": -33.95996856689453}, {"pred": "highway", "count": 1, "cond_log_prob": -4.966850280761719}, {"pred": "past", "count": 1, "cond_log_prob": -6.4957275390625}, {"pred": "police", "count": 2, "cond_log_prob": -5.118415832519531}, {"pred": "policeBut", "count": 1, "cond_log_prob": -20.901412963867188}, {"pred": "rain", "count": 3, "cond_log_prob": -4.142364501953125}, {"pred": "rising", "count": 1, "cond_log_prob": -4.8582763671875}, {"pred": "road", "count": 5, "cond_log_prob": -4.2333831787109375}, {"pred": "signs", "count": 1, "cond_log_prob": -7.4246063232421875}, {"pred": "snow", "count": 1, "cond_log_prob": -5.1745147705078125}, {"pred": "street", "count": 1, "cond_log_prob": -5.14886474609375}, {"pred": "traffic", "count": 1, "cond_log_prob": -4.647979736328125}, {"pred": "war", "count": 1, "cond_log_prob": -6.2181549072265625}]}, "15": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread", "log_prob": -79.29109191894531}, "original": {"pred": "weekend", "cond_log_prob": -8.936607360839844}, "human": [{"pred": "snow", "cond_log_prob": -5.691108703613281, "count": 6}, {"pred": "snowfall", "cond_log_prob": -7.130287170410156, "count": 5}, {"pred": "amount", "cond_log_prob": -7.2818145751953125, "count": 3}, {"pred": "debris", "cond_log_prob": -5.708000183105469, "count": 2}, {"pred": "destruction", "cond_log_prob": -3.1916961669921875, "count": 2}, {"pred": "disaster", "cond_log_prob": -6.6788482666015625, "count": 2}, {"pred": "storm", "cond_log_prob": -5.905006408691406, "count": 2}, {"pred": "accidents", "cond_log_prob": -9.123779296875, "count": 1}, {"pred": "blizzard", "cond_log_prob": -9.012405395507812, "count": 1}, {"pred": "damage", "cond_log_prob": -6.205192565917969, "count": 1}, {"pred": "disease", "cond_log_prob": -6.9237213134765625, "count": 1}, {"pred": "dust", "cond_log_prob": -7.0911712646484375, "count": 1}, {"pred": "earthquake", "cond_log_prob": -6.6948699951171875, "count": 1}, {"pred": "epidemic", "cond_log_prob": -7.367790222167969, "count": 1}, {"pred": "mudslide", "cond_log_prob": -8.593826293945312, "count": 1}, {"pred": "outbreak", "cond_log_prob": -6.730743408203125, "count": 1}, {"pred": "pandemic", "cond_log_prob": -12.226425170898438, "count": 1}, {"pred": "parade", "cond_log_prob": -8.804641723632812, "count": 1}, {"pred": "parking", "cond_log_prob": -5.810569763183594, "count": 1}, {"pred": "quarantine", "cond_log_prob": -10.974578857421875, "count": 1}, {"pred": "rubble", "cond_log_prob": -6.721702575683594, "count": 1}, {"pred": "skunk", "cond_log_prob": -15.979202270507812, "count": 1}, {"pred": "snowpiles", "cond_log_prob": -24.874588012695312, "count": 1}, {"pred": "snowstorm", "cond_log_prob": -8.015525817871094, "count": 1}], "ancestral_samples": [{"pred": "damage", "count": 1, "cond_log_prob": -6.205192565917969}, {"pred": "decay", "count": 1, "cond_log_prob": -6.6716766357421875}, {"pred": "destruction", "count": 13, "cond_log_prob": -3.1916961669921875}, {"pred": "destructionroute", "count": 1, "cond_log_prob": -25.147483825683594}, {"pred": "fire", "count": 1, "cond_log_prob": -4.4216766357421875}, {"pred": "flood", "count": 1, "cond_log_prob": -4.463218688964844}, {"pred": "flooding", "count": 12, "cond_log_prob": -3.2594985961914062}, {"pred": "floodingBut", "count": 1, "cond_log_prob": -19.31255340576172}, {"pred": "flow", "count": 1, "cond_log_prob": -5.101966857910156}, {"pred": "nature", "count": 1, "cond_log_prob": -4.807975769042969}, {"pred": "traffic", "count": 3, "cond_log_prob": -3.4584197998046875}, {"pred": "use", "count": 3, "cond_log_prob": -3.7240066528320312}, {"pred": "violence", "count": 1, "cond_log_prob": -4.3255615234375}]}, "16": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend", "log_prob": -88.22769927978516}, "original": {"pred": "snowstorm,", "cond_log_prob": -7.100868225097656}, "human": [{"pred": "storm", "cond_log_prob": -5.1183624267578125, "count": 11}, {"pred": "snowstorm", "cond_log_prob": -6.812896728515625, "count": 5}, {"pred": "traffic", "cond_log_prob": -2.649169921875, "count": 4}, {"pred": "of", "cond_log_prob": -3.7471389770507812, "count": 3}, {"pred": "snow", "cond_log_prob": -4.605499267578125, "count": 3}, {"pred": "blizzard", "cond_log_prob": -7.3065643310546875, "count": 2}, {"pred": "break", "cond_log_prob": -6.3016204833984375, "count": 2}, {"pred": "snowfall", "cond_log_prob": -5.615196228027344, "count": 2}, {"pred": "and", "cond_log_prob": -6.0518798828125, "count": 1}, {"pred": "disaster", "cond_log_prob": -8.611366271972656, "count": 1}, {"pred": "extravaganza", "cond_log_prob": -9.576148986816406, "count": 1}, {"pred": "parade", "cond_log_prob": -7.141258239746094, "count": 1}, {"pred": "riots", "cond_log_prob": -6.0643310546875, "count": 1}, {"pred": "rush", "cond_log_prob": -2.9424285888671875, "count": 1}, {"pred": "warriors", "cond_log_prob": -9.1329345703125, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -14.164436340332031}, {"pred": "carriding", "count": 1, "cond_log_prob": -23.918861389160156}, {"pred": "closures", "count": 5, "cond_log_prob": -3.6030960083007812}, {"pred": "commute", "count": 1, "cond_log_prob": -4.914421081542969}, {"pred": "flood", "count": 1, "cond_log_prob": -3.8607025146484375}, {"pred": "long", "count": 1, "cond_log_prob": -7.2624969482421875}, {"pred": "marchers", "count": 1, "cond_log_prob": -7.237373352050781}, {"pred": "night", "count": 2, "cond_log_prob": -3.1885833740234375}, {"pred": "of", "count": 1, "cond_log_prob": -3.7471389770507812}, {"pred": "rush", "count": 4, "cond_log_prob": -2.9424285888671875}, {"pred": "rushBut", "count": 1, "cond_log_prob": -17.662330627441406}, {"pred": "rushhour", "count": 2, "cond_log_prob": -11.208137512207031}, {"pred": "traffic", "count": 11, "cond_log_prob": -2.649169921875}, {"pred": "violence", "count": 7, "cond_log_prob": -2.5141143798828125}, {"pred": "violenceroute", "count": 1, "cond_log_prob": -37.40461730957031}]}, "17": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm,", "log_prob": -95.32856750488281}, "original": {"pred": "officials", "cond_log_prob": -4.93194580078125}, "human": [{"pred": "the", "cond_log_prob": -1.995391845703125, "count": 9}, {"pred": "children", "cond_log_prob": -5.967529296875, "count": 5}, {"pred": "people", "cond_log_prob": -5.0442047119140625, "count": 5}, {"pred": "students", "cond_log_prob": -4.2154388427734375, "count": 2}, {"pred": "there", "cond_log_prob": -3.462432861328125, "count": 2}, {"pred": "we", "cond_log_prob": -4.4007110595703125, "count": 2}, {"pred": "also", "cond_log_prob": -10.40435791015625, "count": 1}, {"pred": "and", "cond_log_prob": -5.162689208984375, "count": 1}, {"pred": "citizens", "cond_log_prob": -7.7680816650390625, "count": 1}, {"pred": "city", "cond_log_prob": -5.680419921875, "count": 1}, {"pred": "classes", "cond_log_prob": -9.103179931640625, "count": 1}, {"pred": "everyone", "cond_log_prob": -6.692474365234375, "count": 1}, {"pred": "has", "cond_log_prob": -8.197433471679688, "count": 1}, {"pred": "it", "cond_log_prob": -2.631744384765625, "count": 1}, {"pred": "little", "cond_log_prob": -7.000152587890625, "count": 1}, {"pred": "many", "cond_log_prob": -3.0346221923828125, "count": 1}, {"pred": "nothing", "cond_log_prob": -8.360488891601562, "count": 1}, {"pred": "officials", "cond_log_prob": -4.9320831298828125, "count": 1}, {"pred": "residents", "cond_log_prob": -4.2966461181640625, "count": 1}, {"pred": "traffic", "cond_log_prob": -6.4843597412109375, "count": 1}], "ancestral_samples": [{"pred": "Chicago", "count": 1, "cond_log_prob": -5.953460693359375}, {"pred": "a", "count": 2, "cond_log_prob": -3.6117095947265625}, {"pred": "its", "count": 1, "cond_log_prob": -6.5543060302734375}, {"pred": "many", "count": 1, "cond_log_prob": -3.0346221923828125}, {"pred": "manyroute", "count": 1, "cond_log_prob": -23.130462646484375}, {"pred": "some", "count": 1, "cond_log_prob": -3.562225341796875}, {"pred": "the", "count": 33, "cond_log_prob": -1.995391845703125}]}, "18": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials", "log_prob": -100.26051330566406}, "original": {"pred": "are", "cond_log_prob": -1.1882476806640625}, "human": [{"pred": "are", "cond_log_prob": -1.1884002685546875, "count": 15}, {"pred": "say", "cond_log_prob": -1.9196624755859375, "count": 8}, {"pred": "have", "cond_log_prob": -2.42486572265625, "count": 3}, {"pred": "were", "cond_log_prob": -3.5694122314453125, "count": 2}, {"pred": "advise", "cond_log_prob": -8.255302429199219, "count": 1}, {"pred": "and", "cond_log_prob": -4.286376953125, "count": 1}, {"pred": "believe", "cond_log_prob": -5.08258056640625, "count": 1}, {"pred": "choose", "cond_log_prob": -9.780586242675781, "count": 1}, {"pred": "declared", "cond_log_prob": -7.292228698730469, "count": 1}, {"pred": "had", "cond_log_prob": -5.02349853515625, "count": 1}, {"pred": "prevent", "cond_log_prob": -12.320274353027344, "count": 1}, {"pred": "released", "cond_log_prob": -7.799110412597656, "count": 1}, {"pred": "report", "cond_log_prob": -8.038887023925781, "count": 1}, {"pred": "stated", "cond_log_prob": -10.342109680175781, "count": 1}, {"pred": "told", "cond_log_prob": -5.9709014892578125, "count": 1}], "ancestral_samples": [{"pred": "are", "count": 3, "cond_log_prob": -1.1884002685546875}, {"pred": "have", "count": 2, "cond_log_prob": -2.42486572265625}, {"pred": "said", "count": 11, "cond_log_prob": -2.8354034423828125}, {"pred": "saidAbout", "count": 1, "cond_log_prob": -20.345657348632812}, {"pred": "saidAs", "count": 1, "cond_log_prob": -19.9559326171875}, {"pred": "saidAt", "count": 1, "cond_log_prob": -20.134567260742188}, {"pred": "saidBut", "count": 1, "cond_log_prob": -20.149078369140625}, {"pred": "saidThe", "count": 2, "cond_log_prob": -17.521148681640625}, {"pred": "say", "count": 15, "cond_log_prob": -1.9196624755859375}, {"pred": "sayThe", "count": 1, "cond_log_prob": -16.15650177001953}, {"pred": "sayroute", "count": 1, "cond_log_prob": -19.536544799804688}, {"pred": "were", "count": 1, "cond_log_prob": -3.5694122314453125}]}, "19": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are", "log_prob": -101.44876098632812}, "original": {"pred": "asking", "cond_log_prob": -4.11798095703125}, "human": [{"pred": "saying", "cond_log_prob": -5.545005798339844, "count": 6}, {"pred": "having", "cond_log_prob": -5.625114440917969, "count": 2}, {"pred": "still", "cond_log_prob": -2.6254119873046875, "count": 2}, {"pred": "telling", "cond_log_prob": -6.557670593261719, "count": 2}, {"pred": "warning", "cond_log_prob": -4.4228973388671875, "count": 2}, {"pred": "working", "cond_log_prob": -3.5172271728515625, "count": 2}, {"pred": "advising", "cond_log_prob": -7.062522888183594, "count": 1}, {"pred": "anxious", "cond_log_prob": -6.376274108886719, "count": 1}, {"pred": "asking", "cond_log_prob": -4.1181182861328125, "count": 1}, {"pred": "busy", "cond_log_prob": -5.739387512207031, "count": 1}, {"pred": "calling", "cond_log_prob": -4.35894775390625, "count": 1}, {"pred": "claiming", "cond_log_prob": -7.683204650878906, "count": 1}, {"pred": "confused", "cond_log_prob": -9.960823059082031, "count": 1}, {"pred": "considering", "cond_log_prob": -4.56719970703125, "count": 1}, {"pred": "deciding", "cond_log_prob": -7.240699768066406, "count": 1}, {"pred": "encouraging", "cond_log_prob": -6.576454162597656, "count": 1}, {"pred": "facing", "cond_log_prob": -5.17437744140625, "count": 1}, {"pred": "in", "cond_log_prob": -5.841331481933594, "count": 1}, {"pred": "making", "cond_log_prob": -4.979766845703125, "count": 1}, {"pred": "questioning", "cond_log_prob": -6.871467590332031, "count": 1}, {"pred": "recommending", "cond_log_prob": -7.144630432128906, "count": 1}, {"pred": "reporting", "cond_log_prob": -6.951957702636719, "count": 1}, {"pred": "scrambling", "cond_log_prob": -2.7979583740234375, "count": 1}, {"pred": "starting", "cond_log_prob": -5.093597412109375, "count": 1}, {"pred": "trying", "cond_log_prob": -2.4798431396484375, "count": 2}, {"pred": "unaware", "cond_log_prob": -10.600761413574219, "count": 1}, {"pred": "weary", "cond_log_prob": -9.302131652832031, "count": 1}, {"pred": "worried", "cond_log_prob": -4.3531951904296875, "count": 1}], "ancestral_samples": [{"pred": "already", "count": 1, "cond_log_prob": -4.976593017578125}, {"pred": "calling", "count": 1, "cond_log_prob": -4.35894775390625}, {"pred": "hopeful", "count": 2, "cond_log_prob": -4.994354248046875}, {"pred": "hoping", "count": 5, "cond_log_prob": -3.1533050537109375}, {"pred": "investigating", "count": 1, "cond_log_prob": -5.6224212646484375}, {"pred": "looking", "count": 2, "cond_log_prob": -3.0504608154296875}, {"pred": "now", "count": 3, "cond_log_prob": -3.424896240234375}, {"pred": "planning", "count": 1, "cond_log_prob": -5.3109893798828125}, {"pred": "scrambling", "count": 3, "cond_log_prob": -2.7979583740234375}, {"pred": "scramblingroute", "count": 1, "cond_log_prob": -25.74212646484375}, {"pred": "seeing", "count": 1, "cond_log_prob": -5.51336669921875}, {"pred": "still", "count": 13, "cond_log_prob": -2.6254119873046875}, {"pred": "trying", "count": 4, "cond_log_prob": -2.4798431396484375}, {"pred": "working", "count": 2, "cond_log_prob": -3.5172271728515625}]}, "20": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking", "log_prob": -105.56674194335938}, "original": {"pred": "people", "cond_log_prob": -2.8256378173828125}, "human": [{"pred": "people", "cond_log_prob": -2.8257904052734375, "count": 9}, {"pred": "for", "cond_log_prob": -2.5863800048828125, "count": 5}, {"pred": "that", "cond_log_prob": -4.20098876953125, "count": 5}, {"pred": "everyone", "cond_log_prob": -4.6878662109375, "count": 3}, {"pred": "parents", "cond_log_prob": -1.45892333984375, "count": 2}, {"pred": "all", "cond_log_prob": -4.9386138916015625, "count": 2}, {"pred": "citizens", "cond_log_prob": -5.103141784667969, "count": 1}, {"pred": "local", "cond_log_prob": -5.230743408203125, "count": 1}, {"pred": "questions", "cond_log_prob": -6.6528472900390625, "count": 1}, {"pred": "resident", "cond_log_prob": -10.437141418457031, "count": 1}, {"pred": "residents", "cond_log_prob": -2.1361541748046875, "count": 1}, {"pred": "the", "cond_log_prob": -3.30096435546875, "count": 1}, {"pred": "themselves", "cond_log_prob": -8.92620849609375, "count": 1}, {"pred": "us", "cond_log_prob": -8.647712707519531, "count": 1}, {"pred": "when", "cond_log_prob": -8.381683349609375, "count": 1}, {"pred": "where", "cond_log_prob": -8.416397094726562, "count": 1}, {"pred": "who", "cond_log_prob": -8.447006225585938, "count": 1}, {"pred": "why", "cond_log_prob": -7.843658447265625, "count": 1}, {"pred": "you", "cond_log_prob": -6.875648498535156, "count": 1}], "ancestral_samples": [{"pred": "drivers", "count": 1, "cond_log_prob": -4.020484924316406}, {"pred": "for", "count": 9, "cond_log_prob": -2.5863800048828125}, {"pred": "forroute", "count": 1, "cond_log_prob": -22.918701171875}, {"pred": "parents", "count": 19, "cond_log_prob": -1.45892333984375}, {"pred": "people", "count": 2, "cond_log_prob": -2.8257904052734375}, {"pred": "residents", "count": 5, "cond_log_prob": -2.1361541748046875}, {"pred": "students", "count": 1, "cond_log_prob": -2.559844970703125}, {"pred": "the", "count": 2, "cond_log_prob": -3.30096435546875}]}, "21": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people", "log_prob": -108.39237976074219}, "original": {"pred": "to", "cond_log_prob": -0.191558837890625}, "human": [{"pred": "to", "cond_log_prob": -0.19171142578125, "count": 35}, {"pred": "if", "cond_log_prob": -6.487251281738281, "count": 2}, {"pred": "not", "cond_log_prob": -3.3618621826171875, "count": 1}, {"pred": "why", "cond_log_prob": -8.611778259277344, "count": 1}], "ancestral_samples": [{"pred": "not", "count": 1, "cond_log_prob": -3.3618621826171875}, {"pred": "to", "count": 38, "cond_log_prob": -0.19171142578125}, {"pred": "toroute", "count": 1, "cond_log_prob": -30.408248901367188}]}, "22": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to", "log_prob": -108.58393859863281}, "original": {"pred": "pick", "cond_log_prob": -6.393585205078125}, "human": [{"pred": "stay", "cond_log_prob": -1.620574951171875, "count": 21}, {"pred": "help", "cond_log_prob": -5.384910583496094, "count": 2}, {"pred": "please", "cond_log_prob": -6.799720764160156, "count": 2}, {"pred": "remain", "cond_log_prob": -3.4378204345703125, "count": 2}, {"pred": "volunteer", "cond_log_prob": -8.120292663574219, "count": 2}, {"pred": "assist", "cond_log_prob": -9.120643615722656, "count": 1}, {"pred": "avoid", "cond_log_prob": -2.3651275634765625, "count": 1}, {"pred": "be", "cond_log_prob": -3.2149505615234375, "count": 1}, {"pred": "begin", "cond_log_prob": -7.704093933105469, "count": 1}, {"pred": "do", "cond_log_prob": -5.2600250244140625, "count": 1}, {"pred": "educate", "cond_log_prob": -9.567863464355469, "count": 1}, {"pred": "not", "cond_log_prob": -4.9763641357421875, "count": 1}, {"pred": "park", "cond_log_prob": -5.342613220214844, "count": 1}, {"pred": "use", "cond_log_prob": -4.3382720947265625, "count": 1}, {"pred": "walk", "cond_log_prob": -5.338829040527344, "count": 1}], "ancestral_samples": [{"pred": "avoid", "count": 4, "cond_log_prob": -2.3651275634765625}, {"pred": "be", "count": 1, "cond_log_prob": -3.2149505615234375}, {"pred": "continue", "count": 1, "cond_log_prob": -5.313270568847656}, {"pred": "keep", "count": 3, "cond_log_prob": -2.9036102294921875}, {"pred": "remain", "count": 1, "cond_log_prob": -3.4378204345703125}, {"pred": "stay", "count": 29, "cond_log_prob": -1.620574951171875}, {"pred": "stayroute", "count": 1, "cond_log_prob": -24.947555541992188}]}, "23": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick", "log_prob": -114.97752380371094}, "original": {"pred": "up", "cond_log_prob": -0.125579833984375}, "human": [{"pred": "up", "cond_log_prob": -0.12577056884765625, "count": 22}, {"pred": "a", "cond_log_prob": -5.158210754394531, "count": 9}, {"pred": "their", "cond_log_prob": -3.7720870971679688, "count": 3}, {"pred": "another", "cond_log_prob": -8.850563049316406, "count": 2}, {"pred": "an", "cond_log_prob": -7.784324645996094, "count": 1}, {"pred": "proper", "cond_log_prob": -13.564346313476562, "count": 1}, {"pred": "the", "cond_log_prob": -5.097984313964844, "count": 1}], "ancestral_samples": [{"pred": "up", "count": 39, "cond_log_prob": -0.12577056884765625}, {"pred": "uproute", "count": 1, "cond_log_prob": -19.755722045898438}]}, "24": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up", "log_prob": -115.10310363769531}, "original": {"pred": "a", "cond_log_prob": -3.535980224609375}, "human": [{"pred": "their", "cond_log_prob": -1.0001754760742188, "count": 24}, {"pred": "the", "cond_log_prob": -3.2609176635742188, "count": 6}, {"pred": "a", "cond_log_prob": -3.5361709594726562, "count": 2}, {"pred": "supplies", "cond_log_prob": -4.465217590332031, "count": 2}, {"pred": "as", "cond_log_prob": -6.015480041503906, "count": 1}, {"pred": "children", "cond_log_prob": -5.281669616699219, "count": 1}, {"pred": "other", "cond_log_prob": -6.391578674316406, "count": 1}, {"pred": "snow", "cond_log_prob": -3.9023513793945312, "count": 1}, {"pred": "trash", "cond_log_prob": -4.065071105957031, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.5361709594726562}, {"pred": "shovels", "count": 1, "cond_log_prob": -3.2263107299804688}, {"pred": "the", "count": 1, "cond_log_prob": -3.2609176635742188}, {"pred": "their", "count": 35, "cond_log_prob": -1.0001754760742188}, {"pred": "theirroute", "count": 1, "cond_log_prob": -20.657485961914062}]}, "25": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a", "log_prob": -118.63908386230469}, "original": {"pred": "shovel", "cond_log_prob": -1.58447265625}, "human": [{"pred": "shovel", "cond_log_prob": -1.5846633911132812, "count": 16}, {"pred": "pass", "cond_log_prob": -7.169532775878906, "count": 2}, {"pred": "radio", "cond_log_prob": -10.723190307617188, "count": 2}, {"pred": "snow", "cond_log_prob": -4.377357482910156, "count": 2}, {"pred": "snowshovel", "cond_log_prob": -14.229934692382812, "count": 2}, {"pred": "bottled", "cond_log_prob": -7.916648864746094, "count": 1}, {"pred": "car", "cond_log_prob": -3.9363632202148438, "count": 1}, {"pred": "dog", "cond_log_prob": -6.818428039550781, "count": 1}, {"pred": "flyer", "cond_log_prob": -7.123497009277344, "count": 1}, {"pred": "form", "cond_log_prob": -7.832359313964844, "count": 1}, {"pred": "hammer", "cond_log_prob": -8.293983459472656, "count": 1}, {"pred": "heater", "cond_log_prob": -10.105697631835938, "count": 1}, {"pred": "lot", "cond_log_prob": -6.499488830566406, "count": 1}, {"pred": "packet", "cond_log_prob": -7.664085388183594, "count": 1}, {"pred": "paper", "cond_log_prob": -7.288917541503906, "count": 1}, {"pred": "piece", "cond_log_prob": -4.371238708496094, "count": 1}, {"pred": "supply", "cond_log_prob": -7.628593444824219, "count": 1}, {"pred": "tire", "cond_log_prob": -6.830284118652344, "count": 1}, {"pred": "warning", "cond_log_prob": -8.468666076660156, "count": 1}, {"pred": "weeks", "cond_log_prob": -15.345230102539062, "count": 1}], "ancestral_samples": [{"pred": "blanket", "count": 1, "cond_log_prob": -3.9326095581054688}, {"pred": "box", "count": 1, "cond_log_prob": -5.862190246582031}, {"pred": "car", "count": 1, "cond_log_prob": -3.9363632202148438}, {"pred": "few", "count": 5, "cond_log_prob": -2.3144912719726562}, {"pred": "gallon", "count": 1, "cond_log_prob": -6.160499572753906}, {"pred": "ride", "count": 1, "cond_log_prob": -5.480293273925781}, {"pred": "shovel", "count": 29, "cond_log_prob": -1.5846633911132812}, {"pred": "shovelroute", "count": 1, "cond_log_prob": -22.423904418945312}]}, "26": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel", "log_prob": -120.22355651855469}, "original": {"pred": "and", "cond_log_prob": -1.2960433959960938}, "human": [{"pred": "and", "cond_log_prob": -1.2962417602539062, "count": 38}, {"pred": "to", "cond_log_prob": -2.3339462280273438, "count": 1}], "ancestral_samples": [{"pred": "There", "count": 1, "cond_log_prob": -15.247787475585938}, {"pred": "We", "count": 1, "cond_log_prob": -16.161148071289062}, {"pred": "and", "count": 27, "cond_log_prob": -1.2962417602539062}, {"pred": "androute", "count": 1, "cond_log_prob": -18.913497924804688}, {"pred": "or", "count": 5, "cond_log_prob": -2.0618209838867188}, {"pred": "to", "count": 5, "cond_log_prob": -2.3339462280273438}]}, "27": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and", "log_prob": -121.51959991455078}, "original": {"pred": "help", "cond_log_prob": -3.2600784301757812}, "human": [{"pred": "help", "cond_log_prob": -3.2602996826171875, "count": 17}, {"pred": "clear", "cond_log_prob": -5.627532958984375, "count": 7}, {"pred": "start", "cond_log_prob": -5.1070098876953125, "count": 4}, {"pred": "begin", "cond_log_prob": -6.144012451171875, "count": 2}, {"pred": "attempt", "cond_log_prob": -7.696983337402344, "count": 1}, {"pred": "contribute", "cond_log_prob": -9.407157897949219, "count": 1}, {"pred": "dig", "cond_log_prob": -4.9419403076171875, "count": 1}, {"pred": "go", "cond_log_prob": -4.57598876953125, "count": 1}, {"pred": "salt", "cond_log_prob": -8.840934753417969, "count": 1}, {"pred": "scrape", "cond_log_prob": -7.082603454589844, "count": 1}, {"pred": "take", "cond_log_prob": -4.08160400390625, "count": 1}, {"pred": "try", "cond_log_prob": -5.186798095703125, "count": 1}, {"pred": "use", "cond_log_prob": -4.288116455078125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 10, "cond_log_prob": -2.8294448852539062}, {"pred": "help", "count": 3, "cond_log_prob": -3.2602920532226562}, {"pred": "pick", "count": 1, "cond_log_prob": -4.760429382324219}, {"pred": "shovel", "count": 24, "cond_log_prob": -1.6411666870117188}, {"pred": "shovelroute", "count": 1, "cond_log_prob": -19.016624450683594}, {"pred": "take", "count": 1, "cond_log_prob": -4.081596374511719}]}, "28": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help", "log_prob": -124.77967834472656}, "original": {"pred": "out.", "cond_log_prob": -5.1975860595703125}, "human": [{"pred": "clear", "cond_log_prob": -3.611541748046875, "count": 16}, {"pred": "clean", "cond_log_prob": -3.7777252197265625, "count": 5}, {"pred": "with", "cond_log_prob": -3.4995880126953125, "count": 3}, {"pred": "dig", "cond_log_prob": -4.0439300537109375, "count": 2}, {"pred": "remove", "cond_log_prob": -4.2711181640625, "count": 2}, {"pred": "shovel", "cond_log_prob": -2.870147705078125, "count": 2}, {"pred": "move", "cond_log_prob": -4.2857513427734375, "count": 1}, {"pred": "others", "cond_log_prob": -5.3090362548828125, "count": 1}, {"pred": "out", "cond_log_prob": -3.3924102783203125, "count": 1}, {"pred": "plow", "cond_log_prob": -7.5384979248046875, "count": 1}, {"pred": "scoop", "cond_log_prob": -7.8153228759765625, "count": 1}, {"pred": "to", "cond_log_prob": -4.2973785400390625, "count": 1}, {"pred": "unclear", "cond_log_prob": -13.516448974609375, "count": 1}, {"pred": "uncover", "cond_log_prob": -8.431396484375, "count": 1}, {"pred": "where", "cond_log_prob": -8.969375610351562, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -13.381668090820312}, {"pred": "a", "count": 1, "cond_log_prob": -5.3082733154296875}, {"pred": "evacuate", "count": 1, "cond_log_prob": -4.379608154296875}, {"pred": "evacuateroute", "count": 1, "cond_log_prob": -38.16050720214844}, {"pred": "find", "count": 1, "cond_log_prob": -4.6015472412109375}, {"pred": "keep", "count": 4, "cond_log_prob": -3.643035888671875}, {"pred": "out", "count": 1, "cond_log_prob": -3.3924102783203125}, {"pred": "prevent", "count": 1, "cond_log_prob": -5.41168212890625}, {"pred": "save", "count": 3, "cond_log_prob": -3.5027923583984375}, {"pred": "shovel", "count": 3, "cond_log_prob": -2.870147705078125}, {"pred": "the", "count": 8, "cond_log_prob": -3.0924758911132812}, {"pred": "their", "count": 1, "cond_log_prob": -3.8436737060546875}, {"pred": "them", "count": 8, "cond_log_prob": -2.9903564453125}, {"pred": "to", "count": 1, "cond_log_prob": -4.2973785400390625}, {"pred": "with", "count": 5, "cond_log_prob": -3.4995880126953125}]}, "29": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out.", "log_prob": -129.97726440429688}, "original": {"pred": "In", "cond_log_prob": -5.6123809814453125}, "human": [{"pred": "the", "cond_log_prob": -10.274139404296875, "count": 8}, {"pred": "they", "cond_log_prob": -12.331817626953125, "count": 4}, {"pred": "this", "cond_log_prob": -13.379608154296875, "count": 5}, {"pred": "if", "cond_log_prob": -12.902130126953125, "count": 3}, {"pred": "it", "cond_log_prob": -13.207763671875, "count": 3}, {"pred": "many", "cond_log_prob": -15.119964599609375, "count": 2}, {"pred": "people", "cond_log_prob": -13.605804443359375, "count": 3}, {"pred": "there", "cond_log_prob": -13.958038330078125, "count": 2}, {"pred": "children", "cond_log_prob": -14.682830810546875, "count": 1}, {"pred": "however", "cond_log_prob": -15.24090576171875, "count": 1}, {"pred": "let", "cond_log_prob": -15.4869384765625, "count": 1}, {"pred": "most", "cond_log_prob": -14.96026611328125, "count": 1}, {"pred": "parents", "cond_log_prob": -15.19915771484375, "count": 1}, {"pred": "until", "cond_log_prob": -14.32989501953125, "count": 1}, {"pred": "we", "cond_log_prob": -14.552398681640625, "count": 1}, {"pred": "when", "cond_log_prob": -14.450958251953125, "count": 1}, {"pred": "while", "cond_log_prob": -14.404388427734375, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -5.456146240234375}, {"pred": "I", "count": 3, "cond_log_prob": -8.1754150390625}, {"pred": "If", "count": 1, "cond_log_prob": -6.454010009765625}, {"pred": "Im", "count": 2, "cond_log_prob": -12.046051025390625}, {"pred": "In", "count": 1, "cond_log_prob": -5.612640380859375}, {"pred": "Its", "count": 3, "cond_log_prob": -9.986846923828125}, {"pred": "The", "count": 10, "cond_log_prob": -3.887176513671875}, {"pred": "There", "count": 1, "cond_log_prob": -6.3380126953125}, {"pred": "Theres", "count": 1, "cond_log_prob": -15.93890380859375}, {"pred": "This", "count": 2, "cond_log_prob": -6.5150146484375}, {"pred": "We", "count": 3, "cond_log_prob": -7.329376220703125}, {"pred": "Were", "count": 10, "cond_log_prob": -11.3360595703125}, {"pred": "Weve", "count": 1, "cond_log_prob": -16.7086181640625}, {"pred": "route", "count": 1, "cond_log_prob": -18.02789306640625}]}, "30": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In", "log_prob": -135.5896453857422}, "original": {"pred": "Boston,", "cond_log_prob": -5.960113525390625}, "human": [{"pred": "the", "cond_log_prob": -1.7945709228515625, "count": 12}, {"pred": "a", "cond_log_prob": -2.7727508544921875, "count": 6}, {"pred": "case", "cond_log_prob": -5.6802215576171875, "count": 2}, {"pred": "light", "cond_log_prob": -7.1424713134765625, "count": 2}, {"pred": "order", "cond_log_prob": -5.2670440673828125, "count": 2}, {"pred": "other", "cond_log_prob": -5.1401519775390625, "count": 3}, {"pred": "any", "cond_log_prob": -7.3780059814453125, "count": 1}, {"pred": "breaking", "cond_log_prob": -11.229049682617188, "count": 1}, {"pred": "months", "cond_log_prob": -10.716140747070312, "count": 1}, {"pred": "nebraska", "cond_log_prob": -18.146743774414062, "count": 1}, {"pred": "neighborhoods", "cond_log_prob": -8.057571411132812, "count": 1}, {"pred": "only", "cond_log_prob": -8.249526977539062, "count": 1}, {"pred": "past", "cond_log_prob": -7.0848541259765625, "count": 1}, {"pred": "recent", "cond_log_prob": -4.4885711669921875, "count": 1}, {"pred": "some", "cond_log_prob": -2.7317962646484375, "count": 1}, {"pred": "time", "cond_log_prob": -7.3127593994140625, "count": 1}, {"pred": "times", "cond_log_prob": -7.9658355712890625, "count": 1}, {"pred": "utah", "cond_log_prob": -22.247085571289062, "count": 1}], "ancestral_samples": [{"pred": "Chicago", "count": 1, "cond_log_prob": -5.3014984130859375}, {"pred": "Florida", "count": 1, "cond_log_prob": -5.6464996337890625}, {"pred": "a", "count": 4, "cond_log_prob": -2.7727508544921875}, {"pred": "addition", "count": 2, "cond_log_prob": -2.6558074951171875}, {"pred": "fact", "count": 1, "cond_log_prob": -3.3219757080078125}, {"pred": "manyroute", "count": 1, "cond_log_prob": -24.878189086914062}, {"pred": "other", "count": 1, "cond_log_prob": -5.1401519775390625}, {"pred": "some", "count": 7, "cond_log_prob": -2.7317962646484375}, {"pred": "the", "count": 22, "cond_log_prob": -1.7945709228515625}]}, "31": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston,", "log_prob": -141.5497589111328}, "original": {"pred": "a", "cond_log_prob": -2.5037078857421875}, "human": [{"pred": "the", "cond_log_prob": -2.3960723876953125, "count": 15}, {"pred": "there", "cond_log_prob": -4.0824127197265625, "count": 6}, {"pred": "people", "cond_log_prob": -3.4461517333984375, "count": 4}, {"pred": "many", "cond_log_prob": -5.2950286865234375, "count": 3}, {"pred": "however", "cond_log_prob": -5.9376983642578125, "count": 2}, {"pred": "we", "cond_log_prob": -6.0024566650390625, "count": 2}, {"pred": "hundreds", "cond_log_prob": -5.1460418701171875, "count": 1}, {"pred": "ma", "cond_log_prob": -12.728439331054688, "count": 1}, {"pred": "reports", "cond_log_prob": -8.232711791992188, "count": 1}, {"pred": "residents", "cond_log_prob": -3.1667327880859375, "count": 1}, {"pred": "snow", "cond_log_prob": -6.4718170166015625, "count": 1}, {"pred": "streets", "cond_log_prob": -6.8009796142578125, "count": 1}, {"pred": "this", "cond_log_prob": -6.8058624267578125, "count": 1}], "ancestral_samples": [{"pred": "Mayor", "count": 1, "cond_log_prob": -4.2403411865234375}, {"pred": "a", "count": 13, "cond_log_prob": -2.5039825439453125}, {"pred": "drivers", "count": 1, "cond_log_prob": -5.5575714111328125}, {"pred": "firefighters", "count": 1, "cond_log_prob": -5.3826446533203125}, {"pred": "hospitals", "count": 1, "cond_log_prob": -8.047775268554688}, {"pred": "officials", "count": 2, "cond_log_prob": -3.2421417236328125}, {"pred": "one", "count": 1, "cond_log_prob": -4.1582794189453125}, {"pred": "parents", "count": 1, "cond_log_prob": -4.3401947021484375}, {"pred": "people", "count": 2, "cond_log_prob": -3.4461517333984375}, {"pred": "residents", "count": 2, "cond_log_prob": -3.1667327880859375}, {"pred": "some", "count": 1, "cond_log_prob": -4.2589263916015625}, {"pred": "the", "count": 9, "cond_log_prob": -2.3960723876953125}, {"pred": "theroute", "count": 1, "cond_log_prob": -29.067428588867188}, {"pred": "theyre", "count": 1, "cond_log_prob": -18.244186401367188}, {"pred": "where", "count": 3, "cond_log_prob": -3.4921722412109375}]}, "32": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a", "log_prob": -144.053466796875}, "original": {"pred": "\"snow", "cond_log_prob": -11.326263427734375}, "human": [{"pred": "person", "cond_log_prob": -5.290008544921875, "count": 7}, {"pred": "snowstorm", "cond_log_prob": -6.41058349609375, "count": 5}, {"pred": "man", "cond_log_prob": -3.316650390625, "count": 5}, {"pred": "woman", "cond_log_prob": -3.951812744140625, "count": 3}, {"pred": "large", "cond_log_prob": -4.634002685546875, "count": 2}, {"pred": "big", "cond_log_prob": -6.387725830078125, "count": 1}, {"pred": "boy", "cond_log_prob": -6.037689208984375, "count": 1}, {"pred": "car", "cond_log_prob": -4.8726806640625, "count": 1}, {"pred": "child", "cond_log_prob": -5.412506103515625, "count": 1}, {"pred": "community", "cond_log_prob": -4.953765869140625, "count": 1}, {"pred": "flight", "cond_log_prob": -9.61627197265625, "count": 1}, {"pred": "group", "cond_log_prob": -3.101318359375, "count": 1}, {"pred": "icestorm", "cond_log_prob": -27.733062744140625, "count": 1}, {"pred": "increase", "cond_log_prob": -13.053680419921875, "count": 1}, {"pred": "massive", "cond_log_prob": -6.08984375, "count": 1}, {"pred": "meteorologist", "cond_log_prob": -9.2069091796875, "count": 1}, {"pred": "million", "cond_log_prob": -8.358673095703125, "count": 1}, {"pred": "school", "cond_log_prob": -3.8895263671875, "count": 1}, {"pred": "snow", "cond_log_prob": -4.943695068359375, "count": 1}, {"pred": "total", "cond_log_prob": -6.16815185546875, "count": 1}, {"pred": "widespread", "cond_log_prob": -8.967315673828125, "count": 1}, {"pred": "young", "cond_log_prob": -5.29412841796875, "count": 1}], "ancestral_samples": [{"pred": "bus", "count": 1, "cond_log_prob": -4.68804931640625}, {"pred": "car", "count": 1, "cond_log_prob": -4.8726806640625}, {"pred": "city", "count": 3, "cond_log_prob": -4.0838623046875}, {"pred": "community", "count": 1, "cond_log_prob": -4.953765869140625}, {"pred": "couple", "count": 2, "cond_log_prob": -3.94317626953125}, {"pred": "day", "count": 1, "cond_log_prob": -6.313568115234375}, {"pred": "family", "count": 2, "cond_log_prob": -4.39923095703125}, {"pred": "few", "count": 1, "cond_log_prob": -3.921539306640625}, {"pred": "group", "count": 5, "cond_log_prob": -3.101318359375}, {"pred": "grouproute", "count": 1, "cond_log_prob": -29.408172607421875}, {"pred": "large", "count": 2, "cond_log_prob": -4.634002685546875}, {"pred": "major", "count": 2, "cond_log_prob": -5.1171875}, {"pred": "man", "count": 8, "cond_log_prob": -3.316650390625}, {"pred": "pedestrian", "count": 2, "cond_log_prob": -5.634552001953125}, {"pred": "proKremlin", "count": 1, "cond_log_prob": -26.174957275390625}, {"pred": "school", "count": 1, "cond_log_prob": -3.8895263671875}, {"pred": "snowstorm", "count": 1, "cond_log_prob": -6.41058349609375}, {"pred": "state", "count": 2, "cond_log_prob": -5.26055908203125}, {"pred": "woman", "count": 3, "cond_log_prob": -3.951812744140625}]}, "33": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow", "log_prob": -155.37973022460938}, "original": {"pred": "angel\"", "cond_log_prob": -7.21533203125}, "human": [{"pred": "storm", "cond_log_prob": -3.646514892578125, "count": 18}, {"pred": "day", "cond_log_prob": -5.3472137451171875, "count": 5}, {"pred": "man", "cond_log_prob": -6.01861572265625, "count": 3}, {"pred": "brigade", "cond_log_prob": -7.6651763916015625, "count": 2}, {"pred": "warning", "cond_log_prob": -7.4452667236328125, "count": 2}, {"pred": "crew", "cond_log_prob": -7.7095947265625, "count": 1}, {"pred": "epidemic", "cond_log_prob": -10.048126220703125, "count": 1}, {"pred": "monster", "cond_log_prob": -7.516357421875, "count": 1}, {"pred": "mountain", "cond_log_prob": -8.169235229492188, "count": 1}, {"pred": "plow", "cond_log_prob": -5.0933837890625, "count": 1}, {"pred": "shoveling", "cond_log_prob": -5.8208160400390625, "count": 1}, {"pred": "shut", "cond_log_prob": -8.2227783203125, "count": 1}, {"pred": "team", "cond_log_prob": -6.515777587890625, "count": 1}, {"pred": "watch", "cond_log_prob": -7.236724853515625, "count": 1}], "ancestral_samples": [{"pred": "ball", "count": 3, "cond_log_prob": -5.775238037109375}, {"pred": "bike", "count": 1, "cond_log_prob": -4.9806060791015625}, {"pred": "day", "count": 1, "cond_log_prob": -5.3472137451171875}, {"pred": "man", "count": 1, "cond_log_prob": -6.01861572265625}, {"pred": "mobile", "count": 8, "cond_log_prob": -9.166091918945312}, {"pred": "shoe", "count": 1, "cond_log_prob": -7.771636962890625}, {"pred": "shovel", "count": 4, "cond_log_prob": -2.83880615234375}, {"pred": "storm", "count": 19, "cond_log_prob": -3.646514892578125}, {"pred": "stormroute", "count": 1, "cond_log_prob": -19.80316162109375}, {"pred": "walk", "count": 1, "cond_log_prob": -4.8486328125}]}, "34": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\"", "log_prob": -162.59506225585938}, "original": {"pred": "campaign", "cond_log_prob": -7.67376708984375}, "human": [{"pred": "was", "cond_log_prob": -2.3677978515625, "count": 11}, {"pred": "is", "cond_log_prob": -1.70965576171875, "count": 9}, {"pred": "has", "cond_log_prob": -2.115325927734375, "count": 3}, {"pred": "and", "cond_log_prob": -4.739166259765625, "count": 1}, {"pred": "anonymously", "cond_log_prob": -13.304977416992188, "count": 1}, {"pred": "appeared", "cond_log_prob": -5.624237060546875, "count": 1}, {"pred": "can", "cond_log_prob": -5.068115234375, "count": 1}, {"pred": "cleared", "cond_log_prob": -10.144439697265625, "count": 1}, {"pred": "competition", "cond_log_prob": -10.75103759765625, "count": 1}, {"pred": "formed", "cond_log_prob": -8.3929443359375, "count": 1}, {"pred": "group", "cond_log_prob": -6.1661376953125, "count": 1}, {"pred": "happens", "cond_log_prob": -10.68621826171875, "count": 1}, {"pred": "helped", "cond_log_prob": -4.588592529296875, "count": 1}, {"pred": "means", "cond_log_prob": -8.650726318359375, "count": 1}, {"pred": "sat", "cond_log_prob": -6.80938720703125, "count": 1}, {"pred": "saved", "cond_log_prob": -6.5748291015625, "count": 1}, {"pred": "shoveled", "cond_log_prob": -8.579132080078125, "count": 1}, {"pred": "that", "cond_log_prob": -5.575714111328125, "count": 1}, {"pred": "which", "cond_log_prob": -8.073394775390625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -7.73565673828125}, {"pred": "has", "count": 7, "cond_log_prob": -2.115325927734375}, {"pred": "is", "count": 20, "cond_log_prob": -1.70965576171875}, {"pred": "isroute", "count": 1, "cond_log_prob": -24.581558227539062}, {"pred": "was", "count": 9, "cond_log_prob": -2.3677978515625}, {"pred": "who", "count": 2, "cond_log_prob": -3.544342041015625}]}, "35": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign", "log_prob": -170.26882934570312}, "original": {"pred": "is", "cond_log_prob": -1.181182861328125}, "human": [{"pred": "has", "cond_log_prob": -1.556488037109375, "count": 11}, {"pred": "was", "cond_log_prob": -2.678863525390625, "count": 9}, {"pred": "is", "cond_log_prob": -1.181488037109375, "count": 7}, {"pred": "began", "cond_log_prob": -4.063812255859375, "count": 4}, {"pred": "started", "cond_log_prob": -3.34344482421875, "count": 3}, {"pred": "been", "cond_log_prob": -9.145858764648438, "count": 1}, {"pred": "helped", "cond_log_prob": -5.14447021484375, "count": 1}, {"pred": "launched", "cond_log_prob": -4.532135009765625, "count": 1}, {"pred": "rose", "cond_log_prob": -9.127212524414062, "count": 1}, {"pred": "that", "cond_log_prob": -5.12506103515625, "count": 1}], "ancestral_samples": [{"pred": "has", "count": 9, "cond_log_prob": -1.556488037109375}, {"pred": "is", "count": 26, "cond_log_prob": -1.181488037109375}, {"pred": "isroute", "count": 1, "cond_log_prob": -24.811843872070312}, {"pred": "was", "count": 4, "cond_log_prob": -2.678863525390625}]}, "36": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is", "log_prob": -171.45001220703125}, "original": {"pred": "using", "cond_log_prob": -5.3101806640625}, "human": [{"pred": "being", "cond_log_prob": -2.18988037109375, "count": 8}, {"pred": "underway", "cond_log_prob": -3.551116943359375, "count": 6}, {"pred": "beginning", "cond_log_prob": -5.9197540283203125, "count": 3}, {"pred": "in", "cond_log_prob": -4.190643310546875, "count": 3}, {"pred": "starting", "cond_log_prob": -4.3371734619140625, "count": 2}, {"pred": "the", "cond_log_prob": -6.3479156494140625, "count": 2}, {"pred": "about", "cond_log_prob": -6.0004425048828125, "count": 1}, {"pred": "changing", "cond_log_prob": -7.9169158935546875, "count": 1}, {"pred": "enforced", "cond_log_prob": -12.554611206054688, "count": 1}, {"pred": "focusing", "cond_log_prob": -7.6338043212890625, "count": 1}, {"pred": "going", "cond_log_prob": -4.2987823486328125, "count": 1}, {"pred": "helping", "cond_log_prob": -3.24078369140625, "count": 1}, {"pred": "making", "cond_log_prob": -4.9266510009765625, "count": 1}, {"pred": "now", "cond_log_prob": -4.142486572265625, "count": 1}, {"pred": "picking", "cond_log_prob": -6.4647674560546875, "count": 1}, {"pred": "present", "cond_log_prob": -10.456466674804688, "count": 1}, {"pred": "rallying", "cond_log_prob": -5.9344940185546875, "count": 1}, {"pred": "ran", "cond_log_prob": -12.009078979492188, "count": 1}, {"pred": "spotted", "cond_log_prob": -10.526107788085938, "count": 1}, {"pred": "when", "cond_log_prob": -10.950912475585938, "count": 1}, {"pred": "working", "cond_log_prob": -4.8188323974609375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -5.5516815185546875}, {"pred": "already", "count": 1, "cond_log_prob": -4.0771484375}, {"pred": "also", "count": 5, "cond_log_prob": -3.1787109375}, {"pred": "being", "count": 18, "cond_log_prob": -2.18988037109375}, {"pred": "helping", "count": 2, "cond_log_prob": -3.24078369140625}, {"pred": "opening", "count": 1, "cond_log_prob": -5.3571929931640625}, {"pred": "set", "count": 1, "cond_log_prob": -4.03277587890625}, {"pred": "taking", "count": 5, "cond_log_prob": -3.293365478515625}, {"pred": "takingroute", "count": 1, "cond_log_prob": -24.008102416992188}, {"pred": "trying", "count": 1, "cond_log_prob": -4.0675048828125}, {"pred": "underway", "count": 3, "cond_log_prob": -3.551116943359375}, {"pred": "urging", "count": 1, "cond_log_prob": -4.0279541015625}]}, "37": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using", "log_prob": -176.76019287109375}, "original": {"pred": "social", "cond_log_prob": -4.93359375}, "human": [{"pred": "the", "cond_log_prob": -1.6120452880859375, "count": 10}, {"pred": "a", "cond_log_prob": -2.4709320068359375, "count": 5}, {"pred": "people", "cond_log_prob": -4.5053253173828125, "count": 4}, {"pred": "this", "cond_log_prob": -5.6016693115234375, "count": 3}, {"pred": "children", "cond_log_prob": -5.3228302001953125, "count": 2}, {"pred": "snow", "cond_log_prob": -3.4326629638671875, "count": 2}, {"pred": "aliens", "cond_log_prob": -14.593765258789062, "count": 1}, {"pred": "as", "cond_log_prob": -6.5509490966796875, "count": 1}, {"pred": "citizens", "cond_log_prob": -7.7470550537109375, "count": 1}, {"pred": "civilians", "cond_log_prob": -10.392166137695312, "count": 1}, {"pred": "community", "cond_log_prob": -6.8231658935546875, "count": 1}, {"pred": "it", "cond_log_prob": -5.3948822021484375, "count": 1}, {"pred": "kids", "cond_log_prob": -5.5123443603515625, "count": 1}, {"pred": "pictures", "cond_log_prob": -6.4659271240234375, "count": 1}, {"pred": "residents", "cond_log_prob": -7.0125885009765625, "count": 1}, {"pred": "set", "cond_log_prob": -10.106216430664062, "count": 1}, {"pred": "shovels", "cond_log_prob": -3.0453338623046875, "count": 1}, {"pred": "slogans", "cond_log_prob": -9.505020141601562, "count": 1}, {"pred": "their", "cond_log_prob": -6.3022918701171875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 5, "cond_log_prob": -2.4709320068359375}, {"pred": "shovels", "count": 2, "cond_log_prob": -3.0453338623046875}, {"pred": "snow", "count": 1, "cond_log_prob": -3.4326629638671875}, {"pred": "the", "count": 30, "cond_log_prob": -1.6120452880859375}, {"pred": "theroute", "count": 1, "cond_log_prob": -32.58842468261719}, {"pred": "volunteers", "count": 1, "cond_log_prob": -3.9876556396484375}]}, "38": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social", "log_prob": -181.69378662109375}, "original": {"pred": "media", "cond_log_prob": -0.007904052734375}, "human": [{"pred": "media", "cond_log_prob": -0.0082244873046875, "count": 31}, {"pred": "networking", "cond_log_prob": -7.1054229736328125, "count": 3}, {"pred": "groups", "cond_log_prob": -11.474380493164062, "count": 1}, {"pred": "network", "cond_log_prob": -8.610671997070312, "count": 1}, {"pred": "networks", "cond_log_prob": -6.0972137451171875, "count": 1}, {"pred": "norms", "cond_log_prob": -12.546615600585938, "count": 1}, {"pred": "people", "cond_log_prob": -13.982101440429688, "count": 1}], "ancestral_samples": [{"pred": "media", "count": 39, "cond_log_prob": -0.00823974609375}, {"pred": "mediaroutecom", "count": 1, "cond_log_prob": -49.14585876464844}]}, "39": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media", "log_prob": -181.70169067382812}, "original": {"pred": "to", "cond_log_prob": -0.1842193603515625}, "human": [{"pred": "to", "cond_log_prob": -0.1845703125, "count": 38}, {"pred": "sites", "cond_log_prob": -6.2882843017578125, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -13.12445068359375}, {"pred": "to", "count": 38, "cond_log_prob": -0.1845703125}, {"pred": "toroute", "count": 1, "cond_log_prob": -31.53497314453125}]}, "40": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to", "log_prob": -181.8859100341797}, "original": {"pred": "encourage", "cond_log_prob": -2.4647979736328125}, "human": [{"pred": "spread", "cond_log_prob": -2.586181640625, "count": 11}, {"pred": "get", "cond_log_prob": -3.73187255859375, "count": 4}, {"pred": "inform", "cond_log_prob": -5.3252105712890625, "count": 3}, {"pred": "advertise", "cond_log_prob": -6.5456085205078125, "count": 2}, {"pred": "ask", "cond_log_prob": -4.3060150146484375, "count": 2}, {"pred": "bring", "cond_log_prob": -4.10986328125, "count": 2}, {"pred": "inspire", "cond_log_prob": -5.3808135986328125, "count": 2}, {"pred": "promote", "cond_log_prob": -4.0615997314453125, "count": 2}, {"pred": "raise", "cond_log_prob": -3.023223876953125, "count": 2}, {"pred": "coordinate", "cond_log_prob": -6.4278106689453125, "count": 1}, {"pred": "draw", "cond_log_prob": -4.7769012451171875, "count": 1}, {"pred": "express", "cond_log_prob": -6.708740234375, "count": 1}, {"pred": "help", "cond_log_prob": -1.8969573974609375, "count": 1}, {"pred": "increase", "cond_log_prob": -6.9654083251953125, "count": 1}, {"pred": "influence", "cond_log_prob": -8.916366577148438, "count": 1}, {"pred": "organize", "cond_log_prob": -5.1566314697265625, "count": 1}, {"pred": "reach", "cond_log_prob": -4.3198394775390625, "count": 1}, {"pred": "share", "cond_log_prob": -4.2024993896484375, "count": 1}], "ancestral_samples": [{"pred": "distribute", "count": 1, "cond_log_prob": -5.19952392578125}, {"pred": "encourage", "count": 5, "cond_log_prob": -2.4651641845703125}, {"pred": "find", "count": 1, "cond_log_prob": -4.4029693603515625}, {"pred": "help", "count": 18, "cond_log_prob": -1.8969573974609375}, {"pred": "helpBoston", "count": 1, "cond_log_prob": -15.965072631835938}, {"pred": "helpThe", "count": 1, "cond_log_prob": -14.650466918945312}, {"pred": "helproute", "count": 1, "cond_log_prob": -19.3948974609375}, {"pred": "raise", "count": 4, "cond_log_prob": -3.023223876953125}, {"pred": "spread", "count": 6, "cond_log_prob": -2.586181640625}, {"pred": "urge", "count": 2, "cond_log_prob": -3.68670654296875}]}, "41": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage", "log_prob": -184.3507080078125}, "original": {"pred": "neighbors", "cond_log_prob": -6.7345123291015625}, "human": [{"pred": "people", "cond_log_prob": -0.6935577392578125, "count": 29}, {"pred": "citizens", "cond_log_prob": -5.4969940185546875, "count": 4}, {"pred": "others", "cond_log_prob": -5.5613861083984375, "count": 3}, {"pred": "awareness", "cond_log_prob": -8.135360717773438, "count": 1}, {"pred": "everyone", "cond_log_prob": -5.250152587890625, "count": 1}, {"pred": "residents", "cond_log_prob": -2.6093902587890625, "count": 1}], "ancestral_samples": [{"pred": "parents", "count": 1, "cond_log_prob": -3.23394775390625}, {"pred": "people", "count": 37, "cond_log_prob": -0.6935577392578125}, {"pred": "peopleroute", "count": 1, "cond_log_prob": -36.2947998046875}, {"pred": "volunteers", "count": 1, "cond_log_prob": -4.1680908203125}]}, "42": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors", "log_prob": -191.08522033691406}, "original": {"pred": "and", "cond_log_prob": -2.076873779296875}, "human": [{"pred": "to", "cond_log_prob": -0.23406982421875, "count": 36}, {"pred": "and", "cond_log_prob": -2.077239990234375, "count": 3}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -17.237701416015625}, {"pred": "to", "count": 38, "cond_log_prob": -0.23406982421875}, {"pred": "toroute", "count": 1, "cond_log_prob": -31.9647216796875}]}, "43": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and", "log_prob": -193.16209411621094}, "original": {"pred": "friends", "cond_log_prob": -2.80474853515625}, "human": [{"pred": "friends", "cond_log_prob": -2.8051300048828125, "count": 20}, {"pred": "families", "cond_log_prob": -4.8827972412109375, "count": 3}, {"pred": "family", "cond_log_prob": -4.799163818359375, "count": 2}, {"pred": "children", "cond_log_prob": -3.626251220703125, "count": 1}, {"pred": "churches", "cond_log_prob": -7.307403564453125, "count": 1}, {"pred": "citizens", "cond_log_prob": -4.7804107666015625, "count": 1}, {"pred": "communities", "cond_log_prob": -6.4222412109375, "count": 1}, {"pred": "help", "cond_log_prob": -6.91485595703125, "count": 1}, {"pred": "influence", "cond_log_prob": -13.970840454101562, "count": 1}, {"pred": "inspire", "cond_log_prob": -11.699478149414062, "count": 1}, {"pred": "locals", "cond_log_prob": -5.11468505859375, "count": 1}, {"pred": "others", "cond_log_prob": -4.51904296875, "count": 1}, {"pred": "parents", "cond_log_prob": -4.137451171875, "count": 1}, {"pred": "people", "cond_log_prob": -4.861907958984375, "count": 1}, {"pred": "residents", "cond_log_prob": -2.350982666015625, "count": 1}, {"pred": "try", "cond_log_prob": -10.4573974609375, "count": 1}, {"pred": "youth", "cond_log_prob": -8.394790649414062, "count": 1}], "ancestral_samples": [{"pred": "businesses", "count": 8, "cond_log_prob": -2.6461029052734375}, {"pred": "children", "count": 1, "cond_log_prob": -3.626251220703125}, {"pred": "community", "count": 1, "cond_log_prob": -4.471710205078125}, {"pred": "customers", "count": 1, "cond_log_prob": -5.4363250732421875}, {"pred": "friends", "count": 3, "cond_log_prob": -2.8051300048828125}, {"pred": "local", "count": 1, "cond_log_prob": -3.84588623046875}, {"pred": "neighbors", "count": 1, "cond_log_prob": -3.0018768310546875}, {"pred": "neighborsroute", "count": 1, "cond_log_prob": -23.951400756835938}, {"pred": "other", "count": 1, "cond_log_prob": -4.30267333984375}, {"pred": "parents", "count": 1, "cond_log_prob": -4.137451171875}, {"pred": "passersby", "count": 1, "cond_log_prob": -3.4875640869140625}, {"pred": "residents", "count": 6, "cond_log_prob": -2.350982666015625}, {"pred": "school", "count": 2, "cond_log_prob": -3.045684814453125}, {"pred": "students", "count": 1, "cond_log_prob": -3.35479736328125}, {"pred": "tourists", "count": 1, "cond_log_prob": -3.691986083984375}, {"pred": "visitors", "count": 9, "cond_log_prob": -2.645965576171875}, {"pred": "volunteers", "count": 1, "cond_log_prob": -3.9953155517578125}]}, "44": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends", "log_prob": -195.9668426513672}, "original": {"pred": "to", "cond_log_prob": -0.0982513427734375}, "human": [{"pred": "to", "cond_log_prob": -0.0986480712890625, "count": 38}, {"pred": "shovel", "cond_log_prob": -14.17584228515625, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -16.231475830078125}, {"pred": "to", "count": 38, "cond_log_prob": -0.0986480712890625}, {"pred": "toroute", "count": 1, "cond_log_prob": -33.17779541015625}]}, "45": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to", "log_prob": -196.06509399414062}, "original": {"pred": "be", "cond_log_prob": -4.8976593017578125}, "human": [{"pred": "help", "cond_log_prob": -1.708587646484375, "count": 23}, {"pred": "do", "cond_log_prob": -3.8502960205078125, "count": 3}, {"pred": "clear", "cond_log_prob": -7.96331787109375, "count": 2}, {"pred": "come", "cond_log_prob": -3.8599853515625, "count": 2}, {"pred": "assist", "cond_log_prob": -5.8314056396484375, "count": 1}, {"pred": "band", "cond_log_prob": -9.808853149414062, "count": 1}, {"pred": "donate", "cond_log_prob": -4.1134490966796875, "count": 1}, {"pred": "go", "cond_log_prob": -4.586456298828125, "count": 1}, {"pred": "join", "cond_log_prob": -3.7971038818359375, "count": 1}, {"pred": "lend", "cond_log_prob": -6.843109130859375, "count": 1}, {"pred": "shovel", "cond_log_prob": -3.2342987060546875, "count": 1}, {"pred": "take", "cond_log_prob": -3.044464111328125, "count": 1}, {"pred": "work", "cond_log_prob": -5.61004638671875, "count": 1}], "ancestral_samples": [{"pred": "bring", "count": 1, "cond_log_prob": -3.7567138671875}, {"pred": "donate", "count": 1, "cond_log_prob": -4.1134490966796875}, {"pred": "help", "count": 19, "cond_log_prob": -1.708587646484375}, {"pred": "helpAt", "count": 1, "cond_log_prob": -17.925445556640625}, {"pred": "helpThe", "count": 1, "cond_log_prob": -14.102066040039062}, {"pred": "helproute", "count": 1, "cond_log_prob": -19.102325439453125}, {"pred": "join", "count": 1, "cond_log_prob": -3.7971038818359375}, {"pred": "pick", "count": 10, "cond_log_prob": -2.24029541015625}, {"pred": "share", "count": 1, "cond_log_prob": -4.3407745361328125}, {"pred": "take", "count": 4, "cond_log_prob": -3.044464111328125}]}, "46": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to be", "log_prob": -200.96275329589844}, "original": {"pred": "an", "cond_log_prob": -7.1227569580078125}, "human": [{"pred": "helpful", "cond_log_prob": -5.53179931640625, "count": 7}, {"pred": "active", "cond_log_prob": -5.2827606201171875, "count": 3}, {"pred": "kind", "cond_log_prob": -5.08575439453125, "count": 3}, {"pred": "more", "cond_log_prob": -2.5633392333984375, "count": 3}, {"pred": "proactive", "cond_log_prob": -5.371826171875, "count": 3}, {"pred": "a", "cond_log_prob": -4.4199371337890625, "count": 2}, {"pred": "considerate", "cond_log_prob": -8.03277587890625, "count": 2}, {"pred": "on", "cond_log_prob": -2.6105804443359375, "count": 2}, {"pred": "able", "cond_log_prob": -4.1474151611328125, "count": 1}, {"pred": "alert", "cond_log_prob": -6.9664764404296875, "count": 1}, {"pred": "apart", "cond_log_prob": -10.677505493164062, "count": 1}, {"pred": "aware", "cond_log_prob": -5.108001708984375, "count": 1}, {"pred": "courteous", "cond_log_prob": -8.587615966796875, "count": 1}, {"pred": "creative", "cond_log_prob": -5.597930908203125, "count": 1}, {"pred": "dancers", "cond_log_prob": -15.040283203125, "count": 1}, {"pred": "generous", "cond_log_prob": -6.3350830078125, "count": 1}, {"pred": "happy", "cond_log_prob": -7.703857421875, "count": 1}, {"pred": "hopeful", "cond_log_prob": -8.588775634765625, "count": 1}, {"pred": "involved", "cond_log_prob": -3.681060791015625, "count": 2}, {"pred": "mindful", "cond_log_prob": -6.8555450439453125, "count": 1}, {"pred": "supportive", "cond_log_prob": -6.91845703125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.4199371337890625}, {"pred": "as", "count": 1, "cond_log_prob": -3.4736175537109375}, {"pred": "extra", "count": 2, "cond_log_prob": -3.17822265625}, {"pred": "in", "count": 1, "cond_log_prob": -3.8297882080078125}, {"pred": "more", "count": 6, "cond_log_prob": -2.5633392333984375}, {"pred": "on", "count": 6, "cond_log_prob": -2.6105804443359375}, {"pred": "part", "count": 3, "cond_log_prob": -3.277496337890625}, {"pred": "prepared", "count": 2, "cond_log_prob": -3.231353759765625}, {"pred": "shovelin", "count": 4, "cond_log_prob": -8.159988403320312}, {"pred": "shoveling", "count": 7, "cond_log_prob": -2.588104248046875}, {"pred": "shovelinthe", "count": 3, "cond_log_prob": -20.30145263671875}, {"pred": "shovelready", "count": 3, "cond_log_prob": -12.981109619140625}, {"pred": "shovelroute", "count": 1, "cond_log_prob": -22.778732299804688}]}, "47": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to be an", "log_prob": -208.08551025390625}, "original": {"pred": "angel", "cond_log_prob": -5.273712158203125}, "human": [{"pred": "angel", "cond_log_prob": -5.274139404296875, "count": 13}, {"pred": "example", "cond_log_prob": -4.7012939453125, "count": 4}, {"pred": "influence", "cond_log_prob": -7.3309326171875, "count": 3}, {"pred": "active", "cond_log_prob": -2.76458740234375, "count": 2}, {"pred": "advocate", "cond_log_prob": -3.6222076416015625, "count": 2}, {"pred": "aid", "cond_log_prob": -4.761322021484375, "count": 3}, {"pred": "awesome", "cond_log_prob": -6.5108642578125, "count": 2}, {"pred": "accepting", "cond_log_prob": -12.331573486328125, "count": 1}, {"pred": "asset", "cond_log_prob": -3.8738861083984375, "count": 1}, {"pred": "assistant", "cond_log_prob": -9.595916748046875, "count": 1}, {"pred": "efficient", "cond_log_prob": -5.97967529296875, "count": 1}, {"pred": "encouraging", "cond_log_prob": -8.818206787109375, "count": 1}, {"pred": "extra", "cond_log_prob": -0.8822021484375, "count": 1}, {"pred": "important", "cond_log_prob": -4.186737060546875, "count": 1}, {"pred": "increase", "cond_log_prob": -8.59429931640625, "count": 1}, {"pred": "inspiration", "cond_log_prob": -4.075927734375, "count": 1}, {"pred": "source", "cond_log_prob": -11.887969970703125, "count": 1}], "ancestral_samples": [{"pred": "advocate", "count": 2, "cond_log_prob": -3.6222076416015625}, {"pred": "effective", "count": 1, "cond_log_prob": -2.78759765625}, {"pred": "extra", "count": 35, "cond_log_prob": -0.8822021484375}, {"pred": "extraBoston", "count": 1, "cond_log_prob": -18.337799072265625}, {"pred": "extraroute", "count": 1, "cond_log_prob": -35.37864685058594}]}, "48": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to be an angel", "log_prob": -213.35922241210938}, "original": {"pred": "and", "cond_log_prob": -2.8633575439453125}, "human": [{"pred": "and", "cond_log_prob": -2.8637847900390625, "count": 15}, {"pred": "to", "cond_log_prob": -2.327392578125, "count": 10}, {"pred": "in", "cond_log_prob": -1.99822998046875, "count": 5}, {"pred": "for", "cond_log_prob": -3.49591064453125, "count": 4}, {"pred": "by", "cond_log_prob": -4.328887939453125, "count": 2}, {"pred": "just", "cond_log_prob": -7.5681915283203125, "count": 1}, {"pred": "that", "cond_log_prob": -6.592498779296875, "count": 1}, {"pred": "those", "cond_log_prob": -12.032623291015625, "count": 1}], "ancestral_samples": [{"pred": "Bart", "count": 1, "cond_log_prob": -16.537933349609375}, {"pred": "I", "count": 1, "cond_log_prob": -10.578460693359375}, {"pred": "It", "count": 3, "cond_log_prob": -13.25592041015625}, {"pred": "We", "count": 6, "cond_log_prob": -13.413360595703125}, {"pred": "and", "count": 3, "cond_log_prob": -2.8637847900390625}, {"pred": "in", "count": 12, "cond_log_prob": -1.99822998046875}, {"pred": "on", "count": 2, "cond_log_prob": -2.85443115234375}, {"pred": "routegov", "count": 1, "cond_log_prob": -35.395904541015625}, {"pred": "to", "count": 8, "cond_log_prob": -2.327392578125}, {"pred": "too", "count": 1, "cond_log_prob": -3.953887939453125}, {"pred": "with", "count": 2, "cond_log_prob": -3.45074462890625}]}, "49": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to be an angel and", "log_prob": -216.2225799560547}, "original": {"pred": "help", "cond_log_prob": -0.9314117431640625}, "human": [{"pred": "help", "cond_log_prob": -0.93182373046875, "count": 28}, {"pred": "clear", "cond_log_prob": -8.546173095703125, "count": 2}, {"pred": "shovel", "cond_log_prob": -4.809814453125, "count": 2}, {"pred": "to", "cond_log_prob": -2.683197021484375, "count": 2}, {"pred": "example", "cond_log_prob": -14.360992431640625, "count": 1}, {"pred": "friend", "cond_log_prob": -10.117950439453125, "count": 1}, {"pred": "give", "cond_log_prob": -4.617645263671875, "count": 1}, {"pred": "helper", "cond_log_prob": -11.374481201171875, "count": 1}, {"pred": "pick", "cond_log_prob": -4.900909423828125, "count": 1}], "ancestral_samples": [{"pred": "help", "count": 36, "cond_log_prob": -0.93182373046875}, {"pred": "helproute", "count": 1, "cond_log_prob": -18.509490966796875}, {"pred": "to", "count": 3, "cond_log_prob": -2.683197021484375}]}, "50": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to be an angel and help", "log_prob": -217.15399169921875}, "original": {"pred": "dig", "cond_log_prob": -6.04742431640625}, "human": [{"pred": "out", "cond_log_prob": -1.6991424560546875, "count": 13}, {"pred": "others", "cond_log_prob": -4.0027618408203125, "count": 5}, {"pred": "their", "cond_log_prob": -3.8816375732421875, "count": 4}, {"pred": "shovel", "cond_log_prob": -3.7701568603515625, "count": 4}, {"pred": "the", "cond_log_prob": -2.8852386474609375, "count": 3}, {"pred": "those", "cond_log_prob": -2.9644317626953125, "count": 3}, {"pred": "clear", "cond_log_prob": -5.7108917236328125, "count": 2}, {"pred": "with", "cond_log_prob": -3.4737396240234375, "count": 2}, {"pred": "each", "cond_log_prob": -4.6687774658203125, "count": 1}, {"pred": "in", "cond_log_prob": -4.7859649658203125, "count": 1}, {"pred": "remove", "cond_log_prob": -6.4692840576171875, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -12.686111450195312}, {"pred": "a", "count": 1, "cond_log_prob": -5.3403472900390625}, {"pred": "keep", "count": 2, "cond_log_prob": -3.8909454345703125}, {"pred": "out", "count": 18, "cond_log_prob": -1.6991424560546875}, {"pred": "outAs", "count": 1, "cond_log_prob": -16.848464965820312}, {"pred": "outAt", "count": 1, "cond_log_prob": -16.818649291992188}, {"pred": "outBoston", "count": 1, "cond_log_prob": -13.586990356445312}, {"pred": "outIn", "count": 1, "cond_log_prob": -16.122116088867188}, {"pred": "outThe", "count": 3, "cond_log_prob": -14.314743041992188}, {"pred": "outroute", "count": 1, "cond_log_prob": -19.736190795898438}, {"pred": "save", "count": 3, "cond_log_prob": -3.1633758544921875}, {"pred": "the", "count": 1, "cond_log_prob": -2.8852386474609375}, {"pred": "their", "count": 1, "cond_log_prob": -3.8816375732421875}, {"pred": "them", "count": 2, "cond_log_prob": -3.8010101318359375}, {"pred": "those", "count": 2, "cond_log_prob": -2.9644317626953125}, {"pred": "with", "count": 1, "cond_log_prob": -3.4737396240234375}]}, "51": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to be an angel and help dig", "log_prob": -223.201416015625}, "original": {"pred": "out", "cond_log_prob": -2.6846466064453125}, "human": [{"pred": "out", "cond_log_prob": -2.6850738525390625, "count": 18}, {"pred": "the", "cond_log_prob": -2.6693878173828125, "count": 8}, {"pred": "snow", "cond_log_prob": -3.0778656005859375, "count": 3}, {"pred": "up", "cond_log_prob": -1.6866607666015625, "count": 3}, {"pred": "a", "cond_log_prob": -2.7078704833984375, "count": 2}, {"pred": "canals", "cond_log_prob": -11.171249389648438, "count": 1}, {"pred": "cars", "cond_log_prob": -5.8517913818359375, "count": 1}, {"pred": "houses", "cond_log_prob": -6.1399688720703125, "count": 1}, {"pred": "people", "cond_log_prob": -6.4570159912109375, "count": 1}, {"pred": "trenches", "cond_log_prob": -5.4011688232421875, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -14.012527465820312}, {"pred": "a", "count": 7, "cond_log_prob": -2.7078704833984375}, {"pred": "for", "count": 2, "cond_log_prob": -2.4337310791015625}, {"pred": "holes", "count": 1, "cond_log_prob": -5.2016143798828125}, {"pred": "out", "count": 3, "cond_log_prob": -2.6850738525390625}, {"pred": "snowcovered", "count": 1, "cond_log_prob": -13.929153442382812}, {"pred": "the", "count": 2, "cond_log_prob": -2.6693878173828125}, {"pred": "through", "count": 2, "cond_log_prob": -2.7091217041015625}, {"pred": "up", "count": 20, "cond_log_prob": -1.6866607666015625}, {"pred": "uproute", "count": 1, "cond_log_prob": -22.275497436523438}]}, "52": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to be an angel and help dig out", "log_prob": -225.8860626220703}, "original": {"pred": "the", "cond_log_prob": -1.45465087890625}, "human": [{"pred": "the", "cond_log_prob": -1.455078125, "count": 18}, {"pred": "cars", "cond_log_prob": -4.236297607421875, "count": 12}, {"pred": "people", "cond_log_prob": -6.489898681640625, "count": 2}, {"pred": "their", "cond_log_prob": -2.398956298828125, "count": 2}, {"pred": "houses", "cond_log_prob": -5.913543701171875, "count": 1}, {"pred": "others", "cond_log_prob": -9.29327392578125, "count": 1}, {"pred": "schools", "cond_log_prob": -7.582275390625, "count": 1}, {"pred": "snow", "cond_log_prob": -2.5325927734375, "count": 1}, {"pred": "whoever", "cond_log_prob": -11.375640869140625, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -14.8677978515625}, {"pred": "a", "count": 4, "cond_log_prob": -3.04913330078125}, {"pred": "of", "count": 1, "cond_log_prob": -2.6435546875}, {"pred": "snow", "count": 1, "cond_log_prob": -2.5325927734375}, {"pred": "snowIn", "count": 1, "cond_log_prob": -16.5772705078125}, {"pred": "snowThe", "count": 1, "cond_log_prob": -15.68304443359375}, {"pred": "the", "count": 27, "cond_log_prob": -1.455078125}, {"pred": "their", "count": 3, "cond_log_prob": -2.398956298828125}, {"pred": "theroute", "count": 1, "cond_log_prob": -37.19474792480469}]}, "53": {"context": {"text": "With schools still closed, cars still buried and streets still blocked by the widespread weekend snowstorm, officials are asking people to pick up a shovel and help out. In Boston, a \"snow angel\" campaign is using social media to encourage neighbors and friends to be an angel and help dig out the", "log_prob": -227.34071350097656}, "original": {"pred": "stranded.", "cond_log_prob": -11.0906982421875}, "human": [{"pred": "cars", "cond_log_prob": -4.52252197265625, "count": 17}, {"pred": "city", "cond_log_prob": -3.976287841796875, "count": 4}, {"pred": "snow", "cond_log_prob": -1.799957275390625, "count": 4}, {"pred": "buried", "cond_log_prob": -2.807708740234375, "count": 3}, {"pred": "elderly", "cond_log_prob": -10.111785888671875, "count": 2}, {"pred": "houses", "cond_log_prob": -6.4766845703125, "count": 1}, {"pred": "people", "cond_log_prob": -6.7894287109375, "count": 1}, {"pred": "remaining", "cond_log_prob": -5.182159423828125, "count": 1}, {"pred": "school", "cond_log_prob": -6.72723388671875, "count": 1}, {"pred": "schools", "cond_log_prob": -8.061859130859375, "count": 1}, {"pred": "sidewalks", "cond_log_prob": -4.127899169921875, "count": 1}, {"pred": "stranded", "cond_log_prob": -5.88153076171875, "count": 1}, {"pred": "streets", "cond_log_prob": -3.3968505859375, "count": 1}, {"pred": "the", "cond_log_prob": -8.025421142578125, "count": 1}], "ancestral_samples": [{"pred": "bodies", "count": 1, "cond_log_prob": -3.9317626953125}, {"pred": "buried", "count": 2, "cond_log_prob": -2.807708740234375}, {"pred": "car", "count": 1, "cond_log_prob": -4.796295166015625}, {"pred": "dead", "count": 4, "cond_log_prob": -3.057037353515625}, {"pred": "deadThe", "count": 1, "cond_log_prob": -18.110107421875}, {"pred": "debris", "count": 2, "cond_log_prob": -3.912322998046875}, {"pred": "fallen", "count": 1, "cond_log_prob": -3.93572998046875}, {"pred": "roads", "count": 1, "cond_log_prob": -3.806396484375}, {"pred": "snow", "count": 17, "cond_log_prob": -1.799957275390625}, {"pred": "snowAs", "count": 1, "cond_log_prob": -17.824188232421875}, {"pred": "snowAt", "count": 1, "cond_log_prob": -19.166290283203125}, {"pred": "snowBoston", "count": 1, "cond_log_prob": -19.04827880859375}, {"pred": "snowIn", "count": 3, "cond_log_prob": -16.6925048828125}, {"pred": "snowThe", "count": 1, "cond_log_prob": -15.509246826171875}, {"pred": "snowroute", "count": 1, "cond_log_prob": -20.291900634765625}, {"pred": "street", "count": 1, "cond_log_prob": -4.345489501953125}, {"pred": "streetsThe", "count": 1, "cond_log_prob": -19.103973388671875}]}}, "15": {"2": {"context": {"text": "Greg", "log_prob": -13.931356430053711}, "original": {"pred": "Anderson,", "cond_log_prob": -7.834905624389648}, "human": [{"pred": "is", "cond_log_prob": -5.073450088500977, "count": 14}, {"pred": "was", "cond_log_prob": -6.759599685668945, "count": 6}, {"pred": "has", "cond_log_prob": -6.489339828491211, "count": 2}, {"pred": "and", "cond_log_prob": -5.487112045288086, "count": 1}, {"pred": "ate", "cond_log_prob": -12.425935745239258, "count": 1}, {"pred": "coworker", "cond_log_prob": -16.673246383666992, "count": 1}, {"pred": "hardy", "cond_log_prob": -17.931856155395508, "count": 1}, {"pred": "hipskin", "cond_log_prob": -26.838747024536133, "count": 1}, {"pred": "hopes", "cond_log_prob": -12.450448989868164, "count": 1}, {"pred": "oden", "cond_log_prob": -19.665327072143555, "count": 1}, {"pred": "parker", "cond_log_prob": -17.69327735900879, "count": 1}, {"pred": "sits", "cond_log_prob": -10.147523880004883, "count": 1}, {"pred": "stomped", "cond_log_prob": -17.69608497619629, "count": 1}, {"pred": "swam", "cond_log_prob": -16.724905014038086, "count": 1}, {"pred": "thought", "cond_log_prob": -11.020624160766602, "count": 1}, {"pred": "wants", "cond_log_prob": -8.78788948059082, "count": 1}, {"pred": "went", "cond_log_prob": -10.232065200805664, "count": 1}, {"pred": "will", "cond_log_prob": -8.041284561157227, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 1, "cond_log_prob": -10.214624404907227}, {"pred": "9", "count": 1, "cond_log_prob": -11.637582778930664}, {"pred": "B", "count": 1, "cond_log_prob": -4.629674911499023}, {"pred": "I", "count": 4, "cond_log_prob": -6.39808464050293}, {"pred": "Introduced", "count": 1, "cond_log_prob": -13.484086990356445}, {"pred": "Oscar", "count": 1, "cond_log_prob": -11.973360061645508}, {"pred": "The", "count": 2, "cond_log_prob": -7.443056106567383}, {"pred": "This", "count": 1, "cond_log_prob": -9.59550666809082}, {"pred": "We", "count": 2, "cond_log_prob": -7.012632369995117}, {"pred": "a", "count": 2, "cond_log_prob": -8.099687576293945}, {"pred": "aka", "count": 1, "cond_log_prob": -10.420831680297852}, {"pred": "and", "count": 4, "cond_log_prob": -5.487112045288086}, {"pred": "c", "count": 1, "cond_log_prob": -12.73314094543457}, {"pred": "com", "count": 1, "cond_log_prob": -13.652650833129883}, {"pred": "d", "count": 1, "cond_log_prob": -10.850404739379883}, {"pred": "is", "count": 1, "cond_log_prob": -5.073450088500977}, {"pred": "routemotor", "count": 1, "cond_log_prob": -36.539405822753906}, {"pred": "s", "count": 4, "cond_log_prob": -10.735536575317383}, {"pred": "the", "count": 2, "cond_log_prob": -7.220701217651367}, {"pred": "to", "count": 1, "cond_log_prob": -8.207460403442383}, {"pred": "was", "count": 1, "cond_log_prob": -6.759599685668945}, {"pred": "who", "count": 6, "cond_log_prob": -9.268312454223633}]}, "3": {"context": {"text": "Greg Anderson,", "log_prob": -21.76626205444336}, "original": {"pred": "considered", "cond_log_prob": -10.643245697021484}, "human": [{"pred": "a", "cond_log_prob": -2.4364051818847656, "count": 10}, {"pred": "is", "cond_log_prob": -6.898288726806641, "count": 4}, {"pred": "the", "cond_log_prob": -2.8778724670410156, "count": 3}, {"pred": "was", "cond_log_prob": -8.04873275756836, "count": 3}, {"pred": "will", "cond_log_prob": -9.16665267944336, "count": 2}, {"pred": "ceo", "cond_log_prob": -13.740646362304688, "count": 1}, {"pred": "could", "cond_log_prob": -10.838642120361328, "count": 1}, {"pred": "father", "cond_log_prob": -8.390018463134766, "count": 1}, {"pred": "he", "cond_log_prob": -8.752735137939453, "count": 1}, {"pred": "how", "cond_log_prob": -9.02341079711914, "count": 1}, {"pred": "my", "cond_log_prob": -8.513721466064453, "count": 2}, {"pred": "person", "cond_log_prob": -11.08951187133789, "count": 1}, {"pred": "sarah", "cond_log_prob": -13.87674331665039, "count": 1}, {"pred": "science", "cond_log_prob": -9.360355377197266, "count": 1}, {"pred": "star", "cond_log_prob": -8.56320571899414, "count": 1}, {"pred": "talks", "cond_log_prob": -10.888126373291016, "count": 1}, {"pred": "went", "cond_log_prob": -10.990787506103516, "count": 1}, {"pred": "what", "cond_log_prob": -8.641849517822266, "count": 1}, {"pred": "you", "cond_log_prob": -7.594173431396484, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 19, "cond_log_prob": -2.4364051818847656}, {"pred": "the", "count": 3, "cond_log_prob": -2.8778724670410156}, {"pred": "who", "count": 16, "cond_log_prob": -3.224628448486328}, {"pred": "whoroute", "count": 1, "cond_log_prob": -33.451499938964844}, {"pred": "whose", "count": 1, "cond_log_prob": -5.902393341064453}]}, "4": {"context": {"text": "Greg Anderson, considered", "log_prob": -32.409507751464844}, "original": {"pred": "a", "cond_log_prob": -1.7877426147460938}, "human": [{"pred": "the", "cond_log_prob": -1.7893753051757812, "count": 11}, {"pred": "to", "cond_log_prob": -3.0274734497070312, "count": 4}, {"pred": "a", "cond_log_prob": -1.7877731323242188, "count": 3}, {"pred": "by", "cond_log_prob": -2.2712554931640625, "count": 3}, {"pred": "going", "cond_log_prob": -10.143791198730469, "count": 2}, {"pred": "himself", "cond_log_prob": -8.376602172851562, "count": 2}, {"pred": "one", "cond_log_prob": -0.9659271240234375, "count": 2}, {"pred": "taking", "cond_log_prob": -11.9415283203125, "count": 2}, {"pred": "that", "cond_log_prob": -8.26617431640625, "count": 2}, {"pred": "doing", "cond_log_prob": -11.934249877929688, "count": 1}, {"pred": "eating", "cond_log_prob": -14.774421691894531, "count": 1}, {"pred": "filing", "cond_log_prob": -15.88616943359375, "count": 1}, {"pred": "grades", "cond_log_prob": -17.51087188720703, "count": 1}, {"pred": "his", "cond_log_prob": -6.306919097900391, "count": 1}, {"pred": "whether", "cond_log_prob": -12.510383605957031, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 14, "cond_log_prob": -1.7877731323242188}, {"pred": "one", "count": 14, "cond_log_prob": -0.9659271240234375}, {"pred": "oneroute", "count": 1, "cond_log_prob": -26.99185562133789}, {"pred": "the", "count": 11, "cond_log_prob": -1.7893753051757812}]}, "5": {"context": {"text": "Greg Anderson, considered a", "log_prob": -34.19725036621094}, "original": {"pred": "key", "cond_log_prob": -4.065849304199219}, "human": [{"pred": "job", "cond_log_prob": -10.195098876953125, "count": 5}, {"pred": "good", "cond_log_prob": -4.7684326171875, "count": 2}, {"pred": "new", "cond_log_prob": -6.181884765625, "count": 2}, {"pred": "very", "cond_log_prob": -5.7088623046875, "count": 2}, {"pred": "amazing", "cond_log_prob": -12.886611938476562, "count": 1}, {"pred": "bad", "cond_log_prob": -7.503143310546875, "count": 1}, {"pred": "bully", "cond_log_prob": -10.190605163574219, "count": 1}, {"pred": "candidate", "cond_log_prob": -4.997108459472656, "count": 1}, {"pred": "career", "cond_log_prob": -5.451324462890625, "count": 1}, {"pred": "different", "cond_log_prob": -8.089324951171875, "count": 1}, {"pred": "dog", "cond_log_prob": -9.542327880859375, "count": 1}, {"pred": "fanatic", "cond_log_prob": -10.422637939453125, "count": 1}, {"pred": "genius", "cond_log_prob": -5.8916778564453125, "count": 1}, {"pred": "genuis", "cond_log_prob": -14.967193603515625, "count": 1}, {"pred": "god", "cond_log_prob": -6.7889404296875, "count": 1}, {"pred": "great", "cond_log_prob": -4.618400573730469, "count": 1}, {"pred": "large", "cond_log_prob": -8.406974792480469, "count": 1}, {"pred": "life", "cond_log_prob": -8.10052490234375, "count": 1}, {"pred": "lot", "cond_log_prob": -8.1319580078125, "count": 1}, {"pred": "menace", "cond_log_prob": -8.983322143554688, "count": 1}, {"pred": "pioneer", "cond_log_prob": -5.066162109375, "count": 1}, {"pred": "problem", "cond_log_prob": -9.522857666015625, "count": 1}, {"pred": "professional", "cond_log_prob": -7.149101257324219, "count": 1}, {"pred": "question", "cond_log_prob": -10.194747924804688, "count": 1}, {"pred": "result", "cond_log_prob": -10.925453186035156, "count": 1}, {"pred": "show", "cond_log_prob": -8.86529541015625, "count": 1}, {"pred": "top", "cond_log_prob": -2.7696380615234375, "count": 1}, {"pred": "wonderful", "cond_log_prob": -8.974273681640625, "count": 1}, {"pred": "world", "cond_log_prob": -5.679115295410156, "count": 1}, {"pred": "world-renowned", "cond_log_prob": -8.33209228515625, "count": 1}], "ancestral_samples": [{"pred": "bombshell", "count": 1, "cond_log_prob": -9.8603515625}, {"pred": "candidate", "count": 2, "cond_log_prob": -4.997108459472656}, {"pred": "contender", "count": 2, "cond_log_prob": -4.548835754394531}, {"pred": "favorite", "count": 1, "cond_log_prob": -4.1405181884765625}, {"pred": "future", "count": 1, "cond_log_prob": -4.239677429199219}, {"pred": "great", "count": 2, "cond_log_prob": -4.618400573730469}, {"pred": "possible", "count": 2, "cond_log_prob": -4.2426300048828125}, {"pred": "potential", "count": 8, "cond_log_prob": -3.386932373046875}, {"pred": "prodigy", "count": 1, "cond_log_prob": -7.555767059326172}, {"pred": "rising", "count": 2, "cond_log_prob": -3.5393829345703125}, {"pred": "top", "count": 17, "cond_log_prob": -2.7696380615234375}, {"pred": "toproute", "count": 1, "cond_log_prob": -29.571414947509766}]}, "6": {"context": {"text": "Greg Anderson, considered a key", "log_prob": -38.263099670410156}, "original": {"pred": "witness", "cond_log_prob": -5.713832855224609}, "human": [{"pred": "player", "cond_log_prob": -1.9750137329101562, "count": 6}, {"pred": "to", "cond_log_prob": -5.11505126953125, "count": 5}, {"pred": "component", "cond_log_prob": -4.652534484863281, "count": 4}, {"pred": "figure", "cond_log_prob": -1.5456008911132812, "count": 3}, {"pred": "aspect", "cond_log_prob": -7.608390808105469, "count": 2}, {"pred": "witness", "cond_log_prob": -5.713897705078125, "count": 2}, {"pred": "asset", "cond_log_prob": -6.402252197265625, "count": 1}, {"pred": "concept", "cond_log_prob": -9.927162170410156, "count": 1}, {"pred": "feature", "cond_log_prob": -8.188453674316406, "count": 1}, {"pred": "idea", "cond_log_prob": -9.904975891113281, "count": 1}, {"pred": "instrument", "cond_log_prob": -9.236671447753906, "count": 1}, {"pred": "legislator", "cond_log_prob": -9.559539794921875, "count": 1}, {"pred": "member", "cond_log_prob": -2.863037109375, "count": 1}, {"pred": "observation", "cond_log_prob": -12.923355102539062, "count": 1}, {"pred": "or", "cond_log_prob": -8.531211853027344, "count": 1}, {"pred": "part", "cond_log_prob": -3.2859954833984375, "count": 1}, {"pred": "person", "cond_log_prob": -6.348167419433594, "count": 1}, {"pred": "piece", "cond_log_prob": -3.487762451171875, "count": 1}, {"pred": "point", "cond_log_prob": -6.676506042480469, "count": 1}, {"pred": "study", "cond_log_prob": -8.914466857910156, "count": 1}, {"pred": "word", "cond_log_prob": -9.814041137695312, "count": 1}], "ancestral_samples": [{"pred": "candidate", "count": 1, "cond_log_prob": -4.949180603027344}, {"pred": "contender", "count": 1, "cond_log_prob": -4.833770751953125}, {"pred": "figure", "count": 9, "cond_log_prob": -1.5456008911132812}, {"pred": "figureroute", "count": 1, "cond_log_prob": -25.070343017578125}, {"pred": "member", "count": 2, "cond_log_prob": -2.863037109375}, {"pred": "part", "count": 1, "cond_log_prob": -3.2859954833984375}, {"pred": "player", "count": 25, "cond_log_prob": -1.9750137329101562}]}, "7": {"context": {"text": "Greg Anderson, considered a key witness", "log_prob": -43.976932525634766}, "original": {"pred": "by", "cond_log_prob": -4.809108734130859}, "human": [{"pred": "in", "cond_log_prob": -0.8332023620605469, "count": 23}, {"pred": "to", "cond_log_prob": -2.0020484924316406, "count": 5}, {"pred": "of", "cond_log_prob": -4.537639617919922, "count": 2}, {"pred": "for", "cond_log_prob": -2.0795860290527344, "count": 1}, {"pred": "had", "cond_log_prob": -11.22573471069336, "count": 1}, {"pred": "or", "cond_log_prob": -8.268260955810547, "count": 1}, {"pred": "testimony", "cond_log_prob": -9.178295135498047, "count": 1}, {"pred": "was", "cond_log_prob": -9.379329681396484, "count": 1}, {"pred": "when", "cond_log_prob": -6.126537322998047, "count": 1}, {"pred": "who", "cond_log_prob": -5.644237518310547, "count": 1}], "ancestral_samples": [{"pred": "Anderson", "count": 1, "cond_log_prob": -17.665355682373047}, {"pred": "for", "count": 2, "cond_log_prob": -2.0795860290527344}, {"pred": "forroute", "count": 1, "cond_log_prob": -23.182735443115234}, {"pred": "in", "count": 33, "cond_log_prob": -0.8332023620605469}, {"pred": "to", "count": 3, "cond_log_prob": -2.0020484924316406}]}, "8": {"context": {"text": "Greg Anderson, considered a key witness by", "log_prob": -48.786041259765625}, "original": {"pred": "the", "cond_log_prob": -1.0698165893554688}, "human": [{"pred": "the", "cond_log_prob": -1.0699081420898438, "count": 20}, {"pred": "many", "cond_log_prob": -3.2087631225585938, "count": 3}, {"pred": "asking", "cond_log_prob": -13.430793762207031, "count": 2}, {"pred": "being", "cond_log_prob": -9.988380432128906, "count": 1}, {"pred": "deciding", "cond_log_prob": -12.911956787109375, "count": 1}, {"pred": "federal", "cond_log_prob": -5.191650390625, "count": 1}, {"pred": "his", "cond_log_prob": -3.6434478759765625, "count": 1}, {"pred": "looking", "cond_log_prob": -13.189010620117188, "count": 1}, {"pred": "monitoring", "cond_log_prob": -12.363815307617188, "count": 1}, {"pred": "murder", "cond_log_prob": -11.570808410644531, "count": 1}, {"pred": "others", "cond_log_prob": -6.721961975097656, "count": 1}, {"pred": "police", "cond_log_prob": -4.951171875, "count": 1}, {"pred": "researching", "cond_log_prob": -14.90875244140625, "count": 1}, {"pred": "someone", "cond_log_prob": -9.845794677734375, "count": 1}, {"pred": "thinking", "cond_log_prob": -14.729522705078125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.9945907592773438}, {"pred": "investigators", "count": 1, "cond_log_prob": -5.895835876464844}, {"pred": "many", "count": 1, "cond_log_prob": -3.2087631225585938}, {"pred": "manyroute", "count": 1, "cond_log_prob": -27.739479064941406}, {"pred": "the", "count": 36, "cond_log_prob": -1.0699081420898438}]}, "9": {"context": {"text": "Greg Anderson, considered a key witness by the", "log_prob": -49.855857849121094}, "original": {"pred": "prosecution,", "cond_log_prob": -3.1963348388671875}, "human": [{"pred": "jury", "cond_log_prob": -3.7034454345703125, "count": 8}, {"pred": "police", "cond_log_prob": -5.152046203613281, "count": 5}, {"pred": "court", "cond_log_prob": -3.390960693359375, "count": 4}, {"pred": "way", "cond_log_prob": -9.912246704101562, "count": 4}, {"pred": "prosecution", "cond_log_prob": -2.6408233642578125, "count": 3}, {"pred": "prosecutor", "cond_log_prob": -5.553703308105469, "count": 2}, {"pred": "authorities", "cond_log_prob": -6.964591979980469, "count": 1}, {"pred": "car", "cond_log_prob": -10.619606018066406, "count": 1}, {"pred": "defense", "cond_log_prob": -3.4203414916992188, "count": 1}, {"pred": "fbi", "cond_log_prob": -17.114479064941406, "count": 1}, {"pred": "federal", "cond_log_prob": -4.044776916503906, "count": 1}, {"pred": "judge", "cond_log_prob": -4.127067565917969, "count": 1}, {"pred": "nation", "cond_log_prob": -6.261177062988281, "count": 1}, {"pred": "people", "cond_log_prob": -7.364921569824219, "count": 1}, {"pred": "state", "cond_log_prob": -4.3405609130859375, "count": 1}, {"pred": "supreme", "cond_log_prob": -7.6795806884765625, "count": 1}, {"pred": "testing", "cond_log_prob": -11.447647094726562, "count": 1}], "ancestral_samples": [{"pred": "FBI", "count": 3, "cond_log_prob": -3.518524169921875}, {"pred": "Justice", "count": 1, "cond_log_prob": -4.376365661621094}, {"pred": "Senate", "count": 3, "cond_log_prob": -3.5452194213867188}, {"pred": "Supreme", "count": 2, "cond_log_prob": -3.8866958618164062}, {"pred": "committee", "count": 2, "cond_log_prob": -4.824119567871094}, {"pred": "defense", "count": 5, "cond_log_prob": -3.4203414916992188}, {"pred": "district", "count": 1, "cond_log_prob": -5.061286926269531}, {"pred": "government", "count": 1, "cond_log_prob": -3.8392562866210938}, {"pred": "governmentroute", "count": 1, "cond_log_prob": -28.115028381347656}, {"pred": "investigators", "count": 1, "cond_log_prob": -7.157752990722656}, {"pred": "judge", "count": 1, "cond_log_prob": -4.127067565917969}, {"pred": "jury", "count": 1, "cond_log_prob": -3.7034454345703125}, {"pred": "plaintiffs", "count": 1, "cond_log_prob": -5.125007629394531}, {"pred": "proTrump", "count": 1, "cond_log_prob": -18.690467834472656}, {"pred": "prosecution", "count": 14, "cond_log_prob": -2.6408233642578125}, {"pred": "team", "count": 1, "cond_log_prob": -5.386505126953125}, {"pred": "trial", "count": 1, "cond_log_prob": -4.4766387939453125}]}, "10": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution,", "log_prob": -53.05219268798828}, "original": {"pred": "vowed", "cond_log_prob": -8.965476989746094}, "human": [{"pred": "was", "cond_log_prob": -2.4309921264648438, "count": 16}, {"pred": "had", "cond_log_prob": -3.9814224243164062, "count": 2}, {"pred": "is", "cond_log_prob": -3.4765625, "count": 2}, {"pred": "testified", "cond_log_prob": -1.8082351684570312, "count": 2}, {"pred": "as", "cond_log_prob": -7.829139709472656, "count": 1}, {"pred": "because", "cond_log_prob": -10.506019592285156, "count": 1}, {"pred": "decided", "cond_log_prob": -7.487281799316406, "count": 1}, {"pred": "did", "cond_log_prob": -5.274238586425781, "count": 1}, {"pred": "has", "cond_log_prob": -2.8935623168945312, "count": 1}, {"pred": "he", "cond_log_prob": -8.412712097167969, "count": 1}, {"pred": "refused", "cond_log_prob": -5.772972106933594, "count": 1}, {"pred": "said", "cond_log_prob": -2.283935546875, "count": 1}, {"pred": "sat", "cond_log_prob": -6.376411437988281, "count": 1}, {"pred": "skipped", "cond_log_prob": -10.37701416015625, "count": 1}, {"pred": "spoke", "cond_log_prob": -5.1993865966796875, "count": 1}, {"pred": "stated", "cond_log_prob": -5.448432922363281, "count": 1}, {"pred": "suffered", "cond_log_prob": -8.142738342285156, "count": 1}, {"pred": "then", "cond_log_prob": -7.77813720703125, "count": 1}, {"pred": "will", "cond_log_prob": -4.808280944824219, "count": 1}], "ancestral_samples": [{"pred": "is", "count": 1, "cond_log_prob": -3.476543426513672}, {"pred": "participated", "count": 1, "cond_log_prob": -8.707233428955078}, {"pred": "said", "count": 15, "cond_log_prob": -2.2839393615722656}, {"pred": "testified", "count": 10, "cond_log_prob": -1.8082237243652344}, {"pred": "told", "count": 5, "cond_log_prob": -2.3177146911621094}, {"pred": "toldroutecom", "count": 1, "cond_log_prob": -36.293113708496094}, {"pred": "was", "count": 7, "cond_log_prob": -2.430988311767578}]}, "11": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed", "log_prob": -62.017669677734375}, "original": {"pred": "he", "cond_log_prob": -3.5058746337890625}, "human": [{"pred": "to", "cond_log_prob": -0.5054855346679688, "count": 23}, {"pred": "that", "cond_log_prob": -2.1933746337890625, "count": 7}, {"pred": "he", "cond_log_prob": -3.5059280395507812, "count": 3}, {"pred": "never", "cond_log_prob": -4.883750915527344, "count": 3}, {"pred": "himself", "cond_log_prob": -8.294174194335938, "count": 1}], "ancestral_samples": [{"pred": "not", "count": 1, "cond_log_prob": -3.347930908203125}, {"pred": "to", "count": 38, "cond_log_prob": -0.5054855346679688}, {"pred": "toroute", "count": 1, "cond_log_prob": -29.827110290527344}]}, "12": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he", "log_prob": -65.52354431152344}, "original": {"pred": "wouldn't", "cond_log_prob": -3.248321533203125}, "human": [{"pred": "would", "cond_log_prob": -0.4683837890625, "count": 26}, {"pred": "never", "cond_log_prob": -5.255577087402344, "count": 3}, {"pred": "saw", "cond_log_prob": -8.137733459472656, "count": 3}, {"pred": "did", "cond_log_prob": -4.8774261474609375, "count": 2}, {"pred": "had", "cond_log_prob": -4.0206146240234375, "count": 1}, {"pred": "to", "cond_log_prob": -9.494598388671875, "count": 1}, {"pred": "was", "cond_log_prob": -2.72686767578125, "count": 1}], "ancestral_samples": [{"pred": "was", "count": 1, "cond_log_prob": -2.7268829345703125}, {"pred": "will", "count": 1, "cond_log_prob": -2.431182861328125}, {"pred": "would", "count": 37, "cond_log_prob": -0.46839141845703125}, {"pred": "wouldroute", "count": 1, "cond_log_prob": -22.66889190673828}]}, "13": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't", "log_prob": -68.77186584472656}, "original": {"pred": "testify", "cond_log_prob": -2.3715286254882812}, "human": [{"pred": "lie", "cond_log_prob": -5.492164611816406, "count": 15}, {"pred": "tell", "cond_log_prob": -4.733314514160156, "count": 6}, {"pred": "say", "cond_log_prob": -5.000526428222656, "count": 3}, {"pred": "testify", "cond_log_prob": -2.3716201782226562, "count": 3}, {"pred": "do", "cond_log_prob": -5.032722473144531, "count": 2}, {"pred": "allow", "cond_log_prob": -3.8180923461914062, "count": 1}, {"pred": "be", "cond_log_prob": -2.0142593383789062, "count": 1}, {"pred": "bear", "cond_log_prob": -8.480232238769531, "count": 1}, {"pred": "betray", "cond_log_prob": -7.734245300292969, "count": 1}, {"pred": "give", "cond_log_prob": -3.9825668334960938, "count": 1}, {"pred": "perjure", "cond_log_prob": -11.8101806640625, "count": 1}, {"pred": "speak", "cond_log_prob": -3.9057693481445312, "count": 1}, {"pred": "stray", "cond_log_prob": -10.243476867675781, "count": 1}], "ancestral_samples": [{"pred": "be", "count": 18, "cond_log_prob": -2.0142593383789062}, {"pred": "go", "count": 1, "cond_log_prob": -4.034141540527344}, {"pred": "speak", "count": 1, "cond_log_prob": -3.9057693481445312}, {"pred": "standroute", "count": 1, "cond_log_prob": -31.822959899902344}, {"pred": "testify", "count": 18, "cond_log_prob": -2.3716201782226562}, {"pred": "testifyAnderson", "count": 1, "cond_log_prob": -24.246902465820312}]}, "14": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify", "log_prob": -71.14339447021484}, "original": {"pred": "when", "cond_log_prob": -5.3740234375}, "human": [{"pred": "against", "cond_log_prob": -1.1344985961914062, "count": 24}, {"pred": "unless", "cond_log_prob": -5.395118713378906, "count": 4}, {"pred": "in", "cond_log_prob": -2.0793075561523438, "count": 2}, {"pred": "about", "cond_log_prob": -3.7015533447265625, "count": 1}, {"pred": "at", "cond_log_prob": -3.122772216796875, "count": 1}, {"pred": "because", "cond_log_prob": -4.133903503417969, "count": 1}, {"pred": "falsely", "cond_log_prob": -8.540977478027344, "count": 1}, {"pred": "for", "cond_log_prob": -4.240074157714844, "count": 1}, {"pred": "to", "cond_log_prob": -3.7458953857421875, "count": 1}, {"pred": "without", "cond_log_prob": -6.205146789550781, "count": 1}], "ancestral_samples": [{"pred": "He", "count": 1, "cond_log_prob": -12.496757507324219}, {"pred": "I", "count": 4, "cond_log_prob": -10.030860900878906}, {"pred": "It", "count": 1, "cond_log_prob": -14.461906433105469}, {"pred": "against", "count": 24, "cond_log_prob": -1.1344985961914062}, {"pred": "againstroute", "count": 1, "cond_log_prob": -23.88091278076172}, {"pred": "because", "count": 1, "cond_log_prob": -4.133903503417969}, {"pred": "in", "count": 8, "cond_log_prob": -2.0793075561523438}]}, "15": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when", "log_prob": -76.51741790771484}, "original": {"pred": "served", "cond_log_prob": -8.55322265625}, "human": [{"pred": "he", "cond_log_prob": -1.553802490234375, "count": 15}, {"pred": "the", "cond_log_prob": -1.7281570434570312, "count": 8}, {"pred": "asked", "cond_log_prob": -2.21533203125, "count": 5}, {"pred": "called", "cond_log_prob": -6.154075622558594, "count": 3}, {"pred": "his", "cond_log_prob": -3.4007492065429688, "count": 1}, {"pred": "in", "cond_log_prob": -7.0618896484375, "count": 1}, {"pred": "it", "cond_log_prob": -3.6910476684570312, "count": 1}, {"pred": "people", "cond_log_prob": -7.609214782714844, "count": 1}, {"pred": "there", "cond_log_prob": -6.047508239746094, "count": 1}, {"pred": "threatened", "cond_log_prob": -9.006385803222656, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.769927978515625}, {"pred": "asked", "count": 7, "cond_log_prob": -2.21533203125}, {"pred": "he", "count": 21, "cond_log_prob": -1.553802490234375}, {"pred": "heroute", "count": 1, "cond_log_prob": -28.41576385498047}, {"pred": "she", "count": 1, "cond_log_prob": -4.873939514160156}, {"pred": "the", "count": 9, "cond_log_prob": -1.7281570434570312}]}, "16": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served", "log_prob": -85.07064056396484}, "original": {"pred": "a", "cond_log_prob": -2.8914871215820312}, "human": [{"pred": "a", "cond_log_prob": -2.8915939331054688, "count": 13}, {"pred": "with", "cond_log_prob": -0.31484222412109375, "count": 8}, {"pred": "as", "cond_log_prob": -6.9355316162109375, "count": 3}, {"pred": "by", "cond_log_prob": -4.030448913574219, "count": 2}, {"pred": "his", "cond_log_prob": -4.8164825439453125, "count": 2}, {"pred": "in", "cond_log_prob": -5.32928466796875, "count": 2}, {"pred": "papers", "cond_log_prob": -7.8156890869140625, "count": 2}, {"pred": "cold", "cond_log_prob": -10.688400268554688, "count": 1}, {"pred": "on", "cond_log_prob": -3.9110946655273438, "count": 1}, {"pred": "potatoes", "cond_log_prob": -15.766921997070312, "count": 1}, {"pred": "shrimp", "cond_log_prob": -14.756790161132812, "count": 1}, {"pred": "the", "cond_log_prob": -4.053230285644531, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -11.240158081054688}, {"pred": "a", "count": 1, "cond_log_prob": -2.8915939331054688}, {"pred": "with", "count": 37, "cond_log_prob": -0.31484222412109375}, {"pred": "withroute", "count": 1, "cond_log_prob": -22.875381469726562}]}, "17": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a", "log_prob": -87.96212768554688}, "original": {"pred": "subpoena", "cond_log_prob": -1.043670654296875}, "human": [{"pred": "sentence", "cond_log_prob": -5.007682800292969, "count": 6}, {"pred": "subpoena", "cond_log_prob": -1.0437774658203125, "count": 4}, {"pred": "notice", "cond_log_prob": -3.2541580200195312, "count": 3}, {"pred": "paper", "cond_log_prob": -7.922065734863281, "count": 3}, {"pred": "court", "cond_log_prob": -5.195365905761719, "count": 2}, {"pred": "summons", "cond_log_prob": -2.1746444702148438, "count": 2}, {"pred": "affidavit", "cond_log_prob": -10.141868591308594, "count": 1}, {"pred": "brief", "cond_log_prob": -7.371696472167969, "count": 1}, {"pred": "call", "cond_log_prob": -6.718116760253906, "count": 1}, {"pred": "considerable", "cond_log_prob": -12.847297668457031, "count": 1}, {"pred": "dinner", "cond_log_prob": -11.140434265136719, "count": 1}, {"pred": "drink", "cond_log_prob": -8.419319152832031, "count": 1}, {"pred": "FALSE", "cond_log_prob": -14.871208190917969, "count": 1}, {"pred": "jury", "cond_log_prob": -7.425056457519531, "count": 1}, {"pred": "large", "cond_log_prob": -8.708152770996094, "count": 1}, {"pred": "life", "cond_log_prob": -6.160804748535156, "count": 1}, {"pred": "meal", "cond_log_prob": -10.356101989746094, "count": 1}, {"pred": "pointed", "cond_log_prob": -11.280662536621094, "count": 1}, {"pred": "portion", "cond_log_prob": -8.055488586425781, "count": 1}, {"pred": "question", "cond_log_prob": -6.813713073730469, "count": 1}, {"pred": "shrimp", "cond_log_prob": -16.420433044433594, "count": 1}, {"pred": "time", "cond_log_prob": -8.468955993652344, "count": 1}, {"pred": "very", "cond_log_prob": -9.968147277832031, "count": 1}], "ancestral_samples": [{"pred": "subpoena", "count": 30, "cond_log_prob": -1.0437774658203125}, {"pred": "subpoenaAnderson", "count": 4, "cond_log_prob": -21.472923278808594}, {"pred": "subpoenaAs", "count": 1, "cond_log_prob": -20.980796813964844}, {"pred": "subpoenaThe", "count": 2, "cond_log_prob": -17.475013732910156}, {"pred": "subpoenaroute", "count": 1, "cond_log_prob": -31.811676025390625}, {"pred": "summons", "count": 2, "cond_log_prob": -2.1746444702148438}]}, "18": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena", "log_prob": -89.00579833984375}, "original": {"pred": "last", "cond_log_prob": -4.444580078125}, "human": [{"pred": "to", "cond_log_prob": -1.6035690307617188, "count": 5}, {"pred": "by", "cond_log_prob": -3.6500473022460938, "count": 4}, {"pred": "from", "cond_log_prob": -3.0343399047851562, "count": 3}, {"pred": "----------------------------------------------------", "cond_log_prob": -25.177101135253906, "count": 2}, {"pred": "at", "cond_log_prob": -5.788139343261719, "count": 2}, {"pred": "for", "cond_log_prob": -2.3246841430664062, "count": 2}, {"pred": "in", "cond_log_prob": -3.3846511840820312, "count": 2}, {"pred": "sentence", "cond_log_prob": -12.140647888183594, "count": 2}, {"pred": "that", "cond_log_prob": -3.8106613159179688, "count": 2}, {"pred": "about", "cond_log_prob": -5.916481018066406, "count": 1}, {"pred": "against", "cond_log_prob": -4.442878723144531, "count": 1}, {"pred": "amount", "cond_log_prob": -10.704627990722656, "count": 1}, {"pred": "and", "cond_log_prob": -3.7425155639648438, "count": 1}, {"pred": "because", "cond_log_prob": -5.060691833496094, "count": 1}, {"pred": "days", "cond_log_prob": -10.645942687988281, "count": 1}, {"pred": "last", "cond_log_prob": -4.444709777832031, "count": 1}, {"pred": "of", "cond_log_prob": -4.752159118652344, "count": 1}, {"pred": "question", "cond_log_prob": -11.310844421386719, "count": 1}, {"pred": "under", "cond_log_prob": -5.120887756347656, "count": 1}, {"pred": "unless", "cond_log_prob": -7.705833435058594, "count": 1}, {"pred": "what", "cond_log_prob": -11.807701110839844, "count": 1}, {"pred": "which", "cond_log_prob": -6.806785583496094, "count": 1}], "ancestral_samples": [{"pred": "Anderson", "count": 5, "cond_log_prob": -12.467735290527344}, {"pred": "Andersons", "count": 3, "cond_log_prob": -22.859237670898438}, {"pred": "Bart", "count": 1, "cond_log_prob": -16.82038116455078}, {"pred": "He", "count": 1, "cond_log_prob": -11.180732727050781}, {"pred": "I", "count": 7, "cond_log_prob": -8.809516906738281}, {"pred": "It", "count": 1, "cond_log_prob": -12.906761169433594}, {"pred": "The", "count": 1, "cond_log_prob": -10.448799133300781}, {"pred": "for", "count": 4, "cond_log_prob": -2.3246841430664062}, {"pred": "forroute", "count": 1, "cond_log_prob": -26.081756591796875}, {"pred": "on", "count": 1, "cond_log_prob": -2.9981155395507812}, {"pred": "to", "count": 15, "cond_log_prob": -1.6035690307617188}]}, "19": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last", "log_prob": -93.45037841796875}, "original": {"pred": "week.", "cond_log_prob": -2.2696075439453125}, "human": [{"pred": "week", "cond_log_prob": -1.2394332885742188, "count": 12}, {"pred": "night", "cond_log_prob": -4.934577941894531, "count": 9}, {"pred": "year", "cond_log_prob": -1.513885498046875, "count": 4}, {"pred": "month", "cond_log_prob": -1.4542617797851562, "count": 3}, {"pred": "time", "cond_log_prob": -7.878959655761719, "count": 2}, {"pred": "wednesday", "cond_log_prob": -13.382102966308594, "count": 2}, {"pred": "day", "cond_log_prob": -8.275993347167969, "count": 1}, {"pred": "fall", "cond_log_prob": -3.5947341918945312, "count": 1}, {"pred": "question", "cond_log_prob": -10.707672119140625, "count": 1}, {"pred": "semester", "cond_log_prob": -8.942665100097656, "count": 1}, {"pred": "word", "cond_log_prob": -11.883338928222656, "count": 1}], "ancestral_samples": [{"pred": "month", "count": 10, "cond_log_prob": -1.4542617797851562}, {"pred": "monthAnderson", "count": 1, "cond_log_prob": -24.408416748046875}, {"pred": "week", "count": 9, "cond_log_prob": -1.2394332885742188}, {"pred": "weekAnderson", "count": 6, "cond_log_prob": -23.67809295654297}, {"pred": "weekThe", "count": 1, "cond_log_prob": -17.348121643066406}, {"pred": "year", "count": 7, "cond_log_prob": -1.513885498046875}, {"pred": "yearAnderson", "count": 3, "cond_log_prob": -24.425384521484375}, {"pred": "yearIn", "count": 1, "cond_log_prob": -19.820755004882812}, {"pred": "yearThe", "count": 1, "cond_log_prob": -17.941314697265625}, {"pred": "yearroute", "count": 1, "cond_log_prob": -29.680755615234375}]}, "20": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week.", "log_prob": -95.71998596191406}, "original": {"pred": "His", "cond_log_prob": -4.9444580078125}, "human": [{"pred": "he", "cond_log_prob": -9.881317138671875, "count": 22}, {"pred": "the", "cond_log_prob": -9.771499633789062, "count": 4}, {"pred": "anderson", "cond_log_prob": -18.645851135253906, "count": 2}, {"pred": "however", "cond_log_prob": -13.894485473632812, "count": 3}, {"pred": "after", "cond_log_prob": -12.243865966796875, "count": 1}, {"pred": "batman", "cond_log_prob": -26.22704315185547, "count": 1}, {"pred": "greg", "cond_log_prob": -16.554275512695312, "count": 1}, {"pred": "it", "cond_log_prob": -13.037727355957031, "count": 1}, {"pred": "so", "cond_log_prob": -12.426177978515625, "count": 1}, {"pred": "this", "cond_log_prob": -13.175514221191406, "count": 1}], "ancestral_samples": [{"pred": "Anderson", "count": 6, "cond_log_prob": -2.219482421875}, {"pred": "Andersons", "count": 2, "cond_log_prob": -14.705909729003906}, {"pred": "He", "count": 2, "cond_log_prob": -2.540313720703125}, {"pred": "I", "count": 11, "cond_log_prob": -7.9795379638671875}, {"pred": "If", "count": 1, "cond_log_prob": -6.181114196777344}, {"pred": "Ill", "count": 1, "cond_log_prob": -13.90350341796875}, {"pred": "Im", "count": 9, "cond_log_prob": -11.389755249023438}, {"pred": "In", "count": 1, "cond_log_prob": -4.423004150390625}, {"pred": "The", "count": 4, "cond_log_prob": -3.313629150390625}, {"pred": "There", "count": 1, "cond_log_prob": -7.2418060302734375}, {"pred": "We", "count": 1, "cond_log_prob": -7.627067565917969}, {"pred": "route", "count": 1, "cond_log_prob": -21.157310485839844}]}, "21": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His", "log_prob": -100.66444396972656}, "original": {"pred": "lawyers", "cond_log_prob": -2.9946517944335938}, "human": [{"pred": "testimony", "cond_log_prob": -3.196533203125, "count": 4}, {"pred": "lawyer", "cond_log_prob": -1.8092193603515625, "count": 4}, {"pred": "mother", "cond_log_prob": -5.9908599853515625, "count": 2}, {"pred": "reasons", "cond_log_prob": -8.004791259765625, "count": 2}, {"pred": "refusal", "cond_log_prob": -5.5204620361328125, "count": 2}, {"pred": "statement", "cond_log_prob": -4.5519256591796875, "count": 2}, {"pred": "attorney", "cond_log_prob": -2.126617431640625, "count": 1}, {"pred": "brother", "cond_log_prob": -5.2170867919921875, "count": 1}, {"pred": "comments", "cond_log_prob": -6.3391265869140625, "count": 1}, {"pred": "council", "cond_log_prob": -11.048004150390625, "count": 1}, {"pred": "decision", "cond_log_prob": -5.37054443359375, "count": 1}, {"pred": "defense", "cond_log_prob": -3.6927032470703125, "count": 1}, {"pred": "exact", "cond_log_prob": -8.733383178710938, "count": 1}, {"pred": "first", "cond_log_prob": -5.378692626953125, "count": 1}, {"pred": "last", "cond_log_prob": -6.03533935546875, "count": 1}, {"pred": "life", "cond_log_prob": -7.6395263671875, "count": 1}, {"pred": "neighbor", "cond_log_prob": -8.920364379882812, "count": 1}, {"pred": "only", "cond_log_prob": -5.3766632080078125, "count": 1}, {"pred": "own", "cond_log_prob": -6.0413970947265625, "count": 1}, {"pred": "people", "cond_log_prob": -9.232925415039062, "count": 1}, {"pred": "plea", "cond_log_prob": -4.6619110107421875, "count": 1}, {"pred": "reason", "cond_log_prob": -8.276641845703125, "count": 1}, {"pred": "reasoning", "cond_log_prob": -8.104476928710938, "count": 1}, {"pred": "representation", "cond_log_prob": -8.179122924804688, "count": 1}, {"pred": "very", "cond_log_prob": -9.542770385742188, "count": 1}, {"pred": "vow", "cond_log_prob": -9.108596801757812, "count": 1}, {"pred": "wife", "cond_log_prob": -4.1053619384765625, "count": 1}], "ancestral_samples": [{"pred": "attorney", "count": 13, "cond_log_prob": -2.126617431640625}, {"pred": "attorneys", "count": 1, "cond_log_prob": -3.4484405517578125}, {"pred": "defenseroute", "count": 1, "cond_log_prob": -34.24920654296875}, {"pred": "lawyer", "count": 21, "cond_log_prob": -1.8092193603515625}, {"pred": "lawyers", "count": 2, "cond_log_prob": -2.9947967529296875}, {"pred": "request", "count": 1, "cond_log_prob": -4.286407470703125}, {"pred": "trial", "count": 1, "cond_log_prob": -5.9766693115234375}]}, "22": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers", "log_prob": -103.65909576416016}, "original": {"pred": "said", "cond_log_prob": -2.12786865234375}, "human": [{"pred": "said", "cond_log_prob": -2.1280288696289062, "count": 6}, {"pred": "were", "cond_log_prob": -4.084327697753906, "count": 5}, {"pred": "told", "cond_log_prob": -3.9864730834960938, "count": 4}, {"pred": "have", "cond_log_prob": -2.3556900024414062, "count": 3}, {"pred": "advised", "cond_log_prob": -7.586601257324219, "count": 1}, {"pred": "and", "cond_log_prob": -4.771827697753906, "count": 1}, {"pred": "are", "cond_log_prob": -3.3625259399414062, "count": 1}, {"pred": "argued", "cond_log_prob": -2.5443801879882812, "count": 1}, {"pred": "claimed", "cond_log_prob": -5.414100646972656, "count": 1}, {"pred": "decided", "cond_log_prob": -7.086921691894531, "count": 1}, {"pred": "encouraged", "cond_log_prob": -8.872108459472656, "count": 1}, {"pred": "persuaded", "cond_log_prob": -8.944953918457031, "count": 1}, {"pred": "prompted", "cond_log_prob": -11.406257629394531, "count": 1}, {"pred": "recommended", "cond_log_prob": -8.158576965332031, "count": 1}, {"pred": "refused", "cond_log_prob": -6.168083190917969, "count": 1}, {"pred": "say", "cond_log_prob": -2.9178237915039062, "count": 1}, {"pred": "stated", "cond_log_prob": -7.761329650878906, "count": 1}, {"pred": "suggested", "cond_log_prob": -5.568809509277344, "count": 1}, {"pred": "then", "cond_log_prob": -6.155601501464844, "count": 1}, {"pred": "thought", "cond_log_prob": -7.581901550292969, "count": 1}, {"pred": "tried", "cond_log_prob": -5.567878723144531, "count": 1}, {"pred": "urged", "cond_log_prob": -5.905403137207031, "count": 1}, {"pred": "would", "cond_log_prob": -4.767112731933594, "count": 1}], "ancestral_samples": [{"pred": "also", "count": 1, "cond_log_prob": -3.7502517700195312}, {"pred": "are", "count": 2, "cond_log_prob": -3.3625259399414062}, {"pred": "argued", "count": 5, "cond_log_prob": -2.5443801879882812}, {"pred": "asked", "count": 1, "cond_log_prob": -3.8687210083007812}, {"pred": "contend", "count": 1, "cond_log_prob": -4.676429748535156}, {"pred": "did", "count": 1, "cond_log_prob": -4.470817565917969}, {"pred": "had", "count": 3, "cond_log_prob": -3.1964492797851562}, {"pred": "have", "count": 10, "cond_log_prob": -2.3556900024414062}, {"pred": "haverouteed", "count": 1, "cond_log_prob": -46.62438201904297}, {"pred": "meanwhile", "count": 1, "cond_log_prob": -9.182319641113281}, {"pred": "said", "count": 10, "cond_log_prob": -2.1280288696289062}, {"pred": "say", "count": 2, "cond_log_prob": -2.9178237915039062}, {"pred": "told", "count": 1, "cond_log_prob": -3.9864730834960938}, {"pred": "who", "count": 1, "cond_log_prob": -8.366035461425781}]}, "23": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said", "log_prob": -105.7869644165039}, "original": {"pred": "he", "cond_log_prob": -1.266204833984375}, "human": [{"pred": "that", "cond_log_prob": -2.6962356567382812, "count": 23}, {"pred": "he", "cond_log_prob": -1.2663650512695312, "count": 10}, {"pred": "anderson", "cond_log_prob": -19.04607391357422, "count": 1}, {"pred": "it", "cond_log_prob": -3.2464675903320312, "count": 1}, {"pred": "mr.", "cond_log_prob": -18.43895721435547, "count": 1}, {"pred": "they", "cond_log_prob": -1.6160354614257812, "count": 1}], "ancestral_samples": [{"pred": "Anderson", "count": 1, "cond_log_prob": -2.5821609497070312}, {"pred": "he", "count": 26, "cond_log_prob": -1.2663650512695312}, {"pred": "heroute", "count": 1, "cond_log_prob": -26.01622772216797}, {"pred": "the", "count": 2, "cond_log_prob": -2.1329421997070312}, {"pred": "they", "count": 9, "cond_log_prob": -1.6160354614257812}, {"pred": "theyre", "count": 1, "cond_log_prob": -15.921974182128906}]}, "24": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he", "log_prob": -107.05316925048828}, "original": {"pred": "was", "cond_log_prob": -2.1277618408203125}, "human": [{"pred": "would", "cond_log_prob": -2.0506210327148438, "count": 14}, {"pred": "was", "cond_log_prob": -2.1279373168945312, "count": 8}, {"pred": "did", "cond_log_prob": -3.8922653198242188, "count": 2}, {"pred": "had", "cond_log_prob": -2.5971450805664062, "count": 2}, {"pred": "needed", "cond_log_prob": -4.735679626464844, "count": 2}, {"pred": "will", "cond_log_prob": -3.3536605834960938, "count": 2}, {"pred": "could", "cond_log_prob": -2.8597488403320312, "count": 1}, {"pred": "does", "cond_log_prob": -6.367332458496094, "count": 1}, {"pred": "felt", "cond_log_prob": -6.892387390136719, "count": 1}, {"pred": "is", "cond_log_prob": -4.025856018066406, "count": 1}, {"pred": "made", "cond_log_prob": -6.008476257324219, "count": 1}, {"pred": "must", "cond_log_prob": -4.174858093261719, "count": 1}, {"pred": "should", "cond_log_prob": -3.1793899536132812, "count": 1}], "ancestral_samples": [{"pred": "already", "count": 1, "cond_log_prob": -5.417167663574219}, {"pred": "could", "count": 1, "cond_log_prob": -2.8597488403320312}, {"pred": "couldroute", "count": 1, "cond_log_prob": -24.47063446044922}, {"pred": "had", "count": 6, "cond_log_prob": -2.5971450805664062}, {"pred": "is", "count": 1, "cond_log_prob": -4.025856018066406}, {"pred": "s", "count": 2, "cond_log_prob": -11.129753112792969}, {"pred": "was", "count": 12, "cond_log_prob": -2.1279373168945312}, {"pred": "wasnt", "count": 1, "cond_log_prob": -13.914878845214844}, {"pred": "will", "count": 1, "cond_log_prob": -3.3536605834960938}, {"pred": "would", "count": 14, "cond_log_prob": -2.0506210327148438}]}, "25": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was", "log_prob": -109.1809310913086}, "original": {"pred": "prepared", "cond_log_prob": -4.6053466796875}, "human": [{"pred": "not", "cond_log_prob": -2.8701553344726562, "count": 9}, {"pred": "a", "cond_log_prob": -3.9952774047851562, "count": 4}, {"pred": "going", "cond_log_prob": -4.556037902832031, "count": 4}, {"pred": "in", "cond_log_prob": -4.526344299316406, "count": 2}, {"pred": "unable", "cond_log_prob": -4.691352844238281, "count": 2}, {"pred": "acting", "cond_log_prob": -5.023704528808594, "count": 1}, {"pred": "adamant", "cond_log_prob": -7.041282653808594, "count": 1}, {"pred": "already", "cond_log_prob": -4.677207946777344, "count": 1}, {"pred": "an", "cond_log_prob": -5.639411926269531, "count": 1}, {"pred": "angry", "cond_log_prob": -7.008018493652344, "count": 1}, {"pred": "at", "cond_log_prob": -6.316047668457031, "count": 1}, {"pred": "bound", "cond_log_prob": -5.686012268066406, "count": 1}, {"pred": "called", "cond_log_prob": -6.315650939941406, "count": 1}, {"pred": "crucial", "cond_log_prob": -10.847969055175781, "count": 1}, {"pred": "insane", "cond_log_prob": -10.712776184082031, "count": 1}, {"pred": "required", "cond_log_prob": -5.139396667480469, "count": 1}, {"pred": "scared", "cond_log_prob": -7.411598205566406, "count": 1}, {"pred": "threatened", "cond_log_prob": -5.926124572753906, "count": 1}, {"pred": "too", "cond_log_prob": -4.496131896972656, "count": 1}, {"pred": "unaware", "cond_log_prob": -5.116844177246094, "count": 1}, {"pred": "under", "cond_log_prob": -3.9823074340820312, "count": 1}], "ancestral_samples": [{"pred": "Andersons", "count": 1, "cond_log_prob": -22.65045928955078}, {"pred": "a", "count": 6, "cond_log_prob": -3.9952774047851562}, {"pred": "already", "count": 2, "cond_log_prob": -4.677207946777344}, {"pred": "being", "count": 1, "cond_log_prob": -4.013557434082031}, {"pred": "fired", "count": 1, "cond_log_prob": -5.361320495605469}, {"pred": "forced", "count": 1, "cond_log_prob": -4.099998474121094}, {"pred": "given", "count": 1, "cond_log_prob": -4.044197082519531}, {"pred": "givenroute", "count": 1, "cond_log_prob": -26.70764923095703}, {"pred": "merely", "count": 1, "cond_log_prob": -4.198493957519531}, {"pred": "not", "count": 14, "cond_log_prob": -2.8701553344726562}, {"pred": "resisting", "count": 1, "cond_log_prob": -6.650093078613281}, {"pred": "seeking", "count": 1, "cond_log_prob": -4.667503356933594}, {"pred": "subpoenaed", "count": 1, "cond_log_prob": -4.188423156738281}, {"pred": "threatened", "count": 1, "cond_log_prob": -5.926124572753906}, {"pred": "told", "count": 1, "cond_log_prob": -4.065437316894531}, {"pred": "too", "count": 1, "cond_log_prob": -4.496131896972656}, {"pred": "unable", "count": 1, "cond_log_prob": -4.691352844238281}, {"pred": "under", "count": 4, "cond_log_prob": -3.9823074340820312}]}, "26": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared", "log_prob": -113.7862777709961}, "original": {"pred": "for", "cond_log_prob": -4.2454681396484375}, "human": [{"pred": "to", "cond_log_prob": -0.04039764404296875, "count": 32}, {"pred": "for", "cond_log_prob": -4.245674133300781, "count": 3}, {"pred": "enough", "cond_log_prob": -7.728218078613281, "count": 1}, {"pred": "with", "cond_log_prob": -7.055091857910156, "count": 1}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.04039764404296875}, {"pred": "toroute", "count": 1, "cond_log_prob": -31.57953643798828}]}, "27": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for", "log_prob": -118.03174591064453}, "original": {"pred": "a", "cond_log_prob": -1.4802780151367188}, "human": [{"pred": "a", "cond_log_prob": -1.4804840087890625, "count": 6}, {"pred": "anything", "cond_log_prob": -5.017852783203125, "count": 6}, {"pred": "court", "cond_log_prob": -5.499610900878906, "count": 4}, {"pred": "jail", "cond_log_prob": -6.058296203613281, "count": 3}, {"pred": "the", "cond_log_prob": -1.5760269165039062, "count": 3}, {"pred": "any", "cond_log_prob": -3.8658981323242188, "count": 2}, {"pred": "questioning", "cond_log_prob": -4.7698822021484375, "count": 2}, {"pred": "what", "cond_log_prob": -3.5988845825195312, "count": 2}, {"pred": "battle", "cond_log_prob": -9.028419494628906, "count": 1}, {"pred": "his", "cond_log_prob": -3.09246826171875, "count": 1}, {"pred": "interrogation", "cond_log_prob": -6.694831848144531, "count": 1}, {"pred": "it", "cond_log_prob": -3.4738388061523438, "count": 1}, {"pred": "testifying", "cond_log_prob": -6.097236633300781, "count": 1}, {"pred": "this", "cond_log_prob": -4.4346160888671875, "count": 1}, {"pred": "trial", "cond_log_prob": -4.209190368652344, "count": 1}, {"pred": "vacation", "cond_log_prob": -13.012260437011719, "count": 1}, {"pred": "whatever", "cond_log_prob": -6.217597961425781, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 16, "cond_log_prob": -1.4804840087890625}, {"pred": "his", "count": 1, "cond_log_prob": -3.09246826171875}, {"pred": "such", "count": 1, "cond_log_prob": -3.1329421997070312}, {"pred": "thatAnderson", "count": 1, "cond_log_prob": -25.95787811279297}, {"pred": "thatroute", "count": 1, "cond_log_prob": -23.696678161621094}, {"pred": "the", "count": 19, "cond_log_prob": -1.5760269165039062}, {"pred": "trial", "count": 1, "cond_log_prob": -4.209190368652344}]}, "28": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a", "log_prob": -119.51202392578125}, "original": {"pred": "third", "cond_log_prob": -6.476875305175781}, "human": [{"pred": "long", "cond_log_prob": -3.9501571655273438, "count": 4}, {"pred": "fight", "cond_log_prob": -4.663993835449219, "count": 3}, {"pred": "trial", "cond_log_prob": -3.4778213500976562, "count": 3}, {"pred": "lawsuit", "cond_log_prob": -6.446510314941406, "count": 2}, {"pred": "subpoena", "cond_log_prob": -3.4219131469726562, "count": 2}, {"pred": "argument", "cond_log_prob": -11.834930419921875, "count": 1}, {"pred": "bad", "cond_log_prob": -6.968452453613281, "count": 1}, {"pred": "countersuit", "cond_log_prob": -10.1307373046875, "count": 1}, {"pred": "court", "cond_log_prob": -4.495811462402344, "count": 1}, {"pred": "different", "cond_log_prob": -5.592369079589844, "count": 1}, {"pred": "difficult", "cond_log_prob": -5.474891662597656, "count": 1}, {"pred": "good", "cond_log_prob": -6.851203918457031, "count": 1}, {"pred": "hard", "cond_log_prob": -5.725746154785156, "count": 1}, {"pred": "hearing", "cond_log_prob": -2.7489547729492188, "count": 1}, {"pred": "jail", "cond_log_prob": -5.958412170410156, "count": 1}, {"pred": "life", "cond_log_prob": -6.280265808105469, "count": 1}, {"pred": "litigation", "cond_log_prob": -11.143951416015625, "count": 1}, {"pred": "lot", "cond_log_prob": -5.821556091308594, "count": 1}, {"pred": "plethora", "cond_log_prob": -10.842681884765625, "count": 1}, {"pred": "prosecution", "cond_log_prob": -6.895942687988281, "count": 1}, {"pred": "resultant", "cond_log_prob": -14.30810546875, "count": 1}, {"pred": "storm", "cond_log_prob": -9.790313720703125, "count": 1}, {"pred": "testimony", "cond_log_prob": -7.687019348144531, "count": 1}, {"pred": "tough", "cond_log_prob": -5.193534851074219, "count": 1}, {"pred": "very", "cond_log_prob": -5.560081481933594, "count": 1}, {"pred": "war", "cond_log_prob": -8.116020202636719, "count": 1}, {"pred": "warrant", "cond_log_prob": -8.51739501953125, "count": 1}, {"pred": "whooping", "cond_log_prob": -12.791839599609375, "count": 1}], "ancestral_samples": [{"pred": "bombshell", "count": 1, "cond_log_prob": -8.791778564453125}, {"pred": "hearing", "count": 8, "cond_log_prob": -2.7489547729492188}, {"pred": "hearingAnderson", "count": 1, "cond_log_prob": -26.40008544921875}, {"pred": "lengthy", "count": 14, "cond_log_prob": -2.5983810424804688}, {"pred": "long", "count": 2, "cond_log_prob": -3.9501571655273438}, {"pred": "perjury", "count": 1, "cond_log_prob": -5.234580993652344}, {"pred": "proffer", "count": 1, "cond_log_prob": -8.053184509277344}, {"pred": "prolonged", "count": 1, "cond_log_prob": -5.191261291503906}, {"pred": "public", "count": 1, "cond_log_prob": -4.227272033691406}, {"pred": "second", "count": 1, "cond_log_prob": -4.237281799316406}, {"pred": "subpoena", "count": 4, "cond_log_prob": -3.4219131469726562}, {"pred": "trial", "count": 4, "cond_log_prob": -3.4778213500976562}, {"pred": "trialroute", "count": 1, "cond_log_prob": -25.086151123046875}]}, "29": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third", "log_prob": -125.98889923095703}, "original": {"pred": "prison", "cond_log_prob": -8.387580871582031}, "human": [{"pred": "trial", "cond_log_prob": -2.4807052612304688, "count": 12}, {"pred": "party", "cond_log_prob": -3.1890792846679688, "count": 4}, {"pred": "day", "cond_log_prob": -2.8767623901367188, "count": 3}, {"pred": "witness", "cond_log_prob": -3.7855453491210938, "count": 3}, {"pred": "round", "cond_log_prob": -3.6530990600585938, "count": 2}, {"pred": "subpoena", "cond_log_prob": -4.677238464355469, "count": 2}, {"pred": "time", "cond_log_prob": -3.3293991088867188, "count": 2}, {"pred": "appearance", "cond_log_prob": -4.508872985839844, "count": 1}, {"pred": "baby", "cond_log_prob": -12.239952087402344, "count": 1}, {"pred": "leg", "cond_log_prob": -9.789787292480469, "count": 1}, {"pred": "option", "cond_log_prob": -5.441215515136719, "count": 1}, {"pred": "payment", "cond_log_prob": -11.226371765136719, "count": 1}, {"pred": "prison", "cond_log_prob": -8.387809753417969, "count": 1}, {"pred": "serving", "cond_log_prob": -8.256919860839844, "count": 1}, {"pred": "strike", "cond_log_prob": -5.750022888183594, "count": 1}, {"pred": "testimony", "cond_log_prob": -5.770195007324219, "count": 1}], "ancestral_samples": [{"pred": "Andersons", "count": 1, "cond_log_prob": -22.409507751464844}, {"pred": "day", "count": 2, "cond_log_prob": -2.8767623901367188}, {"pred": "degree", "count": 20, "cond_log_prob": -5.917076110839844}, {"pred": "hearing", "count": 1, "cond_log_prob": -3.3246688842773438}, {"pred": "party", "count": 6, "cond_log_prob": -3.1890792846679688}, {"pred": "route", "count": 1, "cond_log_prob": -8.530204772949219}, {"pred": "trial", "count": 6, "cond_log_prob": -2.4807052612304688}, {"pred": "witness", "count": 3, "cond_log_prob": -3.7855453491210938}]}, "30": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison", "log_prob": -134.37648010253906}, "original": {"pred": "stay", "cond_log_prob": -5.946929931640625}, "human": [{"pred": "sentence", "cond_log_prob": -0.6679840087890625, "count": 29}, {"pred": "stay", "cond_log_prob": -5.9471588134765625, "count": 2}, {"pred": "attempt", "cond_log_prob": -8.015579223632812, "count": 1}, {"pred": "cell", "cond_log_prob": -6.7223663330078125, "count": 1}, {"pred": "guard", "cond_log_prob": -8.012985229492188, "count": 1}, {"pred": "term", "cond_log_prob": -1.4347686767578125, "count": 1}, {"pred": "where", "cond_log_prob": -9.236740112304688, "count": 1}, {"pred": "witness", "cond_log_prob": -10.899581909179688, "count": 1}], "ancestral_samples": [{"pred": "day", "count": 1, "cond_log_prob": -3.2695465087890625}, {"pred": "sentence", "count": 23, "cond_log_prob": -0.6679840087890625}, {"pred": "sentenceAnderson", "count": 5, "cond_log_prob": -20.592697143554688}, {"pred": "sentenceIn", "count": 1, "cond_log_prob": -17.648727416992188}, {"pred": "sentenceProsecutors", "count": 1, "cond_log_prob": -19.806686401367188}, {"pred": "sentenceThe", "count": 1, "cond_log_prob": -16.251510620117188}, {"pred": "sentenceroute", "count": 1, "cond_log_prob": -30.850601196289062}, {"pred": "term", "count": 3, "cond_log_prob": -1.4347686767578125}, {"pred": "termAnderson", "count": 2, "cond_log_prob": -23.516250610351562}, {"pred": "termIn", "count": 1, "cond_log_prob": -19.781326293945312}, {"pred": "trial", "count": 1, "cond_log_prob": -3.6103973388671875}]}, "31": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay", "log_prob": -140.3234100341797}, "original": {"pred": "to", "cond_log_prob": -3.747589111328125}, "human": [{"pred": "if", "cond_log_prob": -2.7752532958984375, "count": 13}, {"pred": "in", "cond_log_prob": -3.4122772216796875, "count": 4}, {"pred": "but", "cond_log_prob": -4.1189117431640625, "count": 3}, {"pred": "after", "cond_log_prob": -3.7289581298828125, "count": 2}, {"pred": "and", "cond_log_prob": -2.7902984619140625, "count": 2}, {"pred": "since", "cond_log_prob": -6.7865753173828125, "count": 2}, {"pred": "to", "cond_log_prob": -3.7478485107421875, "count": 2}, {"pred": "when", "cond_log_prob": -4.2573394775390625, "count": 2}, {"pred": "at", "cond_log_prob": -4.9695281982421875, "count": 1}, {"pred": "due", "cond_log_prob": -6.6779327392578125, "count": 1}, {"pred": "forever", "cond_log_prob": -12.195144653320312, "count": 1}, {"pred": "of", "cond_log_prob": -4.2201080322265625, "count": 1}, {"pred": "skid", "cond_log_prob": -21.602737426757812, "count": 1}, {"pred": "so", "cond_log_prob": -5.7450103759765625, "count": 1}, {"pred": "unless", "cond_log_prob": -5.2256317138671875, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -11.398117065429688}, {"pred": "Anderson", "count": 5, "cond_log_prob": -14.582595825195312}, {"pred": "Andersons", "count": 7, "cond_log_prob": -23.939498901367188}, {"pred": "As", "count": 1, "cond_log_prob": -12.759353637695312}, {"pred": "He", "count": 1, "cond_log_prob": -11.774887084960938}, {"pred": "I", "count": 1, "cond_log_prob": -9.811264038085938}, {"pred": "In", "count": 1, "cond_log_prob": -12.374099731445312}, {"pred": "The", "count": 4, "cond_log_prob": -10.701736450195312}, {"pred": "This", "count": 1, "cond_log_prob": -12.572250366210938}, {"pred": "We", "count": 1, "cond_log_prob": -14.417526245117188}, {"pred": "afterroute", "count": 1, "cond_log_prob": -26.382919311523438}, {"pred": "and", "count": 3, "cond_log_prob": -2.7902984619140625}, {"pred": "because", "count": 1, "cond_log_prob": -4.2797088623046875}, {"pred": "but", "count": 10, "cond_log_prob": -4.1189117431640625}, {"pred": "if", "count": 1, "cond_log_prob": -2.7752532958984375}, {"pred": "so", "count": 1, "cond_log_prob": -5.7450103759765625}]}, "32": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to", "log_prob": -144.0709991455078}, "original": {"pred": "maintain", "cond_log_prob": -6.4766387939453125}, "human": [{"pred": "keep", "cond_log_prob": -2.8144073486328125, "count": 3}, {"pred": "not", "cond_log_prob": -8.342819213867188, "count": 3}, {"pred": "protect", "cond_log_prob": -3.3233795166015625, "count": 3}, {"pred": "be", "cond_log_prob": -3.7857513427734375, "count": 2}, {"pred": "prove", "cond_log_prob": -5.6721954345703125, "count": 2}, {"pred": "allow", "cond_log_prob": -3.2297210693359375, "count": 1}, {"pred": "avoid", "cond_log_prob": -2.8655548095703125, "count": 1}, {"pred": "charge", "cond_log_prob": -8.353012084960938, "count": 1}, {"pred": "date", "cond_log_prob": -8.158554077148438, "count": 1}, {"pred": "embark", "cond_log_prob": -12.759170532226562, "count": 1}, {"pred": "ensure", "cond_log_prob": -3.3226776123046875, "count": 1}, {"pred": "facilitate", "cond_log_prob": -6.9588775634765625, "count": 1}, {"pred": "find", "cond_log_prob": -6.9777679443359375, "count": 1}, {"pred": "follow", "cond_log_prob": -6.1820526123046875, "count": 1}, {"pred": "force", "cond_log_prob": -3.6462249755859375, "count": 1}, {"pred": "have", "cond_log_prob": -6.1628875732421875, "count": 1}, {"pred": "interfere", "cond_log_prob": -7.8081817626953125, "count": 1}, {"pred": "jail", "cond_log_prob": -8.701309204101562, "count": 1}, {"pred": "life", "cond_log_prob": -12.326461791992188, "count": 1}, {"pred": "marks", "cond_log_prob": -16.419692993164062, "count": 1}, {"pred": "pay", "cond_log_prob": -7.6751251220703125, "count": 1}, {"pred": "prevent", "cond_log_prob": -2.5671234130859375, "count": 1}, {"pred": "provide", "cond_log_prob": -5.8615570068359375, "count": 1}, {"pred": "refrain", "cond_log_prob": -10.193649291992188, "count": 1}, {"pred": "remain", "cond_log_prob": -6.6073150634765625, "count": 1}, {"pred": "stay", "cond_log_prob": -4.9910736083984375, "count": 1}, {"pred": "substitute", "cond_log_prob": -11.995529174804688, "count": 1}, {"pred": "the", "cond_log_prob": -6.1562347412109375, "count": 1}, {"pred": "think", "cond_log_prob": -9.592391967773438, "count": 1}], "ancestral_samples": [{"pred": "allow", "count": 2, "cond_log_prob": -3.2297210693359375}, {"pred": "avoid", "count": 6, "cond_log_prob": -2.8655548095703125}, {"pred": "deal", "count": 1, "cond_log_prob": -5.1314544677734375}, {"pred": "ensure", "count": 1, "cond_log_prob": -3.3226776123046875}, {"pred": "force", "count": 2, "cond_log_prob": -3.6462249755859375}, {"pred": "keep", "count": 8, "cond_log_prob": -2.8144073486328125}, {"pred": "keeproute", "count": 1, "cond_log_prob": -25.018386840820312}, {"pred": "make", "count": 1, "cond_log_prob": -3.9355010986328125}, {"pred": "prevent", "count": 11, "cond_log_prob": -2.5671234130859375}, {"pred": "protect", "count": 3, "cond_log_prob": -3.3233795166015625}, {"pred": "put", "count": 2, "cond_log_prob": -4.7992706298828125}, {"pred": "stop", "count": 1, "cond_log_prob": -4.4492950439453125}, {"pred": "try", "count": 1, "cond_log_prob": -3.5977935791015625}]}, "33": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain", "log_prob": -150.54763793945312}, "original": {"pred": "his", "cond_log_prob": -0.691375732421875}, "human": [{"pred": "his", "cond_log_prob": -0.691680908203125, "count": 26}, {"pred": "a", "cond_log_prob": -3.168060302734375, "count": 4}, {"pred": "the", "cond_log_prob": -1.67291259765625, "count": 2}, {"pred": "can", "cond_log_prob": -12.98907470703125, "count": 1}, {"pred": "order", "cond_log_prob": -6.231414794921875, "count": 1}, {"pred": "peace", "cond_log_prob": -7.971832275390625, "count": 1}, {"pred": "their", "cond_log_prob": -4.4189453125, "count": 1}, {"pred": "unable", "cond_log_prob": -14.74041748046875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.168060302734375}, {"pred": "his", "count": 35, "cond_log_prob": -0.691680908203125}, {"pred": "hisroute", "count": 1, "cond_log_prob": -24.011749267578125}, {"pred": "the", "count": 3, "cond_log_prob": -1.67291259765625}]}, "34": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his", "log_prob": -151.239013671875}, "original": {"pred": "silence.", "cond_log_prob": -6.38372802734375}, "human": [{"pred": "innocence", "cond_log_prob": -1.063446044921875, "count": 5}, {"pred": "position", "cond_log_prob": -5.54449462890625, "count": 3}, {"pred": "reputation", "cond_log_prob": -4.2332763671875, "count": 3}, {"pred": "integrity", "cond_log_prob": -3.373046875, "count": 2}, {"pred": "record", "cond_log_prob": -7.837158203125, "count": 2}, {"pred": "right", "cond_log_prob": -4.837615966796875, "count": 2}, {"pred": "silence", "cond_log_prob": -5.691009521484375, "count": 2}, {"pred": "vow", "cond_log_prob": -10.1923828125, "count": 2}, {"pred": "conviction", "cond_log_prob": -6.318511962890625, "count": 1}, {"pred": "current", "cond_log_prob": -7.186309814453125, "count": 1}, {"pred": "health", "cond_log_prob": -5.519287109375, "count": 1}, {"pred": "honesty", "cond_log_prob": -9.07647705078125, "count": 1}, {"pred": "honor", "cond_log_prob": -7.98651123046875, "count": 1}, {"pred": "identity", "cond_log_prob": -6.1568603515625, "count": 1}, {"pred": "image", "cond_log_prob": -8.3291015625, "count": 1}, {"pred": "legal", "cond_log_prob": -4.493377685546875, "count": 1}, {"pred": "level", "cond_log_prob": -7.777740478515625, "count": 1}, {"pred": "official", "cond_log_prob": -9.06817626953125, "count": 1}, {"pred": "rights", "cond_log_prob": -4.386322021484375, "count": 1}, {"pred": "stance", "cond_log_prob": -9.308441162109375, "count": 1}, {"pred": "statement", "cond_log_prob": -8.62994384765625, "count": 1}, {"pred": "stature", "cond_log_prob": -9.30743408203125, "count": 1}, {"pred": "upper", "cond_log_prob": -10.24481201171875, "count": 1}, {"pred": "word", "cond_log_prob": -7.674591064453125, "count": 1}], "ancestral_samples": [{"pred": "anonymityAnderson", "count": 1, "cond_log_prob": -25.070831298828125}, {"pred": "credibility", "count": 1, "cond_log_prob": -2.7822265625}, {"pred": "innocence", "count": 13, "cond_log_prob": -1.063446044921875}, {"pred": "innocenceAnderson", "count": 13, "cond_log_prob": -22.22027587890625}, {"pred": "innocenceAs", "count": 1, "cond_log_prob": -17.835418701171875}, {"pred": "innocenceAt", "count": 1, "cond_log_prob": -18.0264892578125}, {"pred": "innocenceIn", "count": 3, "cond_log_prob": -16.964019775390625}, {"pred": "innocenceProsecutors", "count": 1, "cond_log_prob": -17.665496826171875}, {"pred": "innocenceThe", "count": 5, "cond_log_prob": -15.872100830078125}, {"pred": "innocenceroute", "count": 1, "cond_log_prob": -39.50433349609375}]}, "35": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence.", "log_prob": -157.62274169921875}, "original": {"pred": "Anderson", "cond_log_prob": -2.7642822265625}, "human": [{"pred": "greg", "cond_log_prob": -16.33984375, "count": 7}, {"pred": "he", "cond_log_prob": -10.915298461914062, "count": 11}, {"pred": "however", "cond_log_prob": -14.608901977539062, "count": 5}, {"pred": "the", "cond_log_prob": -10.165634155273438, "count": 4}, {"pred": "after", "cond_log_prob": -12.917129516601562, "count": 1}, {"pred": "anderson", "cond_log_prob": -18.916458129882812, "count": 1}, {"pred": "because", "cond_log_prob": -13.297332763671875, "count": 1}, {"pred": "even", "cond_log_prob": -15.193359375, "count": 1}, {"pred": "if", "cond_log_prob": -12.52471923828125, "count": 1}, {"pred": "now", "cond_log_prob": -13.30963134765625, "count": 1}, {"pred": "they", "cond_log_prob": -12.71734619140625, "count": 1}, {"pred": "this", "cond_log_prob": -13.713134765625, "count": 2}, {"pred": "when", "cond_log_prob": -13.010894775390625, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -5.172393798828125}, {"pred": "Anderson", "count": 9, "cond_log_prob": -2.76458740234375}, {"pred": "Andersons", "count": 8, "cond_log_prob": -14.18829345703125}, {"pred": "He", "count": 1, "cond_log_prob": -3.588714599609375}, {"pred": "Hes", "count": 2, "cond_log_prob": -14.290435791015625}, {"pred": "I", "count": 4, "cond_log_prob": -8.699234008789062}, {"pred": "Im", "count": 3, "cond_log_prob": -11.671295166015625}, {"pred": "In", "count": 1, "cond_log_prob": -4.925994873046875}, {"pred": "The", "count": 8, "cond_log_prob": -3.6961517333984375}, {"pred": "We", "count": 1, "cond_log_prob": -7.998260498046875}, {"pred": "Were", "count": 1, "cond_log_prob": -10.737548828125}, {"pred": "route", "count": 1, "cond_log_prob": -21.669174194335938}]}, "36": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson", "log_prob": -160.38702392578125}, "original": {"pred": "was", "cond_log_prob": -2.264190673828125}, "human": [{"pred": "was", "cond_log_prob": -2.264495849609375, "count": 9}, {"pred": "said", "cond_log_prob": -2.75885009765625, "count": 6}, {"pred": "also", "cond_log_prob": -3.760711669921875, "count": 2}, {"pred": "is", "cond_log_prob": -3.035491943359375, "count": 2}, {"pred": "stated", "cond_log_prob": -8.59747314453125, "count": 2}, {"pred": "will", "cond_log_prob": -4.282196044921875, "count": 2}, {"pred": "believes", "cond_log_prob": -6.96417236328125, "count": 1}, {"pred": "considered", "cond_log_prob": -9.70355224609375, "count": 1}, {"pred": "cooper", "cond_log_prob": -9.776092529296875, "count": 1}, {"pred": "decided", "cond_log_prob": -8.06280517578125, "count": 1}, {"pred": "even", "cond_log_prob": -7.947052001953125, "count": 1}, {"pred": "faces", "cond_log_prob": -5.652313232421875, "count": 1}, {"pred": "had", "cond_log_prob": -3.390045166015625, "count": 1}, {"pred": "has", "cond_log_prob": -2.8807373046875, "count": 1}, {"pred": "lives", "cond_log_prob": -7.965576171875, "count": 1}, {"pred": "made", "cond_log_prob": -5.747894287109375, "count": 1}, {"pred": "now", "cond_log_prob": -6.417144775390625, "count": 1}, {"pred": "thought", "cond_log_prob": -9.251861572265625, "count": 1}, {"pred": "vowed", "cond_log_prob": -7.597747802734375, "count": 1}, {"pred": "wanted", "cond_log_prob": -6.789947509765625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -9.750640869140625}, {"pred": "also", "count": 1, "cond_log_prob": -3.760711669921875}, {"pred": "did", "count": 1, "cond_log_prob": -4.4876708984375}, {"pred": "had", "count": 1, "cond_log_prob": -3.390045166015625}, {"pred": "is", "count": 2, "cond_log_prob": -3.035491943359375}, {"pred": "isroute", "count": 1, "cond_log_prob": -28.828948974609375}, {"pred": "participated", "count": 1, "cond_log_prob": -8.959136962890625}, {"pred": "s", "count": 11, "cond_log_prob": -10.145050048828125}, {"pred": "said", "count": 7, "cond_log_prob": -2.75885009765625}, {"pred": "told", "count": 1, "cond_log_prob": -3.6796875}, {"pred": "was", "count": 5, "cond_log_prob": -2.264495849609375}, {"pred": "who", "count": 8, "cond_log_prob": -8.3773193359375}]}, "37": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was", "log_prob": -162.65121459960938}, "original": {"pred": "released", "cond_log_prob": -3.025146484375}, "human": [{"pred": "a", "cond_log_prob": -3.743896484375, "count": 4}, {"pred": "not", "cond_log_prob": -3.513275146484375, "count": 4}, {"pred": "very", "cond_log_prob": -8.295684814453125, "count": 4}, {"pred": "charged", "cond_log_prob": -3.287933349609375, "count": 2}, {"pred": "ready", "cond_log_prob": -7.89312744140625, "count": 2}, {"pred": "able", "cond_log_prob": -6.315277099609375, "count": 1}, {"pred": "afraid", "cond_log_prob": -9.25299072265625, "count": 1}, {"pred": "aghast", "cond_log_prob": -15.363006591796875, "count": 1}, {"pred": "allowed", "cond_log_prob": -5.230377197265625, "count": 1}, {"pred": "angry", "cond_log_prob": -8.47406005859375, "count": 1}, {"pred": "aquitted", "cond_log_prob": -13.734222412109375, "count": 1}, {"pred": "arrested", "cond_log_prob": -3.15203857421875, "count": 1}, {"pred": "asked", "cond_log_prob": -4.83392333984375, "count": 1}, {"pred": "caught", "cond_log_prob": -6.42279052734375, "count": 1}, {"pred": "concerned", "cond_log_prob": -9.042816162109375, "count": 1}, {"pred": "convicted", "cond_log_prob": -3.54876708984375, "count": 1}, {"pred": "deeply", "cond_log_prob": -9.035400390625, "count": 1}, {"pred": "first", "cond_log_prob": -5.363525390625, "count": 1}, {"pred": "put", "cond_log_prob": -5.948638916015625, "count": 1}, {"pred": "sent", "cond_log_prob": -4.709197998046875, "count": 1}, {"pred": "sentenced", "cond_log_prob": -2.933929443359375, "count": 2}, {"pred": "silent", "cond_log_prob": -9.947113037109375, "count": 1}, {"pred": "stubborn", "cond_log_prob": -11.488983154296875, "count": 1}, {"pred": "told", "cond_log_prob": -5.05426025390625, "count": 1}, {"pred": "under", "cond_log_prob": -5.88958740234375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.743896484375}, {"pred": "already", "count": 1, "cond_log_prob": -5.03753662109375}, {"pred": "also", "count": 9, "cond_log_prob": -2.74920654296875}, {"pred": "arrested", "count": 4, "cond_log_prob": -3.15203857421875}, {"pred": "charged", "count": 5, "cond_log_prob": -3.287933349609375}, {"pred": "convicted", "count": 3, "cond_log_prob": -3.54876708984375}, {"pred": "convictedroute", "count": 1, "cond_log_prob": -30.0869140625}, {"pred": "freed", "count": 2, "cond_log_prob": -5.402740478515625}, {"pred": "initially", "count": 1, "cond_log_prob": -4.78729248046875}, {"pred": "not", "count": 1, "cond_log_prob": -3.513275146484375}, {"pred": "released", "count": 4, "cond_log_prob": -3.025482177734375}, {"pred": "scheduled", "count": 1, "cond_log_prob": -3.800933837890625}, {"pred": "sentenced", "count": 4, "cond_log_prob": -2.933929443359375}, {"pred": "serving", "count": 1, "cond_log_prob": -4.565887451171875}, {"pred": "suspended", "count": 1, "cond_log_prob": -5.7918701171875}]}, "38": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released", "log_prob": -165.67636108398438}, "original": {"pred": "July", "cond_log_prob": -6.7556304931640625}, "human": [{"pred": "from", "cond_log_prob": -1.283599853515625, "count": 13}, {"pred": "on", "cond_log_prob": -1.332427978515625, "count": 6}, {"pred": "after", "cond_log_prob": -2.711395263671875, "count": 4}, {"pred": "the", "cond_log_prob": -5.10198974609375, "count": 3}, {"pred": "last", "cond_log_prob": -3.870849609375, "count": 2}, {"pred": "when", "cond_log_prob": -5.73675537109375, "count": 2}, {"pred": "because", "cond_log_prob": -6.343780517578125, "count": 1}, {"pred": "by", "cond_log_prob": -3.943267822265625, "count": 1}, {"pred": "in", "cond_log_prob": -2.847991943359375, "count": 1}, {"pred": "into", "cond_log_prob": -5.855865478515625, "count": 1}, {"pred": "later", "cond_log_prob": -6.1961669921875, "count": 1}, {"pred": "monday", "cond_log_prob": -17.621826171875, "count": 1}, {"pred": "thursday", "cond_log_prob": -14.923614501953125, "count": 1}], "ancestral_samples": [{"pred": "Andersons", "count": 1, "cond_log_prob": -22.268310546875}, {"pred": "after", "count": 3, "cond_log_prob": -2.711395263671875}, {"pred": "afterroute", "count": 1, "cond_log_prob": -27.258514404296875}, {"pred": "from", "count": 10, "cond_log_prob": -1.283599853515625}, {"pred": "in", "count": 2, "cond_log_prob": -2.847991943359375}, {"pred": "on", "count": 22, "cond_log_prob": -1.332427978515625}, {"pred": "without", "count": 1, "cond_log_prob": -3.722076416015625}]}, "39": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July", "log_prob": -172.43199157714844}, "original": {"pred": "20", "cond_log_prob": -3.28631591796875}, "human": [{"pred": "of", "cond_log_prob": -7.6092376708984375, "count": 5}, {"pred": "14", "cond_log_prob": -3.4771270751953125, "count": 3}, {"pred": "last", "cond_log_prob": -10.527359008789062, "count": 3}, {"pred": "4th", "cond_log_prob": -9.505355834960938, "count": 2}, {"pred": "fourth", "cond_log_prob": -15.548110961914062, "count": 2}, {"pred": "from", "cond_log_prob": -8.860885620117188, "count": 2}, {"pred": "10", "cond_log_prob": -3.5287322998046875, "count": 1}, {"pred": "10th", "cond_log_prob": -9.686813354492188, "count": 1}, {"pred": "11th", "cond_log_prob": -9.389633178710938, "count": 1}, {"pred": "19", "cond_log_prob": -3.4764862060546875, "count": 1}, {"pred": "1948", "cond_log_prob": -13.770401000976562, "count": 1}, {"pred": "19th", "cond_log_prob": -9.285537719726562, "count": 1}, {"pred": "2013", "cond_log_prob": -8.053146362304688, "count": 1}, {"pred": "22", "cond_log_prob": -3.5272979736328125, "count": 1}, {"pred": "23", "cond_log_prob": -3.6215972900390625, "count": 1}, {"pred": "26", "cond_log_prob": -3.7815093994140625, "count": 1}, {"pred": "2nd", "cond_log_prob": -10.425125122070312, "count": 1}, {"pred": "3", "cond_log_prob": -3.7870025634765625, "count": 1}, {"pred": "4", "cond_log_prob": -3.6388702392578125, "count": 1}, {"pred": "5", "cond_log_prob": -3.5542144775390625, "count": 1}, {"pred": "after", "cond_log_prob": -8.355697631835938, "count": 1}, {"pred": "and", "cond_log_prob": -7.7754974365234375, "count": 1}, {"pred": "due", "cond_log_prob": -11.445938110351562, "count": 1}, {"pred": "fourteenth", "cond_log_prob": -22.336318969726562, "count": 1}, {"pred": "on", "cond_log_prob": -8.521286010742188, "count": 1}, {"pred": "when", "cond_log_prob": -9.938766479492188, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 3, "cond_log_prob": -2.6250762939453125}, {"pred": "11", "count": 4, "cond_log_prob": -3.4930572509765625}, {"pred": "12", "count": 3, "cond_log_prob": -3.4127655029296875}, {"pred": "12The", "count": 1, "cond_log_prob": -17.135086059570312}, {"pred": "13", "count": 1, "cond_log_prob": -3.6988677978515625}, {"pred": "15", "count": 1, "cond_log_prob": -3.1108245849609375}, {"pred": "15Anderson", "count": 1, "cond_log_prob": -24.260391235351562}, {"pred": "16In", "count": 1, "cond_log_prob": -20.148147583007812}, {"pred": "17", "count": 1, "cond_log_prob": -3.1832733154296875}, {"pred": "18", "count": 3, "cond_log_prob": -3.3755035400390625}, {"pred": "19", "count": 1, "cond_log_prob": -3.4764862060546875}, {"pred": "19Anderson", "count": 2, "cond_log_prob": -24.466934204101562}, {"pred": "1The", "count": 1, "cond_log_prob": -16.610610961914062}, {"pred": "2", "count": 1, "cond_log_prob": -3.5835418701171875}, {"pred": "20", "count": 1, "cond_log_prob": -3.2866668701171875}, {"pred": "23route", "count": 1, "cond_log_prob": -26.962265014648438}, {"pred": "25Anderson", "count": 2, "cond_log_prob": -24.621627807617188}, {"pred": "25The", "count": 1, "cond_log_prob": -17.761947631835938}, {"pred": "27", "count": 1, "cond_log_prob": -3.6630706787109375}, {"pred": "28In", "count": 1, "cond_log_prob": -20.891647338867188}, {"pred": "30", "count": 1, "cond_log_prob": -3.3172454833984375}, {"pred": "6", "count": 1, "cond_log_prob": -3.3626251220703125}, {"pred": "7", "count": 2, "cond_log_prob": -3.3427581787109375}, {"pred": "7The", "count": 1, "cond_log_prob": -17.487106323242188}, {"pred": "8Prosecutors", "count": 1, "cond_log_prob": -22.557723999023438}, {"pred": "8The", "count": 1, "cond_log_prob": -17.913009643554688}, {"pred": "9Anderson", "count": 1, "cond_log_prob": -24.320693969726562}, {"pred": "Andersons", "count": 1, "cond_log_prob": -24.013961791992188}]}, "40": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20", "log_prob": -175.7183074951172}, "original": {"pred": "after", "cond_log_prob": -1.8729248046875}, "human": [{"pred": "2013", "cond_log_prob": -9.600875854492188, "count": 9}, {"pred": "2012", "cond_log_prob": -10.125778198242188, "count": 4}, {"pred": "2011", "cond_log_prob": -10.651931762695312, "count": 3}, {"pred": "after", "cond_log_prob": -1.8732757568359375, "count": 3}, {"pred": "and", "cond_log_prob": -2.9006195068359375, "count": 2}, {"pred": "from", "cond_log_prob": -2.5894012451171875, "count": 2}, {"pred": "10", "cond_log_prob": -11.667709350585938, "count": 1}, {"pred": "13", "cond_log_prob": -12.286361694335938, "count": 1}, {"pred": "1948", "cond_log_prob": -17.979049682617188, "count": 1}, {"pred": "1987", "cond_log_prob": -14.475784301757812, "count": 1}, {"pred": "1990", "cond_log_prob": -14.886642456054688, "count": 1}, {"pred": "1991", "cond_log_prob": -14.110519409179688, "count": 1}, {"pred": "1998", "cond_log_prob": -14.368026733398438, "count": 1}, {"pred": "2003", "cond_log_prob": -13.458206176757812, "count": 1}, {"pred": "4", "cond_log_prob": -12.657821655273438, "count": 1}, {"pred": "for", "cond_log_prob": -5.5495147705078125, "count": 1}, {"pred": "of", "cond_log_prob": -6.4054107666015625, "count": 1}, {"pred": "th", "cond_log_prob": -10.048751831054688, "count": 1}, {"pred": "to", "cond_log_prob": -5.0454559326171875, "count": 1}, {"pred": "when", "cond_log_prob": -4.8589935302734375, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 2, "cond_log_prob": -11.710891723632812}, {"pred": "Anderson", "count": 3, "cond_log_prob": -15.640823364257812}, {"pred": "Andersons", "count": 10, "cond_log_prob": -23.468765258789062}, {"pred": "I", "count": 3, "cond_log_prob": -12.454330444335938}, {"pred": "In", "count": 2, "cond_log_prob": -13.582199096679688}, {"pred": "The", "count": 6, "cond_log_prob": -10.421737670898438}, {"pred": "after", "count": 6, "cond_log_prob": -1.8732757568359375}, {"pred": "afterroute", "count": 1, "cond_log_prob": -27.473648071289062}, {"pred": "and", "count": 2, "cond_log_prob": -2.9006195068359375}, {"pred": "but", "count": 2, "cond_log_prob": -4.2984771728515625}, {"pred": "on", "count": 3, "cond_log_prob": -2.6649932861328125}]}, "41": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after", "log_prob": -177.5912322998047}, "original": {"pred": "a", "cond_log_prob": -2.4756011962890625}, "human": [{"pred": "he", "cond_log_prob": -3.9009857177734375, "count": 12}, {"pred": "the", "cond_log_prob": -4.1000213623046875, "count": 6}, {"pred": "his", "cond_log_prob": -4.2494964599609375, "count": 5}, {"pred": "serving", "cond_log_prob": -0.9465484619140625, "count": 3}, {"pred": "three", "cond_log_prob": -4.8409881591796875, "count": 2}, {"pred": "20", "cond_log_prob": -5.7234039306640625, "count": 1}, {"pred": "a", "cond_log_prob": -2.4759674072265625, "count": 1}, {"pred": "all", "cond_log_prob": -8.118240356445312, "count": 1}, {"pred": "being", "cond_log_prob": -3.3111419677734375, "count": 1}, {"pred": "deciding", "cond_log_prob": -9.619949340820312, "count": 1}, {"pred": "paying", "cond_log_prob": -6.2329864501953125, "count": 1}, {"pred": "receiving", "cond_log_prob": -6.1053924560546875, "count": 1}, {"pred": "testifying", "cond_log_prob": -6.9946746826171875, "count": 1}, {"pred": "two", "cond_log_prob": -4.7743377685546875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -2.4759674072265625}, {"pred": "being", "count": 1, "cond_log_prob": -3.3111419677734375}, {"pred": "pleading", "count": 1, "cond_log_prob": -2.6718292236328125}, {"pred": "serving", "count": 34, "cond_log_prob": -0.9465484619140625}, {"pred": "servingroute", "count": 1, "cond_log_prob": -25.966812133789062}]}, "42": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a", "log_prob": -180.06683349609375}, "original": {"pred": "two-week", "cond_log_prob": -5.0599212646484375}, "human": [{"pred": "long", "cond_log_prob": -4.796417236328125, "count": 3}, {"pred": "judge", "cond_log_prob": -2.95697021484375, "count": 2}, {"pred": "mistrial", "cond_log_prob": -8.652969360351562, "count": 2}, {"pred": "parole", "cond_log_prob": -5.94989013671875, "count": 2}, {"pred": "trial", "cond_log_prob": -4.29180908203125, "count": 2}, {"pred": "witness", "cond_log_prob": -9.897857666015625, "count": 2}, {"pred": "3", "cond_log_prob": -5.9849853515625, "count": 1}, {"pred": "bail", "cond_log_prob": -6.1654052734375, "count": 1}, {"pred": "confusion", "cond_log_prob": -14.32220458984375, "count": 1}, {"pred": "court", "cond_log_prob": -3.5789794921875, "count": 1}, {"pred": "day", "cond_log_prob": -5.65692138671875, "count": 1}, {"pred": "decision", "cond_log_prob": -7.077606201171875, "count": 1}, {"pred": "different", "cond_log_prob": -9.196746826171875, "count": 1}, {"pred": "grueling", "cond_log_prob": -7.989593505859375, "count": 1}, {"pred": "hung", "cond_log_prob": -9.289947509765625, "count": 1}, {"pred": "jury", "cond_log_prob": -4.6751708984375, "count": 1}, {"pred": "lengthy", "cond_log_prob": -4.008392333984375, "count": 1}, {"pred": "new", "cond_log_prob": -6.900634765625, "count": 1}, {"pred": "not-guilty", "cond_log_prob": -9.202362060546875, "count": 1}, {"pred": "one", "cond_log_prob": -4.890716552734375, "count": 1}, {"pred": "re-trial", "cond_log_prob": -9.801300048828125, "count": 1}, {"pred": "ruling", "cond_log_prob": -7.52001953125, "count": 1}, {"pred": "short", "cond_log_prob": -4.980865478515625, "count": 1}, {"pred": "stay", "cond_log_prob": -5.87188720703125, "count": 1}, {"pred": "substantial", "cond_log_prob": -10.101806640625, "count": 1}, {"pred": "thirty", "cond_log_prob": -9.010772705078125, "count": 1}, {"pred": "three", "cond_log_prob": -2.54168701171875, "count": 1}, {"pred": "turn", "cond_log_prob": -10.778472900390625, "count": 1}, {"pred": "two", "cond_log_prob": -2.9493408203125, "count": 1}, {"pred": "very", "cond_log_prob": -7.733734130859375, "count": 1}], "ancestral_samples": [{"pred": "15day", "count": 1, "cond_log_prob": -14.254852294921875}, {"pred": "brief", "count": 2, "cond_log_prob": -4.48406982421875}, {"pred": "fiveday", "count": 2, "cond_log_prob": -30.107986450195312}, {"pred": "fiveyear", "count": 3, "cond_log_prob": -12.662750244140625}, {"pred": "fouryear", "count": 2, "cond_log_prob": -12.008132934570312}, {"pred": "judge", "count": 7, "cond_log_prob": -2.95697021484375}, {"pred": "lengthy", "count": 1, "cond_log_prob": -4.008392333984375}, {"pred": "sixmonth", "count": 1, "cond_log_prob": -10.912063598632812}, {"pred": "threeday", "count": 1, "cond_log_prob": -26.30499267578125}, {"pred": "threemonth", "count": 1, "cond_log_prob": -32.3492431640625}, {"pred": "threeroute", "count": 1, "cond_log_prob": -35.995849609375}, {"pred": "threeyear", "count": 9, "cond_log_prob": -12.723739624023438}, {"pred": "trial", "count": 1, "cond_log_prob": -4.29180908203125}, {"pred": "twoweek", "count": 1, "cond_log_prob": -29.54736328125}, {"pred": "twoyear", "count": 5, "cond_log_prob": -37.352813720703125}, {"pred": "year", "count": 2, "cond_log_prob": -3.353485107421875}]}, "43": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week", "log_prob": -185.1267547607422}, "original": {"pred": "stay", "cond_log_prob": -2.2008819580078125}, "human": [{"pred": "stay", "cond_log_prob": -2.201263427734375, "count": 9}, {"pred": "trial", "cond_log_prob": -2.441619873046875, "count": 9}, {"pred": "sentence", "cond_log_prob": -2.61895751953125, "count": 8}, {"pred": "prison", "cond_log_prob": -2.47113037109375, "count": 3}, {"pred": "detention", "cond_log_prob": -3.944854736328125, "count": 1}, {"pred": "lawsuit", "cond_log_prob": -9.4501953125, "count": 1}, {"pred": "long", "cond_log_prob": -5.86669921875, "count": 1}, {"pred": "notice", "cond_log_prob": -7.951690673828125, "count": 1}, {"pred": "parole", "cond_log_prob": -5.73223876953125, "count": 1}, {"pred": "period", "cond_log_prob": -3.754241943359375, "count": 1}, {"pred": "probation", "cond_log_prob": -3.448638916015625, "count": 1}, {"pred": "vacation", "cond_log_prob": -6.8553466796875, "count": 1}], "ancestral_samples": [{"pred": "detention", "count": 1, "cond_log_prob": -3.944854736328125}, {"pred": "jail", "count": 7, "cond_log_prob": -2.976959228515625}, {"pred": "prison", "count": 5, "cond_log_prob": -2.47113037109375}, {"pred": "probation", "count": 2, "cond_log_prob": -3.448638916015625}, {"pred": "sentence", "count": 2, "cond_log_prob": -2.61895751953125}, {"pred": "sentenceThe", "count": 1, "cond_log_prob": -18.527099609375}, {"pred": "stay", "count": 5, "cond_log_prob": -2.201263427734375}, {"pred": "stayAnderson", "count": 4, "cond_log_prob": -23.66815185546875}, {"pred": "stayAt", "count": 1, "cond_log_prob": -19.031951904296875}, {"pred": "stint", "count": 5, "cond_log_prob": -2.831817626953125}, {"pred": "trial", "count": 4, "cond_log_prob": -2.441619873046875}, {"pred": "trialAs", "count": 1, "cond_log_prob": -21.380645751953125}, {"pred": "trialThe", "count": 1, "cond_log_prob": -17.823333740234375}, {"pred": "trialroute", "count": 1, "cond_log_prob": -24.0146484375}]}, "44": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay", "log_prob": -187.32763671875}, "original": {"pred": "for", "cond_log_prob": -4.45172119140625}, "human": [{"pred": "in", "cond_log_prob": -1.3364410400390625, "count": 26}, {"pred": "at", "cond_log_prob": -3.5432891845703125, "count": 5}, {"pred": "for", "cond_log_prob": -4.4521026611328125, "count": 3}, {"pred": "and", "cond_log_prob": -3.6057891845703125, "count": 2}, {"pred": "where", "cond_log_prob": -5.9634857177734375, "count": 1}], "ancestral_samples": [{"pred": "Anderson", "count": 4, "cond_log_prob": -15.017929077148438}, {"pred": "Andersons", "count": 5, "cond_log_prob": -23.679458618164062}, {"pred": "Bart", "count": 1, "cond_log_prob": -16.719467163085938}, {"pred": "I", "count": 2, "cond_log_prob": -10.556411743164062}, {"pred": "In", "count": 2, "cond_log_prob": -11.395553588867188}, {"pred": "The", "count": 5, "cond_log_prob": -11.460250854492188}, {"pred": "but", "count": 1, "cond_log_prob": -5.9918060302734375}, {"pred": "in", "count": 18, "cond_log_prob": -1.3364410400390625}, {"pred": "on", "count": 1, "cond_log_prob": -3.0518646240234375}, {"pred": "route", "count": 1, "cond_log_prob": -17.619064331054688}]}, "45": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for", "log_prob": -191.77935791015625}, "original": {"pred": "previously", "cond_log_prob": -9.79498291015625}, "human": [{"pred": "his", "cond_log_prob": -2.6027069091796875, "count": 6}, {"pred": "not", "cond_log_prob": -5.2832489013671875, "count": 4}, {"pred": "refusing", "cond_log_prob": -4.3426666259765625, "count": 4}, {"pred": "theft", "cond_log_prob": -9.319839477539062, "count": 3}, {"pred": "a", "cond_log_prob": -1.9082794189453125, "count": 2}, {"pred": "good", "cond_log_prob": -5.5648040771484375, "count": 2}, {"pred": "the", "cond_log_prob": -3.1248321533203125, "count": 2}, {"pred": "battery", "cond_log_prob": -9.064895629882812, "count": 1}, {"pred": "being", "cond_log_prob": -5.7321624755859375, "count": 1}, {"pred": "claiming", "cond_log_prob": -8.300857543945312, "count": 1}, {"pred": "doing", "cond_log_prob": -6.3642120361328125, "count": 1}, {"pred": "embezzlement", "cond_log_prob": -9.262313842773438, "count": 1}, {"pred": "failing", "cond_log_prob": -4.2762603759765625, "count": 1}, {"pred": "failure", "cond_log_prob": -5.101318359375, "count": 1}, {"pred": "keeping", "cond_log_prob": -7.8742828369140625, "count": 1}, {"pred": "killing", "cond_log_prob": -9.980758666992188, "count": 1}, {"pred": "murder", "cond_log_prob": -8.347457885742188, "count": 1}, {"pred": "public", "cond_log_prob": -5.6537017822265625, "count": 1}, {"pred": "subpoena", "cond_log_prob": -10.133010864257812, "count": 1}, {"pred": "unwillingness", "cond_log_prob": -11.707504272460938, "count": 1}, {"pred": "withholding", "cond_log_prob": -8.027664184570312, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 30, "cond_log_prob": -1.9082794189453125}, {"pred": "aroute", "count": 1, "cond_log_prob": -28.139755249023438}, {"pred": "his", "count": 5, "cond_log_prob": -2.6027069091796875}, {"pred": "questioning", "count": 1, "cond_log_prob": -3.7406158447265625}, {"pred": "refusing", "count": 1, "cond_log_prob": -4.3426666259765625}, {"pred": "the", "count": 2, "cond_log_prob": -3.1248321533203125}]}, "46": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for previously", "log_prob": -201.5743408203125}, "original": {"pred": "declining", "cond_log_prob": -7.0341033935546875}, "human": [{"pred": "refusing", "cond_log_prob": -4.892547607421875, "count": 5}, {"pred": "committing", "cond_log_prob": -8.255050659179688, "count": 3}, {"pred": "committed", "cond_log_prob": -6.30242919921875, "count": 2}, {"pred": "denying", "cond_log_prob": -6.50970458984375, "count": 2}, {"pred": "having", "cond_log_prob": -7.2439117431640625, "count": 2}, {"pred": "withholding", "cond_log_prob": -8.478515625, "count": 2}, {"pred": "a", "cond_log_prob": -7.1156463623046875, "count": 1}, {"pred": "accused", "cond_log_prob": -6.733428955078125, "count": 1}, {"pred": "allowing", "cond_log_prob": -8.647781372070312, "count": 1}, {"pred": "alluding", "cond_log_prob": -11.367050170898438, "count": 1}, {"pred": "aquitted", "cond_log_prob": -12.962677001953125, "count": 1}, {"pred": "assaulted", "cond_log_prob": -10.279586791992188, "count": 1}, {"pred": "attempting", "cond_log_prob": -9.732452392578125, "count": 1}, {"pred": "beating", "cond_log_prob": -9.857818603515625, "count": 1}, {"pred": "breaking", "cond_log_prob": -8.9588623046875, "count": 1}, {"pred": "choosing", "cond_log_prob": -10.825637817382812, "count": 1}, {"pred": "comitting", "cond_log_prob": -16.214691162109375, "count": 1}, {"pred": "commited", "cond_log_prob": -16.891738891601562, "count": 1}, {"pred": "declining", "cond_log_prob": -7.03448486328125, "count": 1}, {"pred": "keeping", "cond_log_prob": -8.014373779296875, "count": 1}, {"pred": "killing", "cond_log_prob": -10.821578979492188, "count": 1}, {"pred": "maiming", "cond_log_prob": -15.57843017578125, "count": 1}, {"pred": "not", "cond_log_prob": -6.846160888671875, "count": 1}, {"pred": "punching", "cond_log_prob": -12.649948120117188, "count": 1}, {"pred": "stating", "cond_log_prob": -8.596954345703125, "count": 1}, {"pred": "stealing", "cond_log_prob": -10.54351806640625, "count": 1}, {"pred": "violating", "cond_log_prob": -6.4532623291015625, "count": 1}], "ancestral_samples": [{"pred": "Andersons", "count": 1, "cond_log_prob": -23.806564331054688}, {"pred": "charged", "count": 1, "cond_log_prob": -4.0106964111328125}, {"pred": "granted", "count": 1, "cond_log_prob": -3.8518524169921875}, {"pred": "released", "count": 10, "cond_log_prob": -2.3582611083984375}, {"pred": "resisting", "count": 1, "cond_log_prob": -6.7867279052734375}, {"pred": "scheduled", "count": 18, "cond_log_prob": -2.0148162841796875}, {"pred": "sentencing", "count": 2, "cond_log_prob": -9.315994262695312}, {"pred": "serving", "count": 1, "cond_log_prob": -4.2919464111328125}, {"pred": "suspended", "count": 1, "cond_log_prob": -4.6848907470703125}, {"pred": "undisclosed", "count": 3, "cond_log_prob": -2.7527923583984375}, {"pred": "undisclosedroute", "count": 1, "cond_log_prob": -29.626876831054688}]}, "47": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for previously declining", "log_prob": -208.6084442138672}, "original": {"pred": "to", "cond_log_prob": -0.5064697265625}, "human": [{"pred": "to", "cond_log_prob": -0.506866455078125, "count": 29}, {"pred": "a", "cond_log_prob": -2.441741943359375, "count": 4}, {"pred": "the", "cond_log_prob": -3.927459716796875, "count": 3}, {"pred": "health", "cond_log_prob": -8.593231201171875, "count": 1}], "ancestral_samples": [{"pred": "Andersons", "count": 1, "cond_log_prob": -19.526870727539062}, {"pred": "a", "count": 3, "cond_log_prob": -2.44171142578125}, {"pred": "to", "count": 35, "cond_log_prob": -0.506866455078125}, {"pred": "toroute", "count": 1, "cond_log_prob": -28.825180053710938}]}, "48": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for previously declining to", "log_prob": -209.1149139404297}, "original": {"pred": "testify", "cond_log_prob": -1.18756103515625}, "human": [{"pred": "testify", "cond_log_prob": -1.187957763671875, "count": 26}, {"pred": "appear", "cond_log_prob": -3.32666015625, "count": 3}, {"pred": "speak", "cond_log_prob": -3.1837158203125, "count": 2}, {"pred": "witness", "cond_log_prob": -9.5321044921875, "count": 2}, {"pred": "answer", "cond_log_prob": -2.6528167724609375, "count": 1}, {"pred": "be", "cond_log_prob": -3.867462158203125, "count": 1}, {"pred": "drive", "cond_log_prob": -9.626724243164062, "count": 1}, {"pred": "talk", "cond_log_prob": -3.9866485595703125, "count": 1}], "ancestral_samples": [{"pred": "answer", "count": 1, "cond_log_prob": -2.6528167724609375}, {"pred": "comment", "count": 2, "cond_log_prob": -2.8631744384765625}, {"pred": "speak", "count": 2, "cond_log_prob": -3.1837158203125}, {"pred": "testify", "count": 10, "cond_log_prob": -1.187957763671875}, {"pred": "testifyA", "count": 1, "cond_log_prob": -17.739334106445312}, {"pred": "testifyAnderson", "count": 13, "cond_log_prob": -24.408920288085938}, {"pred": "testifyAs", "count": 1, "cond_log_prob": -19.849716186523438}, {"pred": "testifyAt", "count": 1, "cond_log_prob": -19.19598388671875}, {"pred": "testifyIn", "count": 2, "cond_log_prob": -18.110504150390625}, {"pred": "testifyProsecutors", "count": 1, "cond_log_prob": -20.172882080078125}, {"pred": "testifyThe", "count": 5, "cond_log_prob": -17.929916381835938}, {"pred": "testifyroute", "count": 1, "cond_log_prob": -29.0618896484375}]}, "49": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for previously declining to testify", "log_prob": -210.30247497558594}, "original": {"pred": "before", "cond_log_prob": -3.3115081787109375}, "human": [{"pred": "in", "cond_log_prob": -2.5530548095703125, "count": 22}, {"pred": "against", "cond_log_prob": -3.7617950439453125, "count": 9}, {"pred": "when", "cond_log_prob": -5.612457275390625, "count": 2}, {"pred": "and", "cond_log_prob": -3.8562164306640625, "count": 1}, {"pred": "for", "cond_log_prob": -5.0106201171875, "count": 1}, {"pred": "his", "cond_log_prob": -7.71197509765625, "count": 1}, {"pred": "to", "cond_log_prob": -4.832305908203125, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -12.340225219726562}, {"pred": "Anderson", "count": 9, "cond_log_prob": -16.53466796875}, {"pred": "Andersons", "count": 12, "cond_log_prob": -23.875778198242188}, {"pred": "Bart", "count": 1, "cond_log_prob": -18.021331787109375}, {"pred": "He", "count": 1, "cond_log_prob": -13.148895263671875}, {"pred": "Hes", "count": 1, "cond_log_prob": -20.408111572265625}, {"pred": "I", "count": 5, "cond_log_prob": -11.101791381835938}, {"pred": "In", "count": 2, "cond_log_prob": -12.289825439453125}, {"pred": "The", "count": 6, "cond_log_prob": -11.431411743164062}, {"pred": "in", "count": 1, "cond_log_prob": -2.5530548095703125}, {"pred": "route", "count": 1, "cond_log_prob": -18.524093627929688}]}, "50": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for previously declining to testify before", "log_prob": -213.61398315429688}, "original": {"pred": "a", "cond_log_prob": -0.9896087646484375}, "human": [{"pred": "the", "cond_log_prob": -0.87689208984375, "count": 18}, {"pred": "a", "cond_log_prob": -0.99005126953125, "count": 13}, {"pred": "being", "cond_log_prob": -9.49993896484375, "count": 1}, {"pred": "court", "cond_log_prob": -6.536651611328125, "count": 1}, {"pred": "declining", "cond_log_prob": -14.630401611328125, "count": 1}, {"pred": "he", "cond_log_prob": -7.792083740234375, "count": 1}, {"pred": "his", "cond_log_prob": -3.939544677734375, "count": 1}, {"pred": "when", "cond_log_prob": -12.386749267578125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 19, "cond_log_prob": -0.99005126953125}, {"pred": "the", "count": 20, "cond_log_prob": -0.87689208984375}, {"pred": "theroute", "count": 1, "cond_log_prob": -30.762237548828125}]}, "51": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for previously declining to testify before a", "log_prob": -214.6035919189453}, "original": {"pred": "different", "cond_log_prob": -7.9060516357421875}, "human": [{"pred": "jury", "cond_log_prob": -4.0022430419921875, "count": 24}, {"pred": "court", "cond_log_prob": -4.7605438232421875, "count": 7}, {"pred": "judge", "cond_log_prob": -2.4800262451171875, "count": 4}, {"pred": "grand", "cond_log_prob": -0.5254058837890625, "count": 1}, {"pred": "time", "cond_log_prob": -10.864791870117188, "count": 1}], "ancestral_samples": [{"pred": "grand", "count": 38, "cond_log_prob": -0.5254058837890625}, {"pred": "grandroute", "count": 1, "cond_log_prob": -28.254867553710938}, {"pred": "judge", "count": 1, "cond_log_prob": -2.4800262451171875}]}, "52": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for previously declining to testify before a different", "log_prob": -222.5096435546875}, "original": {"pred": "grand", "cond_log_prob": -1.549591064453125}, "human": [{"pred": "jury", "cond_log_prob": -4.17816162109375, "count": 16}, {"pred": "judge", "cond_log_prob": -1.517852783203125, "count": 13}, {"pred": "court", "cond_log_prob": -2.7513427734375, "count": 4}, {"pred": "case", "cond_log_prob": -6.922821044921875, "count": 1}, {"pred": "group", "cond_log_prob": -5.911468505859375, "count": 1}, {"pred": "person", "cond_log_prob": -8.702423095703125, "count": 1}, {"pred": "set", "cond_log_prob": -7.745208740234375, "count": 1}], "ancestral_samples": [{"pred": "federal", "count": 2, "cond_log_prob": -2.1988525390625}, {"pred": "grand", "count": 15, "cond_log_prob": -1.550048828125}, {"pred": "judge", "count": 4, "cond_log_prob": -1.517852783203125}, {"pred": "judgeAnderson", "count": 10, "cond_log_prob": -23.344879150390625}, {"pred": "judgeAt", "count": 1, "cond_log_prob": -19.84417724609375}, {"pred": "judgeIn", "count": 2, "cond_log_prob": -17.790252685546875}, {"pred": "judgeProsecutors", "count": 1, "cond_log_prob": -19.46527099609375}, {"pred": "judgeThe", "count": 3, "cond_log_prob": -17.822601318359375}, {"pred": "judgeroute", "count": 1, "cond_log_prob": -42.2974853515625}, {"pred": "state", "count": 1, "cond_log_prob": -4.05810546875}]}, "53": {"context": {"text": "Greg Anderson, considered a key witness by the prosecution, vowed he wouldn't testify when served a subpoena last week. His lawyers said he was prepared for a third prison stay to maintain his silence. Anderson was released July 20 after a two-week stay for previously declining to testify before a different grand", "log_prob": -224.05923461914062}, "original": {"pred": "jury.", "cond_log_prob": -0.397918701171875}, "human": [{"pred": "jury", "cond_log_prob": -0.005645751953125, "count": 31}, {"pred": "court", "cond_log_prob": -11.165771484375, "count": 2}, {"pred": "judge", "cond_log_prob": -9.68902587890625, "count": 1}, {"pred": "old", "cond_log_prob": -13.847808837890625, "count": 1}, {"pred": "process", "cond_log_prob": -16.192657470703125, "count": 1}, {"pred": "scheme", "cond_log_prob": -12.96685791015625, "count": 1}], "ancestral_samples": [{"pred": "jury", "count": 10, "cond_log_prob": -0.005645751953125}, {"pred": "juryA", "count": 1, "cond_log_prob": -14.83050537109375}, {"pred": "juryAnderson", "count": 16, "cond_log_prob": -23.509185791015625}, {"pred": "juryAs", "count": 1, "cond_log_prob": -17.156494140625}, {"pred": "juryAt", "count": 1, "cond_log_prob": -17.486419677734375}, {"pred": "juryIn", "count": 2, "cond_log_prob": -14.78668212890625}, {"pred": "juryProsecutors", "count": 1, "cond_log_prob": -17.325469970703125}, {"pred": "juryThe", "count": 7, "cond_log_prob": -15.11187744140625}, {"pred": "juryroute", "count": 1, "cond_log_prob": -25.546966552734375}]}}, "16": {"2": {"context": {"text": "Steam", "log_prob": -13.856992721557617}, "original": {"pred": "sterilization", "cond_log_prob": -15.27393913269043}, "human": [{"pred": "is", "cond_log_prob": -4.032560348510742, "count": 6}, {"pred": "boat", "cond_log_prob": -12.854101181030273, "count": 5}, {"pred": "engines", "cond_log_prob": -10.258443832397461, "count": 4}, {"pred": "boats", "cond_log_prob": -13.464902877807617, "count": 3}, {"pred": "engine", "cond_log_prob": -7.920324325561523, "count": 4}, {"pred": "clean", "cond_log_prob": -12.364645004272461, "count": 2}, {"pred": "announced", "cond_log_prob": -8.079084396362305, "count": 1}, {"pred": "came", "cond_log_prob": -8.799955368041992, "count": 1}, {"pred": "can", "cond_log_prob": -6.254301071166992, "count": 1}, {"pred": "clouds", "cond_log_prob": -12.438009262084961, "count": 1}, {"pred": "comes", "cond_log_prob": -8.584844589233398, "count": 1}, {"pred": "from", "cond_log_prob": -8.159566879272461, "count": 1}, {"pred": "hot", "cond_log_prob": -10.008115768432617, "count": 1}, {"pred": "of", "cond_log_prob": -7.518896102905273, "count": 1}, {"pred": "pot", "cond_log_prob": -10.818731307983398, "count": 1}, {"pred": "power", "cond_log_prob": -8.830984115600586, "count": 2}, {"pred": "powers", "cond_log_prob": -10.09834098815918, "count": 1}, {"pred": "rises", "cond_log_prob": -12.454435348510742, "count": 1}, {"pred": "room", "cond_log_prob": -9.67976188659668, "count": 2}, {"pred": "was", "cond_log_prob": -6.445981979370117, "count": 1}], "ancestral_samples": [{"pred": "10", "count": 1, "cond_log_prob": -8.42848014831543}, {"pred": "20", "count": 1, "cond_log_prob": -9.623517990112305}, {"pred": "2013", "count": 1, "cond_log_prob": -8.888387680053711}, {"pred": "2steamappsworkshop", "count": 1, "cond_log_prob": -41.99400329589844}, {"pred": "Android", "count": 1, "cond_log_prob": -7.921102523803711}, {"pred": "Aura", "count": 1, "cond_log_prob": -9.724668502807617}, {"pred": "Failed to generate word", "count": 1, "cond_log_prob": -30.585176467895508}, {"pred": "Gemini", "count": 1, "cond_log_prob": -11.449766159057617}, {"pred": "I", "count": 1, "cond_log_prob": -8.087217330932617}, {"pred": "SucksTO", "count": 1, "cond_log_prob": -22.710233688354492}, {"pred": "The", "count": 2, "cond_log_prob": -7.33314323425293}, {"pred": "Xexe", "count": 1, "cond_log_prob": -19.4332332611084}, {"pred": "a", "count": 2, "cond_log_prob": -7.87220573425293}, {"pred": "and", "count": 4, "cond_log_prob": -4.721532821655273}, {"pred": "but", "count": 1, "cond_log_prob": -8.78468132019043}, {"pred": "comDownloads", "count": 1, "cond_log_prob": -23.400514602661133}, {"pred": "comapp", "count": 1, "cond_log_prob": -20.378599166870117}, {"pred": "comdownload", "count": 1, "cond_log_prob": -21.26352882385254}, {"pred": "comdownloads", "count": 2, "cond_log_prob": -23.53399085998535}, {"pred": "comen", "count": 1, "cond_log_prob": -17.719194412231445}, {"pred": "comu", "count": 1, "cond_log_prob": -17.2719669342041}, {"pred": "exeFor", "count": 1, "cond_log_prob": -23.79899024963379}, {"pred": "http", "count": 1, "cond_log_prob": -9.155332565307617}, {"pred": "is", "count": 1, "cond_log_prob": -4.032560348510742}, {"pred": "net", "count": 1, "cond_log_prob": -10.978139877319336}, {"pred": "netdownloads", "count": 1, "cond_log_prob": -22.345666885375977}, {"pred": "or", "count": 1, "cond_log_prob": -6.871488571166992}, {"pred": "routemapping", "count": 1, "cond_log_prob": -27.8734073638916}, {"pred": "sToPlay", "count": 1, "cond_log_prob": -24.18476676940918}, {"pred": "the", "count": 2, "cond_log_prob": -7.327138900756836}, {"pred": "to", "count": 2, "cond_log_prob": -6.412641525268555}, {"pred": "was", "count": 1, "cond_log_prob": -6.445981979370117}]}, "3": {"context": {"text": "Steam sterilization", "log_prob": -29.130931854248047}, "original": {"pred": "is", "cond_log_prob": -2.6399269104003906}, "human": [{"pred": "is", "cond_log_prob": -2.639965057373047, "count": 21}, {"pred": "process", "cond_log_prob": -5.232074737548828, "count": 2}, {"pred": "a", "cond_log_prob": -7.022365570068359, "count": 1}, {"pred": "and", "cond_log_prob": -3.245464324951172, "count": 1}, {"pred": "chamber", "cond_log_prob": -7.897579193115234, "count": 1}, {"pred": "cleaner", "cond_log_prob": -10.154956817626953, "count": 1}, {"pred": "has", "cond_log_prob": -4.518093109130859, "count": 1}, {"pred": "helps", "cond_log_prob": -7.130809783935547, "count": 1}, {"pred": "hurts", "cond_log_prob": -10.933650970458984, "count": 1}, {"pred": "includes", "cond_log_prob": -8.588008880615234, "count": 1}, {"pred": "machine", "cond_log_prob": -6.102687835693359, "count": 1}, {"pred": "of", "cond_log_prob": -3.983715057373047, "count": 1}, {"pred": "processing", "cond_log_prob": -9.874187469482422, "count": 1}, {"pred": "system", "cond_log_prob": -4.350353240966797, "count": 1}, {"pred": "technique", "cond_log_prob": -6.269603729248047, "count": 1}, {"pred": "techniques", "cond_log_prob": -6.498462677001953, "count": 1}, {"pred": "test", "cond_log_prob": -6.131885528564453, "count": 1}, {"pred": "tool", "cond_log_prob": -5.008014678955078, "count": 1}, {"pred": "was", "cond_log_prob": -5.242198944091797, "count": 1}], "ancestral_samples": [{"pred": "10", "count": 1, "cond_log_prob": -7.642063140869141}, {"pred": "6", "count": 1, "cond_log_prob": -8.248149871826172}, {"pred": "Filename", "count": 1, "cond_log_prob": -14.573478698730469}, {"pred": "I", "count": 1, "cond_log_prob": -7.199504852294922}, {"pred": "In", "count": 1, "cond_log_prob": -7.750591278076172}, {"pred": "The", "count": 5, "cond_log_prob": -6.369655609130859}, {"pred": "We", "count": 1, "cond_log_prob": -8.290081024169922}, {"pred": "What", "count": 1, "cond_log_prob": -9.052265167236328}, {"pred": "a", "count": 1, "cond_log_prob": -7.022365570068359}, {"pred": "and", "count": 12, "cond_log_prob": -3.245464324951172}, {"pred": "but", "count": 1, "cond_log_prob": -8.05093765258789}, {"pred": "dmg", "count": 1, "cond_log_prob": -15.370174407958984}, {"pred": "for", "count": 1, "cond_log_prob": -4.111217498779297}, {"pred": "is", "count": 4, "cond_log_prob": -2.639965057373047}, {"pred": "isroute", "count": 1, "cond_log_prob": -25.246402740478516}, {"pred": "or", "count": 1, "cond_log_prob": -5.268337249755859}, {"pred": "processThis", "count": 1, "cond_log_prob": -16.20889663696289}, {"pred": "sterilization", "count": 1, "cond_log_prob": -6.607540130615234}, {"pred": "the", "count": 1, "cond_log_prob": -6.818126678466797}, {"pred": "to", "count": 1, "cond_log_prob": -5.343517303466797}, {"pred": "was", "count": 1, "cond_log_prob": -5.242198944091797}, {"pred": "which", "count": 1, "cond_log_prob": -7.358333587646484}]}, "4": {"context": {"text": "Steam sterilization is", "log_prob": -31.770858764648438}, "original": {"pred": "limited", "cond_log_prob": -7.065666198730469}, "human": [{"pred": "a", "cond_log_prob": -1.6711959838867188, "count": 15}, {"pred": "the", "cond_log_prob": -2.7013092041015625, "count": 8}, {"pred": "used", "cond_log_prob": -5.001983642578125, "count": 4}, {"pred": "necessary", "cond_log_prob": -5.946922302246094, "count": 2}, {"pred": "very", "cond_log_prob": -4.9027099609375, "count": 2}, {"pred": "an", "cond_log_prob": -3.0479278564453125, "count": 1}, {"pred": "dangerous", "cond_log_prob": -7.065895080566406, "count": 1}, {"pred": "effective", "cond_log_prob": -5.854026794433594, "count": 1}, {"pred": "for", "cond_log_prob": -6.058929443359375, "count": 1}, {"pred": "fun", "cond_log_prob": -7.4709930419921875, "count": 1}, {"pred": "good", "cond_log_prob": -5.995628356933594, "count": 1}, {"pred": "known", "cond_log_prob": -5.942207336425781, "count": 1}, {"pred": "not", "cond_log_prob": -2.63653564453125, "count": 1}, {"pred": "useful", "cond_log_prob": -6.575447082519531, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -9.278060913085938}, {"pred": "a", "count": 19, "cond_log_prob": -1.6711959838867188}, {"pred": "also", "count": 2, "cond_log_prob": -4.551300048828125}, {"pred": "not", "count": 14, "cond_log_prob": -2.63653564453125}, {"pred": "notrouteable", "count": 1, "cond_log_prob": -29.321815490722656}, {"pred": "now", "count": 2, "cond_log_prob": -3.741943359375}, {"pred": "the", "count": 1, "cond_log_prob": -2.7013092041015625}]}, "5": {"context": {"text": "Steam sterilization is limited", "log_prob": -38.836524963378906}, "original": {"pred": "in", "cond_log_prob": -4.698753356933594}, "human": [{"pred": "to", "cond_log_prob": -0.15601348876953125, "count": 29}, {"pred": "in", "cond_log_prob": -4.6988677978515625, "count": 4}, {"pred": "because", "cond_log_prob": -7.300323486328125, "count": 3}, {"pred": "on", "cond_log_prob": -6.96307373046875, "count": 1}, {"pred": "procedure", "cond_log_prob": -12.401573181152344, "count": 1}, {"pred": "through", "cond_log_prob": -7.722068786621094, "count": 1}, {"pred": "when", "cond_log_prob": -8.152183532714844, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -10.646202087402344}, {"pred": "to", "count": 38, "cond_log_prob": -0.15601348876953125}, {"pred": "toroute", "count": 1, "cond_log_prob": -31.008262634277344}]}, "6": {"context": {"text": "Steam sterilization is limited in", "log_prob": -43.5352783203125}, "original": {"pred": "the", "cond_log_prob": -2.0081024169921875}, "human": [{"pred": "its", "cond_log_prob": -2.6078338623046875, "count": 9}, {"pred": "the", "cond_log_prob": -2.0082473754882812, "count": 6}, {"pred": "how", "cond_log_prob": -4.7107696533203125, "count": 5}, {"pred": "some", "cond_log_prob": -4.654319763183594, "count": 3}, {"pred": "a", "cond_log_prob": -4.6474761962890625, "count": 2}, {"pred": "many", "cond_log_prob": -5.6828765869140625, "count": 2}, {"pred": "all", "cond_log_prob": -5.472999572753906, "count": 1}, {"pred": "capacity", "cond_log_prob": -6.767890930175781, "count": 1}, {"pred": "cleaning", "cond_log_prob": -12.431732177734375, "count": 1}, {"pred": "different", "cond_log_prob": -7.696311950683594, "count": 1}, {"pred": "few", "cond_log_prob": -7.9182586669921875, "count": 1}, {"pred": "large", "cond_log_prob": -8.125312805175781, "count": 1}, {"pred": "lots", "cond_log_prob": -10.134834289550781, "count": 1}, {"pred": "number", "cond_log_prob": -3.2578811645507812, "count": 1}, {"pred": "several", "cond_log_prob": -6.15716552734375, "count": 1}, {"pred": "supply", "cond_log_prob": -6.669975280761719, "count": 1}, {"pred": "that", "cond_log_prob": -2.5151824951171875, "count": 1}, {"pred": "usefulness", "cond_log_prob": -8.074913024902344, "count": 1}, {"pred": "ways", "cond_log_prob": -8.231712341308594, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.6474761962890625}, {"pred": "duration", "count": 1, "cond_log_prob": -4.1404876708984375}, {"pred": "its", "count": 2, "cond_log_prob": -2.6078338623046875}, {"pred": "most", "count": 1, "cond_log_prob": -5.5373992919921875}, {"pred": "scope", "count": 6, "cond_log_prob": -2.2873764038085938}, {"pred": "terms", "count": 1, "cond_log_prob": -3.2671432495117188}, {"pred": "that", "count": 11, "cond_log_prob": -2.5151824951171875}, {"pred": "thatroute", "count": 1, "cond_log_prob": -22.38568878173828}, {"pred": "the", "count": 16, "cond_log_prob": -2.0082473754882812}]}, "7": {"context": {"text": "Steam sterilization is limited in the", "log_prob": -45.54338073730469}, "original": {"pred": "types", "cond_log_prob": -7.75018310546875}, "human": [{"pred": "way", "cond_log_prob": -4.746269226074219, "count": 5}, {"pred": "ability", "cond_log_prob": -6.409210205078125, "count": 3}, {"pred": "best", "cond_log_prob": -6.803680419921875, "count": 2}, {"pred": "field", "cond_log_prob": -6.4853057861328125, "count": 2}, {"pred": "hospital", "cond_log_prob": -8.31036376953125, "count": 2}, {"pred": "united", "cond_log_prob": -11.80535888671875, "count": 4}, {"pred": "ways", "cond_log_prob": -7.3321075439453125, "count": 2}, {"pred": "absence", "cond_log_prob": -6.725982666015625, "count": 1}, {"pred": "animal", "cond_log_prob": -10.110801696777344, "count": 1}, {"pred": "basis", "cond_log_prob": -9.379074096679688, "count": 1}, {"pred": "capability", "cond_log_prob": -9.779769897460938, "count": 1}, {"pred": "capacity", "cond_log_prob": -6.7406463623046875, "count": 1}, {"pred": "degree", "cond_log_prob": -7.5202178955078125, "count": 1}, {"pred": "doctor", "cond_log_prob": -9.431785583496094, "count": 1}, {"pred": "fact", "cond_log_prob": -7.635406494140625, "count": 1}, {"pred": "food", "cond_log_prob": -9.759201049804688, "count": 1}, {"pred": "industry", "cond_log_prob": -7.5303192138671875, "count": 1}, {"pred": "kitchen", "cond_log_prob": -9.266448974609375, "count": 1}, {"pred": "levels", "cond_log_prob": -9.545669555664062, "count": 1}, {"pred": "necessary", "cond_log_prob": -10.371749877929688, "count": 1}, {"pred": "new", "cond_log_prob": -7.598457336425781, "count": 1}, {"pred": "process", "cond_log_prob": -7.67462158203125, "count": 1}, {"pred": "scientific", "cond_log_prob": -8.848159790039062, "count": 1}, {"pred": "sense", "cond_log_prob": -5.586944580078125, "count": 1}, {"pred": "us", "cond_log_prob": -11.635360717773438, "count": 1}, {"pred": "usages", "cond_log_prob": -15.077316284179688, "count": 1}, {"pred": "work", "cond_log_prob": -9.147804260253906, "count": 1}], "ancestral_samples": [{"pred": "UKThe", "count": 1, "cond_log_prob": -15.346031188964844}, {"pred": "US", "count": 7, "cond_log_prob": -2.7163009643554688}, {"pred": "USA", "count": 2, "cond_log_prob": -5.0191192626953125}, {"pred": "USThe", "count": 1, "cond_log_prob": -14.554977416992188}, {"pred": "USThis", "count": 1, "cond_log_prob": -14.888984680175781}, {"pred": "United", "count": 5, "cond_log_prob": -3.40948486328125}, {"pred": "Unitedroute", "count": 1, "cond_log_prob": -26.77393341064453}, {"pred": "amount", "count": 4, "cond_log_prob": -3.2441558837890625}, {"pred": "case", "count": 7, "cond_log_prob": -3.342041015625}, {"pred": "following", "count": 6, "cond_log_prob": -2.0459976196289062}, {"pred": "form", "count": 1, "cond_log_prob": -4.2209930419921875}, {"pred": "number", "count": 4, "cond_log_prob": -3.1874923706054688}]}, "8": {"context": {"text": "Steam sterilization is limited in the types", "log_prob": -53.29356384277344}, "original": {"pred": "of", "cond_log_prob": -0.1143798828125}, "human": [{"pred": "of", "cond_log_prob": -0.11457443237304688, "count": 39}, {"pred": "and", "cond_log_prob": -3.473388671875, "count": 1}], "ancestral_samples": [{"pred": "of", "count": 39, "cond_log_prob": -0.11457443237304688}, {"pred": "ofroute", "count": 1, "cond_log_prob": -22.57049560546875}]}, "9": {"context": {"text": "Steam sterilization is limited in the types of", "log_prob": -53.40794372558594}, "original": {"pred": "medical", "cond_log_prob": -6.214454650878906}, "human": [{"pred": "cleaning", "cond_log_prob": -7.174869537353516, "count": 3}, {"pred": "materials", "cond_log_prob": -4.149517059326172, "count": 3}, {"pred": "things", "cond_log_prob": -4.973308563232422, "count": 4}, {"pred": "ways", "cond_log_prob": -6.013820648193359, "count": 3}, {"pred": "methods", "cond_log_prob": -5.098659515380859, "count": 2}, {"pred": "applications", "cond_log_prob": -5.241352081298828, "count": 1}, {"pred": "bacteria", "cond_log_prob": -5.266658782958984, "count": 1}, {"pred": "businesses", "cond_log_prob": -8.832820892333984, "count": 1}, {"pred": "chemical", "cond_log_prob": -6.181079864501953, "count": 1}, {"pred": "clients", "cond_log_prob": -9.099300384521484, "count": 1}, {"pred": "devices", "cond_log_prob": -4.782192230224609, "count": 1}, {"pred": "disorders", "cond_log_prob": -9.05770492553711, "count": 1}, {"pred": "fertilizer", "cond_log_prob": -8.830013275146484, "count": 1}, {"pred": "foods", "cond_log_prob": -5.462963104248047, "count": 1}, {"pred": "germs", "cond_log_prob": -6.754016876220703, "count": 1}, {"pred": "hospitals", "cond_log_prob": -7.399028778076172, "count": 1}, {"pred": "liquids", "cond_log_prob": -6.060161590576172, "count": 1}, {"pred": "objects", "cond_log_prob": -5.337085723876953, "count": 1}, {"pred": "power", "cond_log_prob": -7.921695709228516, "count": 1}, {"pred": "practices", "cond_log_prob": -7.585979461669922, "count": 1}, {"pred": "processes", "cond_log_prob": -6.492321014404297, "count": 1}, {"pred": "production", "cond_log_prob": -8.838787078857422, "count": 1}, {"pred": "situtations", "cond_log_prob": -19.602249145507812, "count": 1}, {"pred": "sterilization", "cond_log_prob": -3.4159011840820312, "count": 1}, {"pred": "sterillization", "cond_log_prob": -21.745384216308594, "count": 1}, {"pred": "styles", "cond_log_prob": -9.555362701416016, "count": 1}, {"pred": "substances", "cond_log_prob": -4.909290313720703, "count": 1}, {"pred": "temperature", "cond_log_prob": -8.298946380615234, "count": 1}, {"pred": "tools", "cond_log_prob": -4.939533233642578, "count": 1}, {"pred": "varieties", "cond_log_prob": -8.461200714111328, "count": 1}], "ancestral_samples": [{"pred": "animals", "count": 3, "cond_log_prob": -5.513484954833984}, {"pred": "biological", "count": 1, "cond_log_prob": -7.207042694091797}, {"pred": "drugs", "count": 1, "cond_log_prob": -5.053310394287109}, {"pred": "hospitals", "count": 1, "cond_log_prob": -7.399028778076172}, {"pred": "nutrients", "count": 1, "cond_log_prob": -6.184864044189453}, {"pred": "organisms", "count": 1, "cond_log_prob": -6.075016021728516}, {"pred": "prophylaxis", "count": 1, "cond_log_prob": -11.439224243164062}, {"pred": "sterilization", "count": 21, "cond_log_prob": -3.4159011840820312}, {"pred": "sterilizations", "count": 6, "cond_log_prob": -3.8316574096679688}, {"pred": "sterilized", "count": 2, "cond_log_prob": -4.942714691162109}, {"pred": "sterilroute", "count": 1, "cond_log_prob": -24.268844604492188}, {"pred": "substances", "count": 1, "cond_log_prob": -4.909290313720703}]}, "10": {"context": {"text": "Steam sterilization is limited in the types of medical", "log_prob": -59.622398376464844}, "original": {"pred": "waste", "cond_log_prob": -7.0345916748046875}, "human": [{"pred": "procedures", "cond_log_prob": -1.5346565246582031, "count": 5}, {"pred": "devices", "cond_log_prob": -2.751056671142578, "count": 3}, {"pred": "practices", "cond_log_prob": -4.222385406494141, "count": 3}, {"pred": "care", "cond_log_prob": -2.753009796142578, "count": 2}, {"pred": "instruments", "cond_log_prob": -4.990592956542969, "count": 2}, {"pred": "processes", "cond_log_prob": -7.022148132324219, "count": 2}, {"pred": "supplies", "cond_log_prob": -3.8037681579589844, "count": 2}, {"pred": "usage", "cond_log_prob": -9.351676940917969, "count": 2}, {"pred": "uses", "cond_log_prob": -5.190635681152344, "count": 2}, {"pred": "application", "cond_log_prob": -8.718772888183594, "count": 1}, {"pred": "applications", "cond_log_prob": -4.466300964355469, "count": 1}, {"pred": "benefits", "cond_log_prob": -5.946968078613281, "count": 1}, {"pred": "centers", "cond_log_prob": -6.193977355957031, "count": 1}, {"pred": "cleansing", "cond_log_prob": -11.022483825683594, "count": 1}, {"pred": "cures", "cond_log_prob": -8.403907775878906, "count": 1}, {"pred": "disciplines", "cond_log_prob": -8.845893859863281, "count": 1}, {"pred": "equipment", "cond_log_prob": -3.402294158935547, "count": 1}, {"pred": "examinations", "cond_log_prob": -6.913307189941406, "count": 1}, {"pred": "fields", "cond_log_prob": -8.893196105957031, "count": 1}, {"pred": "insturments", "cond_log_prob": -19.978622436523438, "count": 1}, {"pred": "practice", "cond_log_prob": -6.472511291503906, "count": 1}, {"pred": "resources", "cond_log_prob": -7.231056213378906, "count": 1}, {"pred": "studies", "cond_log_prob": -6.286628723144531, "count": 1}, {"pred": "system", "cond_log_prob": -8.728385925292969, "count": 1}, {"pred": "tools", "cond_log_prob": -6.043373107910156, "count": 1}, {"pred": "treatments", "cond_log_prob": -3.127483367919922, "count": 1}], "ancestral_samples": [{"pred": "care", "count": 2, "cond_log_prob": -2.753009796142578}, {"pred": "devices", "count": 2, "cond_log_prob": -2.751056671142578}, {"pred": "devicesroute", "count": 1, "cond_log_prob": -28.342567443847656}, {"pred": "equipment", "count": 1, "cond_log_prob": -3.402294158935547}, {"pred": "facilities", "count": 1, "cond_log_prob": -4.328701019287109}, {"pred": "instruments", "count": 1, "cond_log_prob": -4.990592956542969}, {"pred": "procedures", "count": 29, "cond_log_prob": -1.5346565246582031}, {"pred": "proceduresThe", "count": 1, "cond_log_prob": -16.30365753173828}, {"pred": "treatment", "count": 1, "cond_log_prob": -3.232654571533203}, {"pred": "treatments", "count": 1, "cond_log_prob": -3.127483367919922}]}, "11": {"context": {"text": "Steam sterilization is limited in the types of medical waste", "log_prob": -66.65699005126953}, "original": {"pred": "it", "cond_log_prob": -3.105255126953125}, "human": [{"pred": "it", "cond_log_prob": -3.1055374145507812, "count": 16}, {"pred": "that", "cond_log_prob": -1.0107803344726562, "count": 13}, {"pred": "products", "cond_log_prob": -4.145713806152344, "count": 2}, {"pred": "used", "cond_log_prob": -4.207298278808594, "count": 2}, {"pred": "we", "cond_log_prob": -4.219490051269531, "count": 2}, {"pred": "----------------------------------------------------", "cond_log_prob": -21.067527770996094, "count": 1}, {"pred": "and", "cond_log_prob": -3.0565414428710938, "count": 1}, {"pred": "available", "cond_log_prob": -4.003715515136719, "count": 1}, {"pred": "disposal", "cond_log_prob": -5.074562072753906, "count": 1}, {"pred": "material", "cond_log_prob": -8.052040100097656, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -9.925193786621094}, {"pred": "and", "count": 1, "cond_log_prob": -3.0565414428710938}, {"pred": "hospitals", "count": 1, "cond_log_prob": -6.821372985839844}, {"pred": "that", "count": 36, "cond_log_prob": -1.0107803344726562}, {"pred": "thatroute", "count": 1, "cond_log_prob": -22.689910888671875}]}, "12": {"context": {"text": "Steam sterilization is limited in the types of medical waste it", "log_prob": -69.76224517822266}, "original": {"pred": "can", "cond_log_prob": -1.299285888671875}, "human": [{"pred": "can", "cond_log_prob": -1.2995986938476562, "count": 20}, {"pred": "produces", "cond_log_prob": -4.094459533691406, "count": 11}, {"pred": "is", "cond_log_prob": -2.4026412963867188, "count": 3}, {"pred": "uses", "cond_log_prob": -3.5354995727539062, "count": 2}, {"pred": "contains", "cond_log_prob": -3.2583694458007812, "count": 1}, {"pred": "disinfects", "cond_log_prob": -7.970558166503906, "count": 1}, {"pred": "has", "cond_log_prob": -4.739448547363281, "count": 1}, {"pred": "occupies", "cond_log_prob": -8.686622619628906, "count": 1}], "ancestral_samples": [{"pred": "can", "count": 29, "cond_log_prob": -1.2995986938476562}, {"pred": "canroute", "count": 1, "cond_log_prob": -21.019271850585938}, {"pred": "contains", "count": 1, "cond_log_prob": -3.2583694458007812}, {"pred": "is", "count": 6, "cond_log_prob": -2.4026412963867188}, {"pred": "producesThe", "count": 1, "cond_log_prob": -17.216636657714844}, {"pred": "usesIn", "count": 1, "cond_log_prob": -17.83063507080078}, {"pred": "will", "count": 1, "cond_log_prob": -3.1330337524414062}]}, "13": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can", "log_prob": -71.06153106689453}, "original": {"pred": "treat,", "cond_log_prob": -6.8966217041015625}, "human": [{"pred": "clean", "cond_log_prob": -4.9649810791015625, "count": 9}, {"pred": "produce", "cond_log_prob": -4.1809234619140625, "count": 7}, {"pred": "be", "cond_log_prob": -1.487152099609375, "count": 5}, {"pred": "sterilize", "cond_log_prob": -3.4031143188476562, "count": 4}, {"pred": "acquire", "cond_log_prob": -7.3992462158203125, "count": 1}, {"pred": "affect", "cond_log_prob": -6.012176513671875, "count": 1}, {"pred": "create", "cond_log_prob": -5.50469970703125, "count": 1}, {"pred": "decontaminate", "cond_log_prob": -9.144676208496094, "count": 1}, {"pred": "disinfect", "cond_log_prob": -7.330360412597656, "count": 1}, {"pred": "dispose", "cond_log_prob": -3.3097457885742188, "count": 1}, {"pred": "eliminate", "cond_log_prob": -6.4098968505859375, "count": 1}, {"pred": "have", "cond_log_prob": -6.5680084228515625, "count": 1}, {"pred": "help", "cond_log_prob": -5.904380798339844, "count": 1}, {"pred": "prevent", "cond_log_prob": -6.3187103271484375, "count": 1}, {"pred": "remove", "cond_log_prob": -3.8618850708007812, "count": 1}, {"pred": "sanitize", "cond_log_prob": -7.14276123046875, "count": 1}, {"pred": "take", "cond_log_prob": -3.5281524658203125, "count": 1}, {"pred": "use", "cond_log_prob": -3.918914794921875, "count": 1}, {"pred": "ve", "cond_log_prob": -13.735260009765625, "count": 1}], "ancestral_samples": [{"pred": "be", "count": 31, "cond_log_prob": -1.487152099609375}, {"pred": "collect", "count": 3, "cond_log_prob": -3.33172607421875}, {"pred": "containIt", "count": 2, "cond_log_prob": -15.752197265625}, {"pred": "containroute", "count": 1, "cond_log_prob": -22.677711486816406}, {"pred": "generate", "count": 1, "cond_log_prob": -5.89227294921875}, {"pred": "safely", "count": 1, "cond_log_prob": -3.9653091430664062}, {"pred": "transport", "count": 1, "cond_log_prob": -5.178680419921875}]}, "14": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat,", "log_prob": -77.9581527709961}, "original": {"pred": "but", "cond_log_prob": -1.5585556030273438}, "human": [{"pred": "but", "cond_log_prob": -1.558685302734375, "count": 10}, {"pred": "and", "cond_log_prob": -1.3768463134765625, "count": 5}, {"pred": "because", "cond_log_prob": -5.1262969970703125, "count": 5}, {"pred": "it", "cond_log_prob": -4.618461608886719, "count": 5}, {"pred": "as", "cond_log_prob": -3.6256179809570312, "count": 2}, {"pred": "so", "cond_log_prob": -2.9323577880859375, "count": 2}, {"pred": "therefore", "cond_log_prob": -7.59783935546875, "count": 2}, {"pred": "also", "cond_log_prob": -7.6417236328125, "count": 1}, {"pred": "for", "cond_log_prob": -5.8036651611328125, "count": 1}, {"pred": "like", "cond_log_prob": -4.820243835449219, "count": 1}, {"pred": "many", "cond_log_prob": -7.146675109863281, "count": 1}, {"pred": "meaning", "cond_log_prob": -6.170135498046875, "count": 1}, {"pred": "reduce", "cond_log_prob": -8.956710815429688, "count": 1}, {"pred": "such", "cond_log_prob": -3.4059906005859375, "count": 1}, {"pred": "which", "cond_log_prob": -3.6025543212890625, "count": 1}, {"pred": "with", "cond_log_prob": -4.781517028808594, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 32, "cond_log_prob": -1.3768463134765625}, {"pred": "androute", "count": 1, "cond_log_prob": -23.63343048095703}, {"pred": "but", "count": 6, "cond_log_prob": -1.558685302734375}, {"pred": "so", "count": 1, "cond_log_prob": -2.9323577880859375}]}, "15": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but", "log_prob": -79.51670837402344}, "original": {"pred": "is", "cond_log_prob": -3.64544677734375}, "human": [{"pred": "it", "cond_log_prob": -1.417205810546875, "count": 26}, {"pred": "is", "cond_log_prob": -3.6455841064453125, "count": 3}, {"pred": "the", "cond_log_prob": -2.5893402099609375, "count": 3}, {"pred": "can", "cond_log_prob": -3.9276275634765625, "count": 2}, {"pred": "fire", "cond_log_prob": -10.003265380859375, "count": 1}, {"pred": "its", "cond_log_prob": -4.242347717285156, "count": 1}, {"pred": "new", "cond_log_prob": -7.37188720703125, "count": 1}, {"pred": "not", "cond_log_prob": -4.297126770019531, "count": 1}, {"pred": "other", "cond_log_prob": -5.433074951171875, "count": 1}, {"pred": "with", "cond_log_prob": -4.903594970703125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.265106201171875}, {"pred": "hospitals", "count": 1, "cond_log_prob": -6.7859039306640625}, {"pred": "in", "count": 1, "cond_log_prob": -3.7513885498046875}, {"pred": "is", "count": 1, "cond_log_prob": -3.6455841064453125}, {"pred": "it", "count": 26, "cond_log_prob": -1.417205810546875}, {"pred": "itroute", "count": 1, "cond_log_prob": -28.49163818359375}, {"pred": "most", "count": 1, "cond_log_prob": -4.669975280761719}, {"pred": "not", "count": 1, "cond_log_prob": -4.297126770019531}, {"pred": "some", "count": 1, "cond_log_prob": -4.2391357421875}, {"pred": "the", "count": 6, "cond_log_prob": -2.5893402099609375}]}, "16": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is", "log_prob": -83.16215515136719}, "original": {"pred": "appropriate", "cond_log_prob": -8.641494750976562}, "human": [{"pred": "very", "cond_log_prob": -4.3205718994140625, "count": 10}, {"pred": "not", "cond_log_prob": -3.1302337646484375, "count": 7}, {"pred": "useful", "cond_log_prob": -5.7475738525390625, "count": 4}, {"pred": "a", "cond_log_prob": -3.776214599609375, "count": 3}, {"pred": "also", "cond_log_prob": -3.0253448486328125, "count": 2}, {"pred": "effective", "cond_log_prob": -5.1491241455078125, "count": 2}, {"pred": "highly", "cond_log_prob": -4.77471923828125, "count": 2}, {"pred": "the", "cond_log_prob": -4.8879852294921875, "count": 2}, {"pred": "affective", "cond_log_prob": -15.815986633300781, "count": 1}, {"pred": "always", "cond_log_prob": -5.5673370361328125, "count": 1}, {"pred": "cost", "cond_log_prob": -7.08868408203125, "count": 1}, {"pred": "helpful", "cond_log_prob": -7.482177734375, "count": 1}, {"pred": "it", "cond_log_prob": -7.1878662109375, "count": 1}, {"pred": "more", "cond_log_prob": -4.6640167236328125, "count": 1}, {"pred": "still", "cond_log_prob": -3.54852294921875, "count": 2}], "ancestral_samples": [{"pred": "a", "count": 4, "cond_log_prob": -3.776214599609375}, {"pred": "already", "count": 1, "cond_log_prob": -5.7547149658203125}, {"pred": "also", "count": 9, "cond_log_prob": -3.0253448486328125}, {"pred": "available", "count": 2, "cond_log_prob": -2.4810638427734375}, {"pred": "availableThe", "count": 1, "cond_log_prob": -19.22093963623047}, {"pred": "availableroute", "count": 1, "cond_log_prob": -37.009986877441406}, {"pred": "effective", "count": 1, "cond_log_prob": -5.1491241455078125}, {"pred": "generally", "count": 2, "cond_log_prob": -3.59246826171875}, {"pred": "likely", "count": 1, "cond_log_prob": -4.8754425048828125}, {"pred": "limited", "count": 3, "cond_log_prob": -3.25701904296875}, {"pred": "most", "count": 1, "cond_log_prob": -5.560272216796875}, {"pred": "not", "count": 3, "cond_log_prob": -3.1302337646484375}, {"pred": "often", "count": 2, "cond_log_prob": -4.1142730712890625}, {"pred": "possible", "count": 1, "cond_log_prob": -3.8758697509765625}, {"pred": "still", "count": 7, "cond_log_prob": -3.54852294921875}, {"pred": "very", "count": 1, "cond_log_prob": -4.3205718994140625}]}, "17": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate", "log_prob": -91.80364990234375}, "original": {"pred": "for", "cond_log_prob": -0.5481338500976562}, "human": [{"pred": "for", "cond_log_prob": -0.5482864379882812, "count": 25}, {"pred": "in", "cond_log_prob": -2.510009765625, "count": 7}, {"pred": "when", "cond_log_prob": -2.957611083984375, "count": 6}, {"pred": "to", "cond_log_prob": -2.5550918579101562, "count": 2}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -12.395263671875}, {"pred": "for", "count": 33, "cond_log_prob": -0.5482864379882812}, {"pred": "forroute", "count": 1, "cond_log_prob": -22.433700561523438}, {"pred": "in", "count": 1, "cond_log_prob": -2.510009765625}, {"pred": "to", "count": 4, "cond_log_prob": -2.5550918579101562}]}, "18": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for", "log_prob": -92.3517837524414}, "original": {"pred": "laboratory", "cond_log_prob": -8.466285705566406}, "human": [{"pred": "other", "cond_log_prob": -5.487068176269531, "count": 7}, {"pred": "a", "cond_log_prob": -3.2538604736328125, "count": 4}, {"pred": "use", "cond_log_prob": -3.4204940795898438, "count": 4}, {"pred": "the", "cond_log_prob": -3.0920639038085938, "count": 3}, {"pred": "treating", "cond_log_prob": -4.522682189941406, "count": 3}, {"pred": "all", "cond_log_prob": -3.0989303588867188, "count": 2}, {"pred": "cleaning", "cond_log_prob": -6.370513916015625, "count": 2}, {"pred": "most", "cond_log_prob": -3.4209213256835938, "count": 2}, {"pred": "certain", "cond_log_prob": -3.35894775390625, "count": 1}, {"pred": "cleansing", "cond_log_prob": -8.395668029785156, "count": 1}, {"pred": "hospitals", "cond_log_prob": -5.239738464355469, "count": 1}, {"pred": "it", "cond_log_prob": -6.869499206542969, "count": 1}, {"pred": "many", "cond_log_prob": -4.049964904785156, "count": 1}, {"pred": "medical", "cond_log_prob": -4.105964660644531, "count": 1}, {"pred": "minor", "cond_log_prob": -7.531486511230469, "count": 1}, {"pred": "several", "cond_log_prob": -6.518135070800781, "count": 1}, {"pred": "some", "cond_log_prob": -4.096412658691406, "count": 1}, {"pred": "surgeries", "cond_log_prob": -8.142234802246094, "count": 1}, {"pred": "usage", "cond_log_prob": -8.216209411621094, "count": 1}, {"pred": "using", "cond_log_prob": -6.712074279785156, "count": 1}, {"pred": "waste", "cond_log_prob": -6.6099395751953125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 8, "cond_log_prob": -3.2538604736328125}, {"pred": "all", "count": 3, "cond_log_prob": -3.0989303588867188}, {"pred": "both", "count": 1, "cond_log_prob": -4.365730285644531}, {"pred": "certain", "count": 1, "cond_log_prob": -3.35894775390625}, {"pred": "hospitals", "count": 1, "cond_log_prob": -5.239738464355469}, {"pred": "many", "count": 1, "cond_log_prob": -4.049964904785156}, {"pred": "most", "count": 6, "cond_log_prob": -3.4209213256835938}, {"pred": "other", "count": 1, "cond_log_prob": -5.487068176269531}, {"pred": "patients", "count": 1, "cond_log_prob": -3.3434829711914062}, {"pred": "patientsroute", "count": 1, "cond_log_prob": -29.78362274169922}, {"pred": "people", "count": 2, "cond_log_prob": -3.2232742309570312}, {"pred": "some", "count": 2, "cond_log_prob": -4.096412658691406}, {"pred": "the", "count": 9, "cond_log_prob": -3.0920639038085938}, {"pred": "those", "count": 1, "cond_log_prob": -2.9233245849609375}, {"pred": "use", "count": 2, "cond_log_prob": -3.4204940795898438}]}, "19": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory", "log_prob": -100.81806945800781}, "original": {"pred": "cultures", "cond_log_prob": -5.3299560546875}, "human": [{"pred": "use", "cond_log_prob": -1.8704147338867188, "count": 9}, {"pred": "equipment", "cond_log_prob": -5.730796813964844, "count": 4}, {"pred": "experiments", "cond_log_prob": -4.2321319580078125, "count": 4}, {"pred": "procedures", "cond_log_prob": -4.106742858886719, "count": 3}, {"pred": "tools", "cond_log_prob": -8.64898681640625, "count": 3}, {"pred": "purposes", "cond_log_prob": -3.0714035034179688, "count": 2}, {"pred": "research", "cond_log_prob": -4.923774719238281, "count": 2}, {"pred": "sterilization", "cond_log_prob": -4.260551452636719, "count": 2}, {"pred": "work", "cond_log_prob": -4.1576690673828125, "count": 2}, {"pred": "cleaning", "cond_log_prob": -5.869781494140625, "count": 1}, {"pred": "f", "cond_log_prob": -8.353614807128906, "count": 1}, {"pred": "instruments", "cond_log_prob": -8.285606384277344, "count": 1}, {"pred": "office", "cond_log_prob": -10.174713134765625, "count": 1}, {"pred": "settings", "cond_log_prob": -3.6378173828125, "count": 1}, {"pred": "studies", "cond_log_prob": -4.598686218261719, "count": 1}, {"pred": "testing", "cond_log_prob": -3.4450759887695312, "count": 1}, {"pred": "usage", "cond_log_prob": -5.419960021972656, "count": 1}, {"pred": "waste", "cond_log_prob": -4.840385437011719, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -12.104049682617188}, {"pred": "and", "count": 5, "cond_log_prob": -2.7038040161132812}, {"pred": "animals", "count": 1, "cond_log_prob": -3.1020126342773438}, {"pred": "based", "count": 5, "cond_log_prob": -6.5601654052734375}, {"pred": "environments", "count": 1, "cond_log_prob": -4.335838317871094}, {"pred": "facilities", "count": 1, "cond_log_prob": -5.530525207519531}, {"pred": "grown", "count": 1, "cond_log_prob": -9.416893005371094}, {"pred": "hospitals", "count": 1, "cond_log_prob": -7.486518859863281}, {"pred": "or", "count": 2, "cond_log_prob": -2.9374313354492188}, {"pred": "purposes", "count": 1, "cond_log_prob": -3.0714035034179688}, {"pred": "route", "count": 1, "cond_log_prob": -15.372459411621094}, {"pred": "settings", "count": 1, "cond_log_prob": -3.6378173828125}, {"pred": "settingsThis", "count": 1, "cond_log_prob": -20.96576690673828}, {"pred": "use", "count": 4, "cond_log_prob": -1.8704147338867188}, {"pred": "useA", "count": 1, "cond_log_prob": -17.589210510253906}, {"pred": "useC", "count": 1, "cond_log_prob": -18.254501342773438}, {"pred": "useFor", "count": 1, "cond_log_prob": -18.322059631347656}, {"pred": "useIn", "count": 1, "cond_log_prob": -18.067955017089844}, {"pred": "useIt", "count": 1, "cond_log_prob": -18.298912048339844}, {"pred": "useOne", "count": 1, "cond_log_prob": -20.848403930664062}, {"pred": "usePro", "count": 1, "cond_log_prob": -22.113792419433594}, {"pred": "useThe", "count": 5, "cond_log_prob": -17.21831512451172}, {"pred": "useThere", "count": 1, "cond_log_prob": -18.807418823242188}, {"pred": "useThis", "count": 1, "cond_log_prob": -18.655075073242188}]}, "20": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures", "log_prob": -106.14802551269531}, "original": {"pred": "and", "cond_log_prob": -1.9261550903320312}, "human": [{"pred": "and", "cond_log_prob": -1.92633056640625, "count": 18}, {"pred": "in", "cond_log_prob": -4.211585998535156, "count": 6}, {"pred": "that", "cond_log_prob": -2.5570907592773438, "count": 5}, {"pred": "----------------------------------------------------", "cond_log_prob": -21.381195068359375, "count": 2}, {"pred": "because", "cond_log_prob": -5.538017272949219, "count": 2}, {"pred": "always", "cond_log_prob": -11.219551086425781, "count": 1}, {"pred": "as", "cond_log_prob": -4.157752990722656, "count": 1}, {"pred": "research", "cond_log_prob": -12.462196350097656, "count": 1}, {"pred": "to", "cond_log_prob": -4.0839080810546875, "count": 1}, {"pred": "using", "cond_log_prob": -6.283607482910156, "count": 1}, {"pred": "waste", "cond_log_prob": -12.9163818359375, "count": 1}, {"pred": "where", "cond_log_prob": -3.8275985717773438, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 3, "cond_log_prob": -11.741813659667969}, {"pred": "B", "count": 1, "cond_log_prob": -12.911033630371094}, {"pred": "How", "count": 1, "cond_log_prob": -15.150611877441406}, {"pred": "In", "count": 2, "cond_log_prob": -13.545967102050781}, {"pred": "It", "count": 1, "cond_log_prob": -12.731010437011719}, {"pred": "Ster", "count": 1, "cond_log_prob": -16.67835235595703}, {"pred": "Surgical", "count": 1, "cond_log_prob": -13.834571838378906}, {"pred": "The", "count": 14, "cond_log_prob": -10.624168395996094}, {"pred": "We", "count": 1, "cond_log_prob": -13.610061645507812}, {"pred": "What", "count": 1, "cond_log_prob": -14.704399108886719}, {"pred": "and", "count": 7, "cond_log_prob": -1.92633056640625}, {"pred": "as", "count": 1, "cond_log_prob": -4.157752990722656}, {"pred": "or", "count": 1, "cond_log_prob": -4.019584655761719}, {"pred": "such", "count": 2, "cond_log_prob": -3.8423690795898438}, {"pred": "that", "count": 1, "cond_log_prob": -2.5570907592773438}, {"pred": "thatroute", "count": 1, "cond_log_prob": -24.190933227539062}, {"pred": "where", "count": 1, "cond_log_prob": -3.8275985717773438}]}, "21": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and", "log_prob": -108.07418060302734}, "original": {"pred": "substances", "cond_log_prob": -8.651947021484375}, "human": [{"pred": "other", "cond_log_prob": -3.407470703125, "count": 13}, {"pred": "experiments", "cond_log_prob": -6.3614349365234375, "count": 3}, {"pred": "research", "cond_log_prob": -6.0838775634765625, "count": 3}, {"pred": "medical", "cond_log_prob": -3.7283859252929688, "count": 2}, {"pred": "also", "cond_log_prob": -6.259422302246094, "count": 1}, {"pred": "cleaning", "cond_log_prob": -6.8064727783203125, "count": 1}, {"pred": "countries", "cond_log_prob": -9.021507263183594, "count": 1}, {"pred": "cures", "cond_log_prob": -8.799240112304688, "count": 1}, {"pred": "dishes", "cond_log_prob": -8.66705322265625, "count": 1}, {"pred": "environments", "cond_log_prob": -6.0148162841796875, "count": 1}, {"pred": "equipment", "cond_log_prob": -6.0586090087890625, "count": 1}, {"pred": "for", "cond_log_prob": -2.27423095703125, "count": 1}, {"pred": "instruments", "cond_log_prob": -7.55609130859375, "count": 2}, {"pred": "it", "cond_log_prob": -7.1450958251953125, "count": 1}, {"pred": "procedures", "cond_log_prob": -5.5140380859375, "count": 1}, {"pred": "rooms", "cond_log_prob": -8.682525634765625, "count": 1}, {"pred": "surgary", "cond_log_prob": -24.008949279785156, "count": 1}, {"pred": "this", "cond_log_prob": -8.05755615234375, "count": 1}, {"pred": "tools", "cond_log_prob": -7.947044372558594, "count": 1}, {"pred": "treatment", "cond_log_prob": -5.989204406738281, "count": 1}, {"pred": "use", "cond_log_prob": -5.5184326171875, "count": 1}, {"pred": "waste", "cond_log_prob": -5.6695404052734375, "count": 1}], "ancestral_samples": [{"pred": "biological", "count": 1, "cond_log_prob": -5.4876251220703125}, {"pred": "for", "count": 32, "cond_log_prob": -2.27423095703125}, {"pred": "forroute", "count": 1, "cond_log_prob": -23.34980010986328}, {"pred": "hospitalsIn", "count": 1, "cond_log_prob": -20.796653747558594}, {"pred": "in", "count": 1, "cond_log_prob": -3.7953033447265625}, {"pred": "other", "count": 3, "cond_log_prob": -3.407470703125}, {"pred": "the", "count": 1, "cond_log_prob": -4.231361389160156}]}, "22": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances", "log_prob": -116.72612762451172}, "original": {"pred": "contaminated", "cond_log_prob": -6.157798767089844}, "human": [{"pred": "that", "cond_log_prob": -1.1129608154296875, "count": 22}, {"pred": "found", "cond_log_prob": -4.999992370605469, "count": 2}, {"pred": "in", "cond_log_prob": -4.2577972412109375, "count": 3}, {"pred": "used", "cond_log_prob": -2.1789398193359375, "count": 2}, {"pred": "which", "cond_log_prob": -4.34747314453125, "count": 2}, {"pred": "abuse", "cond_log_prob": -12.600288391113281, "count": 1}, {"pred": "and", "cond_log_prob": -5.1578826904296875, "count": 1}, {"pred": "because", "cond_log_prob": -8.262771606445312, "count": 1}, {"pred": "if", "cond_log_prob": -7.77276611328125, "count": 1}, {"pred": "needed", "cond_log_prob": -4.9672393798828125, "count": 1}, {"pred": "occasionally", "cond_log_prob": -10.537979125976562, "count": 1}, {"pred": "of", "cond_log_prob": -3.3494415283203125, "count": 1}, {"pred": "such", "cond_log_prob": -2.6145095825195312, "count": 1}, {"pred": "to", "cond_log_prob": -4.036766052246094, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -11.075859069824219}, {"pred": "such", "count": 2, "cond_log_prob": -2.6145095825195312}, {"pred": "that", "count": 30, "cond_log_prob": -1.1129608154296875}, {"pred": "thatroute", "count": 1, "cond_log_prob": -22.90686798095703}, {"pred": "to", "count": 1, "cond_log_prob": -4.036766052246094}, {"pred": "used", "count": 5, "cond_log_prob": -2.1789398193359375}]}, "23": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated", "log_prob": -122.88392639160156}, "original": {"pred": "with", "cond_log_prob": -0.21247100830078125}, "human": [{"pred": "by", "cond_log_prob": -2.0958480834960938, "count": 20}, {"pred": "with", "cond_log_prob": -0.2126617431640625, "count": 10}, {"pred": "in", "cond_log_prob": -4.614631652832031, "count": 6}, {"pred": "during", "cond_log_prob": -5.4510955810546875, "count": 2}, {"pred": "after", "cond_log_prob": -6.98883056640625, "count": 1}, {"pred": "the", "cond_log_prob": -8.327285766601562, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -13.403335571289062}, {"pred": "by", "count": 2, "cond_log_prob": -2.0958480834960938}, {"pred": "with", "count": 36, "cond_log_prob": -0.2126617431640625}, {"pred": "withroute", "count": 1, "cond_log_prob": -23.04754638671875}]}, "24": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with", "log_prob": -123.09639739990234}, "original": {"pred": "infectious", "cond_log_prob": -4.1462249755859375}, "human": [{"pred": "bacteria", "cond_log_prob": -2.3278427124023438, "count": 8}, {"pred": "germs", "cond_log_prob": -5.471107482910156, "count": 3}, {"pred": "a", "cond_log_prob": -4.3633880615234375, "count": 2}, {"pred": "blood", "cond_log_prob": -5.534950256347656, "count": 3}, {"pred": "different", "cond_log_prob": -6.795158386230469, "count": 2}, {"pred": "harmful", "cond_log_prob": -5.140052795410156, "count": 2}, {"pred": "biohazardous", "cond_log_prob": -8.934974670410156, "count": 1}, {"pred": "biological", "cond_log_prob": -5.674079895019531, "count": 1}, {"pred": "chemicals", "cond_log_prob": -4.0458526611328125, "count": 1}, {"pred": "dangerous", "cond_log_prob": -6.027565002441406, "count": 1}, {"pred": "debris", "cond_log_prob": -8.736488342285156, "count": 1}, {"pred": "disease", "cond_log_prob": -6.710182189941406, "count": 1}, {"pred": "harsh", "cond_log_prob": -9.058753967285156, "count": 1}, {"pred": "hazardous", "cond_log_prob": -4.713584899902344, "count": 1}, {"pred": "human", "cond_log_prob": -2.771636962890625, "count": 1}, {"pred": "i", "cond_log_prob": -10.235450744628906, "count": 1}, {"pred": "liquid", "cond_log_prob": -6.856544494628906, "count": 1}, {"pred": "medical", "cond_log_prob": -6.432777404785156, "count": 1}, {"pred": "other", "cond_log_prob": -4.7427825927734375, "count": 1}, {"pred": "radioactive", "cond_log_prob": -4.2229766845703125, "count": 1}, {"pred": "something", "cond_log_prob": -8.514289855957031, "count": 1}, {"pred": "steam", "cond_log_prob": -6.512748718261719, "count": 1}, {"pred": "the", "cond_log_prob": -3.5203628540039062, "count": 1}, {"pred": "toxic", "cond_log_prob": -3.8354339599609375, "count": 1}, {"pred": "various", "cond_log_prob": -5.880989074707031, "count": 1}, {"pred": "waste", "cond_log_prob": -5.392219543457031, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -4.3633880615234375}, {"pred": "bacteria", "count": 3, "cond_log_prob": -2.3278427124023438}, {"pred": "bacteriaIn", "count": 1, "cond_log_prob": -18.08960723876953}, {"pred": "bacteriaIt", "count": 1, "cond_log_prob": -17.09947967529297}, {"pred": "biological", "count": 1, "cond_log_prob": -5.674079895019531}, {"pred": "genetically", "count": 1, "cond_log_prob": -7.654121398925781}, {"pred": "human", "count": 16, "cond_log_prob": -2.771636962890625}, {"pred": "pathogens", "count": 2, "cond_log_prob": -3.4870452880859375}, {"pred": "pathogensAs", "count": 1, "cond_log_prob": -19.712989807128906}, {"pred": "pathogensIn", "count": 1, "cond_log_prob": -19.60509490966797}, {"pred": "pathogensThe", "count": 1, "cond_log_prob": -17.330421447753906}, {"pred": "pathogensThis", "count": 1, "cond_log_prob": -19.37982940673828}, {"pred": "pharmaceutical", "count": 1, "cond_log_prob": -5.673606872558594}, {"pred": "protonproton", "count": 1, "cond_log_prob": -20.408363342285156}, {"pred": "radioactiveroute", "count": 1, "cond_log_prob": -42.53588104248047}, {"pred": "the", "count": 3, "cond_log_prob": -3.5203628540039062}, {"pred": "virusThe", "count": 1, "cond_log_prob": -20.867759704589844}, {"pred": "viruses", "count": 2, "cond_log_prob": -3.4349899291992188}]}, "25": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious", "log_prob": -127.24262237548828}, "original": {"pred": "organisms.", "cond_log_prob": -3.6058731079101562}, "human": [{"pred": "diseases", "cond_log_prob": -2.4044723510742188, "count": 15}, {"pred": "bacteria", "cond_log_prob": -2.5651168823242188, "count": 8}, {"pred": "disease", "cond_log_prob": -3.4000015258789062, "count": 3}, {"pred": "viruses", "cond_log_prob": -3.4475631713867188, "count": 3}, {"pred": "substances", "cond_log_prob": -3.3974838256835938, "count": 2}, {"pred": "agents", "cond_log_prob": -1.3393478393554688, "count": 1}, {"pred": "and", "cond_log_prob": -3.7665176391601562, "count": 1}, {"pred": "chemicals", "cond_log_prob": -5.715614318847656, "count": 1}, {"pred": "cultures", "cond_log_prob": -8.414222717285156, "count": 1}, {"pred": "germs", "cond_log_prob": -5.093559265136719, "count": 1}, {"pred": "matter", "cond_log_prob": -6.952537536621094, "count": 1}, {"pred": "microorganisms", "cond_log_prob": -5.615165710449219, "count": 1}, {"pred": "once", "cond_log_prob": -13.086082458496094, "count": 1}, {"pred": "pathogens", "cond_log_prob": -2.8096237182617188, "count": 1}], "ancestral_samples": [{"pred": "agents", "count": 3, "cond_log_prob": -1.3393478393554688}, {"pred": "agentsC", "count": 1, "cond_log_prob": -15.951896667480469}, {"pred": "agentsDr", "count": 1, "cond_log_prob": -18.32514190673828}, {"pred": "agentsFor", "count": 2, "cond_log_prob": -18.47197723388672}, {"pred": "agentsIn", "count": 3, "cond_log_prob": -17.73413848876953}, {"pred": "agentsIt", "count": 1, "cond_log_prob": -16.56177520751953}, {"pred": "agentsOne", "count": 1, "cond_log_prob": -19.36457061767578}, {"pred": "agentsThe", "count": 7, "cond_log_prob": -15.594062805175781}, {"pred": "agentsThere", "count": 1, "cond_log_prob": -17.662879943847656}, {"pred": "agentsThis", "count": 1, "cond_log_prob": -17.308250427246094}, {"pred": "agentsWhat", "count": 1, "cond_log_prob": -18.20526885986328}, {"pred": "bacteria", "count": 2, "cond_log_prob": -2.5651168823242188}, {"pred": "diseases", "count": 1, "cond_log_prob": -2.4044723510742188}, {"pred": "diseasesThe", "count": 5, "cond_log_prob": -16.120079040527344}, {"pred": "diseasesroute", "count": 1, "cond_log_prob": -25.42552947998047}, {"pred": "or", "count": 1, "cond_log_prob": -2.7389755249023438}, {"pred": "organismsThis", "count": 1, "cond_log_prob": -19.05040740966797}, {"pred": "pathogens", "count": 2, "cond_log_prob": -2.8096237182617188}, {"pred": "pathogensA", "count": 1, "cond_log_prob": -16.24567413330078}, {"pred": "pathogensAs", "count": 1, "cond_log_prob": -18.814491271972656}, {"pred": "substancesThe", "count": 1, "cond_log_prob": -18.067298889160156}, {"pred": "virusThe", "count": 1, "cond_log_prob": -19.59937286376953}, {"pred": "viruses", "count": 1, "cond_log_prob": -3.4475631713867188}]}, "26": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms.", "log_prob": -130.84849548339844}, "original": {"pred": "The", "cond_log_prob": -2.686553955078125}, "human": [{"pred": "it", "cond_log_prob": -11.072341918945312, "count": 10}, {"pred": "steam", "cond_log_prob": -13.143157958984375, "count": 4}, {"pred": "the", "cond_log_prob": -9.717330932617188, "count": 4}, {"pred": "however", "cond_log_prob": -13.95941162109375, "count": 3}, {"pred": "this", "cond_log_prob": -12.698760986328125, "count": 3}, {"pred": ".", "cond_log_prob": -8.884078979492188, "count": 1}, {"pred": "?", "cond_log_prob": -12.462783813476562, "count": 1}, {"pred": "all", "cond_log_prob": -13.927764892578125, "count": 1}, {"pred": "also", "cond_log_prob": -12.145553588867188, "count": 1}, {"pred": "because", "cond_log_prob": -12.552108764648438, "count": 1}, {"pred": "had", "cond_log_prob": -15.63653564453125, "count": 1}, {"pred": "likewise", "cond_log_prob": -18.035797119140625, "count": 1}, {"pred": "many", "cond_log_prob": -14.3602294921875, "count": 1}, {"pred": "now", "cond_log_prob": -15.374176025390625, "count": 1}, {"pred": "so", "cond_log_prob": -13.0267333984375, "count": 1}, {"pred": "such", "cond_log_prob": -14.1964111328125, "count": 1}, {"pred": "that", "cond_log_prob": -12.672210693359375, "count": 1}, {"pred": "therefore", "cond_log_prob": -14.94110107421875, "count": 1}, {"pred": "they", "cond_log_prob": -14.45916748046875, "count": 1}, {"pred": "thoguh", "cond_log_prob": -33.921722412109375, "count": 1}, {"pred": "what", "cond_log_prob": -14.50091552734375, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 2, "cond_log_prob": -3.9045562744140625}, {"pred": "Dr", "count": 1, "cond_log_prob": -6.9290924072265625}, {"pred": "Identification", "count": 1, "cond_log_prob": -10.064315795898438}, {"pred": "In", "count": 4, "cond_log_prob": -3.6223907470703125}, {"pred": "It", "count": 1, "cond_log_prob": -2.9916534423828125}, {"pred": "Other", "count": 1, "cond_log_prob": -6.3146209716796875}, {"pred": "Some", "count": 1, "cond_log_prob": -4.9956512451171875}, {"pred": "Stirring", "count": 1, "cond_log_prob": -12.900650024414062}, {"pred": "The", "count": 25, "cond_log_prob": -2.6867828369140625}, {"pred": "Were", "count": 1, "cond_log_prob": -10.927169799804688}, {"pred": "What", "count": 1, "cond_log_prob": -6.4286651611328125}, {"pred": "route", "count": 1, "cond_log_prob": -20.619598388671875}]}, "27": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The", "log_prob": -133.53504943847656}, "original": {"pred": "waste", "cond_log_prob": -5.7733001708984375}, "human": [{"pred": "process", "cond_log_prob": -4.1963348388671875, "count": 8}, {"pred": "best", "cond_log_prob": -4.8248138427734375, "count": 5}, {"pred": "steam", "cond_log_prob": -5.5482177734375, "count": 5}, {"pred": "sterilization", "cond_log_prob": -2.7860565185546875, "count": 4}, {"pred": "a", "cond_log_prob": -8.330368041992188, "count": 1}, {"pred": "contamination", "cond_log_prob": -7.0640106201171875, "count": 1}, {"pred": "difference", "cond_log_prob": -7.4632415771484375, "count": 1}, {"pred": "experts", "cond_log_prob": -9.389190673828125, "count": 1}, {"pred": "latest", "cond_log_prob": -6.96417236328125, "count": 1}, {"pred": "number", "cond_log_prob": -5.4507293701171875, "count": 1}, {"pred": "only", "cond_log_prob": -4.3078155517578125, "count": 2}, {"pred": "organisms", "cond_log_prob": -9.643661499023438, "count": 1}, {"pred": "procedure", "cond_log_prob": -4.5309600830078125, "count": 1}, {"pred": "question", "cond_log_prob": -7.2241058349609375, "count": 1}, {"pred": "reason", "cond_log_prob": -6.4334716796875, "count": 1}, {"pred": "sterilzation", "cond_log_prob": -16.770492553710938, "count": 1}, {"pred": "test", "cond_log_prob": -6.4058074951171875, "count": 1}, {"pred": "treatment", "cond_log_prob": -5.3310699462890625, "count": 1}, {"pred": "type", "cond_log_prob": -4.93023681640625, "count": 1}, {"pred": "way", "cond_log_prob": -7.0528411865234375, "count": 1}, {"pred": "ways", "cond_log_prob": -9.714996337890625, "count": 1}], "ancestral_samples": [{"pred": "Centers", "count": 1, "cond_log_prob": -6.23773193359375}, {"pred": "FDA", "count": 1, "cond_log_prob": -3.6611480712890625}, {"pred": "FDAroute", "count": 1, "cond_log_prob": -37.51414489746094}, {"pred": "US", "count": 1, "cond_log_prob": -6.148040771484375}, {"pred": "amount", "count": 3, "cond_log_prob": -4.47540283203125}, {"pred": "current", "count": 1, "cond_log_prob": -5.6678924560546875}, {"pred": "goal", "count": 2, "cond_log_prob": -4.43524169921875}, {"pred": "most", "count": 3, "cond_log_prob": -4.1371612548828125}, {"pred": "only", "count": 2, "cond_log_prob": -4.3078155517578125}, {"pred": "procedure", "count": 2, "cond_log_prob": -4.5309600830078125}, {"pred": "process", "count": 1, "cond_log_prob": -4.1963348388671875}, {"pred": "prophylactic", "count": 1, "cond_log_prob": -9.4759521484375}, {"pred": "standard", "count": 1, "cond_log_prob": -4.5954742431640625}, {"pred": "sterilization", "count": 13, "cond_log_prob": -2.7860565185546875}, {"pred": "term", "count": 1, "cond_log_prob": -5.2500762939453125}, {"pred": "type", "count": 1, "cond_log_prob": -4.93023681640625}, {"pred": "use", "count": 5, "cond_log_prob": -4.2305145263671875}]}, "28": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste", "log_prob": -139.308349609375}, "original": {"pred": "is", "cond_log_prob": -1.723724365234375}, "human": [{"pred": "is", "cond_log_prob": -1.723968505859375, "count": 14}, {"pred": "can", "cond_log_prob": -1.3131103515625, "count": 10}, {"pred": "of", "cond_log_prob": -4.5168609619140625, "count": 4}, {"pred": "that", "cond_log_prob": -3.9056549072265625, "count": 4}, {"pred": "products", "cond_log_prob": -5.1167144775390625, "count": 2}, {"pred": "bird", "cond_log_prob": -14.037506103515625, "count": 1}, {"pred": "must", "cond_log_prob": -2.706817626953125, "count": 1}, {"pred": "not", "cond_log_prob": -6.684783935546875, "count": 1}, {"pred": "on", "cond_log_prob": -7.4887542724609375, "count": 1}, {"pred": "produced", "cond_log_prob": -5.636077880859375, "count": 1}, {"pred": "treatment", "cond_log_prob": -5.6492156982421875, "count": 1}], "ancestral_samples": [{"pred": "can", "count": 21, "cond_log_prob": -1.3131103515625}, {"pred": "canroute", "count": 1, "cond_log_prob": -22.010711669921875}, {"pred": "is", "count": 16, "cond_log_prob": -1.723968505859375}, {"pred": "must", "count": 2, "cond_log_prob": -2.706817626953125}]}, "29": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is", "log_prob": -141.03207397460938}, "original": {"pred": "subjected", "cond_log_prob": -7.3369598388671875}, "human": [{"pred": "then", "cond_log_prob": -2.51611328125, "count": 10}, {"pred": "not", "cond_log_prob": -3.47625732421875, "count": 4}, {"pred": "treated", "cond_log_prob": -3.8113861083984375, "count": 4}, {"pred": "very", "cond_log_prob": -6.6442108154296875, "count": 3}, {"pred": "a", "cond_log_prob": -5.369598388671875, "count": 1}, {"pred": "also", "cond_log_prob": -3.987396240234375, "count": 1}, {"pred": "available", "cond_log_prob": -6.068359375, "count": 1}, {"pred": "bad", "cond_log_prob": -10.586105346679688, "count": 1}, {"pred": "considered", "cond_log_prob": -4.887786865234375, "count": 1}, {"pred": "disposed", "cond_log_prob": -4.65985107421875, "count": 1}, {"pred": "easily", "cond_log_prob": -6.1190643310546875, "count": 1}, {"pred": "easy", "cond_log_prob": -8.303329467773438, "count": 1}, {"pred": "eliminated", "cond_log_prob": -6.770599365234375, "count": 1}, {"pred": "first", "cond_log_prob": -6.2635040283203125, "count": 1}, {"pred": "full", "cond_log_prob": -9.582168579101562, "count": 1}, {"pred": "highly", "cond_log_prob": -6.4558563232421875, "count": 1}, {"pred": "limited", "cond_log_prob": -6.5912322998046875, "count": 1}, {"pred": "named", "cond_log_prob": -8.836532592773438, "count": 1}, {"pred": "resistant", "cond_log_prob": -9.690658569335938, "count": 1}, {"pred": "studied", "cond_log_prob": -8.839340209960938, "count": 1}, {"pred": "the", "cond_log_prob": -6.023834228515625, "count": 1}, {"pred": "toxic", "cond_log_prob": -7.233642578125, "count": 1}, {"pred": "used", "cond_log_prob": -4.39013671875, "count": 1}], "ancestral_samples": [{"pred": "also", "count": 4, "cond_log_prob": -3.987396240234375}, {"pred": "cleaned", "count": 1, "cond_log_prob": -3.578399658203125}, {"pred": "collected", "count": 1, "cond_log_prob": -3.665283203125}, {"pred": "excreted", "count": 1, "cond_log_prob": -6.430267333984375}, {"pred": "not", "count": 4, "cond_log_prob": -3.47625732421875}, {"pred": "often", "count": 1, "cond_log_prob": -4.521331787109375}, {"pred": "removed", "count": 1, "cond_log_prob": -3.76080322265625}, {"pred": "stored", "count": 2, "cond_log_prob": -3.6650238037109375}, {"pred": "storedroute", "count": 1, "cond_log_prob": -28.11309814453125}, {"pred": "then", "count": 20, "cond_log_prob": -2.51611328125}, {"pred": "used", "count": 2, "cond_log_prob": -4.39013671875}, {"pred": "usually", "count": 2, "cond_log_prob": -3.4680938720703125}]}, "30": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected", "log_prob": -148.36903381347656}, "original": {"pred": "to", "cond_log_prob": -0.0345001220703125}, "human": [{"pred": "to", "cond_log_prob": -0.0347442626953125, "count": 39}, {"pred": "ronnie", "cond_log_prob": -34.75123596191406, "count": 1}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.0347442626953125}, {"pred": "toroute", "count": 1, "cond_log_prob": -30.817825317382812}]}, "31": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to", "log_prob": -148.40353393554688}, "original": {"pred": "steam", "cond_log_prob": -5.400848388671875}, "human": [{"pred": "the", "cond_log_prob": -3.11187744140625, "count": 7}, {"pred": "a", "cond_log_prob": -1.587799072265625, "count": 5}, {"pred": "steam", "cond_log_prob": -5.401123046875, "count": 4}, {"pred": "high", "cond_log_prob": -4.74176025390625, "count": 3}, {"pred": "several", "cond_log_prob": -5.532135009765625, "count": 2}, {"pred": "250", "cond_log_prob": -9.99951171875, "count": 1}, {"pred": "an", "cond_log_prob": -3.13897705078125, "count": 1}, {"pred": "bacterial", "cond_log_prob": -6.207550048828125, "count": 1}, {"pred": "be", "cond_log_prob": -8.076568603515625, "count": 1}, {"pred": "change", "cond_log_prob": -10.005767822265625, "count": 1}, {"pred": "different", "cond_log_prob": -6.418365478515625, "count": 1}, {"pred": "extreme", "cond_log_prob": -6.04144287109375, "count": 1}, {"pred": "further", "cond_log_prob": -7.0223388671875, "count": 1}, {"pred": "he", "cond_log_prob": -10.61248779296875, "count": 1}, {"pred": "heat", "cond_log_prob": -4.41717529296875, "count": 1}, {"pred": "large", "cond_log_prob": -7.476806640625, "count": 1}, {"pred": "many", "cond_log_prob": -6.89605712890625, "count": 1}, {"pred": "molecules", "cond_log_prob": -12.185516357421875, "count": 1}, {"pred": "research", "cond_log_prob": -8.27691650390625, "count": 1}, {"pred": "severe", "cond_log_prob": -7.0726318359375, "count": 1}, {"pred": "sterilization", "cond_log_prob": -3.13037109375, "count": 1}, {"pred": "sterlilization", "cond_log_prob": -27.733489990234375, "count": 1}, {"pred": "temperatures", "cond_log_prob": -5.74481201171875, "count": 1}, {"pred": "various", "cond_log_prob": -4.725494384765625, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 36, "cond_log_prob": -1.587799072265625}, {"pred": "anroute", "count": 1, "cond_log_prob": -24.279052734375}, {"pred": "disinfection", "count": 1, "cond_log_prob": -4.27716064453125}, {"pred": "the", "count": 2, "cond_log_prob": -3.11187744140625}]}, "32": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam", "log_prob": -153.80438232421875}, "original": {"pred": "in", "cond_log_prob": -6.5780792236328125}, "human": [{"pred": "and", "cond_log_prob": -5.1331787109375, "count": 14}, {"pred": "sterilization", "cond_log_prob": -0.11151123046875, "count": 12}, {"pred": "at", "cond_log_prob": -7.391204833984375, "count": 3}, {"pred": "for", "cond_log_prob": -6.074188232421875, "count": 2}, {"pred": "as", "cond_log_prob": -7.309173583984375, "count": 1}, {"pred": "lived", "cond_log_prob": -18.00213623046875, "count": 1}, {"pred": "pressurized", "cond_log_prob": -15.3277587890625, "count": 1}, {"pred": "sterilzation", "cond_log_prob": -15.06591796875, "count": 1}, {"pred": "sterlilization", "cond_log_prob": -30.86431884765625, "count": 1}, {"pred": "that", "cond_log_prob": -8.6915283203125, "count": 1}, {"pred": "under", "cond_log_prob": -8.1534423828125, "count": 1}, {"pred": "when", "cond_log_prob": -8.9154052734375, "count": 1}, {"pred": "which", "cond_log_prob": -8.780303955078125, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -14.593292236328125}, {"pred": "or", "count": 1, "cond_log_prob": -5.670318603515625}, {"pred": "sterilization", "count": 36, "cond_log_prob": -0.11151123046875}, {"pred": "sterilroute", "count": 1, "cond_log_prob": -25.02508544921875}, {"pred": "treatment", "count": 1, "cond_log_prob": -4.737152099609375}]}, "33": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in", "log_prob": -160.38246154785156}, "original": {"pred": "a", "cond_log_prob": -1.2816314697265625}, "human": [{"pred": "a", "cond_log_prob": -1.2819061279296875, "count": 13}, {"pred": "the", "cond_log_prob": -1.7454071044921875, "count": 6}, {"pred": "high", "cond_log_prob": -6.5684356689453125, "count": 3}, {"pred": "different", "cond_log_prob": -5.6028900146484375, "count": 2}, {"pred": "small", "cond_log_prob": -5.3478546142578125, "count": 2}, {"pred": "all", "cond_log_prob": -5.6990814208984375, "count": 1}, {"pred": "an", "cond_log_prob": -2.7683258056640625, "count": 1}, {"pred": "attempt", "cond_log_prob": -11.277328491210938, "count": 1}, {"pred": "certain", "cond_log_prob": -6.6528472900390625, "count": 1}, {"pred": "extreme", "cond_log_prob": -8.008468627929688, "count": 1}, {"pred": "in", "cond_log_prob": -8.407119750976562, "count": 1}, {"pred": "increments", "cond_log_prob": -8.917617797851562, "count": 1}, {"pred": "most", "cond_log_prob": -6.5290069580078125, "count": 1}, {"pred": "short", "cond_log_prob": -8.479141235351562, "count": 1}, {"pred": "specialized", "cond_log_prob": -8.470718383789062, "count": 1}, {"pred": "sterilization", "cond_log_prob": -4.9467315673828125, "count": 1}, {"pred": "various", "cond_log_prob": -4.6345977783203125, "count": 1}, {"pred": "vast", "cond_log_prob": -9.858016967773438, "count": 1}, {"pred": "very", "cond_log_prob": -6.5691375732421875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 22, "cond_log_prob": -1.2819061279296875}, {"pred": "hospitals", "count": 1, "cond_log_prob": -7.1862030029296875}, {"pred": "the", "count": 16, "cond_log_prob": -1.7454071044921875}, {"pred": "theroute", "count": 1, "cond_log_prob": -32.51438903808594}]}, "34": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a", "log_prob": -161.66409301757812}, "original": {"pred": "sealed,", "cond_log_prob": -6.051605224609375}, "human": [{"pred": "controlled", "cond_log_prob": -3.9830322265625, "count": 5}, {"pred": "closed", "cond_log_prob": -4.450042724609375, "count": 4}, {"pred": "room", "cond_log_prob": -5.3074951171875, "count": 3}, {"pred": "container", "cond_log_prob": -5.171478271484375, "count": 2}, {"pred": "high", "cond_log_prob": -5.27734375, "count": 2}, {"pred": "hot", "cond_log_prob": -5.200347900390625, "count": 2}, {"pred": "laboratory", "cond_log_prob": -3.676116943359375, "count": 2}, {"pred": "large", "cond_log_prob": -4.89056396484375, "count": 2}, {"pred": "small", "cond_log_prob": -4.9114990234375, "count": 2}, {"pred": "a", "cond_log_prob": -8.095062255859375, "count": 1}, {"pred": "box", "cond_log_prob": -8.090484619140625, "count": 1}, {"pred": "certain", "cond_log_prob": -7.061859130859375, "count": 1}, {"pred": "chamber", "cond_log_prob": -4.128875732421875, "count": 1}, {"pred": "enclosed", "cond_log_prob": -7.5626220703125, "count": 1}, {"pred": "highly", "cond_log_prob": -6.3125, "count": 1}, {"pred": "machine", "cond_log_prob": -4.97235107421875, "count": 2}, {"pred": "procedure", "cond_log_prob": -6.57696533203125, "count": 1}, {"pred": "smaller", "cond_log_prob": -8.557342529296875, "count": 1}, {"pred": "specialized", "cond_log_prob": -6.56256103515625, "count": 1}, {"pred": "sterile", "cond_log_prob": -4.10333251953125, "count": 1}, {"pred": "sterilized", "cond_log_prob": -3.196868896484375, "count": 1}, {"pred": "vacuum", "cond_log_prob": -3.5316162109375, "count": 1}, {"pred": "various", "cond_log_prob": -9.482818603515625, "count": 1}, {"pred": "vat", "cond_log_prob": -6.878387451171875, "count": 1}], "ancestral_samples": [{"pred": "centrifuge", "count": 5, "cond_log_prob": -4.36761474609375}, {"pred": "chamber", "count": 1, "cond_log_prob": -4.128875732421875}, {"pred": "chlorinebased", "count": 1, "cond_log_prob": -20.76849365234375}, {"pred": "closed", "count": 5, "cond_log_prob": -4.450042724609375}, {"pred": "closedroute", "count": 1, "cond_log_prob": -27.702667236328125}, {"pred": "confined", "count": 1, "cond_log_prob": -6.02093505859375}, {"pred": "cooling", "count": 2, "cond_log_prob": -5.99700927734375}, {"pred": "greenhouse", "count": 1, "cond_log_prob": -4.942535400390625}, {"pred": "laboratory", "count": 2, "cond_log_prob": -3.676116943359375}, {"pred": "large", "count": 1, "cond_log_prob": -4.89056396484375}, {"pred": "liquid", "count": 1, "cond_log_prob": -4.548492431640625}, {"pred": "process", "count": 1, "cond_log_prob": -4.156768798828125}, {"pred": "sealed", "count": 3, "cond_log_prob": -3.43438720703125}, {"pred": "special", "count": 1, "cond_log_prob": -4.638275146484375}, {"pred": "steam", "count": 4, "cond_log_prob": -3.7178955078125}, {"pred": "steamoperated", "count": 1, "cond_log_prob": -16.67755126953125}, {"pred": "sterilized", "count": 2, "cond_log_prob": -3.196868896484375}, {"pred": "vacuum", "count": 3, "cond_log_prob": -3.5316162109375}, {"pred": "ventilator", "count": 1, "cond_log_prob": -7.893310546875}, {"pred": "way", "count": 1, "cond_log_prob": -4.14715576171875}, {"pred": "well", "count": 2, "cond_log_prob": -5.4232177734375}]}, "35": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed,", "log_prob": -167.7156982421875}, "original": {"pred": "pressurized", "cond_log_prob": -7.627960205078125}, "human": [{"pred": "airtight", "cond_log_prob": -3.747314453125, "count": 6}, {"pred": "container", "cond_log_prob": -6.0386962890625, "count": 6}, {"pred": "closed", "cond_log_prob": -4.439483642578125, "count": 3}, {"pred": "and", "cond_log_prob": -6.628448486328125, "count": 2}, {"pred": "clean", "cond_log_prob": -4.490203857421875, "count": 2}, {"pred": "plastic", "cond_log_prob": -4.384796142578125, "count": 2}, {"pred": "air", "cond_log_prob": -3.28509521484375, "count": 1}, {"pred": "cage", "cond_log_prob": -8.4354248046875, "count": 1}, {"pred": "clear", "cond_log_prob": -5.922210693359375, "count": 1}, {"pred": "contained", "cond_log_prob": -8.4625244140625, "count": 1}, {"pred": "controlled", "cond_log_prob": -5.211761474609375, "count": 1}, {"pred": "enclosed", "cond_log_prob": -4.141571044921875, "count": 1}, {"pred": "glass", "cond_log_prob": -5.127471923828125, "count": 1}, {"pred": "heated", "cond_log_prob": -5.284698486328125, "count": 1}, {"pred": "hot", "cond_log_prob": -5.481719970703125, "count": 1}, {"pred": "isolated", "cond_log_prob": -6.752899169921875, "count": 1}, {"pred": "large", "cond_log_prob": -6.245330810546875, "count": 1}, {"pred": "metal", "cond_log_prob": -5.054840087890625, "count": 1}, {"pred": "small", "cond_log_prob": -6.331451416015625, "count": 1}, {"pred": "solid", "cond_log_prob": -6.62353515625, "count": 1}, {"pred": "sterilized", "cond_log_prob": -3.0846099853515625, "count": 1}, {"pred": "strong", "cond_log_prob": -7.9434814453125, "count": 1}, {"pred": "uncontaminated", "cond_log_prob": -8.94500732421875, "count": 1}, {"pred": "vacuum", "cond_log_prob": -4.791748046875, "count": 1}, {"pred": "yet", "cond_log_prob": -8.246002197265625, "count": 1}], "ancestral_samples": [{"pred": "airconditioned", "count": 1, "cond_log_prob": -11.69287109375}, {"pred": "airtight", "count": 1, "cond_log_prob": -3.747314453125}, {"pred": "chlorinefree", "count": 1, "cond_log_prob": -16.665435791015625}, {"pred": "closed", "count": 4, "cond_log_prob": -4.439483642578125}, {"pred": "closedroute", "count": 1, "cond_log_prob": -28.0997314453125}, {"pred": "cold", "count": 2, "cond_log_prob": -4.3497314453125}, {"pred": "confined", "count": 1, "cond_log_prob": -6.63824462890625}, {"pred": "enclosed", "count": 1, "cond_log_prob": -4.141571044921875}, {"pred": "sealed", "count": 18, "cond_log_prob": -2.485321044921875}, {"pred": "steamfree", "count": 1, "cond_log_prob": -11.68121337890625}, {"pred": "sterile", "count": 4, "cond_log_prob": -3.07745361328125}, {"pred": "sterilized", "count": 1, "cond_log_prob": -3.0846099853515625}, {"pred": "ventilated", "count": 1, "cond_log_prob": -4.970733642578125}, {"pred": "wellventilated", "count": 3, "cond_log_prob": -12.910293579101562}]}, "36": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized", "log_prob": -175.34365844726562}, "original": {"pred": "chamber.", "cond_log_prob": -3.173065185546875}, "human": [{"pred": "container", "cond_log_prob": -1.637420654296875, "count": 26}, {"pred": "and", "cond_log_prob": -4.980743408203125, "count": 3}, {"pred": "chamber", "cond_log_prob": -1.632171630859375, "count": 2}, {"pred": "room", "cond_log_prob": -2.778778076171875, "count": 2}, {"pred": "tank", "cond_log_prob": -3.189453125, "count": 2}, {"pred": "bottle", "cond_log_prob": -6.1131591796875, "count": 1}, {"pred": "flask", "cond_log_prob": -8.347442626953125, "count": 1}, {"pred": "in", "cond_log_prob": -8.135345458984375, "count": 1}, {"pred": "this", "cond_log_prob": -12.257720947265625, "count": 1}, {"pred": "with", "cond_log_prob": -9.798919677734375, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 1, "cond_log_prob": -4.980743408203125}, {"pred": "chamber", "count": 13, "cond_log_prob": -1.632171630859375}, {"pred": "chamberThe", "count": 1, "cond_log_prob": -17.543548583984375}, {"pred": "chamberroute", "count": 1, "cond_log_prob": -24.1358642578125}, {"pred": "container", "count": 15, "cond_log_prob": -1.637420654296875}, {"pred": "facility", "count": 1, "cond_log_prob": -4.72998046875}, {"pred": "form", "count": 1, "cond_log_prob": -5.285858154296875}, {"pred": "room", "count": 2, "cond_log_prob": -2.778778076171875}, {"pred": "sealed", "count": 1, "cond_log_prob": -6.59942626953125}, {"pred": "tank", "count": 3, "cond_log_prob": -3.189453125}, {"pred": "vessel", "count": 1, "cond_log_prob": -3.342437744140625}]}, "37": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber.", "log_prob": -178.5167236328125}, "original": {"pred": "The", "cond_log_prob": -1.625030517578125}, "human": [{"pred": "it", "cond_log_prob": -11.299530029296875, "count": 9}, {"pred": "the", "cond_log_prob": -9.16400146484375, "count": 8}, {"pred": "then", "cond_log_prob": -13.195831298828125, "count": 7}, {"pred": "this", "cond_log_prob": -12.491790771484375, "count": 4}, {"pred": "?", "cond_log_prob": -13.552764892578125, "count": 1}, {"pred": "a", "cond_log_prob": -10.401397705078125, "count": 1}, {"pred": "after", "cond_log_prob": -12.416961669921875, "count": 1}, {"pred": "afterwards", "cond_log_prob": -17.60821533203125, "count": 1}, {"pred": "alright", "cond_log_prob": -22.07073974609375, "count": 1}, {"pred": "following", "cond_log_prob": -15.774932861328125, "count": 1}, {"pred": "in", "cond_log_prob": -10.372314453125, "count": 1}, {"pred": "is", "cond_log_prob": -10.94195556640625, "count": 1}, {"pred": "making", "cond_log_prob": -17.806915283203125, "count": 1}, {"pred": "steam", "cond_log_prob": -10.308258056640625, "count": 1}, {"pred": "when", "cond_log_prob": -11.54052734375, "count": 1}, {"pred": "while", "cond_log_prob": -12.828521728515625, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 2, "cond_log_prob": -3.1475830078125}, {"pred": "It", "count": 1, "cond_log_prob": -2.926483154296875}, {"pred": "The", "count": 36, "cond_log_prob": -1.625335693359375}, {"pred": "Theroute", "count": 1, "cond_log_prob": -26.109161376953125}]}, "38": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The", "log_prob": -180.14175415039062}, "original": {"pred": "liquid", "cond_log_prob": -5.2781524658203125}, "human": [{"pred": "waste", "cond_log_prob": -2.792510986328125, "count": 15}, {"pred": "chamber", "cond_log_prob": -4.342010498046875, "count": 8}, {"pred": "steam", "cond_log_prob": -1.208465576171875, "count": 4}, {"pred": "process", "cond_log_prob": -3.973785400390625, "count": 2}, {"pred": "sterilization", "cond_log_prob": -2.554901123046875, "count": 2}, {"pred": "container", "cond_log_prob": -6.028045654296875, "count": 1}, {"pred": "infectious", "cond_log_prob": -9.83575439453125, "count": 1}, {"pred": "lab", "cond_log_prob": -7.979827880859375, "count": 1}, {"pred": "large", "cond_log_prob": -7.66650390625, "count": 1}, {"pred": "main", "cond_log_prob": -6.930023193359375, "count": 1}, {"pred": "organisms", "cond_log_prob": -9.4649658203125, "count": 1}, {"pred": "reason", "cond_log_prob": -8.27154541015625, "count": 1}, {"pred": "subject", "cond_log_prob": -7.643096923828125, "count": 1}, {"pred": "the", "cond_log_prob": -7.907470703125, "count": 1}], "ancestral_samples": [{"pred": "amount", "count": 1, "cond_log_prob": -5.476226806640625}, {"pred": "process", "count": 1, "cond_log_prob": -3.973785400390625}, {"pred": "steam", "count": 19, "cond_log_prob": -1.208465576171875}, {"pred": "sterilization", "count": 6, "cond_log_prob": -2.554901123046875}, {"pred": "sterilroute", "count": 1, "cond_log_prob": -24.419647216796875}, {"pred": "waste", "count": 12, "cond_log_prob": -2.792510986328125}]}, "39": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid", "log_prob": -185.41990661621094}, "original": {"pred": "that", "cond_log_prob": -4.2195587158203125}, "human": [{"pred": "is", "cond_log_prob": -0.8769073486328125, "count": 25}, {"pred": "from", "cond_log_prob": -4.6176300048828125, "count": 2}, {"pred": "begins", "cond_log_prob": -6.9732513427734375, "count": 1}, {"pred": "bowl", "cond_log_prob": -12.398544311523438, "count": 1}, {"pred": "contained", "cond_log_prob": -5.8488922119140625, "count": 1}, {"pred": "evaporated", "cond_log_prob": -11.807601928710938, "count": 1}, {"pred": "in", "cond_log_prob": -3.7898101806640625, "count": 1}, {"pred": "of", "cond_log_prob": -4.6359710693359375, "count": 1}, {"pred": "reaches", "cond_log_prob": -6.6711273193359375, "count": 1}, {"pred": "steam", "cond_log_prob": -5.2324676513671875, "count": 1}, {"pred": "sterilization", "cond_log_prob": -4.5551300048828125, "count": 1}, {"pred": "that", "cond_log_prob": -4.2198944091796875, "count": 1}, {"pred": "waste", "cond_log_prob": -5.3529510498046875, "count": 1}, {"pred": "will", "cond_log_prob": -4.7910308837890625, "count": 1}, {"pred": "worst", "cond_log_prob": -14.461196899414062, "count": 1}], "ancestral_samples": [{"pred": "is", "count": 38, "cond_log_prob": -0.8769073486328125}, {"pred": "isroute", "count": 1, "cond_log_prob": -24.116409301757812}, {"pred": "then", "count": 1, "cond_log_prob": -4.2587432861328125}]}, "40": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that", "log_prob": -189.63946533203125}, "original": {"pred": "may", "cond_log_prob": -6.46197509765625}, "human": [{"pred": "is", "cond_log_prob": -0.8935546875, "count": 19}, {"pred": "comes", "cond_log_prob": -3.025482177734375, "count": 6}, {"pred": "evaporates", "cond_log_prob": -5.93707275390625, "count": 2}, {"pred": "remains", "cond_log_prob": -4.512847900390625, "count": 3}, {"pred": "results", "cond_log_prob": -5.808624267578125, "count": 2}, {"pred": "cleanses", "cond_log_prob": -7.71075439453125, "count": 1}, {"pred": "exists", "cond_log_prob": -7.092559814453125, "count": 1}, {"pred": "heats", "cond_log_prob": -7.73516845703125, "count": 1}, {"pred": "one", "cond_log_prob": -9.75506591796875, "count": 1}, {"pred": "steam", "cond_log_prob": -6.36651611328125, "count": 1}, {"pred": "sterilizes", "cond_log_prob": -6.29620361328125, "count": 1}, {"pred": "the", "cond_log_prob": -4.384521484375, "count": 1}, {"pred": "use", "cond_log_prob": -12.417510986328125, "count": 1}], "ancestral_samples": [{"pred": "enters", "count": 1, "cond_log_prob": -2.871551513671875}, {"pred": "escapes", "count": 1, "cond_log_prob": -4.836273193359375}, {"pred": "is", "count": 36, "cond_log_prob": -0.8935546875}, {"pred": "isroute", "count": 1, "cond_log_prob": -26.40106201171875}, {"pred": "was", "count": 1, "cond_log_prob": -4.445159912109375}]}, "41": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may", "log_prob": -196.1014404296875}, "original": {"pred": "form", "cond_log_prob": -4.72491455078125}, "human": [{"pred": "be", "cond_log_prob": -0.413818359375, "count": 13}, {"pred": "escape", "cond_log_prob": -4.871490478515625, "count": 4}, {"pred": "come", "cond_log_prob": -3.79949951171875, "count": 3}, {"pred": "remain", "cond_log_prob": -4.78094482421875, "count": 3}, {"pred": "leak", "cond_log_prob": -6.324737548828125, "count": 2}, {"pred": "appear", "cond_log_prob": -6.46014404296875, "count": 2}, {"pred": "bet", "cond_log_prob": -15.535430908203125, "count": 1}, {"pred": "cause", "cond_log_prob": -5.328643798828125, "count": 1}, {"pred": "collect", "cond_log_prob": -6.816162109375, "count": 1}, {"pred": "condense", "cond_log_prob": -8.511505126953125, "count": 1}, {"pred": "day", "cond_log_prob": -12.062957763671875, "count": 1}, {"pred": "enter", "cond_log_prob": -3.397430419921875, "count": 1}, {"pred": "form", "cond_log_prob": -4.7252197265625, "count": 1}, {"pred": "have", "cond_log_prob": -3.313873291015625, "count": 1}, {"pred": "heat", "cond_log_prob": -10.9378662109375, "count": 1}, {"pred": "of", "cond_log_prob": -9.447662353515625, "count": 1}, {"pred": "result", "cond_log_prob": -5.6138916015625, "count": 1}, {"pred": "stay", "cond_log_prob": -6.890960693359375, "count": 1}, {"pred": "sterilize", "cond_log_prob": -8.48980712890625, "count": 1}], "ancestral_samples": [{"pred": "be", "count": 38, "cond_log_prob": -0.413818359375}, {"pred": "beroute", "count": 1, "cond_log_prob": -28.657196044921875}, {"pred": "form", "count": 1, "cond_log_prob": -4.7252197265625}]}, "42": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form", "log_prob": -200.82635498046875}, "original": {"pred": "is", "cond_log_prob": -1.572998046875}, "human": [{"pred": "in", "cond_log_prob": -2.4085845947265625, "count": 5}, {"pred": "is", "cond_log_prob": -1.5733184814453125, "count": 6}, {"pred": "from", "cond_log_prob": -4.0220489501953125, "count": 4}, {"pred": "at", "cond_log_prob": -4.7994842529296875, "count": 3}, {"pred": "will", "cond_log_prob": -4.5528564453125, "count": 3}, {"pred": "during", "cond_log_prob": -5.043212890625, "count": 2}, {"pred": "my", "cond_log_prob": -9.324798583984375, "count": 2}, {"pred": "steam", "cond_log_prob": -2.9613189697265625, "count": 2}, {"pred": "after", "cond_log_prob": -4.97003173828125, "count": 1}, {"pred": "around", "cond_log_prob": -7.1943359375, "count": 1}, {"pred": "becomes", "cond_log_prob": -6.8567962646484375, "count": 1}, {"pred": "clumps", "cond_log_prob": -8.530075073242188, "count": 1}, {"pred": "collects", "cond_log_prob": -8.772186279296875, "count": 1}, {"pred": "disease", "cond_log_prob": -8.831832885742188, "count": 1}, {"pred": "droplets", "cond_log_prob": -8.603927612304688, "count": 1}, {"pred": "due", "cond_log_prob": -7.9985809326171875, "count": 1}, {"pred": "foam", "cond_log_prob": -9.18646240234375, "count": 1}, {"pred": "infectious", "cond_log_prob": -8.2838134765625, "count": 1}, {"pred": "inside", "cond_log_prob": -5.926055908203125, "count": 1}, {"pred": "on", "cond_log_prob": -4.64495849609375, "count": 1}, {"pred": "when", "cond_log_prob": -4.44158935546875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 6, "cond_log_prob": -2.47265625}, {"pred": "in", "count": 3, "cond_log_prob": -2.4085845947265625}, {"pred": "is", "count": 10, "cond_log_prob": -1.5733184814453125}, {"pred": "isroute", "count": 1, "cond_log_prob": -24.255081176757812}, {"pred": "the", "count": 20, "cond_log_prob": -1.623687744140625}]}, "43": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is", "log_prob": -202.39935302734375}, "original": {"pred": "drained", "cond_log_prob": -6.126861572265625}, "human": [{"pred": "then", "cond_log_prob": -2.0143280029296875, "count": 6}, {"pred": "called", "cond_log_prob": -4.7546539306640625, "count": 2}, {"pred": "disposed", "cond_log_prob": -6.1411285400390625, "count": 2}, {"pred": "hot", "cond_log_prob": -7.4737701416015625, "count": 2}, {"pred": "not", "cond_log_prob": -4.6046295166015625, "count": 2}, {"pred": "the", "cond_log_prob": -5.2572479248046875, "count": 2}, {"pred": "toxic", "cond_log_prob": -7.6288299560546875, "count": 3}, {"pred": "a", "cond_log_prob": -4.7894439697265625, "count": 1}, {"pred": "able", "cond_log_prob": -8.380325317382812, "count": 1}, {"pred": "brother", "cond_log_prob": -16.214126586914062, "count": 1}, {"pred": "clean", "cond_log_prob": -6.6132354736328125, "count": 1}, {"pred": "collected", "cond_log_prob": -4.7835845947265625, "count": 1}, {"pred": "condensation", "cond_log_prob": -13.406021118164062, "count": 1}, {"pred": "contained", "cond_log_prob": -6.6826629638671875, "count": 1}, {"pred": "drained", "cond_log_prob": -6.1272125244140625, "count": 1}, {"pred": "due", "cond_log_prob": -10.939102172851562, "count": 1}, {"pred": "extremely", "cond_log_prob": -7.9606781005859375, "count": 1}, {"pred": "from", "cond_log_prob": -8.237167358398438, "count": 1}, {"pred": "just", "cond_log_prob": -8.664657592773438, "count": 1}, {"pred": "only", "cond_log_prob": -7.2432098388671875, "count": 1}, {"pred": "pooled", "cond_log_prob": -9.007186889648438, "count": 1}, {"pred": "pure", "cond_log_prob": -7.7026824951171875, "count": 1}, {"pred": "steam", "cond_log_prob": -5.5524749755859375, "count": 1}, {"pred": "sterile", "cond_log_prob": -5.5364532470703125, "count": 1}, {"pred": "sterilizing", "cond_log_prob": -10.855819702148438, "count": 1}, {"pred": "subject", "cond_log_prob": -6.4839019775390625, "count": 1}, {"pred": "time", "cond_log_prob": -9.903549194335938, "count": 1}, {"pred": "washed", "cond_log_prob": -5.5580902099609375, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -4.7894439697265625}, {"pred": "filtered", "count": 1, "cond_log_prob": -4.3426666259765625}, {"pred": "heated", "count": 1, "cond_log_prob": -3.4322967529296875}, {"pred": "not", "count": 1, "cond_log_prob": -4.6046295166015625}, {"pred": "removed", "count": 2, "cond_log_prob": -3.8349456787109375}, {"pred": "sterilized", "count": 3, "cond_log_prob": -2.3875274658203125}, {"pred": "sterilrouteable", "count": 1, "cond_log_prob": -30.877334594726562}, {"pred": "then", "count": 28, "cond_log_prob": -2.0143280029296875}, {"pred": "used", "count": 2, "cond_log_prob": -3.9475555419921875}]}, "44": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is drained", "log_prob": -208.52621459960938}, "original": {"pred": "off", "cond_log_prob": -2.787994384765625}, "human": [{"pred": "from", "cond_log_prob": -2.0075225830078125, "count": 18}, {"pred": "and", "cond_log_prob": -2.0850982666015625, "count": 7}, {"pred": "into", "cond_log_prob": -1.7350616455078125, "count": 5}, {"pred": "through", "cond_log_prob": -2.7267913818359375, "count": 2}, {"pred": "abd", "cond_log_prob": -19.484207153320312, "count": 1}, {"pred": "at", "cond_log_prob": -5.3945465087890625, "count": 1}, {"pred": "by", "cond_log_prob": -4.1466522216796875, "count": 1}, {"pred": "in", "cond_log_prob": -4.3230133056640625, "count": 1}, {"pred": "of", "cond_log_prob": -3.3758087158203125, "count": 1}, {"pred": "shot", "cond_log_prob": -14.115585327148438, "count": 1}, {"pred": "to", "cond_log_prob": -3.3773345947265625, "count": 1}, {"pred": "with", "cond_log_prob": -4.6352691650390625, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -12.213455200195312}, {"pred": "and", "count": 11, "cond_log_prob": -2.0850982666015625}, {"pred": "away", "count": 1, "cond_log_prob": -4.1352996826171875}, {"pred": "cleaned", "count": 1, "cond_log_prob": -11.399063110351562}, {"pred": "from", "count": 4, "cond_log_prob": -2.0075225830078125}, {"pred": "into", "count": 11, "cond_log_prob": -1.7350616455078125}, {"pred": "intoroute", "count": 1, "cond_log_prob": -32.02244567871094}, {"pred": "or", "count": 1, "cond_log_prob": -4.0958404541015625}, {"pred": "out", "count": 4, "cond_log_prob": -2.4652252197265625}, {"pred": "through", "count": 3, "cond_log_prob": -2.7267913818359375}, {"pred": "to", "count": 2, "cond_log_prob": -3.3773345947265625}]}, "45": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is drained off", "log_prob": -211.314208984375}, "original": {"pred": "to", "cond_log_prob": -3.14324951171875}, "human": [{"pred": "the", "cond_log_prob": -1.4009552001953125, "count": 14}, {"pred": "of", "cond_log_prob": -1.9690093994140625, "count": 8}, {"pred": "and", "cond_log_prob": -2.2639923095703125, "count": 7}, {"pred": "into", "cond_log_prob": -3.6031341552734375, "count": 5}, {"pred": "completely", "cond_log_prob": -7.4430694580078125, "count": 1}, {"pred": "is", "cond_log_prob": -9.218978881835938, "count": 1}, {"pred": "ronnie", "cond_log_prob": -27.810165405273438, "count": 1}, {"pred": "to", "cond_log_prob": -3.1436004638671875, "count": 1}, {"pred": "water", "cond_log_prob": -7.0954742431640625, "count": 1}, {"pred": "when", "cond_log_prob": -5.3253631591796875, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -9.041519165039062}, {"pred": "a", "count": 1, "cond_log_prob": -3.6431121826171875}, {"pred": "and", "count": 2, "cond_log_prob": -2.2639923095703125}, {"pred": "by", "count": 1, "cond_log_prob": -3.1982879638671875}, {"pred": "into", "count": 1, "cond_log_prob": -3.6031341552734375}, {"pred": "of", "count": 6, "cond_log_prob": -1.9690093994140625}, {"pred": "the", "count": 26, "cond_log_prob": -1.4009552001953125}, {"pred": "theroute", "count": 1, "cond_log_prob": -35.00941467285156}, {"pred": "to", "count": 1, "cond_log_prob": -3.1436004638671875}]}, "46": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is drained off to", "log_prob": -214.45745849609375}, "original": {"pred": "the", "cond_log_prob": -1.7238006591796875}, "human": [{"pred": "a", "cond_log_prob": -1.3312225341796875, "count": 11}, {"pred": "the", "cond_log_prob": -1.7241668701171875, "count": 8}, {"pred": "another", "cond_log_prob": -4.9969329833984375, "count": 4}, {"pred": "be", "cond_log_prob": -1.8746490478515625, "count": 3}, {"pred": "keep", "cond_log_prob": -5.8774261474609375, "count": 2}, {"pred": "sterilize", "cond_log_prob": -5.0579071044921875, "count": 2}, {"pred": "allow", "cond_log_prob": -5.6413421630859375, "count": 1}, {"pred": "decrease", "cond_log_prob": -9.126968383789062, "count": 1}, {"pred": "help", "cond_log_prob": -7.1367645263671875, "count": 1}, {"pred": "leave", "cond_log_prob": -7.2079925537109375, "count": 1}, {"pred": "preserve", "cond_log_prob": -6.8129119873046875, "count": 1}, {"pred": "prevent", "cond_log_prob": -4.0284271240234375, "count": 1}, {"pred": "remove", "cond_log_prob": -4.3051300048828125, "count": 2}, {"pred": "waste", "cond_log_prob": -6.8865509033203125, "count": 1}, {"pred": "with", "cond_log_prob": -11.158187866210938, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 22, "cond_log_prob": -1.3312225341796875}, {"pred": "be", "count": 8, "cond_log_prob": -1.8746490478515625}, {"pred": "prevent", "count": 1, "cond_log_prob": -4.0284271240234375}, {"pred": "the", "count": 8, "cond_log_prob": -1.7241668701171875}, {"pred": "theroute", "count": 1, "cond_log_prob": -33.38658142089844}]}, "47": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is drained off to the", "log_prob": -216.18125915527344}, "original": {"pred": "sewer", "cond_log_prob": -6.7492218017578125}, "human": [{"pred": "side", "cond_log_prob": -5.053466796875, "count": 6}, {"pred": "chamber", "cond_log_prob": -6.421722412109375, "count": 5}, {"pred": "floor", "cond_log_prob": -5.130462646484375, "count": 4}, {"pred": "waste", "cond_log_prob": -3.55059814453125, "count": 4}, {"pred": "bottom", "cond_log_prob": -3.517120361328125, "count": 3}, {"pred": "other", "cond_log_prob": -6.011871337890625, "count": 2}, {"pred": "sewer", "cond_log_prob": -6.749603271484375, "count": 2}, {"pred": "sink", "cond_log_prob": -6.37286376953125, "count": 2}, {"pred": "a", "cond_log_prob": -7.86737060546875, "count": 1}, {"pred": "chemical", "cond_log_prob": -5.46148681640625, "count": 1}, {"pred": "edges", "cond_log_prob": -8.740814208984375, "count": 1}, {"pred": "lab", "cond_log_prob": -4.871826171875, "count": 1}, {"pred": "laboratory", "cond_log_prob": -3.381317138671875, "count": 1}, {"pred": "next", "cond_log_prob": -4.486602783203125, "count": 1}, {"pred": "sea", "cond_log_prob": -6.00152587890625, "count": 1}, {"pred": "sewers", "cond_log_prob": -9.235443115234375, "count": 1}, {"pred": "sides", "cond_log_prob": -7.6123046875, "count": 1}, {"pred": "system", "cond_log_prob": -7.142974853515625, "count": 1}, {"pred": "trash", "cond_log_prob": -5.924072265625, "count": 1}, {"pred": "treatment", "cond_log_prob": -5.65740966796875, "count": 1}], "ancestral_samples": [{"pred": "appropriate", "count": 1, "cond_log_prob": -4.895843505859375}, {"pred": "bottom", "count": 3, "cond_log_prob": -3.517120361328125}, {"pred": "environment", "count": 2, "cond_log_prob": -4.259002685546875}, {"pred": "environmentThe", "count": 1, "cond_log_prob": -19.949493408203125}, {"pred": "facility", "count": 1, "cond_log_prob": -5.29034423828125}, {"pred": "laboratory", "count": 10, "cond_log_prob": -3.38128662109375}, {"pred": "liquid", "count": 1, "cond_log_prob": -5.047149658203125}, {"pred": "main", "count": 1, "cond_log_prob": -4.92578125}, {"pred": "nearest", "count": 4, "cond_log_prob": -3.3568115234375}, {"pred": "next", "count": 2, "cond_log_prob": -4.486602783203125}, {"pred": "outside", "count": 1, "cond_log_prob": -4.518463134765625}, {"pred": "point", "count": 1, "cond_log_prob": -3.92041015625}, {"pred": "side", "count": 1, "cond_log_prob": -5.053466796875}, {"pred": "sterilization", "count": 1, "cond_log_prob": -5.204071044921875}, {"pred": "surface", "count": 6, "cond_log_prob": -3.655609130859375}, {"pred": "surfaceroute", "count": 1, "cond_log_prob": -31.904556274414062}, {"pred": "waste", "count": 3, "cond_log_prob": -3.550567626953125}]}, "48": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is drained off to the sewer", "log_prob": -222.93048095703125}, "original": {"pred": "or", "cond_log_prob": -3.0216064453125}, "human": [{"pred": "and", "cond_log_prob": -2.0633392333984375, "count": 14}, {"pred": "where", "cond_log_prob": -3.7741546630859375, "count": 6}, {"pred": "system", "cond_log_prob": -1.619720458984375, "count": 4}, {"pred": "so", "cond_log_prob": -5.753753662109375, "count": 3}, {"pred": "to", "cond_log_prob": -3.6352081298828125, "count": 2}, {"pred": "as", "cond_log_prob": -4.8887481689453125, "count": 1}, {"pred": "drain", "cond_log_prob": -4.5552825927734375, "count": 1}, {"pred": "for", "cond_log_prob": -3.8768310546875, "count": 1}, {"pred": "it", "cond_log_prob": -8.302459716796875, "count": 1}, {"pred": "line", "cond_log_prob": -4.44097900390625, "count": 1}, {"pred": "pellet", "cond_log_prob": -13.8853759765625, "count": 1}, {"pred": "pipe", "cond_log_prob": -5.2474365234375, "count": 1}, {"pred": "then", "cond_log_prob": -7.7969512939453125, "count": 1}, {"pred": "under", "cond_log_prob": -5.763671875, "count": 1}, {"pred": "underneath", "cond_log_prob": -8.485610961914062, "count": 1}, {"pred": "with", "cond_log_prob": -4.9121551513671875, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 3, "cond_log_prob": -12.662948608398438}, {"pred": "and", "count": 12, "cond_log_prob": -2.0633392333984375}, {"pred": "androute", "count": 1, "cond_log_prob": -23.94110107421875}, {"pred": "or", "count": 1, "cond_log_prob": -3.0219879150390625}, {"pred": "system", "count": 17, "cond_log_prob": -1.619720458984375}, {"pred": "systemThe", "count": 2, "cond_log_prob": -16.39202880859375}, {"pred": "to", "count": 1, "cond_log_prob": -3.6352081298828125}, {"pred": "where", "count": 3, "cond_log_prob": -3.7741546630859375}]}, "49": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is drained off to the sewer or", "log_prob": -225.95208740234375}, "original": {"pred": "sent", "cond_log_prob": -6.2996673583984375}, "human": [{"pred": "the", "cond_log_prob": -4.1454620361328125, "count": 5}, {"pred": "drain", "cond_log_prob": -5.8048095703125, "count": 3}, {"pred": "into", "cond_log_prob": -4.195098876953125, "count": 3}, {"pred": "ocean", "cond_log_prob": -6.506072998046875, "count": 3}, {"pred": "other", "cond_log_prob": -2.9918365478515625, "count": 3}, {"pred": "waste", "cond_log_prob": -4.7716064453125, "count": 3}, {"pred": "river", "cond_log_prob": -5.5321044921875, "count": 2}, {"pred": "to", "cond_log_prob": -3.2072601318359375, "count": 2}, {"pred": "another", "cond_log_prob": -6.32843017578125, "count": 1}, {"pred": "burned", "cond_log_prob": -6.6235198974609375, "count": 1}, {"pred": "container", "cond_log_prob": -6.3331451416015625, "count": 1}, {"pred": "drainage", "cond_log_prob": -6.52728271484375, "count": 1}, {"pred": "dump", "cond_log_prob": -5.3258514404296875, "count": 1}, {"pred": "garbage", "cond_log_prob": -4.68377685546875, "count": 1}, {"pred": "gun", "cond_log_prob": -10.141510009765625, "count": 1}, {"pred": "is", "cond_log_prob": -4.992828369140625, "count": 1}, {"pred": "lake", "cond_log_prob": -6.9476470947265625, "count": 1}, {"pred": "left", "cond_log_prob": -7.9287567138671875, "count": 1}, {"pred": "removed", "cond_log_prob": -7.01849365234375, "count": 1}, {"pred": "reverted", "cond_log_prob": -13.439682006835938, "count": 1}, {"pred": "separate", "cond_log_prob": -8.954742431640625, "count": 1}, {"pred": "thrown", "cond_log_prob": -7.682464599609375, "count": 1}, {"pred": "trash", "cond_log_prob": -5.1712646484375, "count": 1}, {"pred": "underground", "cond_log_prob": -5.45135498046875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.684722900390625}, {"pred": "incinerator", "count": 29, "cond_log_prob": -2.033447265625}, {"pred": "incinerroute", "count": 1, "cond_log_prob": -24.228958129882812}, {"pred": "into", "count": 1, "cond_log_prob": -4.195098876953125}, {"pred": "other", "count": 2, "cond_log_prob": -2.9918365478515625}, {"pred": "the", "count": 1, "cond_log_prob": -4.1454620361328125}, {"pred": "to", "count": 4, "cond_log_prob": -3.2072601318359375}]}, "50": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is drained off to the sewer or sent", "log_prob": -232.2517547607422}, "original": {"pred": "for", "cond_log_prob": -3.217803955078125}, "human": [{"pred": "to", "cond_log_prob": -0.3426666259765625, "count": 34}, {"pred": "down", "cond_log_prob": -5.573883056640625, "count": 2}, {"pred": "back", "cond_log_prob": -3.8661956787109375, "count": 1}, {"pred": "i", "cond_log_prob": -13.54541015625, "count": 1}, {"pred": "into", "cond_log_prob": -3.4914703369140625, "count": 1}, {"pred": "off", "cond_log_prob": -4.7386474609375, "count": 1}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.3426666259765625}, {"pred": "toroute", "count": 1, "cond_log_prob": -30.810104370117188}]}, "51": {"context": {"text": "Steam sterilization is limited in the types of medical waste it can treat, but is appropriate for laboratory cultures and substances contaminated with infectious organisms. The waste is subjected to steam in a sealed, pressurized chamber. The liquid that may form is drained off to the sewer or sent for", "log_prob": -235.4695587158203}, "original": {"pred": "processing.", "cond_log_prob": -3.9105072021484375}, "human": [{"pred": "testing", "cond_log_prob": -4.468505859375, "count": 7}, {"pred": "examination", "cond_log_prob": -5.708526611328125, "count": 5}, {"pred": "inspection", "cond_log_prob": -6.428619384765625, "count": 3}, {"pred": "sterilization", "cond_log_prob": -3.130584716796875, "count": 3}, {"pred": "the", "cond_log_prob": -4.33587646484375, "count": 3}, {"pred": "analysis", "cond_log_prob": -4.24786376953125, "count": 2}, {"pred": "recycling", "cond_log_prob": -3.20379638671875, "count": 2}, {"pred": "a", "cond_log_prob": -3.396881103515625, "count": 1}, {"pred": "analyzing", "cond_log_prob": -9.926971435546875, "count": 1}, {"pred": "chemical", "cond_log_prob": -6.22784423828125, "count": 1}, {"pred": "destruction", "cond_log_prob": -7.262969970703125, "count": 1}, {"pred": "disposal", "cond_log_prob": -1.877960205078125, "count": 2}, {"pred": "further", "cond_log_prob": -3.66326904296875, "count": 1}, {"pred": "immediate", "cond_log_prob": -6.15264892578125, "count": 1}, {"pred": "more", "cond_log_prob": -7.31854248046875, "count": 1}, {"pred": "other", "cond_log_prob": -6.305267333984375, "count": 1}, {"pred": "someone", "cond_log_prob": -9.46282958984375, "count": 1}, {"pred": "study", "cond_log_prob": -6.468536376953125, "count": 1}, {"pred": "treatment", "cond_log_prob": -3.466888427734375, "count": 1}, {"pred": "was", "cond_log_prob": -9.78668212890625, "count": 1}, {"pred": "waste", "cond_log_prob": -5.03143310546875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -3.396881103515625}, {"pred": "analysisThe", "count": 1, "cond_log_prob": -20.51934814453125}, {"pred": "collection", "count": 1, "cond_log_prob": -3.413726806640625}, {"pred": "disinfection", "count": 5, "cond_log_prob": -3.1234893798828125}, {"pred": "disposal", "count": 11, "cond_log_prob": -1.877960205078125}, {"pred": "disposalC", "count": 1, "cond_log_prob": -18.6343994140625}, {"pred": "disposalFor", "count": 1, "cond_log_prob": -19.849853515625}, {"pred": "disposalIn", "count": 1, "cond_log_prob": -18.39093017578125}, {"pred": "disposalS", "count": 1, "cond_log_prob": -18.961334228515625}, {"pred": "disposalThe", "count": 6, "cond_log_prob": -17.418487548828125}, {"pred": "disposalThere", "count": 1, "cond_log_prob": -18.3468017578125}, {"pred": "disposalroute", "count": 1, "cond_log_prob": -22.732223510742188}, {"pred": "incineration", "count": 2, "cond_log_prob": -3.3614654541015625}, {"pred": "processing", "count": 1, "cond_log_prob": -3.164398193359375}, {"pred": "processingThe", "count": 1, "cond_log_prob": -18.8907470703125}, {"pred": "recyclingA", "count": 1, "cond_log_prob": -18.724609375}, {"pred": "the", "count": 1, "cond_log_prob": -4.33587646484375}, {"pred": "treatment", "count": 2, "cond_log_prob": -3.466888427734375}]}}, "17": {"2": {"context": {"text": "Owls", "log_prob": -16.174924850463867}, "original": {"pred": "are", "cond_log_prob": -3.998720169067383}, "human": [{"pred": "are", "cond_log_prob": -3.9987316131591797, "count": 19}, {"pred": "have", "cond_log_prob": -4.434736251831055, "count": 6}, {"pred": "fly", "cond_log_prob": -7.583524703979492, "count": 5}, {"pred": "can", "cond_log_prob": -5.511167526245117, "count": 2}, {"pred": "hoot", "cond_log_prob": -13.318647384643555, "count": 2}, {"pred": "!", "cond_log_prob": -9.046758651733398, "count": 1}, {"pred": "a", "cond_log_prob": -7.241636276245117, "count": 1}, {"pred": "do", "cond_log_prob": -6.773305892944336, "count": 1}, {"pred": "eat", "cond_log_prob": -9.516294479370117, "count": 1}, {"pred": "in", "cond_log_prob": -4.379209518432617, "count": 1}, {"pred": "night", "cond_log_prob": -9.084577560424805, "count": 1}, {"pred": "see", "cond_log_prob": -7.593839645385742, "count": 1}, {"pred": "this", "cond_log_prob": -8.030271530151367, "count": 1}], "ancestral_samples": [{"pred": "0x1", "count": 1, "cond_log_prob": -15.301740646362305}, {"pred": "1", "count": 1, "cond_log_prob": -5.352994918823242}, {"pred": "14", "count": 1, "cond_log_prob": -7.319196701049805}, {"pred": "29", "count": 1, "cond_log_prob": -8.171979904174805}, {"pred": "2jpgow", "count": 1, "cond_log_prob": -28.2254695892334}, {"pred": "3c8", "count": 1, "cond_log_prob": -20.004079818725586}, {"pred": "A", "count": 1, "cond_log_prob": -7.027265548706055}, {"pred": "Abra", "count": 1, "cond_log_prob": -16.266977310180664}, {"pred": "Courtesy", "count": 1, "cond_log_prob": -11.295270919799805}, {"pred": "Horton", "count": 1, "cond_log_prob": -14.599454879760742}, {"pred": "It", "count": 1, "cond_log_prob": -8.665472030639648}, {"pred": "K", "count": 1, "cond_log_prob": -8.606985092163086}, {"pred": "Klok", "count": 1, "cond_log_prob": -16.01100730895996}, {"pred": "LgQAo", "count": 1, "cond_log_prob": -36.8563232421875}, {"pred": "The", "count": 4, "cond_log_prob": -6.858015060424805}, {"pred": "There", "count": 1, "cond_log_prob": -9.710454940795898}, {"pred": "This", "count": 1, "cond_log_prob": -8.75819206237793}, {"pred": "We", "count": 2, "cond_log_prob": -9.26667594909668}, {"pred": "a", "count": 1, "cond_log_prob": -7.241636276245117}, {"pred": "and", "count": 1, "cond_log_prob": -3.580900192260742}, {"pred": "are", "count": 2, "cond_log_prob": -3.9987316131591797}, {"pred": "c", "count": 1, "cond_log_prob": -9.503660202026367}, {"pred": "com", "count": 1, "cond_log_prob": -11.275999069213867}, {"pred": "comB", "count": 1, "cond_log_prob": -19.603715896606445}, {"pred": "comwp", "count": 1, "cond_log_prob": -25.506685256958008}, {"pred": "doDw2z", "count": 1, "cond_log_prob": -39.05048370361328}, {"pred": "is", "count": 1, "cond_log_prob": -6.012235641479492}, {"pred": "routemigration", "count": 1, "cond_log_prob": -38.713600158691406}, {"pred": "the", "count": 1, "cond_log_prob": -6.50819206237793}, {"pred": "to", "count": 1, "cond_log_prob": -5.067045211791992}, {"pred": "who", "count": 1, "cond_log_prob": -6.956663131713867}, {"pred": "wie", "count": 1, "cond_log_prob": -14.965719223022461}, {"pred": "wmv", "count": 1, "cond_log_prob": -19.71724510192871}, {"pred": "zTo1nW", "count": 1, "cond_log_prob": -39.43513488769531}, {"pred": "zd5e", "count": 1, "cond_log_prob": -30.520193099975586}]}, "3": {"context": {"text": "Owls are", "log_prob": -20.17364501953125}, "original": {"pred": "more", "cond_log_prob": -5.341268539428711}, "human": [{"pred": "the", "cond_log_prob": -2.9626731872558594, "count": 7}, {"pred": "birds", "cond_log_prob": -8.595256805419922, "count": 5}, {"pred": "a", "cond_log_prob": -2.491466522216797, "count": 4}, {"pred": "animals", "cond_log_prob": -8.630298614501953, "count": 3}, {"pred": "nocturnal", "cond_log_prob": -9.785686492919922, "count": 3}, {"pred": "always", "cond_log_prob": -5.178539276123047, "count": 2}, {"pred": "beautiful", "cond_log_prob": -6.997570037841797, "count": 2}, {"pred": "known", "cond_log_prob": -4.071666717529297, "count": 2}, {"pred": "very", "cond_log_prob": -4.991725921630859, "count": 2}, {"pred": "able", "cond_log_prob": -5.875629425048828, "count": 1}, {"pred": "awesome", "cond_log_prob": -6.669025421142578, "count": 1}, {"pred": "brown", "cond_log_prob": -9.988643646240234, "count": 1}, {"pred": "creatures", "cond_log_prob": -8.266498565673828, "count": 1}, {"pred": "found", "cond_log_prob": -6.957607269287109, "count": 1}, {"pred": "not", "cond_log_prob": -3.906749725341797, "count": 1}, {"pred": "often", "cond_log_prob": -5.215007781982422, "count": 1}, {"pred": "one", "cond_log_prob": -3.824077606201172, "count": 1}, {"pred": "predatory", "cond_log_prob": -10.516674041748047, "count": 1}, {"pred": "silent", "cond_log_prob": -8.38003158569336, "count": 1}, {"pred": "some", "cond_log_prob": -6.720912933349609, "count": 1}, {"pred": "wise", "cond_log_prob": -8.908832550048828, "count": 1}], "ancestral_samples": [{"pred": "I", "count": 1, "cond_log_prob": -9.878307342529297}, {"pred": "a", "count": 14, "cond_log_prob": -2.491466522216797}, {"pred": "also", "count": 3, "cond_log_prob": -4.892559051513672}, {"pred": "generally", "count": 1, "cond_log_prob": -6.410381317138672}, {"pred": "genetically", "count": 1, "cond_log_prob": -8.844173431396484}, {"pred": "great", "count": 2, "cond_log_prob": -5.202419281005859}, {"pred": "known", "count": 1, "cond_log_prob": -4.071666717529297}, {"pred": "not", "count": 11, "cond_log_prob": -3.906749725341797}, {"pred": "notrouteable", "count": 1, "cond_log_prob": -27.023181915283203}, {"pred": "often", "count": 2, "cond_log_prob": -5.215007781982422}, {"pred": "the", "count": 1, "cond_log_prob": -2.9626731872558594}, {"pred": "very", "count": 2, "cond_log_prob": -4.991725921630859}]}, "4": {"context": {"text": "Owls are more", "log_prob": -25.51491355895996}, "original": {"pred": "flexible", "cond_log_prob": -6.113086700439453}, "human": [{"pred": "than", "cond_log_prob": -2.016752243041992, "count": 5}, {"pred": "intelligent", "cond_log_prob": -4.884305953979492, "count": 3}, {"pred": "likely", "cond_log_prob": -1.5406475067138672, "count": 4}, {"pred": "apt", "cond_log_prob": -5.856138229370117, "count": 2}, {"pred": "interesting", "cond_log_prob": -6.336713790893555, "count": 2}, {"pred": "nocturnal", "cond_log_prob": -11.956136703491211, "count": 2}, {"pred": "prone", "cond_log_prob": -4.964834213256836, "count": 2}, {"pred": "silent", "cond_log_prob": -9.38038444519043, "count": 2}, {"pred": "smart", "cond_log_prob": -7.846982955932617, "count": 2}, {"pred": "susceptible", "cond_log_prob": -5.422163009643555, "count": 2}, {"pred": "a", "cond_log_prob": -6.899435043334961, "count": 1}, {"pred": "active", "cond_log_prob": -4.971799850463867, "count": 1}, {"pred": "aggressive", "cond_log_prob": -4.147008895874023, "count": 1}, {"pred": "agile", "cond_log_prob": -5.329343795776367, "count": 1}, {"pred": "beautiful", "cond_log_prob": -6.899076461791992, "count": 1}, {"pred": "capable", "cond_log_prob": -6.251462936401367, "count": 1}, {"pred": "common", "cond_log_prob": -4.70301628112793, "count": 1}, {"pred": "discrete", "cond_log_prob": -10.390043258666992, "count": 1}, {"pred": "elusive", "cond_log_prob": -7.429288864135742, "count": 1}, {"pred": "flexible", "cond_log_prob": -6.113065719604492, "count": 1}, {"pred": "fluffy", "cond_log_prob": -10.57130241394043, "count": 1}, {"pred": "mobile", "cond_log_prob": -4.845090866088867, "count": 1}, {"pred": "quiet", "cond_log_prob": -8.269926071166992, "count": 1}, {"pred": "sensitive", "cond_log_prob": -6.397626876831055, "count": 1}, {"pred": "vicious", "cond_log_prob": -7.505216598510742, "count": 1}, {"pred": "wise", "cond_log_prob": -10.091718673706055, "count": 1}], "ancestral_samples": [{"pred": "common", "count": 3, "cond_log_prob": -4.70301628112793}, {"pred": "efficient", "count": 1, "cond_log_prob": -5.271024703979492}, {"pred": "likely", "count": 32, "cond_log_prob": -1.5406475067138672}, {"pred": "likelyroute", "count": 1, "cond_log_prob": -21.57514762878418}, {"pred": "numerous", "count": 1, "cond_log_prob": -6.896879196166992}, {"pred": "than", "count": 1, "cond_log_prob": -2.016752243041992}, {"pred": "vulnerable", "count": 1, "cond_log_prob": -5.532621383666992}]}, "5": {"context": {"text": "Owls are more flexible", "log_prob": -31.628000259399414}, "original": {"pred": "than", "cond_log_prob": -0.8125133514404297}, "human": [{"pred": "than", "cond_log_prob": -0.8125247955322266, "count": 32}, {"pred": "in", "cond_log_prob": -2.641550064086914, "count": 3}, {"pred": "when", "cond_log_prob": -3.7469730377197266, "count": 2}, {"pred": "a", "cond_log_prob": -8.411874771118164, "count": 1}, {"pred": "animals", "cond_log_prob": -7.286539077758789, "count": 1}, {"pred": "at", "cond_log_prob": -4.938119888305664, "count": 1}, {"pred": "then", "cond_log_prob": -6.503236770629883, "count": 1}, {"pred": "to", "cond_log_prob": -5.084627151489258, "count": 1}], "ancestral_samples": [{"pred": "The", "count": 1, "cond_log_prob": -9.53477668762207}, {"pred": "While", "count": 1, "cond_log_prob": -12.901460647583008}, {"pred": "and", "count": 16, "cond_log_prob": -2.2303333282470703}, {"pred": "androute", "count": 1, "cond_log_prob": -22.35869789123535}, {"pred": "but", "count": 2, "cond_log_prob": -5.92076301574707}, {"pred": "easier", "count": 1, "cond_log_prob": -14.00468635559082}, {"pred": "have", "count": 1, "cond_log_prob": -9.961114883422852}, {"pred": "than", "count": 17, "cond_log_prob": -0.8125247955322266}]}, "6": {"context": {"text": "Owls are more flexible than", "log_prob": -32.440513610839844}, "original": {"pred": "humans", "cond_log_prob": -4.433750152587891}, "human": [{"pred": "other", "cond_log_prob": -3.0103111267089844, "count": 16}, {"pred": "most", "cond_log_prob": -2.3963661193847656, "count": 7}, {"pred": "any", "cond_log_prob": -3.5615501403808594, "count": 2}, {"pred": "humans", "cond_log_prob": -4.433757781982422, "count": 2}, {"pred": "robins", "cond_log_prob": -12.372371673583984, "count": 2}, {"pred": "a", "cond_log_prob": -4.661510467529297, "count": 1}, {"pred": "ants", "cond_log_prob": -8.757335662841797, "count": 1}, {"pred": "bears", "cond_log_prob": -7.373088836669922, "count": 1}, {"pred": "bunny", "cond_log_prob": -10.409038543701172, "count": 1}, {"pred": "crows", "cond_log_prob": -8.636180877685547, "count": 1}, {"pred": "eagles", "cond_log_prob": -8.123218536376953, "count": 1}, {"pred": "human", "cond_log_prob": -6.291637420654297, "count": 1}, {"pred": "me", "cond_log_prob": -7.873775482177734, "count": 1}, {"pred": "one", "cond_log_prob": -7.442577362060547, "count": 1}, {"pred": "regular", "cond_log_prob": -4.553852081298828, "count": 1}, {"pred": "their", "cond_log_prob": -3.1318931579589844, "count": 1}, {"pred": "they", "cond_log_prob": -3.9262046813964844, "count": 1}, {"pred": "you", "cond_log_prob": -3.4013938903808594, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 3, "cond_log_prob": -4.661510467529297}, {"pred": "everThe", "count": 1, "cond_log_prob": -14.374752044677734}, {"pred": "many", "count": 1, "cond_log_prob": -4.416065216064453}, {"pred": "manyroute", "count": 1, "cond_log_prob": -24.811275482177734}, {"pred": "most", "count": 6, "cond_log_prob": -2.3963661193847656}, {"pred": "other", "count": 7, "cond_log_prob": -3.0103111267089844}, {"pred": "others", "count": 1, "cond_log_prob": -4.985042572021484}, {"pred": "regular", "count": 1, "cond_log_prob": -4.553852081298828}, {"pred": "the", "count": 13, "cond_log_prob": -2.9085426330566406}, {"pred": "their", "count": 4, "cond_log_prob": -3.1318931579589844}, {"pred": "they", "count": 1, "cond_log_prob": -3.9262046813964844}, {"pred": "your", "count": 1, "cond_log_prob": -4.661800384521484}]}, "7": {"context": {"text": "Owls are more flexible than humans", "log_prob": -36.874263763427734}, "original": {"pred": "because", "cond_log_prob": -3.481395721435547}, "human": [{"pred": "because", "cond_log_prob": -3.4813613891601562, "count": 15}, {"pred": "are", "cond_log_prob": -4.579803466796875, "count": 8}, {"pred": "in", "cond_log_prob": -3.1782379150390625, "count": 7}, {"pred": "and", "cond_log_prob": -1.967926025390625, "count": 3}, {"pred": "a", "cond_log_prob": -8.341995239257812, "count": 1}, {"pred": "around", "cond_log_prob": -7.473518371582031, "count": 1}, {"pred": "generally", "cond_log_prob": -8.2003173828125, "count": 1}, {"pred": "or", "cond_log_prob": -6.19866943359375, "count": 1}, {"pred": "throughout", "cond_log_prob": -9.01776123046875, "count": 1}, {"pred": "typically", "cond_log_prob": -9.413101196289062, "count": 1}, {"pred": "which", "cond_log_prob": -6.515106201171875, "count": 1}, {"pred": "with", "cond_log_prob": -4.166839599609375, "count": 1}, {"pred": "would", "cond_log_prob": -8.133796691894531, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -9.925567626953125}, {"pred": "The", "count": 2, "cond_log_prob": -8.347900390625}, {"pred": "They", "count": 3, "cond_log_prob": -8.379440307617188}, {"pred": "We", "count": 2, "cond_log_prob": -9.413749694824219}, {"pred": "While", "count": 1, "cond_log_prob": -11.660606384277344}, {"pred": "and", "count": 24, "cond_log_prob": -1.967926025390625}, {"pred": "androute", "count": 1, "cond_log_prob": -22.666595458984375}, {"pred": "because", "count": 1, "cond_log_prob": -3.4813613891601562}, {"pred": "but", "count": 3, "cond_log_prob": -4.2666778564453125}, {"pred": "have", "count": 1, "cond_log_prob": -6.192527770996094}, {"pred": "so", "count": 1, "cond_log_prob": -4.9510955810546875}]}, "8": {"context": {"text": "Owls are more flexible than humans because", "log_prob": -40.35565948486328}, "original": {"pred": "a", "cond_log_prob": -6.065269470214844}, "human": [{"pred": "they", "cond_log_prob": -0.5652122497558594, "count": 27}, {"pred": "of", "cond_log_prob": -1.7815208435058594, "count": 8}, {"pred": "their", "cond_log_prob": -2.9447364807128906, "count": 5}, {"pred": "a", "cond_log_prob": -6.065296173095703, "count": 1}, {"pred": "other", "cond_log_prob": -8.552440643310547, "count": 1}], "ancestral_samples": [{"pred": "of", "count": 3, "cond_log_prob": -1.7815208435058594}, {"pred": "they", "count": 34, "cond_log_prob": -0.5652122497558594}, {"pred": "theyre", "count": 2, "cond_log_prob": -13.613277435302734}, {"pred": "theyroute", "count": 1, "cond_log_prob": -22.447872161865234}]}, "9": {"context": {"text": "Owls are more flexible than humans because a", "log_prob": -46.420928955078125}, "original": {"pred": "bird's", "cond_log_prob": -6.0550537109375}, "human": [{"pred": "human", "cond_log_prob": -3.931293487548828, "count": 10}, {"pred": "bone", "cond_log_prob": -7.707042694091797, "count": 6}, {"pred": "owl", "cond_log_prob": -5.969402313232422, "count": 5}, {"pred": "special", "cond_log_prob": -6.888416290283203, "count": 4}, {"pred": "bird", "cond_log_prob": -4.746692657470703, "count": 3}, {"pred": "muscle", "cond_log_prob": -6.972064971923828, "count": 2}, {"pred": "tendon", "cond_log_prob": -9.23782730102539, "count": 2}, {"pred": "a", "cond_log_prob": -9.260997772216797, "count": 1}, {"pred": "difference", "cond_log_prob": -7.570423126220703, "count": 1}, {"pred": "extra", "cond_log_prob": -11.318317413330078, "count": 1}, {"pred": "joint", "cond_log_prob": -8.545825958251953, "count": 1}, {"pred": "new", "cond_log_prob": -5.068401336669922, "count": 1}, {"pred": "part", "cond_log_prob": -5.972492218017578, "count": 1}, {"pred": "perfect", "cond_log_prob": -7.626270294189453, "count": 1}, {"pred": "rotating", "cond_log_prob": -9.568050384521484, "count": 1}, {"pred": "vertabrae", "cond_log_prob": -33.097434997558594, "count": 1}, {"pred": "vertebrae", "cond_log_prob": -11.134349822998047, "count": 1}], "ancestral_samples": [{"pred": "baby", "count": 1, "cond_log_prob": -6.437137603759766}, {"pred": "bees", "count": 1, "cond_log_prob": -11.742115020751953}, {"pred": "dwarfs", "count": 1, "cond_log_prob": -14.224510192871094}, {"pred": "few", "count": 1, "cond_log_prob": -4.526264190673828}, {"pred": "human", "count": 10, "cond_log_prob": -3.931293487548828}, {"pred": "humans", "count": 4, "cond_log_prob": -9.947689056396484}, {"pred": "large", "count": 2, "cond_log_prob": -3.911090850830078}, {"pred": "lot", "count": 4, "cond_log_prob": -3.176563262939453}, {"pred": "person", "count": 6, "cond_log_prob": -3.536113739013672}, {"pred": "personroute", "count": 1, "cond_log_prob": -27.878524780273438}, {"pred": "persons", "count": 4, "cond_log_prob": -13.121723175048828}, {"pred": "plants", "count": 1, "cond_log_prob": -13.12399673461914}, {"pred": "single", "count": 1, "cond_log_prob": -4.151004791259766}, {"pred": "tiny", "count": 1, "cond_log_prob": -6.723545074462891}, {"pred": "tree", "count": 1, "cond_log_prob": -5.658466339111328}, {"pred": "virus", "count": 1, "cond_log_prob": -8.757511138916016}]}, "10": {"context": {"text": "Owls are more flexible than humans because a bird's", "log_prob": -52.475982666015625}, "original": {"pred": "head", "cond_log_prob": -2.9095077514648438}, "human": [{"pred": "neck", "cond_log_prob": -5.480777740478516, "count": 17}, {"pred": "wings", "cond_log_prob": -3.4190101623535156, "count": 4}, {"pred": "body", "cond_log_prob": -3.078510284423828, "count": 3}, {"pred": "bones", "cond_log_prob": -6.944034576416016, "count": 4}, {"pred": "skeleton", "cond_log_prob": -7.179950714111328, "count": 2}, {"pred": "a", "cond_log_prob": -7.499866485595703, "count": 1}, {"pred": "ability", "cond_log_prob": -4.093875885009766, "count": 1}, {"pred": "anatomy", "cond_log_prob": -5.216358184814453, "count": 1}, {"pred": "back", "cond_log_prob": -6.270183563232422, "count": 1}, {"pred": "eye", "cond_log_prob": -4.740276336669922, "count": 1}, {"pred": "flexibility", "cond_log_prob": -7.350124359130859, "count": 1}, {"pred": "is", "cond_log_prob": -8.282909393310547, "count": 1}, {"pred": "joints", "cond_log_prob": -7.786350250244141, "count": 1}, {"pred": "muscles", "cond_log_prob": -5.346797943115234, "count": 1}, {"pred": "skeletal", "cond_log_prob": -8.88320541381836, "count": 1}, {"pred": "spine", "cond_log_prob": -6.188289642333984, "count": 1}, {"pred": "vertebrae", "cond_log_prob": -8.794479370117188, "count": 1}], "ancestral_samples": [{"pred": "body", "count": 7, "cond_log_prob": -3.078510284423828}, {"pred": "brain", "count": 14, "cond_log_prob": -2.469837188720703}, {"pred": "brainroute", "count": 1, "cond_log_prob": -22.552719116210938}, {"pred": "flight", "count": 1, "cond_log_prob": -4.294124603271484}, {"pred": "gills", "count": 1, "cond_log_prob": -7.136653900146484}, {"pred": "head", "count": 4, "cond_log_prob": -2.909534454345703}, {"pred": "heart", "count": 1, "cond_log_prob": -4.664188385009766}, {"pred": "legs", "count": 1, "cond_log_prob": -4.990192413330078}, {"pred": "mouth", "count": 1, "cond_log_prob": -6.441577911376953}, {"pred": "natural", "count": 1, "cond_log_prob": -3.8568153381347656}, {"pred": "skin", "count": 1, "cond_log_prob": -5.260547637939453}, {"pred": "tiny", "count": 1, "cond_log_prob": -7.087871551513672}, {"pred": "wing", "count": 2, "cond_log_prob": -4.369388580322266}, {"pred": "wings", "count": 4, "cond_log_prob": -3.4190101623535156}]}, "11": {"context": {"text": "Owls are more flexible than humans because a bird's head", "log_prob": -55.38549041748047}, "original": {"pred": "is", "cond_log_prob": -1.0720634460449219}, "human": [{"pred": "is", "cond_log_prob": -1.0721549987792969, "count": 20}, {"pred": "can", "cond_log_prob": -2.3325157165527344, "count": 13}, {"pred": "has", "cond_log_prob": -3.306629180908203, "count": 3}, {"pred": "a", "cond_log_prob": -9.256675720214844, "count": 1}, {"pred": "contains", "cond_log_prob": -6.974658966064453, "count": 1}, {"pred": "does", "cond_log_prob": -4.374858856201172, "count": 1}, {"pred": "lacks", "cond_log_prob": -7.118267059326172, "count": 1}, {"pred": "must", "cond_log_prob": -4.692470550537109, "count": 1}, {"pred": "swivels", "cond_log_prob": -7.330738067626953, "count": 1}], "ancestral_samples": [{"pred": "can", "count": 3, "cond_log_prob": -2.3324928283691406}, {"pred": "is", "count": 36, "cond_log_prob": -1.0721168518066406}, {"pred": "isroute", "count": 1, "cond_log_prob": -26.056991577148438}]}, "12": {"context": {"text": "Owls are more flexible than humans because a bird's head is", "log_prob": -56.45755386352539}, "original": {"pred": "only", "cond_log_prob": -4.917610168457031}, "human": [{"pred": "more", "cond_log_prob": -2.9600906372070312, "count": 11}, {"pred": "able", "cond_log_prob": -5.325660705566406, "count": 7}, {"pred": "smaller", "cond_log_prob": -3.9117050170898438, "count": 5}, {"pred": "attached", "cond_log_prob": -4.621604919433594, "count": 3}, {"pred": "not", "cond_log_prob": -3.48907470703125, "count": 3}, {"pred": "a", "cond_log_prob": -3.3253555297851562, "count": 2}, {"pred": "connected", "cond_log_prob": -5.396171569824219, "count": 2}, {"pred": "less", "cond_log_prob": -4.766761779785156, "count": 2}, {"pred": "better", "cond_log_prob": -7.032844543457031, "count": 1}, {"pred": "capable", "cond_log_prob": -6.720008850097656, "count": 1}, {"pred": "designed", "cond_log_prob": -5.682670593261719, "count": 1}, {"pred": "far", "cond_log_prob": -5.437629699707031, "count": 1}, {"pred": "light", "cond_log_prob": -6.470146179199219, "count": 1}, {"pred": "much", "cond_log_prob": -3.6861648559570312, "count": 1}, {"pred": "too", "cond_log_prob": -5.193641662597656, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 6, "cond_log_prob": -3.3254013061523438}, {"pred": "already", "count": 1, "cond_log_prob": -6.336296081542969}, {"pred": "alwaysroute", "count": 1, "cond_log_prob": -28.968204498291016}, {"pred": "defined", "count": 1, "cond_log_prob": -6.358589172363281}, {"pred": "flexible", "count": 1, "cond_log_prob": -4.670570373535156}, {"pred": "larger", "count": 1, "cond_log_prob": -4.096305847167969}, {"pred": "more", "count": 9, "cond_log_prob": -2.960113525390625}, {"pred": "much", "count": 5, "cond_log_prob": -3.6862106323242188}, {"pred": "naturally", "count": 2, "cond_log_prob": -5.619285583496094}, {"pred": "not", "count": 8, "cond_log_prob": -3.489105224609375}, {"pred": "shorter", "count": 2, "cond_log_prob": -4.505058288574219}, {"pred": "smaller", "count": 1, "cond_log_prob": -3.9117660522460938}, {"pred": "so", "count": 1, "cond_log_prob": -4.078269958496094}, {"pred": "very", "count": 1, "cond_log_prob": -5.291542053222656}]}, "13": {"context": {"text": "Owls are more flexible than humans because a bird's head is only", "log_prob": -61.37516403198242}, "original": {"pred": "connected", "cond_log_prob": -7.507480621337891}, "human": [{"pred": "attached", "cond_log_prob": -6.183498382568359, "count": 8}, {"pred": "a", "cond_log_prob": -2.280975341796875, "count": 7}, {"pred": "connected", "cond_log_prob": -7.507564544677734, "count": 5}, {"pred": "able", "cond_log_prob": -4.885334014892578, "count": 4}, {"pred": "made", "cond_log_prob": -6.016696929931641, "count": 3}, {"pred": "one", "cond_log_prob": -2.8718605041503906, "count": 2}, {"pred": "the", "cond_log_prob": -4.865756988525391, "count": 2}, {"pred": "three", "cond_log_prob": -4.023319244384766, "count": 2}, {"pred": "as", "cond_log_prob": -3.308429718017578, "count": 1}, {"pred": "focused", "cond_log_prob": -8.241161346435547, "count": 1}, {"pred": "half", "cond_log_prob": -3.2226295471191406, "count": 1}, {"pred": "held", "cond_log_prob": -6.348415374755859, "count": 1}, {"pred": "huge", "cond_log_prob": -9.847652435302734, "count": 1}, {"pred": "on", "cond_log_prob": -6.688503265380859, "count": 1}, {"pred": "shorter", "cond_log_prob": -7.845699310302734, "count": 1}, {"pred": "ten", "cond_log_prob": -5.784656524658203, "count": 1}, {"pred": "two", "cond_log_prob": -4.030857086181641, "count": 1}], "ancestral_samples": [{"pred": "30cm", "count": 1, "cond_log_prob": -7.357547760009766}, {"pred": "a", "count": 14, "cond_log_prob": -2.280975341796875}, {"pred": "about", "count": 20, "cond_log_prob": -1.962860107421875}, {"pred": "aboutroute", "count": 1, "cond_log_prob": -26.43960952758789}, {"pred": "as", "count": 1, "cond_log_prob": -3.308429718017578}, {"pred": "one", "count": 1, "cond_log_prob": -2.8718605041503906}, {"pred": "partially", "count": 1, "cond_log_prob": -4.721118927001953}, {"pred": "slightly", "count": 1, "cond_log_prob": -3.200153350830078}]}, "14": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected", "log_prob": -68.88264465332031}, "original": {"pred": "by", "cond_log_prob": -2.3027877807617188}, "human": [{"pred": "to", "cond_log_prob": -0.24204254150390625, "count": 18}, {"pred": "by", "cond_log_prob": -2.3028793334960938, "count": 15}, {"pred": "in", "cond_log_prob": -5.116966247558594, "count": 4}, {"pred": "at", "cond_log_prob": -5.0391693115234375, "count": 3}, {"pred": "a", "cond_log_prob": -6.708686828613281, "count": 1}, {"pred": "with", "cond_log_prob": -3.6701583862304688, "count": 1}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.24204254150390625}, {"pred": "toroute", "count": 1, "cond_log_prob": -30.14606475830078}]}, "15": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by", "log_prob": -71.18543243408203}, "original": {"pred": "one", "cond_log_prob": -3.126953125}, "human": [{"pred": "one", "cond_log_prob": -3.1270599365234375, "count": 15}, {"pred": "the", "cond_log_prob": -2.286773681640625, "count": 10}, {"pred": "a", "cond_log_prob": -1.2636566162109375, "count": 10}, {"pred": "two", "cond_log_prob": -2.8763885498046875, "count": 2}, {"pred": "1", "cond_log_prob": -6.9523468017578125, "count": 1}, {"pred": "cartilage", "cond_log_prob": -8.510055541992188, "count": 1}, {"pred": "it", "cond_log_prob": -6.51116943359375, "count": 1}, {"pred": "ligaments", "cond_log_prob": -7.3421783447265625, "count": 1}, {"pred": "seven", "cond_log_prob": -6.9102020263671875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 35, "cond_log_prob": -1.2636566162109375}, {"pred": "aroute", "count": 1, "cond_log_prob": -25.858009338378906}, {"pred": "its", "count": 2, "cond_log_prob": -2.1947479248046875}, {"pred": "the", "count": 2, "cond_log_prob": -2.286773681640625}]}, "16": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one", "log_prob": -74.31238555908203}, "original": {"pred": "socket", "cond_log_prob": -5.7606658935546875}, "human": [{"pred": "bone", "cond_log_prob": -4.0739593505859375, "count": 13}, {"pred": "muscle", "cond_log_prob": -4.0414886474609375, "count": 6}, {"pred": "tendon", "cond_log_prob": -5.7370147705078125, "count": 4}, {"pred": "ligament", "cond_log_prob": -7.5430908203125, "count": 3}, {"pred": "connection", "cond_log_prob": -6.6372528076171875, "count": 2}, {"pred": "joint", "cond_log_prob": -5.016693115234375, "count": 2}, {"pred": "nerve", "cond_log_prob": -3.51678466796875, "count": 2}, {"pred": "vertebrae", "cond_log_prob": -6.0745849609375, "count": 2}, {"pred": "a", "cond_log_prob": -8.540191650390625, "count": 1}, {"pred": "cord", "cond_log_prob": -6.61163330078125, "count": 1}, {"pred": "location", "cond_log_prob": -8.209747314453125, "count": 1}, {"pred": "or", "cond_log_prob": -3.1614227294921875, "count": 1}, {"pred": "point", "cond_log_prob": -5.697509765625, "count": 1}, {"pred": "small", "cond_log_prob": -5.263275146484375, "count": 1}, {"pred": "socket", "cond_log_prob": -5.760772705078125, "count": 1}, {"pred": "spinal", "cond_log_prob": -7.485015869140625, "count": 1}], "ancestral_samples": [{"pred": "arm", "count": 1, "cond_log_prob": -3.81866455078125}, {"pred": "ear", "count": 2, "cond_log_prob": -3.0306243896484375}, {"pred": "earroute", "count": 1, "cond_log_prob": -21.650611877441406}, {"pred": "end", "count": 4, "cond_log_prob": -3.79168701171875}, {"pred": "eye", "count": 3, "cond_log_prob": -2.8604736328125}, {"pred": "eyeThe", "count": 1, "cond_log_prob": -17.040138244628906}, {"pred": "hand", "count": 1, "cond_log_prob": -3.4188232421875}, {"pred": "leg", "count": 5, "cond_log_prob": -3.3047332763671875}, {"pred": "legThe", "count": 1, "cond_log_prob": -17.97748565673828}, {"pred": "muscle", "count": 1, "cond_log_prob": -4.0414886474609375}, {"pred": "muscleThe", "count": 1, "cond_log_prob": -19.358543395996094}, {"pred": "nerve", "count": 1, "cond_log_prob": -3.51678466796875}, {"pred": "neuron", "count": 1, "cond_log_prob": -5.8331146240234375}, {"pred": "of", "count": 5, "cond_log_prob": -3.166748046875}, {"pred": "or", "count": 3, "cond_log_prob": -3.1614227294921875}, {"pred": "pair", "count": 1, "cond_log_prob": -4.3484344482421875}, {"pred": "part", "count": 1, "cond_log_prob": -4.2639617919921875}, {"pred": "side", "count": 1, "cond_log_prob": -4.40240478515625}, {"pred": "tiny", "count": 1, "cond_log_prob": -5.6498260498046875}, {"pred": "wing", "count": 1, "cond_log_prob": -4.9093017578125}, {"pred": "wire", "count": 4, "cond_log_prob": -3.8769989013671875}]}, "17": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket", "log_prob": -80.07305145263672}, "original": {"pred": "pivot.", "cond_log_prob": -16.14789581298828}, "human": [{"pred": "in", "cond_log_prob": -3.585205078125, "count": 9}, {"pred": "and", "cond_log_prob": -2.827850341796875, "count": 6}, {"pred": "instead", "cond_log_prob": -5.494140625, "count": 3}, {"pred": "rather", "cond_log_prob": -5.4970855712890625, "count": 3}, {"pred": "at", "cond_log_prob": -3.70440673828125, "count": 2}, {"pred": "of", "cond_log_prob": -3.9409027099609375, "count": 2}, {"pred": "on", "cond_log_prob": -3.466461181640625, "count": 2}, {"pred": "to", "cond_log_prob": -3.8330841064453125, "count": 2}, {"pred": "a", "cond_log_prob": -8.320365905761719, "count": 1}, {"pred": "as", "cond_log_prob": -6.3367462158203125, "count": 1}, {"pred": "from", "cond_log_prob": -5.942169189453125, "count": 1}, {"pred": "ine", "cond_log_prob": -17.300682067871094, "count": 1}, {"pred": "joint", "cond_log_prob": -9.744071960449219, "count": 1}, {"pred": "near", "cond_log_prob": -8.606361389160156, "count": 1}, {"pred": "or", "cond_log_prob": -4.4781036376953125, "count": 1}, {"pred": "pivot", "cond_log_prob": -15.145179748535156, "count": 1}, {"pred": "that", "cond_log_prob": -4.0390777587890625, "count": 1}, {"pred": "where", "cond_log_prob": -6.65557861328125, "count": 1}, {"pred": "whereas", "cond_log_prob": -7.18072509765625, "count": 1}, {"pred": "while", "cond_log_prob": -5.86907958984375, "count": 1}, {"pred": "with", "cond_log_prob": -5.5150299072265625, "count": 1}], "ancestral_samples": [{"pred": "1", "count": 1, "cond_log_prob": -8.888221740722656}, {"pred": "A", "count": 3, "cond_log_prob": -10.333518981933594}, {"pred": "According", "count": 1, "cond_log_prob": -15.860328674316406}, {"pred": "Birds", "count": 1, "cond_log_prob": -18.484764099121094}, {"pred": "In", "count": 1, "cond_log_prob": -11.761528015136719}, {"pred": "Ow", "count": 1, "cond_log_prob": -15.233909606933594}, {"pred": "The", "count": 17, "cond_log_prob": -10.442359924316406}, {"pred": "There", "count": 1, "cond_log_prob": -12.198081970214844}, {"pred": "They", "count": 1, "cond_log_prob": -13.812629699707031}, {"pred": "This", "count": 5, "cond_log_prob": -12.009590148925781}, {"pred": "We", "count": 1, "cond_log_prob": -13.520179748535156}, {"pred": "When", "count": 1, "cond_log_prob": -12.869316101074219}, {"pred": "and", "count": 2, "cond_log_prob": -2.827850341796875}, {"pred": "not", "count": 1, "cond_log_prob": -9.157676696777344}, {"pred": "route", "count": 1, "cond_log_prob": -12.887763977050781}, {"pred": "so", "count": 1, "cond_log_prob": -5.64215087890625}, {"pred": "which", "count": 1, "cond_log_prob": -4.7513580322265625}]}, "18": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot.", "log_prob": -96.220947265625}, "original": {"pred": "People", "cond_log_prob": -7.116310119628906}, "human": [{"pred": "this", "cond_log_prob": -10.296051025390625, "count": 13}, {"pred": "humans", "cond_log_prob": -13.395217895507812, "count": 5}, {"pred": "owls", "cond_log_prob": -10.2608642578125, "count": 5}, {"pred": "the", "cond_log_prob": -8.956130981445312, "count": 5}, {"pred": "and", "cond_log_prob": -9.40283203125, "count": 2}, {"pred": "they", "cond_log_prob": -11.857086181640625, "count": 3}, {"pred": "a", "cond_log_prob": -9.595611572265625, "count": 1}, {"pred": "also", "cond_log_prob": -12.0938720703125, "count": 1}, {"pred": "because", "cond_log_prob": -11.44720458984375, "count": 1}, {"pred": "gross", "cond_log_prob": -21.70494842529297, "count": 1}, {"pred": "point", "cond_log_prob": -15.945526123046875, "count": 1}, {"pred": "that", "cond_log_prob": -10.656890869140625, "count": 2}, {"pred": "thus", "cond_log_prob": -13.794174194335938, "count": 2}], "ancestral_samples": [{"pred": "A", "count": 3, "cond_log_prob": -3.5777130126953125}, {"pred": "In", "count": 2, "cond_log_prob": -3.46319580078125}, {"pred": "It", "count": 1, "cond_log_prob": -3.884552001953125}, {"pred": "Since", "count": 1, "cond_log_prob": -5.6841278076171875}, {"pred": "Some", "count": 1, "cond_log_prob": -5.56268310546875}, {"pred": "The", "count": 23, "cond_log_prob": -2.31939697265625}, {"pred": "They", "count": 1, "cond_log_prob": -3.908843994140625}, {"pred": "This", "count": 4, "cond_log_prob": -2.370758056640625}, {"pred": "We", "count": 2, "cond_log_prob": -5.193023681640625}, {"pred": "When", "count": 1, "cond_log_prob": -3.9415740966796875}, {"pred": "route_motor", "count": 1, "cond_log_prob": -30.48370361328125}]}, "19": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People", "log_prob": -103.3372573852539}, "original": {"pred": "have", "cond_log_prob": -2.6041641235351562}, "human": [{"pred": "have", "cond_log_prob": -2.6043167114257812, "count": 19}, {"pred": "are", "cond_log_prob": -3.2330245971679688, "count": 11}, {"pred": "do", "cond_log_prob": -4.797889709472656, "count": 3}, {"pred": "a", "cond_log_prob": -9.016807556152344, "count": 1}, {"pred": "also", "cond_log_prob": -4.588279724121094, "count": 1}, {"pred": "believe", "cond_log_prob": -4.505332946777344, "count": 1}, {"pred": "ca", "cond_log_prob": -11.9674072265625, "count": 1}, {"pred": "generally", "cond_log_prob": -5.319374084472656, "count": 1}, {"pred": "say", "cond_log_prob": -4.468894958496094, "count": 1}, {"pred": "should", "cond_log_prob": -6.046318054199219, "count": 1}, {"pred": "that", "cond_log_prob": -5.942298889160156, "count": 1}, {"pred": "who", "cond_log_prob": -2.1106948852539062, "count": 1}], "ancestral_samples": [{"pred": "are", "count": 3, "cond_log_prob": -3.2330245971679688}, {"pred": "can", "count": 3, "cond_log_prob": -3.1390762329101562}, {"pred": "have", "count": 6, "cond_log_prob": -2.6043167114257812}, {"pred": "haveroute", "count": 1, "cond_log_prob": -29.57109832763672}, {"pred": "often", "count": 1, "cond_log_prob": -2.8873214721679688}, {"pred": "who", "count": 23, "cond_log_prob": -2.1106948852539062}, {"pred": "with", "count": 3, "cond_log_prob": -2.7629776000976562}]}, "20": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have", "log_prob": -105.94142150878906}, "original": {"pred": "two,", "cond_log_prob": -11.332809448242188}, "human": [{"pred": "two", "cond_log_prob": -6.449432373046875, "count": 10}, {"pred": "more", "cond_log_prob": -5.3150634765625, "count": 8}, {"pred": "multiple", "cond_log_prob": -7.7433319091796875, "count": 6}, {"pred": "three", "cond_log_prob": -7.3300933837890625, "count": 5}, {"pred": "a", "cond_log_prob": -3.5501861572265625, "count": 2}, {"pred": "at", "cond_log_prob": -7.751800537109375, "count": 2}, {"pred": "fewer", "cond_log_prob": -8.52972412109375, "count": 2}, {"pred": "13", "cond_log_prob": -10.963546752929688, "count": 1}, {"pred": "bones", "cond_log_prob": -10.819595336914062, "count": 1}, {"pred": "heads", "cond_log_prob": -11.598876953125, "count": 1}, {"pred": "many", "cond_log_prob": -5.4858551025390625, "count": 1}, {"pred": "no", "cond_log_prob": -4.979583740234375, "count": 1}, {"pred": "several", "cond_log_prob": -6.6562957763671875, "count": 1}, {"pred": "studied", "cond_log_prob": -6.452911376953125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 6, "cond_log_prob": -3.5501861572265625}, {"pred": "also", "count": 1, "cond_log_prob": -4.2170867919921875}, {"pred": "been", "count": 27, "cond_log_prob": -2.1174774169921875}, {"pred": "beenrouteing", "count": 1, "cond_log_prob": -29.82342529296875}, {"pred": "had", "count": 1, "cond_log_prob": -3.9252166748046875}, {"pred": "known", "count": 1, "cond_log_prob": -3.6162261962890625}, {"pred": "said", "count": 1, "cond_log_prob": -4.1082305908203125}, {"pred": "to", "count": 1, "cond_log_prob": -4.2733306884765625}, {"pred": "used", "count": 1, "cond_log_prob": -3.34307861328125}]}, "21": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two,", "log_prob": -117.27423095703125}, "original": {"pred": "which", "cond_log_prob": -3.6043014526367188}, "human": [{"pred": "which", "cond_log_prob": -3.6044692993164062, "count": 9}, {"pred": "so", "cond_log_prob": -3.4153671264648438, "count": 7}, {"pred": "or", "cond_log_prob": -2.7808303833007812, "count": 3}, {"pred": "that", "cond_log_prob": -6.597328186035156, "count": 2}, {"pred": "this", "cond_log_prob": -7.281364440917969, "count": 3}, {"pred": "a", "cond_log_prob": -4.591728210449219, "count": 1}, {"pred": "because", "cond_log_prob": -5.748725891113281, "count": 1}, {"pred": "causing", "cond_log_prob": -9.846725463867188, "count": 1}, {"pred": "connected", "cond_log_prob": -6.185417175292969, "count": 1}, {"pred": "four", "cond_log_prob": -3.6712875366210938, "count": 1}, {"pred": "making", "cond_log_prob": -7.598320007324219, "count": 2}, {"pred": "meaning", "cond_log_prob": -7.121803283691406, "count": 1}, {"pred": "owls", "cond_log_prob": -10.602767944335938, "count": 1}, {"pred": "pivot", "cond_log_prob": -11.093414306640625, "count": 1}, {"pred": "points", "cond_log_prob": -11.626251220703125, "count": 1}, {"pred": "restricting", "cond_log_prob": -11.926971435546875, "count": 1}, {"pred": "socket", "cond_log_prob": -9.876754760742188, "count": 1}, {"pred": "sockets", "cond_log_prob": -12.226058959960938, "count": 1}, {"pred": "the", "cond_log_prob": -4.877204895019531, "count": 1}, {"pred": "therefore", "cond_log_prob": -6.951271057128906, "count": 1}, {"pred": "three", "cond_log_prob": -3.2482528686523438, "count": 1}, {"pred": "with", "cond_log_prob": -4.848274230957031, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -4.591728210449219}, {"pred": "and", "count": 4, "cond_log_prob": -2.6235885620117188}, {"pred": "but", "count": 24, "cond_log_prob": -1.6701126098632812}, {"pred": "butroute", "count": 1, "cond_log_prob": -24.503448486328125}, {"pred": "or", "count": 6, "cond_log_prob": -2.7808303833007812}, {"pred": "so", "count": 1, "cond_log_prob": -3.4153671264648438}, {"pred": "three", "count": 1, "cond_log_prob": -3.2482528686523438}, {"pred": "two", "count": 1, "cond_log_prob": -3.4262161254882812}]}, "22": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which", "log_prob": -120.87853240966797}, "original": {"pred": "limits", "cond_log_prob": -8.005256652832031}, "human": [{"pred": "makes", "cond_log_prob": -2.6515655517578125, "count": 10}, {"pred": "are", "cond_log_prob": -2.94805908203125, "count": 4}, {"pred": "means", "cond_log_prob": -1.0443878173828125, "count": 4}, {"pred": "prevents", "cond_log_prob": -7.047981262207031, "count": 4}, {"pred": "restricts", "cond_log_prob": -8.092689514160156, "count": 3}, {"pred": "causes", "cond_log_prob": -6.095252990722656, "count": 2}, {"pred": "connect", "cond_log_prob": -6.556587219238281, "count": 2}, {"pred": "is", "cond_log_prob": -1.9523773193359375, "count": 2}, {"pred": "only", "cond_log_prob": -7.025932312011719, "count": 2}, {"pred": "a", "cond_log_prob": -7.194313049316406, "count": 1}, {"pred": "allow", "cond_log_prob": -5.098274230957031, "count": 1}, {"pred": "creates", "cond_log_prob": -5.718727111816406, "count": 1}, {"pred": "explains", "cond_log_prob": -5.470222473144531, "count": 1}, {"pred": "helps", "cond_log_prob": -4.840538024902344, "count": 1}, {"pred": "limits", "cond_log_prob": -8.005424499511719, "count": 1}, {"pred": "make", "cond_log_prob": -4.339591979980469, "count": 1}, {"pred": "reduce", "cond_log_prob": -8.324974060058594, "count": 1}, {"pred": "restrict", "cond_log_prob": -9.779029846191406, "count": 1}], "ancestral_samples": [{"pred": "are", "count": 4, "cond_log_prob": -2.94805908203125}, {"pred": "is", "count": 7, "cond_log_prob": -1.9523773193359375}, {"pred": "isroute", "count": 1, "cond_log_prob": -27.012962341308594}, {"pred": "means", "count": 28, "cond_log_prob": -1.0443878173828125}]}, "23": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits", "log_prob": -128.8837890625}, "original": {"pred": "our", "cond_log_prob": -4.73828125}, "human": [{"pred": "the", "cond_log_prob": -1.2713775634765625, "count": 16}, {"pred": "their", "cond_log_prob": -1.5322113037109375, "count": 15}, {"pred": "movement", "cond_log_prob": -5.76287841796875, "count": 3}, {"pred": "our", "cond_log_prob": -4.73846435546875, "count": 3}, {"pred": "flexibility", "cond_log_prob": -5.102691650390625, "count": 2}, {"pred": "them", "cond_log_prob": -4.1096954345703125, "count": 2}, {"pred": "a", "cond_log_prob": -4.53369140625, "count": 1}], "ancestral_samples": [{"pred": "how", "count": 1, "cond_log_prob": -2.1258544921875}, {"pred": "its", "count": 1, "cond_log_prob": -2.435455322265625}, {"pred": "the", "count": 26, "cond_log_prob": -1.2713775634765625}, {"pred": "their", "count": 11, "cond_log_prob": -1.5322113037109375}, {"pred": "theirroute", "count": 1, "cond_log_prob": -24.916061401367188}]}, "24": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our", "log_prob": -133.6220703125}, "original": {"pred": "ability", "cond_log_prob": -0.5109405517578125}, "human": [{"pred": "ability", "cond_log_prob": -0.5111236572265625, "count": 11}, {"pred": "flexibility", "cond_log_prob": -3.1750946044921875, "count": 11}, {"pred": "movement", "cond_log_prob": -5.2117919921875, "count": 7}, {"pred": "capacity", "cond_log_prob": -4.1265411376953125, "count": 2}, {"pred": "motion", "cond_log_prob": -8.20477294921875, "count": 2}, {"pred": "rotation", "cond_log_prob": -9.42584228515625, "count": 2}, {"pred": "a", "cond_log_prob": -10.303298950195312, "count": 1}, {"pred": "mobility", "cond_log_prob": -4.562957763671875, "count": 2}, {"pred": "movements", "cond_log_prob": -6.227569580078125, "count": 1}, {"pred": "range", "cond_log_prob": -4.4440155029296875, "count": 1}, {"pred": "the", "cond_log_prob": -9.222335815429688, "count": 1}, {"pred": "understanding", "cond_log_prob": -4.1974945068359375, "count": 1}], "ancestral_samples": [{"pred": "ability", "count": 39, "cond_log_prob": -0.5111236572265625}, {"pred": "abilityroute", "count": 1, "cond_log_prob": -24.77899169921875}]}, "25": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability", "log_prob": -134.1330108642578}, "original": {"pred": "to", "cond_log_prob": -0.0054931640625}, "human": [{"pred": "to", "cond_log_prob": -0.0056915283203125, "count": 40}, {"pred": "a", "cond_log_prob": -11.502838134765625, "count": 1}, {"pred": "the", "cond_log_prob": -11.3026123046875, "count": 1}], "ancestral_samples": [{"pred": "to", "count": 39, "cond_log_prob": -0.0056915283203125}, {"pred": "toroute", "count": 1, "cond_log_prob": -31.137405395507812}]}, "26": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to", "log_prob": -134.1385040283203}, "original": {"pred": "twist,", "cond_log_prob": -10.84014892578125}, "human": [{"pred": "move", "cond_log_prob": -3.4132843017578125, "count": 15}, {"pred": "turn", "cond_log_prob": -5.9157867431640625, "count": 10}, {"pred": "rotate", "cond_log_prob": -5.4129638671875, "count": 7}, {"pred": "be", "cond_log_prob": -5.1337127685546875, "count": 3}, {"pred": "a", "cond_log_prob": -9.313461303710938, "count": 1}, {"pred": "bend", "cond_log_prob": -6.0315704345703125, "count": 1}, {"pred": "flex", "cond_log_prob": -6.5589141845703125, "count": 1}, {"pred": "have", "cond_log_prob": -5.315643310546875, "count": 1}, {"pred": "see", "cond_log_prob": -3.563507080078125, "count": 1}, {"pred": "twist", "cond_log_prob": -7.4047088623046875, "count": 1}, {"pred": "two", "cond_log_prob": -9.977935791015625, "count": 1}], "ancestral_samples": [{"pred": "change", "count": 4, "cond_log_prob": -4.263641357421875}, {"pred": "communicate", "count": 1, "cond_log_prob": -4.2683258056640625}, {"pred": "control", "count": 2, "cond_log_prob": -3.8352203369140625}, {"pred": "detect", "count": 2, "cond_log_prob": -5.7080078125}, {"pred": "fly", "count": 2, "cond_log_prob": -3.4677581787109375}, {"pred": "flyAs", "count": 1, "cond_log_prob": -21.10174560546875}, {"pred": "flyThe", "count": 1, "cond_log_prob": -19.13671875}, {"pred": "form", "count": 1, "cond_log_prob": -5.654541015625}, {"pred": "generate", "count": 1, "cond_log_prob": -6.8358306884765625}, {"pred": "make", "count": 3, "cond_log_prob": -3.5746612548828125}, {"pred": "move", "count": 3, "cond_log_prob": -3.4132843017578125}, {"pred": "moveroute", "count": 1, "cond_log_prob": -33.82029724121094}, {"pred": "operate", "count": 1, "cond_log_prob": -6.0413055419921875}, {"pred": "pick", "count": 1, "cond_log_prob": -5.1345062255859375}, {"pred": "see", "count": 5, "cond_log_prob": -3.563507080078125}, {"pred": "switch", "count": 1, "cond_log_prob": -5.1806793212890625}, {"pred": "use", "count": 10, "cond_log_prob": -3.1173553466796875}]}, "27": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist,", "log_prob": -144.97865295410156}, "original": {"pred": "Forsman", "cond_log_prob": -21.486831665039062}, "human": [{"pred": "and", "cond_log_prob": -2.8992767333984375, "count": 15}, {"pred": "turn", "cond_log_prob": -3.556976318359375, "count": 10}, {"pred": "or", "cond_log_prob": -4.010986328125, "count": 2}, {"pred": "the", "cond_log_prob": -6.3582000732421875, "count": 2}, {"pred": "which", "cond_log_prob": -3.6232452392578125, "count": 2}, {"pred": "a", "cond_log_prob": -6.8272247314453125, "count": 1}, {"pred": "bend", "cond_log_prob": -2.6235198974609375, "count": 1}, {"pred": "however", "cond_log_prob": -7.31317138671875, "count": 1}, {"pred": "move", "cond_log_prob": -4.9983673095703125, "count": 1}, {"pred": "our", "cond_log_prob": -8.467056274414062, "count": 1}, {"pred": "owls", "cond_log_prob": -12.280563354492188, "count": 1}, {"pred": "pivot", "cond_log_prob": -6.54498291015625, "count": 1}, {"pred": "preventing", "cond_log_prob": -11.960174560546875, "count": 1}, {"pred": "therefore", "cond_log_prob": -8.878189086914062, "count": 1}, {"pred": "thus", "cond_log_prob": -6.6902008056640625, "count": 1}, {"pred": "where", "cond_log_prob": -8.09027099609375, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 7, "cond_log_prob": -2.8992767333984375}, {"pred": "as", "count": 1, "cond_log_prob": -4.5601654052734375}, {"pred": "bend", "count": 5, "cond_log_prob": -2.6235198974609375}, {"pred": "curl", "count": 1, "cond_log_prob": -5.1487274169921875}, {"pred": "or", "count": 1, "cond_log_prob": -4.010986328125}, {"pred": "slice", "count": 1, "cond_log_prob": -6.846221923828125}, {"pred": "spin", "count": 1, "cond_log_prob": -4.5081634521484375}, {"pred": "stretch", "count": 1, "cond_log_prob": -5.2803497314453125}, {"pred": "to", "count": 2, "cond_log_prob": -3.7751922607421875}, {"pred": "twist", "count": 18, "cond_log_prob": -1.860198974609375}, {"pred": "twistroute", "count": 1, "cond_log_prob": -23.469406127929688}, {"pred": "which", "count": 1, "cond_log_prob": -3.6232452392578125}]}, "28": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman", "log_prob": -166.46548461914062}, "original": {"pred": "added.", "cond_log_prob": -5.8108367919921875}, "human": [{"pred": "said", "cond_log_prob": -1.1833648681640625, "count": 11}, {"pred": "says", "cond_log_prob": -1.3468170166015625, "count": 5}, {"pred": "and", "cond_log_prob": -2.7702178955078125, "count": 3}, {"pred": "a", "cond_log_prob": -10.221481323242188, "count": 2}, {"pred": "are", "cond_log_prob": -13.185623168945312, "count": 1}, {"pred": "can", "cond_log_prob": -8.634780883789062, "count": 1}, {"pred": "concludes", "cond_log_prob": -7.4405364990234375, "count": 1}, {"pred": "dave", "cond_log_prob": -17.144317626953125, "count": 1}, {"pred": "end", "cond_log_prob": -12.425491333007812, "count": 1}, {"pred": "finds", "cond_log_prob": -8.801971435546875, "count": 1}, {"pred": "foramen", "cond_log_prob": -20.136856079101562, "count": 1}, {"pred": "found", "cond_log_prob": -5.6685943603515625, "count": 1}, {"pred": "has", "cond_log_prob": -4.8899078369140625, "count": 1}, {"pred": "have", "cond_log_prob": -10.288528442382812, "count": 1}, {"pred": "in", "cond_log_prob": -7.5028076171875, "count": 1}, {"pred": "is", "cond_log_prob": -7.4855194091796875, "count": 1}, {"pred": "knew", "cond_log_prob": -9.230667114257812, "count": 1}, {"pred": "maneuver", "cond_log_prob": -14.120864868164062, "count": 1}, {"pred": "miller", "cond_log_prob": -20.216812133789062, "count": 1}, {"pred": "please", "cond_log_prob": -16.203262329101562, "count": 1}, {"pred": "studied", "cond_log_prob": -8.482437133789062, "count": 1}, {"pred": "sucks", "cond_log_prob": -15.641006469726562, "count": 1}, {"pred": "teaches", "cond_log_prob": -9.878433227539062, "count": 1}, {"pred": "turn", "cond_log_prob": -14.519607543945312, "count": 1}, {"pred": "writes", "cond_log_prob": -4.6108551025390625, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -10.300033569335938}, {"pred": "and", "count": 1, "cond_log_prob": -2.7702178955078125}, {"pred": "said", "count": 20, "cond_log_prob": -1.1833648681640625}, {"pred": "saidAs", "count": 1, "cond_log_prob": -17.828598022460938}, {"pred": "saidBut", "count": 1, "cond_log_prob": -15.722244262695312}, {"pred": "saidThe", "count": 1, "cond_log_prob": -15.314682006835938}, {"pred": "says", "count": 13, "cond_log_prob": -1.3468170166015625}, {"pred": "saysOne", "count": 1, "cond_log_prob": -18.310836791992188}, {"pred": "saysroute", "count": 1, "cond_log_prob": -23.910476684570312}]}, "29": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added.", "log_prob": -172.2763214111328}, "original": {"pred": "Owls", "cond_log_prob": -4.0830841064453125}, "human": [{"pred": "this", "cond_log_prob": -13.0826416015625, "count": 9}, {"pred": "owls", "cond_log_prob": -12.817245483398438, "count": 7}, {"pred": "in", "cond_log_prob": -11.760101318359375, "count": 3}, {"pred": "additionally", "cond_log_prob": -19.9803466796875, "count": 2}, {"pred": "so", "cond_log_prob": -12.40020751953125, "count": 2}, {"pred": "that", "cond_log_prob": -12.139022827148438, "count": 3}, {"pred": "a", "cond_log_prob": -11.558486938476562, "count": 1}, {"pred": "also", "cond_log_prob": -13.090240478515625, "count": 1}, {"pred": "as", "cond_log_prob": -13.335784912109375, "count": 1}, {"pred": "birds", "cond_log_prob": -14.260955810546875, "count": 1}, {"pred": "end", "cond_log_prob": -17.375778198242188, "count": 1}, {"pred": "furthermore", "cond_log_prob": -19.252532958984375, "count": 1}, {"pred": "he", "cond_log_prob": -13.204193115234375, "count": 1}, {"pred": "it", "cond_log_prob": -13.642974853515625, "count": 1}, {"pred": "people", "cond_log_prob": -13.685714721679688, "count": 1}, {"pred": "some", "cond_log_prob": -15.88653564453125, "count": 1}, {"pred": "the", "cond_log_prob": -10.198318481445312, "count": 1}, {"pred": "then", "cond_log_prob": -15.3426513671875, "count": 1}, {"pred": "therefore", "cond_log_prob": -15.548477172851562, "count": 1}, {"pred": "they", "cond_log_prob": -13.875579833984375, "count": 1}, {"pred": "we", "cond_log_prob": -13.32257080078125, "count": 1}, {"pred": "with", "cond_log_prob": -12.548675537109375, "count": 1}], "ancestral_samples": [{"pred": "A", "count": 1, "cond_log_prob": -4.676300048828125}, {"pred": "Fors", "count": 1, "cond_log_prob": -5.437255859375}, {"pred": "Forsman", "count": 1, "cond_log_prob": -5.4462432861328125}, {"pred": "I", "count": 1, "cond_log_prob": -7.3740997314453125}, {"pred": "If", "count": 2, "cond_log_prob": -4.927825927734375}, {"pred": "In", "count": 2, "cond_log_prob": -4.1393280029296875}, {"pred": "Its", "count": 1, "cond_log_prob": -8.196441650390625}, {"pred": "Our", "count": 1, "cond_log_prob": -5.7499847412109375}, {"pred": "The", "count": 11, "cond_log_prob": -3.0565185546875}, {"pred": "There", "count": 1, "cond_log_prob": -6.0741424560546875}, {"pred": "They", "count": 1, "cond_log_prob": -4.723236083984375}, {"pred": "This", "count": 2, "cond_log_prob": -4.3240966796875}, {"pred": "We", "count": 9, "cond_log_prob": -4.6190185546875}, {"pred": "Were", "count": 4, "cond_log_prob": -9.223403930664062}, {"pred": "Weve", "count": 1, "cond_log_prob": -17.3515625}, {"pred": "route", "count": 1, "cond_log_prob": -22.49908447265625}]}, "30": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls", "log_prob": -176.35940551757812}, "original": {"pred": "also", "cond_log_prob": -2.6964111328125}, "human": [{"pred": "are", "cond_log_prob": -1.6470184326171875, "count": 20}, {"pred": "can", "cond_log_prob": -2.186370849609375, "count": 7}, {"pred": "also", "cond_log_prob": -2.6966705322265625, "count": 6}, {"pred": "have", "cond_log_prob": -2.343963623046875, "count": 4}, {"pred": "a", "cond_log_prob": -9.411376953125, "count": 1}, {"pred": "i", "cond_log_prob": -13.255813598632812, "count": 1}, {"pred": "not", "cond_log_prob": -7.6177825927734375, "count": 1}, {"pred": "survey", "cond_log_prob": -12.717178344726562, "count": 1}, {"pred": "use", "cond_log_prob": -3.5619354248046875, "count": 1}], "ancestral_samples": [{"pred": "also", "count": 3, "cond_log_prob": -2.6966705322265625}, {"pred": "are", "count": 21, "cond_log_prob": -1.6470184326171875}, {"pred": "can", "count": 5, "cond_log_prob": -2.186370849609375}, {"pred": "have", "count": 10, "cond_log_prob": -2.343963623046875}, {"pred": "haveroute", "count": 1, "cond_log_prob": -30.289093017578125}]}, "31": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also", "log_prob": -179.05581665039062}, "original": {"pred": "have", "cond_log_prob": -1.182647705078125}, "human": [{"pred": "have", "cond_log_prob": -1.1829071044921875, "count": 27}, {"pred": "are", "cond_log_prob": -3.2173309326171875, "count": 4}, {"pred": "can", "cond_log_prob": -3.132720947265625, "count": 5}, {"pred": "a", "cond_log_prob": -10.012832641601562, "count": 1}, {"pred": "also", "cond_log_prob": -6.307281494140625, "count": 1}, {"pred": "is", "cond_log_prob": -9.671859741210938, "count": 1}, {"pred": "not", "cond_log_prob": -8.156982421875, "count": 1}, {"pred": "tired", "cond_log_prob": -13.36572265625, "count": 1}, {"pred": "try", "cond_log_prob": -6.702117919921875, "count": 1}], "ancestral_samples": [{"pred": "dont", "count": 1, "cond_log_prob": -10.19024658203125}, {"pred": "have", "count": 38, "cond_log_prob": -1.1829071044921875}, {"pred": "haveroute", "count": 1, "cond_log_prob": -30.25030517578125}]}, "32": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have", "log_prob": -180.23846435546875}, "original": {"pred": "multiple", "cond_log_prob": -5.003570556640625}, "human": [{"pred": "the", "cond_log_prob": -3.21588134765625, "count": 10}, {"pred": "a", "cond_log_prob": -1.7948455810546875, "count": 9}, {"pred": "more", "cond_log_prob": -2.885345458984375, "count": 5}, {"pred": "one", "cond_log_prob": -4.49652099609375, "count": 3}, {"pred": "only", "cond_log_prob": -5.576171875, "count": 3}, {"pred": "less", "cond_log_prob": -4.41070556640625, "count": 2}, {"pred": "claws", "cond_log_prob": -6.128326416015625, "count": 1}, {"pred": "feathers", "cond_log_prob": -5.8002471923828125, "count": 1}, {"pred": "hollow", "cond_log_prob": -8.39239501953125, "count": 1}, {"pred": "large", "cond_log_prob": -5.83319091796875, "count": 1}, {"pred": "no", "cond_log_prob": -4.80767822265625, "count": 1}, {"pred": "of", "cond_log_prob": -9.280853271484375, "count": 1}, {"pred": "other", "cond_log_prob": -5.358642578125, "count": 1}, {"pred": "small", "cond_log_prob": -5.5330810546875, "count": 1}, {"pred": "two", "cond_log_prob": -2.257110595703125, "count": 1}, {"pred": "worthless", "cond_log_prob": -14.745391845703125, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 22, "cond_log_prob": -1.7948455810546875}, {"pred": "four", "count": 1, "cond_log_prob": -3.93994140625}, {"pred": "more", "count": 1, "cond_log_prob": -2.885345458984375}, {"pred": "the", "count": 1, "cond_log_prob": -3.21588134765625}, {"pred": "three", "count": 1, "cond_log_prob": -3.681976318359375}, {"pred": "two", "count": 13, "cond_log_prob": -2.257110595703125}, {"pred": "tworoute", "count": 1, "cond_log_prob": -33.9654541015625}]}, "33": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple", "log_prob": -185.24203491210938}, "original": {"pred": "vertebrae,", "cond_log_prob": -6.698883056640625}, "human": [{"pred": "joints", "cond_log_prob": -3.966796875, "count": 7}, {"pred": "bones", "cond_log_prob": -5.631439208984375, "count": 5}, {"pred": "muscles", "cond_log_prob": -4.610626220703125, "count": 4}, {"pred": "sockets", "cond_log_prob": -5.456268310546875, "count": 4}, {"pred": "vertebrae", "cond_log_prob": -5.66937255859375, "count": 3}, {"pred": "feathers", "cond_log_prob": -5.468780517578125, "count": 2}, {"pred": "ways", "cond_log_prob": -4.882415771484375, "count": 2}, {"pred": "a", "cond_log_prob": -8.47576904296875, "count": 1}, {"pred": "abilities", "cond_log_prob": -8.73931884765625, "count": 1}, {"pred": "aortas", "cond_log_prob": -14.47784423828125, "count": 1}, {"pred": "backbones", "cond_log_prob": -7.909912109375, "count": 1}, {"pred": "hearts", "cond_log_prob": -7.661865234375, "count": 1}, {"pred": "hollow", "cond_log_prob": -8.07061767578125, "count": 1}, {"pred": "ligaments", "cond_log_prob": -5.925506591796875, "count": 2}, {"pred": "options", "cond_log_prob": -7.11083984375, "count": 1}, {"pred": "rivets", "cond_log_prob": -11.81488037109375, "count": 1}, {"pred": "socket", "cond_log_prob": -7.49530029296875, "count": 1}, {"pred": "such", "cond_log_prob": -8.8916015625, "count": 1}, {"pred": "talons", "cond_log_prob": -7.32586669921875, "count": 1}, {"pred": "tendons", "cond_log_prob": -8.0572509765625, "count": 1}, {"pred": "this", "cond_log_prob": -11.064697265625, "count": 1}], "ancestral_samples": [{"pred": "axial", "count": 1, "cond_log_prob": -6.68341064453125}, {"pred": "bones", "count": 1, "cond_log_prob": -5.631439208984375}, {"pred": "but", "count": 1, "cond_log_prob": -8.4119873046875}, {"pred": "flexible", "count": 2, "cond_log_prob": -7.02349853515625}, {"pred": "hands", "count": 1, "cond_log_prob": -5.076690673828125}, {"pred": "handsBut", "count": 1, "cond_log_prob": -20.7130126953125}, {"pred": "head", "count": 1, "cond_log_prob": -4.676025390625}, {"pred": "heads", "count": 14, "cond_log_prob": -3.503936767578125}, {"pred": "headsroute", "count": 1, "cond_log_prob": -26.316375732421875}, {"pred": "internal", "count": 1, "cond_log_prob": -4.92315673828125}, {"pred": "jointed", "count": 1, "cond_log_prob": -7.099639892578125}, {"pred": "joints", "count": 3, "cond_log_prob": -3.966796875}, {"pred": "legs", "count": 2, "cond_log_prob": -4.133026123046875}, {"pred": "limbs", "count": 1, "cond_log_prob": -4.573699951171875}, {"pred": "much", "count": 1, "cond_log_prob": -9.8533935546875}, {"pred": "or", "count": 1, "cond_log_prob": -6.988006591796875}, {"pred": "pairs", "count": 2, "cond_log_prob": -4.3675537109375}, {"pred": "spines", "count": 1, "cond_log_prob": -5.840118408203125}, {"pred": "tails", "count": 1, "cond_log_prob": -4.058837890625}, {"pred": "tiny", "count": 1, "cond_log_prob": -7.1248779296875}, {"pred": "which", "count": 2, "cond_log_prob": -9.974334716796875}]}, "34": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae,", "log_prob": -191.94091796875}, "original": {"pred": "the", "cond_log_prob": -4.6739349365234375}, "human": [{"pred": "which", "cond_log_prob": -0.7109375, "count": 24}, {"pred": "that", "cond_log_prob": -5.4681396484375, "count": 4}, {"pred": "a", "cond_log_prob": -3.873870849609375, "count": 2}, {"pred": "allowing", "cond_log_prob": -4.040679931640625, "count": 2}, {"pred": "and", "cond_log_prob": -2.994415283203125, "count": 2}, {"pred": "making", "cond_log_prob": -3.412017822265625, "count": 2}, {"pred": "causing", "cond_log_prob": -6.558685302734375, "count": 1}, {"pred": "increasing", "cond_log_prob": -7.334716796875, "count": 1}, {"pred": "joints", "cond_log_prob": -9.757598876953125, "count": 1}, {"pred": "study", "cond_log_prob": -12.4525146484375, "count": 1}, {"pred": "these", "cond_log_prob": -8.237152099609375, "count": 1}, {"pred": "unlike", "cond_log_prob": -6.58465576171875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.873870849609375}, {"pred": "which", "count": 38, "cond_log_prob": -0.7109375}, {"pred": "whichroute", "count": 1, "cond_log_prob": -20.103729248046875}]}, "35": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the", "log_prob": -196.61485290527344}, "original": {"pred": "small", "cond_log_prob": -5.4980926513671875}, "human": [{"pred": "vertebrae", "cond_log_prob": -4.2801971435546875, "count": 4}, {"pred": "bones", "cond_log_prob": -3.8360748291015625, "count": 3}, {"pred": "first", "cond_log_prob": -4.2274017333984375, "count": 2}, {"pred": "main", "cond_log_prob": -4.1163787841796875, "count": 2}, {"pred": "more", "cond_log_prob": -5.4142913818359375, "count": 2}, {"pred": "same", "cond_log_prob": -2.4117279052734375, "count": 2}, {"pred": "spine", "cond_log_prob": -6.0444488525390625, "count": 2}, {"pred": "----------------------------------------------------", "cond_log_prob": -21.464431762695312, "count": 1}, {"pred": "a", "cond_log_prob": -8.106796264648438, "count": 1}, {"pred": "ability", "cond_log_prob": -5.0032501220703125, "count": 1}, {"pred": "back", "cond_log_prob": -5.7074432373046875, "count": 1}, {"pred": "biggest", "cond_log_prob": -5.1495819091796875, "count": 1}, {"pred": "cervical", "cond_log_prob": -8.597946166992188, "count": 1}, {"pred": "difference", "cond_log_prob": -5.6337432861328125, "count": 1}, {"pred": "flexibility", "cond_log_prob": -7.5376129150390625, "count": 1}, {"pred": "head", "cond_log_prob": -5.2532806396484375, "count": 1}, {"pred": "human", "cond_log_prob": -6.0663909912109375, "count": 1}, {"pred": "length", "cond_log_prob": -5.4943695068359375, "count": 1}, {"pred": "lower", "cond_log_prob": -5.9876251220703125, "count": 1}, {"pred": "neck", "cond_log_prob": -6.6985931396484375, "count": 1}, {"pred": "one", "cond_log_prob": -6.3137054443359375, "count": 1}, {"pred": "owl", "cond_log_prob": -10.315597534179688, "count": 1}, {"pred": "owls", "cond_log_prob": -9.714279174804688, "count": 1}, {"pred": "part", "cond_log_prob": -4.9701690673828125, "count": 1}, {"pred": "purpose", "cond_log_prob": -8.744430541992188, "count": 1}, {"pred": "result", "cond_log_prob": -6.3396148681640625, "count": 1}, {"pred": "scientist", "cond_log_prob": -10.877426147460938, "count": 1}, {"pred": "size", "cond_log_prob": -5.2522125244140625, "count": 1}, {"pred": "smallest", "cond_log_prob": -4.8299407958984375, "count": 1}, {"pred": "top", "cond_log_prob": -5.4480438232421875, "count": 1}, {"pred": "waste", "cond_log_prob": -11.634445190429688, "count": 1}, {"pred": "which", "cond_log_prob": -9.008804321289062, "count": 1}], "ancestral_samples": [{"pred": "bones", "count": 2, "cond_log_prob": -3.8360748291015625}, {"pred": "first", "count": 1, "cond_log_prob": -4.2274017333984375}, {"pred": "joint", "count": 1, "cond_log_prob": -4.9472198486328125}, {"pred": "kind", "count": 1, "cond_log_prob": -4.4368133544921875}, {"pred": "main", "count": 1, "cond_log_prob": -4.1163787841796875}, {"pred": "most", "count": 1, "cond_log_prob": -3.4443817138671875}, {"pred": "muscle", "count": 1, "cond_log_prob": -5.6221771240234375}, {"pred": "muscles", "count": 1, "cond_log_prob": -4.1102447509765625}, {"pred": "same", "count": 26, "cond_log_prob": -2.4117279052734375}, {"pred": "sameroute", "count": 1, "cond_log_prob": -34.84422302246094}, {"pred": "shape", "count": 1, "cond_log_prob": -5.7252044677734375}, {"pred": "type", "count": 1, "cond_log_prob": -5.2334747314453125}, {"pred": "vertebrae", "count": 1, "cond_log_prob": -4.2801971435546875}, {"pred": "wing", "count": 1, "cond_log_prob": -6.1900177001953125}]}, "36": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small", "log_prob": -202.11294555664062}, "original": {"pred": "bones", "cond_log_prob": -2.1379241943359375}, "human": [{"pred": "vertebrae", "cond_log_prob": -2.7574005126953125, "count": 12}, {"pred": "bones", "cond_log_prob": -2.13824462890625, "count": 6}, {"pred": "ones", "cond_log_prob": -3.4412841796875, "count": 4}, {"pred": "one", "cond_log_prob": -5.975982666015625, "count": 3}, {"pred": "part", "cond_log_prob": -4.68939208984375, "count": 2}, {"pred": "size", "cond_log_prob": -6.856170654296875, "count": 2}, {"pred": "a", "cond_log_prob": -8.919525146484375, "count": 1}, {"pred": "amount", "cond_log_prob": -7.764404296875, "count": 1}, {"pred": "and", "cond_log_prob": -5.089813232421875, "count": 1}, {"pred": "bird", "cond_log_prob": -7.33843994140625, "count": 1}, {"pred": "connectors", "cond_log_prob": -9.184417724609375, "count": 1}, {"pred": "difference", "cond_log_prob": -7.22216796875, "count": 1}, {"pred": "disc", "cond_log_prob": -8.27313232421875, "count": 1}, {"pred": "discs", "cond_log_prob": -6.531829833984375, "count": 1}, {"pred": "necks", "cond_log_prob": -8.522735595703125, "count": 1}, {"pred": "of", "cond_log_prob": -7.1395263671875, "count": 1}, {"pred": "spine", "cond_log_prob": -7.444976806640625, "count": 1}, {"pred": "there", "cond_log_prob": -10.24981689453125, "count": 1}, {"pred": "wings", "cond_log_prob": -7.558929443359375, "count": 1}], "ancestral_samples": [{"pred": "bones", "count": 18, "cond_log_prob": -2.13824462890625}, {"pred": "bonesroute", "count": 1, "cond_log_prob": -27.7574462890625}, {"pred": "bulbous", "count": 1, "cond_log_prob": -7.7089385986328125}, {"pred": "flexible", "count": 3, "cond_log_prob": -6.261077880859375}, {"pred": "holes", "count": 1, "cond_log_prob": -5.076446533203125}, {"pred": "joint", "count": 1, "cond_log_prob": -4.514892578125}, {"pred": "muscle", "count": 1, "cond_log_prob": -4.509429931640625}, {"pred": "muscles", "count": 2, "cond_log_prob": -3.022186279296875}, {"pred": "ones", "count": 2, "cond_log_prob": -3.4412841796875}, {"pred": "part", "count": 1, "cond_log_prob": -4.68939208984375}, {"pred": "vertebrae", "count": 9, "cond_log_prob": -2.7574005126953125}]}, "37": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones", "log_prob": -204.25086975097656}, "original": {"pred": "that", "cond_log_prob": -1.0048370361328125}, "human": [{"pred": "in", "cond_log_prob": -2.92376708984375, "count": 11}, {"pred": "that", "cond_log_prob": -1.0051727294921875, "count": 7}, {"pred": "allow", "cond_log_prob": -12.393264770507812, "count": 6}, {"pred": "are", "cond_log_prob": -8.078903198242188, "count": 4}, {"pred": "help", "cond_log_prob": -10.710403442382812, "count": 2}, {"pred": "of", "cond_log_prob": -1.8457794189453125, "count": 2}, {"pred": "a", "cond_log_prob": -6.863311767578125, "count": 1}, {"pred": "and", "cond_log_prob": -4.1591644287109375, "count": 1}, {"pred": "consist", "cond_log_prob": -12.837448120117188, "count": 1}, {"pred": "enable", "cond_log_prob": -14.152389526367188, "count": 1}, {"pred": "have", "cond_log_prob": -10.868972778320312, "count": 1}, {"pred": "is", "cond_log_prob": -9.244735717773438, "count": 1}, {"pred": "make", "cond_log_prob": -11.533218383789062, "count": 1}, {"pred": "makes", "cond_log_prob": -11.37066650390625, "count": 1}, {"pred": "marked", "cond_log_prob": -9.61322021484375, "count": 1}, {"pred": "time", "cond_log_prob": -13.678253173828125, "count": 1}], "ancestral_samples": [{"pred": "in", "count": 2, "cond_log_prob": -2.92376708984375}, {"pred": "of", "count": 8, "cond_log_prob": -1.8457794189453125}, {"pred": "that", "count": 29, "cond_log_prob": -1.0051727294921875}, {"pred": "thatroute", "count": 1, "cond_log_prob": -20.307510375976562}]}, "38": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that", "log_prob": -205.25570678710938}, "original": {"pred": "make", "cond_log_prob": -2.9290771484375}, "human": [{"pred": "make", "cond_log_prob": -2.929412841796875, "count": 11}, {"pred": "are", "cond_log_prob": -3.773681640625, "count": 7}, {"pred": "connect", "cond_log_prob": -2.05816650390625, "count": 6}, {"pred": "help", "cond_log_prob": -3.02520751953125, "count": 3}, {"pred": "allow", "cond_log_prob": -2.755645751953125, "count": 2}, {"pred": "can", "cond_log_prob": -5.227447509765625, "count": 1}, {"pred": "compose", "cond_log_prob": -7.541900634765625, "count": 1}, {"pred": "form", "cond_log_prob": -3.85174560546875, "count": 1}, {"pred": "have", "cond_log_prob": -6.49639892578125, "count": 1}, {"pred": "join", "cond_log_prob": -6.88677978515625, "count": 1}, {"pred": "keep", "cond_log_prob": -4.237091064453125, "count": 1}, {"pred": "makes", "cond_log_prob": -7.402496337890625, "count": 1}, {"pred": "neck", "cond_log_prob": -12.155303955078125, "count": 1}, {"pred": "no", "cond_log_prob": -9.676849365234375, "count": 1}, {"pred": "support", "cond_log_prob": -2.541412353515625, "count": 1}, {"pred": "the", "cond_log_prob": -5.865020751953125, "count": 1}, {"pred": "this", "cond_log_prob": -10.019317626953125, "count": 1}, {"pred": "work", "cond_log_prob": -6.7913818359375, "count": 1}], "ancestral_samples": [{"pred": "allow", "count": 3, "cond_log_prob": -2.755645751953125}, {"pred": "are", "count": 3, "cond_log_prob": -3.773681640625}, {"pred": "connect", "count": 14, "cond_log_prob": -2.05816650390625}, {"pred": "connectroute", "count": 1, "cond_log_prob": -26.79034423828125}, {"pred": "form", "count": 1, "cond_log_prob": -3.85174560546875}, {"pred": "help", "count": 4, "cond_log_prob": -3.02520751953125}, {"pred": "hold", "count": 3, "cond_log_prob": -3.0819091796875}, {"pred": "keep", "count": 1, "cond_log_prob": -4.237091064453125}, {"pred": "make", "count": 5, "cond_log_prob": -2.929412841796875}, {"pred": "support", "count": 5, "cond_log_prob": -2.541412353515625}]}, "39": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make", "log_prob": -208.18478393554688}, "original": {"pred": "up", "cond_log_prob": -0.3224639892578125}, "human": [{"pred": "up", "cond_log_prob": -0.32281494140625, "count": 23}, {"pred": "the", "cond_log_prob": -3.85052490234375, "count": 7}, {"pred": "them", "cond_log_prob": -2.545257568359375, "count": 4}, {"pred": "a", "cond_log_prob": -3.551666259765625, "count": 2}, {"pred": "only", "cond_log_prob": -9.95220947265625, "count": 1}, {"pred": "their", "cond_log_prob": -2.91522216796875, "count": 1}, {"pred": "things", "cond_log_prob": -9.01336669921875, "count": 1}, {"pred": "turning", "cond_log_prob": -10.3802490234375, "count": 1}, {"pred": "way", "cond_log_prob": -10.14111328125, "count": 1}, {"pred": "you", "cond_log_prob": -8.170379638671875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -3.551666259765625}, {"pred": "them", "count": 2, "cond_log_prob": -2.545257568359375}, {"pred": "up", "count": 36, "cond_log_prob": -0.32281494140625}, {"pred": "uproute", "count": 1, "cond_log_prob": -26.357177734375}]}, "40": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up", "log_prob": -208.5072479248047}, "original": {"pred": "the", "cond_log_prob": -0.9947052001953125}, "human": [{"pred": "the", "cond_log_prob": -0.9950408935546875, "count": 31}, {"pred": "their", "cond_log_prob": -1.3382415771484375, "count": 4}, {"pred": "a", "cond_log_prob": -2.7294158935546875, "count": 2}, {"pred": "all", "cond_log_prob": -6.4453582763671875, "count": 1}, {"pred": "most", "cond_log_prob": -3.6971588134765625, "count": 1}, {"pred": "neck", "cond_log_prob": -8.817520141601562, "count": 1}, {"pred": "thing", "cond_log_prob": -14.345748901367188, "count": 1}, {"pred": "to", "cond_log_prob": -8.774703979492188, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 2, "cond_log_prob": -2.7294158935546875}, {"pred": "most", "count": 1, "cond_log_prob": -3.6971588134765625}, {"pred": "the", "count": 24, "cond_log_prob": -0.9950408935546875}, {"pred": "their", "count": 12, "cond_log_prob": -1.3382415771484375}, {"pred": "theirroute", "count": 1, "cond_log_prob": -28.389358520507812}]}, "41": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the", "log_prob": -209.501953125}, "original": {"pred": "neck", "cond_log_prob": -3.4334259033203125}, "human": [{"pred": "spine", "cond_log_prob": -2.294342041015625, "count": 16}, {"pred": "neck", "cond_log_prob": -3.43377685546875, "count": 8}, {"pred": "vertebrae", "cond_log_prob": -3.800079345703125, "count": 4}, {"pred": "back", "cond_log_prob": -3.14910888671875, "count": 3}, {"pred": "wings", "cond_log_prob": -4.64385986328125, "count": 2}, {"pred": "a", "cond_log_prob": -7.7359619140625, "count": 1}, {"pred": "accurately", "cond_log_prob": -16.336395263671875, "count": 1}, {"pred": "backbone", "cond_log_prob": -5.164459228515625, "count": 1}, {"pred": "best", "cond_log_prob": -8.742584228515625, "count": 1}, {"pred": "bones", "cond_log_prob": -4.767303466796875, "count": 1}, {"pred": "socket", "cond_log_prob": -8.365814208984375, "count": 1}, {"pred": "spinal", "cond_log_prob": -4.062652587890625, "count": 1}, {"pred": "that", "cond_log_prob": -10.10601806640625, "count": 1}, {"pred": "way", "cond_log_prob": -8.452423095703125, "count": 1}], "ancestral_samples": [{"pred": "back", "count": 5, "cond_log_prob": -3.14910888671875}, {"pred": "body", "count": 1, "cond_log_prob": -3.534271240234375}, {"pred": "bones", "count": 1, "cond_log_prob": -4.767303466796875}, {"pred": "head", "count": 1, "cond_log_prob": -2.845367431640625}, {"pred": "legs", "count": 1, "cond_log_prob": -5.017578125}, {"pred": "skeletonThe", "count": 1, "cond_log_prob": -19.09423828125}, {"pred": "spine", "count": 24, "cond_log_prob": -2.294342041015625}, {"pred": "spineBut", "count": 1, "cond_log_prob": -17.708099365234375}, {"pred": "spineroute", "count": 1, "cond_log_prob": -34.204315185546875}, {"pred": "vertebrae", "count": 3, "cond_log_prob": -3.800079345703125}, {"pred": "wingO", "count": 1, "cond_log_prob": -21.5341796875}]}, "42": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck", "log_prob": -212.9353790283203}, "original": {"pred": "and", "cond_log_prob": -1.2538909912109375}, "human": [{"pred": "and", "cond_log_prob": -1.2542572021484375, "count": 13}, {"pred": "are", "cond_log_prob": -8.407821655273438, "count": 7}, {"pred": "of", "cond_log_prob": -3.5483245849609375, "count": 4}, {"pred": "in", "cond_log_prob": -6.3282012939453125, "count": 3}, {"pred": "area", "cond_log_prob": -7.7532806396484375, "count": 2}, {"pred": "which", "cond_log_prob": -6.2822418212890625, "count": 2}, {"pred": "a", "cond_log_prob": -8.683914184570312, "count": 1}, {"pred": "bone", "cond_log_prob": -6.1841888427734375, "count": 1}, {"pred": "bones", "cond_log_prob": -4.9703521728515625, "count": 1}, {"pred": "cause", "cond_log_prob": -13.206619262695312, "count": 1}, {"pred": "guess", "cond_log_prob": -19.031295776367188, "count": 1}, {"pred": "have", "cond_log_prob": -11.229598999023438, "count": 1}, {"pred": "help", "cond_log_prob": -11.360427856445312, "count": 1}, {"pred": "is", "cond_log_prob": -9.155685424804688, "count": 1}, {"pred": "structure", "cond_log_prob": -7.3648529052734375, "count": 2}, {"pred": "while", "cond_log_prob": -7.9020843505859375, "count": 1}], "ancestral_samples": [{"pred": "In", "count": 1, "cond_log_prob": -13.554458618164062}, {"pred": "It", "count": 1, "cond_log_prob": -13.569442749023438}, {"pred": "Ow", "count": 1, "cond_log_prob": -16.752090454101562}, {"pred": "The", "count": 5, "cond_log_prob": -11.253402709960938}, {"pred": "This", "count": 1, "cond_log_prob": -13.214248657226562}, {"pred": "We", "count": 4, "cond_log_prob": -13.628158569335938}, {"pred": "and", "count": 20, "cond_log_prob": -1.2542572021484375}, {"pred": "androute", "count": 1, "cond_log_prob": -23.082839965820312}, {"pred": "so", "count": 2, "cond_log_prob": -7.4018707275390625}, {"pred": "that", "count": 3, "cond_log_prob": -3.9968719482421875}, {"pred": "which", "count": 1, "cond_log_prob": -6.2822418212890625}]}, "43": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and", "log_prob": -214.18927001953125}, "original": {"pred": "spine,", "cond_log_prob": -4.3616943359375}, "human": [{"pred": "spine", "cond_log_prob": -2.971588134765625, "count": 15}, {"pred": "back", "cond_log_prob": -2.71136474609375, "count": 9}, {"pred": "the", "cond_log_prob": -2.982177734375, "count": 8}, {"pred": "shoulders", "cond_log_prob": -2.339935302734375, "count": 2}, {"pred": "wings", "cond_log_prob": -5.57220458984375, "count": 2}, {"pred": "a", "cond_log_prob": -5.0247802734375, "count": 1}, {"pred": "head", "cond_log_prob": -3.9346923828125, "count": 2}, {"pred": "humans", "cond_log_prob": -13.44464111328125, "count": 1}, {"pred": "keeping", "cond_log_prob": -9.392486572265625, "count": 1}, {"pred": "their", "cond_log_prob": -6.959716796875, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 1, "cond_log_prob": -5.024749755859375}, {"pred": "are", "count": 1, "cond_log_prob": -4.74365234375}, {"pred": "back", "count": 9, "cond_log_prob": -2.71136474609375}, {"pred": "hands", "count": 1, "cond_log_prob": -4.74481201171875}, {"pred": "handsBut", "count": 1, "cond_log_prob": -19.269134521484375}, {"pred": "jaw", "count": 1, "cond_log_prob": -4.721405029296875}, {"pred": "legs", "count": 2, "cond_log_prob": -4.04864501953125}, {"pred": "lower", "count": 1, "cond_log_prob": -3.62091064453125}, {"pred": "neck", "count": 1, "cond_log_prob": -3.260009765625}, {"pred": "neckbone", "count": 1, "cond_log_prob": -5.887603759765625}, {"pred": "other", "count": 1, "cond_log_prob": -4.5286865234375}, {"pred": "shoulders", "count": 5, "cond_log_prob": -2.339935302734375}, {"pred": "shouldersOne", "count": 1, "cond_log_prob": -19.237579345703125}, {"pred": "shouldersThe", "count": 2, "cond_log_prob": -15.6029052734375}, {"pred": "shouldersroute", "count": 1, "cond_log_prob": -24.4027099609375}, {"pred": "spine", "count": 4, "cond_log_prob": -2.9715576171875}, {"pred": "spineThe", "count": 1, "cond_log_prob": -15.93780517578125}, {"pred": "tail", "count": 2, "cond_log_prob": -2.748870849609375}, {"pred": "the", "count": 4, "cond_log_prob": -2.982177734375}]}, "44": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and spine,", "log_prob": -218.55096435546875}, "original": {"pred": "helping", "cond_log_prob": -6.96453857421875}, "human": [{"pred": "which", "cond_log_prob": -1.4772796630859375, "count": 13}, {"pred": "and", "cond_log_prob": -1.870086669921875, "count": 4}, {"pred": "so", "cond_log_prob": -3.705902099609375, "count": 4}, {"pred": "that", "cond_log_prob": -1.402069091796875, "count": 4}, {"pred": "are", "cond_log_prob": -7.8268890380859375, "count": 2}, {"pred": "humans", "cond_log_prob": -9.198318481445312, "count": 2}, {"pred": "this", "cond_log_prob": -7.58447265625, "count": 2}, {"pred": "a", "cond_log_prob": -5.205718994140625, "count": 1}, {"pred": "allow", "cond_log_prob": -10.713058471679688, "count": 1}, {"pred": "allowing", "cond_log_prob": -5.204559326171875, "count": 2}, {"pred": "can", "cond_log_prob": -8.474472045898438, "count": 1}, {"pred": "correct", "cond_log_prob": -11.196044921875, "count": 1}, {"pred": "forsman", "cond_log_prob": -27.163818359375, "count": 1}, {"pred": "making", "cond_log_prob": -4.5985870361328125, "count": 1}, {"pred": "these", "cond_log_prob": -7.9989471435546875, "count": 1}, {"pred": "they", "cond_log_prob": -6.2006072998046875, "count": 1}, {"pred": "thus", "cond_log_prob": -7.717010498046875, "count": 1}], "ancestral_samples": [{"pred": "and", "count": 13, "cond_log_prob": -1.870086669921875}, {"pred": "that", "count": 6, "cond_log_prob": -1.402069091796875}, {"pred": "thatroute", "count": 1, "cond_log_prob": -20.54412841796875}, {"pred": "to", "count": 2, "cond_log_prob": -3.0797119140625}, {"pred": "which", "count": 18, "cond_log_prob": -1.4772796630859375}]}, "45": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and spine, helping", "log_prob": -225.5155029296875}, "original": {"pred": "them", "cond_log_prob": -0.897491455078125}, "human": [{"pred": "them", "cond_log_prob": -0.89788818359375, "count": 22}, {"pred": "the", "cond_log_prob": -3.1507568359375, "count": 13}, {"pred": "owls", "cond_log_prob": -7.3118896484375, "count": 2}, {"pred": "a", "cond_log_prob": -4.968109130859375, "count": 1}, {"pred": "movement", "cond_log_prob": -9.671539306640625, "count": 1}, {"pred": "their", "cond_log_prob": -4.625213623046875, "count": 1}, {"pred": "to", "cond_log_prob": -1.554290771484375, "count": 1}, {"pred": "words", "cond_log_prob": -11.888336181640625, "count": 1}], "ancestral_samples": [{"pred": "prevent", "count": 1, "cond_log_prob": -4.64923095703125}, {"pred": "reduce", "count": 1, "cond_log_prob": -4.83380126953125}, {"pred": "the", "count": 1, "cond_log_prob": -3.1507568359375}, {"pred": "them", "count": 23, "cond_log_prob": -0.89788818359375}, {"pred": "themroute", "count": 1, "cond_log_prob": -21.136627197265625}, {"pred": "to", "count": 13, "cond_log_prob": -1.554290771484375}]}, "46": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and spine, helping them", "log_prob": -226.41299438476562}, "original": {"pred": "achieve", "cond_log_prob": -6.3305511474609375}, "human": [{"pred": "to", "cond_log_prob": -1.75213623046875, "count": 15}, {"pred": "move", "cond_log_prob": -2.974456787109375, "count": 7}, {"pred": "twist", "cond_log_prob": -6.944488525390625, "count": 5}, {"pred": "rotate", "cond_log_prob": -5.95697021484375, "count": 2}, {"pred": "turn", "cond_log_prob": -5.775299072265625, "count": 2}, {"pred": "a", "cond_log_prob": -8.802032470703125, "count": 1}, {"pred": "and", "cond_log_prob": -6.99310302734375, "count": 1}, {"pred": "be", "cond_log_prob": -5.7120361328125, "count": 1}, {"pred": "completely", "cond_log_prob": -10.2064208984375, "count": 1}, {"pred": "erect", "cond_log_prob": -10.33697509765625, "count": 1}, {"pred": "find", "cond_log_prob": -5.640045166015625, "count": 1}, {"pred": "fly", "cond_log_prob": -5.85443115234375, "count": 1}, {"pred": "is", "cond_log_prob": -10.926727294921875, "count": 1}, {"pred": "react", "cond_log_prob": -7.28662109375, "count": 1}, {"pred": "sit", "cond_log_prob": -6.189910888671875, "count": 1}, {"pred": "support", "cond_log_prob": -6.40625, "count": 1}], "ancestral_samples": [{"pred": "form", "count": 2, "cond_log_prob": -3.796051025390625}, {"pred": "move", "count": 4, "cond_log_prob": -2.974456787109375}, {"pred": "moveroute", "count": 1, "cond_log_prob": -38.177520751953125}, {"pred": "navigate", "count": 2, "cond_log_prob": -3.57550048828125}, {"pred": "rideBut", "count": 1, "cond_log_prob": -25.042083740234375}, {"pred": "shape", "count": 1, "cond_log_prob": -5.746826171875}, {"pred": "stretch", "count": 1, "cond_log_prob": -4.89984130859375}, {"pred": "to", "count": 28, "cond_log_prob": -1.75213623046875}]}, "47": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and spine, helping them achieve", "log_prob": -232.74354553222656}, "original": {"pred": "a", "cond_log_prob": -2.2860565185546875}, "human": [{"pred": "more", "cond_log_prob": -3.5058135986328125, "count": 10}, {"pred": "a", "cond_log_prob": -2.2864532470703125, "count": 6}, {"pred": "the", "cond_log_prob": -2.5342254638671875, "count": 5}, {"pred": "greater", "cond_log_prob": -4.1544952392578125, "count": 4}, {"pred": "flexibility", "cond_log_prob": -4.3644866943359375, "count": 3}, {"pred": "their", "cond_log_prob": -2.6010894775390625, "count": 3}, {"pred": "maximum", "cond_log_prob": -4.2898101806640625, "count": 2}, {"pred": "balance", "cond_log_prob": -1.6550445556640625, "count": 1}, {"pred": "extra", "cond_log_prob": -7.4990386962890625, "count": 1}, {"pred": "further", "cond_log_prob": -9.543533325195312, "count": 1}, {"pred": "is", "cond_log_prob": -9.998153686523438, "count": 1}, {"pred": "mobility", "cond_log_prob": -6.0153045654296875, "count": 1}, {"pred": "monumental", "cond_log_prob": -13.609542846679688, "count": 1}, {"pred": "rotation", "cond_log_prob": -9.492111206054688, "count": 1}, {"pred": "stability", "cond_log_prob": -4.4926910400390625, "count": 1}, {"pred": "structure", "cond_log_prob": -9.310012817382812, "count": 1}], "ancestral_samples": [{"pred": "a", "count": 10, "cond_log_prob": -2.2864532470703125}, {"pred": "balance", "count": 19, "cond_log_prob": -1.6550445556640625}, {"pred": "balanceAs", "count": 1, "cond_log_prob": -19.135147094726562}, {"pred": "balanceBut", "count": 1, "cond_log_prob": -19.161483764648438}, {"pred": "balanceThe", "count": 3, "cond_log_prob": -17.609176635742188}, {"pred": "balanceroute", "count": 1, "cond_log_prob": -36.04362487792969}, {"pred": "the", "count": 2, "cond_log_prob": -2.5342254638671875}, {"pred": "their", "count": 3, "cond_log_prob": -2.6010894775390625}]}, "48": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and spine, helping them achieve a", "log_prob": -235.02960205078125}, "original": {"pred": "wide", "cond_log_prob": -4.46759033203125}, "human": [{"pred": "greater", "cond_log_prob": -4.017181396484375, "count": 7}, {"pred": "more", "cond_log_prob": -1.8175048828125, "count": 5}, {"pred": "higher", "cond_log_prob": -3.448333740234375, "count": 4}, {"pred": "wider", "cond_log_prob": -5.782745361328125, "count": 4}, {"pred": "better", "cond_log_prob": -3.96453857421875, "count": 3}, {"pred": "a", "cond_log_prob": -8.841278076171875, "count": 2}, {"pred": "flexibility", "cond_log_prob": -8.3392333984375, "count": 2}, {"pred": "flexible", "cond_log_prob": -5.07403564453125, "count": 2}, {"pred": "balanced", "cond_log_prob": -2.766448974609375, "count": 1}, {"pred": "complete", "cond_log_prob": -5.6263427734375, "count": 1}, {"pred": "different", "cond_log_prob": -5.03326416015625, "count": 1}, {"pred": "full", "cond_log_prob": -4.94232177734375, "count": 1}, {"pred": "larger", "cond_log_prob": -5.216552734375, "count": 1}, {"pred": "level", "cond_log_prob": -5.306549072265625, "count": 1}, {"pred": "lighter", "cond_log_prob": -8.631378173828125, "count": 1}, {"pred": "new", "cond_log_prob": -6.465301513671875, "count": 1}, {"pred": "stance", "cond_log_prob": -8.8231201171875, "count": 1}, {"pred": "straight", "cond_log_prob": -6.049835205078125, "count": 1}, {"pred": "twist", "cond_log_prob": -10.22601318359375, "count": 1}, {"pred": "variety", "cond_log_prob": -4.618804931640625, "count": 1}, {"pred": "very", "cond_log_prob": -5.5936279296875, "count": 1}], "ancestral_samples": [{"pred": "balance", "count": 2, "cond_log_prob": -2.950103759765625}, {"pred": "balanced", "count": 3, "cond_log_prob": -2.766448974609375}, {"pred": "form", "count": 1, "cond_log_prob": -5.4769287109375}, {"pred": "greater", "count": 1, "cond_log_prob": -4.017181396484375}, {"pred": "more", "count": 30, "cond_log_prob": -1.8175048828125}, {"pred": "moreroute", "count": 1, "cond_log_prob": -24.5595703125}, {"pred": "precise", "count": 1, "cond_log_prob": -5.34735107421875}, {"pred": "shape", "count": 1, "cond_log_prob": -5.682586669921875}]}, "49": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and spine, helping them achieve a wide", "log_prob": -239.4971923828125}, "original": {"pred": "range", "cond_log_prob": -0.2744140625}, "human": [{"pred": "range", "cond_log_prob": -0.27484130859375, "count": 26}, {"pred": "rotation", "cond_log_prob": -10.027130126953125, "count": 3}, {"pred": "variety", "cond_log_prob": -2.593353271484375, "count": 4}, {"pred": "array", "cond_log_prob": -5.046478271484375, "count": 2}, {"pred": "a", "cond_log_prob": -10.755584716796875, "count": 1}, {"pred": "angle", "cond_log_prob": -6.200592041015625, "count": 1}, {"pred": "level", "cond_log_prob": -9.169830322265625, "count": 1}, {"pred": "open", "cond_log_prob": -6.84832763671875, "count": 1}, {"pred": "stance", "cond_log_prob": -6.690093994140625, "count": 1}, {"pred": "view", "cond_log_prob": -6.68939208984375, "count": 1}, {"pred": "waste", "cond_log_prob": -17.66986083984375, "count": 1}], "ancestral_samples": [{"pred": "range", "count": 39, "cond_log_prob": -0.27484130859375}, {"pred": "rangeroute", "count": 1, "cond_log_prob": -28.9737548828125}]}, "50": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and spine, helping them achieve a wide range", "log_prob": -239.7716064453125}, "original": {"pred": "of", "cond_log_prob": -0.041290283203125}, "human": [{"pred": "of", "cond_log_prob": -0.041717529296875, "count": 39}, {"pred": "a", "cond_log_prob": -10.805877685546875, "count": 1}, {"pred": "and", "cond_log_prob": -7.293243408203125, "count": 1}, {"pred": "to", "cond_log_prob": -8.463104248046875, "count": 1}], "ancestral_samples": [{"pred": "We", "count": 1, "cond_log_prob": -16.96685791015625}, {"pred": "of", "count": 38, "cond_log_prob": -0.041717529296875}, {"pred": "ofroute", "count": 1, "cond_log_prob": -24.684295654296875}]}, "51": {"context": {"text": "Owls are more flexible than humans because a bird's head is only connected by one socket pivot. People have two, which limits our ability to twist, Forsman added. Owls also have multiple vertebrae, the small bones that make up the neck and spine, helping them achieve a wide range of", "log_prob": -239.81289672851562}, "original": {"pred": "motion.", "cond_log_prob": -2.915557861328125}, "human": [{"pred": "motion", "cond_log_prob": -2.418121337890625, "count": 16}, {"pred": "movement", "cond_log_prob": -3.028564453125, "count": 10}, {"pred": "a", "cond_log_prob": -7.97369384765625, "count": 2}, {"pred": "flexibility", "cond_log_prob": -5.00128173828125, "count": 2}, {"pred": "movements", "cond_log_prob": -4.09710693359375, "count": 3}, {"pred": "sight", "cond_log_prob": -8.701171875, "count": 2}, {"pred": "abilities", "cond_log_prob": -4.849945068359375, "count": 1}, {"pred": "mobility", "cond_log_prob": -3.724884033203125, "count": 1}, {"pred": "movememnt", "cond_log_prob": -30.100067138671875, "count": 1}, {"pred": "positions", "cond_log_prob": -5.092926025390625, "count": 1}, {"pred": "time", "cond_log_prob": -9.993682861328125, "count": 1}, {"pred": "turning", "cond_log_prob": -10.631134033203125, "count": 1}, {"pred": "vision", "cond_log_prob": -4.834259033203125, "count": 1}], "ancestral_samples": [{"pred": "facial", "count": 1, "cond_log_prob": -4.927459716796875}, {"pred": "flight", "count": 1, "cond_log_prob": -3.08306884765625}, {"pred": "functions", "count": 1, "cond_log_prob": -4.268585205078125}, {"pred": "heights", "count": 2, "cond_log_prob": -3.147247314453125}, {"pred": "joint", "count": 2, "cond_log_prob": -3.62750244140625}, {"pred": "locomotion", "count": 1, "cond_log_prob": -4.18634033203125}, {"pred": "mobilityO", "count": 1, "cond_log_prob": -22.456512451171875}, {"pred": "motion", "count": 20, "cond_log_prob": -2.418121337890625}, {"pred": "motionOne", "count": 1, "cond_log_prob": -21.571441650390625}, {"pred": "motionThe", "count": 3, "cond_log_prob": -18.20648193359375}, {"pred": "motionroute", "count": 1, "cond_log_prob": -25.231414794921875}, {"pred": "movement", "count": 2, "cond_log_prob": -3.028564453125}, {"pred": "movementAs", "count": 1, "cond_log_prob": -20.061309814453125}, {"pred": "movementBut", "count": 1, "cond_log_prob": -20.220489501953125}, {"pred": "movementThe", "count": 2, "cond_log_prob": -19.390899658203125}]}}}